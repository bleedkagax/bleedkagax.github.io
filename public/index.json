[{"content":"åŸºæœ¬ä¿¡æ¯ Fitness æ¦‚å†µ è®­ç»ƒæ—¶é•¿2å¹´ ä½“é‡ï¼š63kg å§æ¨ï¼š90kg ç¡¬æ‹‰ï¼š150kg æ·±è¹²ï¼š130kg è‡ªé‡å¼•ä½“å‘ä¸Šï¼š25+ä¸ª è´Ÿé‡25Kgå¼•ä½“å‘ä¸Šï¼š10+ä¸ª\nå¾®ä¹ æƒ¯ é™ä½å®æ–½æˆæœ¬ï¼Œæ­£åé¦ˆ\nä¸ªäººé”»ç‚¼ä¹ æƒ¯å…»æˆï¼š ä»èµ·æ­¥æ¯å¤© 5 ä¸ªå¼•ä½“å‘ä¸Šå¼€å§‹ åˆ°æ¯å¤© 10 ä¸ªå¼•ä½“å‘ä¸Š åˆ°æ¯å¤© 50 ä¸ªå¼•ä½“å‘ä¸Š åˆ°æ¯å¤© 100 ä¸ªå¼•ä½“å‘ä¸Š\nä»å¾’æ‰‹è®­ç»ƒåˆ°å¥èº«æˆ¿ æ–°æ‰‹ä¸Šè·¯ï¼Œä»è§‚çœ‹å¥èº«è§†é¢‘å¼€å§‹ï¼Œç…§çŒ«ç”»è™\næ¨èå¥èº«åšä¸» çº¯å¹²è´§ç‰ˆï¼š\nå®æˆ˜ç±», è¯¦ç»†åŠ¨ä½œæ•™ç¨‹ï¼šå‡¯åœ£ç‹ https://m.bilibili.com/space/2100737396 æ—¥å¸¸ç±», å¥èº«ç»éªŒåˆ†äº«ï¼šçƒ§æ¯ä¸€åˆ‡å°±æ˜¯ç¾ https://m.bilibili.com/space/1024129080 ç†è®ºç±», å¥èº«çŸ¥è¯†ç§‘æ™®ï¼šä»°æœ›å°¾è¿¹äº‘ https://m.bilibili.com/space/1879203169 è™æ‰‘è¯„ä»·ï¼š è®­ç»ƒæ€è·¯ åˆ†åŒ–è®­ç»ƒ äº”åˆ†åŒ–ï¼šèƒ¸èƒŒè‚©è…¿è‡‚ï¼Œä»£è°¢å‹åŠ›å¤§ï¼Œæ¢å¤æ…¢ï¼Œä¸é€‚åˆæ–°æ‰‹ ä¸‰åˆ†åŒ–ï¼šèƒ¸èƒŒè…¿ï¼ˆæ¨æ‹‰è¹²ï¼‰ï¼Œä»£è°¢å‹åŠ›å°ï¼Œæ¢å¤å¿«ï¼Œé€‚åˆæ–°æ‰‹ å››åˆ†åŒ–ï¼šèƒ¸è‚©èƒŒè…¿ + æ‰‹è‡‚/è…¹éƒ¨ï¼Œä»£è°¢å‹åŠ›å°ï¼Œæ¢å¤å¿«ï¼Œå®¹é”™æ€§é«˜\nè´¨é‡ã€æ•°é‡ã€é‡é‡ æ•°é‡ x é‡é‡ = è®­ç»ƒå®¹é‡ è¿½æ±‚è´¨é‡ï¼Œæ”¾ä¸‹è™šè£å¿ƒï¼Œæ¯”å¦‚å§æ¨è§¦èƒ¸ã€å¼•ä½“å‘ä¸Šè‚©è†€ä¸‹å›æ—‹ ç®€å•çš„åŠ¨ä½œåšé«˜çº§\nè¡¥å‰‚ è¾¨åˆ«æ™ºå•†ç¨\nè›‹ç™½ç²‰ï¼šå¢è‚Œ è‚Œé…¸ï¼šå¢åŠ› å‡è„‚ 65kg -\u0026gt; 70kg æ–°æ‰‹ç¦åˆ©æœŸï¼ˆæ–°æ‰‹è†¨èƒ€æœŸï¼‰ï¼šä¸åšé¥®é£Ÿï¼Œè„‚åŒ…è‚Œ 70kg -\u0026gt; 57kg å‡è„‚ï¼šé¥®é£Ÿ + æ— æ°§ + æœ‰æ°§\nä½“é‡æœ€è½»æ—¶å€™ç…§ç‰‡ï¼š\nä½“è„‚ç‡ï¼š11%\n57kg -\u0026gt; 63kg å¢è‚Œï¼šé¥®é£Ÿ + æ— æ°§\nå…³é”®å› ç´  ç¡çœ ï¼Œé¥®é£Ÿï¼Œè®­ç»ƒ\nEnglish å¯ç†è§£æ€§è¾“å…¥ Comprehensible Input N+1\nhttps://m.bilibili.com/video/BV1aD4y127GE\nè¾“å…¥ï¼š é˜…è¯» å¬å†™\nè¾“å‡ºï¼š å£è¯­ å†™ä½œ\né˜…è¯»ç¯‡ è¯æ±‡ç§¯ç´¯ å¢¨å¢¨èƒŒå•è¯ =\u0026gt; AnKi\nå¢¨å¢¨èƒŒå•è¯ï¼šç´¯è®¡ä½¿ç”¨ 300+ å°æ—¶ï¼Œè®°å¿† 15000+ å•è¯è¯ç»„ï¼ˆé›…æ€è¯æ±‡ï¼‰ Anki: ç´¯è®¡ä½¿ç”¨ 200+ å°æ—¶ï¼Œè®°å¿† 13000+ å•è¯è¯ç»„ï¼ˆé›…æ€è¯æ±‡ï¼‰\nAnKi-SM2ï¼ˆSuperMemo 2ï¼‰ é—´éš”é‡å¤è®°å¿†ç®—æ³• =\u0026gt; FSRSï¼ˆFree Spaced Repetition Schedulerï¼‰ç®—æ³•\nJunyao Ye\nå¦‚ä½•æ°¸ä¹…çš„è®°ä½ä¸€ä¸ªå•è¯ï¼Ÿ æµ·é‡é˜…è¯»é‡ + åˆ»æ„ç»ƒä¹ \né€‰æ‹©è‡ªå·±æ„Ÿå…´è¶£å¹¶ä¸”å¯ç†è§£çš„ææ–™ï¼Œæµ·é‡é˜…è¯»\nmedium https://medium.com/\nå¬åŠ›ç¯‡ ç²¾å¬ + æ³›å¬\nç²¾å¬ å¬å†™\nDaily Dictation https://dailydictation.com/\næ³›å¬ Podcast é€šå‹¤è·¯ä¸Šå¬ï¼Œå¥èº«æ—¶å€™å¬\nå£è¯­ç¯‡ AI å£è¯­æ•™ç»ƒ ä»˜è´¹ç‰ˆï¼š ChatGPTé€šè¯æ¨¡å¼\nå…è´¹ç‰ˆï¼š Pi https://pi.ai/discover\nå£è¯­è€å¸ˆ æ€§ä»·æ¯”ç‰ˆï¼š pdd è²æ•™\né«˜ä»·ç‰ˆï¼š Cambly æ¬§ç¾å¤–æ•™\nå£è¯­ç»ƒä¹  Elsa Speak\nAI è¯­éŸ³æŠ€æœ¯ï¼Œå‘éŸ³çº æ­£ ä¸ªæ€§åŒ–å­¦ä¹ ï¼Œå¤§é‡çš„è¯¾ç¨‹ å®ç”¨æ€§å¼ºï¼Œæ—¥å¸¸å¯¹è¯åœºæ™¯ï¼ŒèŒåœºè‹±è¯­è®­ç»ƒ\nå†™ä½œç¯‡ ç§¯ç´¯è‡ªå·±çš„è¯­æ–™åº“\nTips æ‰“é€ å…¨è‹±æ–‡ç¯å¢ƒ æœ€ç®€å•çš„ä¸€æ­¥ï¼šæŠŠæ‰‹æœºã€ç”µè„‘ç³»ç»Ÿè¯­è¨€è®¾ç½®æˆè‹±æ–‡\nå–„ç”¨è¯å…¸ï¼Œå¤šçœ‹è‹±æ–‡è§£é‡Šï¼Œç”¨è‹±æ–‡è§£é‡Šè‹±æ–‡\nå°è¯•å°†è‡ªå·±çš„å·¥ä½œå­¦ä¹ ç”Ÿæ´»ä¸­åˆ‡æ¢æˆè‹±æ–‡ç¯å¢ƒ\nçŸ¥ä¹ =\u0026gt; Reddit\næŠŠè‹±æ–‡å½“æˆå·¥å…· æœ€å¥½çš„æƒ…å†µä¸‹ä¸æ˜¯å­¦ä¹ è‹±æ–‡ï¼Œè€Œæ˜¯ä½¿ç”¨è‹±æ–‡å­¦ä¹ è‡ªå·±å–œæ¬¢çš„ä¸œè¥¿\nAI \u0026amp;\u0026amp; Tool cursor .cursorrules .cursorrulesÂ is a powerful feature in Cursor AI that allows developers to define project-specific instructions for the AI.\nhttps://github.com/PatrickJS/awesome-cursorrules https://github.com/pontusab/cursor.directory\nå¼€æºæ›¿ä»£å“ void https://voideditor.com/\nllm notebook https://notebooklm.google/\næ€»ç»“ youtube è§†é¢‘ï¼Œå¦‚æŠ€æœ¯æ•™ç¨‹ =\u0026gt; podcast\nobsidian self learning/long-termlism pku cs self learning lixiaolai https://github.com/ZuodaoTech/everyone-can-use-english https://github.com/selfteaching/the-craft-of-selfteaching\nlipu\nproduct: quizAI use experiences/toast å®Œå–„çŸ¥è¯†ç‚¹ä½“ç³»ï¼Œ road map ä¸ªæ€§åŒ–æ¨è å¤ä¹ æœºåˆ¶ï¼ˆanki / duolingguoï¼‰\nQ\u0026amp;A ","permalink":"https://bleedkagax.github.io/post/share_11_14/","summary":"\u003ch1 id=\"åŸºæœ¬ä¿¡æ¯\"\u003eåŸºæœ¬ä¿¡æ¯\u003c/h1\u003e\n\u003ch1 id=\"fitness\"\u003eFitness\u003c/h1\u003e\n\u003ch2 id=\"æ¦‚å†µ\"\u003eæ¦‚å†µ\u003c/h2\u003e\n\u003cp\u003eè®­ç»ƒæ—¶é•¿2å¹´\nä½“é‡ï¼š63kg\nå§æ¨ï¼š90kg\nç¡¬æ‹‰ï¼š150kg\næ·±è¹²ï¼š130kg\nè‡ªé‡å¼•ä½“å‘ä¸Šï¼š25+ä¸ª\nè´Ÿé‡25Kgå¼•ä½“å‘ä¸Šï¼š10+ä¸ª\u003c/p\u003e\n\u003ch2 id=\"å¾®ä¹ æƒ¯\"\u003eå¾®ä¹ æƒ¯\u003c/h2\u003e\n\u003cp\u003eé™ä½å®æ–½æˆæœ¬ï¼Œæ­£åé¦ˆ\u003c/p\u003e\n\u003cp\u003eä¸ªäººé”»ç‚¼ä¹ æƒ¯å…»æˆï¼š\nä»èµ·æ­¥æ¯å¤© 5 ä¸ªå¼•ä½“å‘ä¸Šå¼€å§‹\nåˆ°æ¯å¤© 10 ä¸ªå¼•ä½“å‘ä¸Š\nåˆ°æ¯å¤© 50 ä¸ªå¼•ä½“å‘ä¸Š\nåˆ°æ¯å¤© 100 ä¸ªå¼•ä½“å‘ä¸Š\u003c/p\u003e\n\u003ch2 id=\"ä»å¾’æ‰‹è®­ç»ƒåˆ°å¥èº«æˆ¿\"\u003eä»å¾’æ‰‹è®­ç»ƒåˆ°å¥èº«æˆ¿\u003c/h2\u003e\n\u003cp\u003eæ–°æ‰‹ä¸Šè·¯ï¼Œä»è§‚çœ‹å¥èº«è§†é¢‘å¼€å§‹ï¼Œç…§çŒ«ç”»è™\u003c/p\u003e\n\u003ch3 id=\"æ¨èå¥èº«åšä¸»\"\u003eæ¨èå¥èº«åšä¸»\u003c/h3\u003e\n\u003cp\u003eçº¯å¹²è´§ç‰ˆï¼š\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eå®æˆ˜ç±», è¯¦ç»†åŠ¨ä½œæ•™ç¨‹ï¼šå‡¯åœ£ç‹ \u003ca href=\"https://m.bilibili.com/space/2100737396\"\u003ehttps://m.bilibili.com/space/2100737396\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eæ—¥å¸¸ç±», å¥èº«ç»éªŒåˆ†äº«ï¼šçƒ§æ¯ä¸€åˆ‡å°±æ˜¯ç¾ \u003ca href=\"https://m.bilibili.com/space/1024129080\"\u003ehttps://m.bilibili.com/space/1024129080\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eç†è®ºç±», å¥èº«çŸ¥è¯†ç§‘æ™®ï¼šä»°æœ›å°¾è¿¹äº‘ \u003ca href=\"https://m.bilibili.com/space/1879203169\"\u003ehttps://m.bilibili.com/space/1879203169\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eè™æ‰‘è¯„ä»·ï¼š\n\u003cimg loading=\"lazy\" src=\"/img/share_11_14.jpg\" alt=\"|400\"  /\u003e\n\n\u003cimg loading=\"lazy\" src=\"/img/share_11_14-1.jpg\" alt=\"|400\"  /\u003e\n\u003c/p\u003e\n\u003ch3 id=\"è®­ç»ƒæ€è·¯\"\u003eè®­ç»ƒæ€è·¯\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eåˆ†åŒ–è®­ç»ƒ\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eäº”åˆ†åŒ–ï¼šèƒ¸èƒŒè‚©è…¿è‡‚ï¼Œä»£è°¢å‹åŠ›å¤§ï¼Œæ¢å¤æ…¢ï¼Œä¸é€‚åˆæ–°æ‰‹\nä¸‰åˆ†åŒ–ï¼šèƒ¸èƒŒè…¿ï¼ˆæ¨æ‹‰è¹²ï¼‰ï¼Œä»£è°¢å‹åŠ›å°ï¼Œæ¢å¤å¿«ï¼Œé€‚åˆæ–°æ‰‹\nå››åˆ†åŒ–ï¼šèƒ¸è‚©èƒŒè…¿ + æ‰‹è‡‚/è…¹éƒ¨ï¼Œä»£è°¢å‹åŠ›å°ï¼Œæ¢å¤å¿«ï¼Œå®¹é”™æ€§é«˜\u003c/p\u003e","title":"share"},{"content":"share_11_14 Basic Info Fitness è®­ç»ƒæ¦‚å†µ å¾®ä¹ æƒ¯ ä»å¾’æ‰‹è®­ç»ƒåˆ°å¥èº«æˆ¿ æ–°æ‰‹ä¸Šè·¯ï¼Œä»è§‚çœ‹å¥èº«è§†é¢‘å¼€å§‹ï¼Œ\nå®æˆ˜ç±», è¯¦ç»†åŠ¨ä½œæ•™ç¨‹ï¼šå‡¯åœ£ç‹ https://m.bilibili.com/space/2100737396 æ—¥å¸¸ç±», å¥èº«ç»éªŒåˆ†äº«ï¼šçƒ§æ¯ä¸€åˆ‡å°±æ˜¯ç¾ https://m.bilibili.com/space/1024129080 ç†è®ºç±», å¥èº«çŸ¥è¯†ç§‘æ™®ï¼šä»°æœ›å°¾è¿¹äº‘ https://m.bilibili.com/space/1879203169 è®­ç»ƒæ€è·¯ æ•°é‡ x é‡é‡ = è®­ç»ƒå®¹é‡ è¿½æ±‚è´¨é‡ï¼Œæ”¾ä¸‹è™šè£å¿ƒï¼Œæ¯”å¦‚å§æ¨è§¦èƒ¸ã€å¼•ä½“å‘ä¸Šè‚©è†€ä¸‹å›æ—‹ ç®€å•çš„åŠ¨ä½œåšé«˜çº§\nè¡¥å‰‚ è¾¨åˆ«æ™ºå•†ç¨\nå‡è„‚å¢è‚Œ ä½“è„‚ç‡11%ï¼š\nå…³é”®å› ç´  English è¿™ä¸ªä¸–ç•Œä¸Š90%çš„ä¿¡æ¯éƒ½æ˜¯ written in English çš„ï¼Œæ‰€ä»¥å­¦å¥½è‹±æ–‡ç¡®å®å¯¹äººå¤§æœ‰è£¨ç›Šã€‚\nå¯ç†è§£æ€§è¾“å…¥ å—åŠ å·å¤§å­¦çš„è£ä¼‘æ•™æˆæ–¯è’‚èŠ¬â€¢å…‹æ‹‰ç”³ï¼ˆStephen D.Krashenï¼‰åšå£«çš„å‡è¯´ç†è®º\nç½—è‚–å°¼ https://m.bilibili.com/video/BV1aD4y127GE\né˜…è¯»ç¯‡ è¯æ±‡ç§¯ç´¯ å¦‚ä½•æ°¸ä¹…çš„è®°ä½ä¸€ä¸ªå•è¯ï¼Ÿ æ¨è medium https://medium.com/\nå¬åŠ›ç¯‡ ç²¾å¬ å¬å†™\nDaily Dictation https://dailydictation.com/\næ³›å¬ Podcast é€šå‹¤è·¯ä¸Šå¬ï¼Œå¥èº«æ—¶å€™å¬\nå£è¯­ç¯‡ AI å£è¯­æ•™ç»ƒ ä»˜è´¹ç‰ˆï¼š ChatGPTé€šè¯æ¨¡å¼\nå…è´¹ç‰ˆï¼š Pi https://pi.ai/discover\nçœŸäººå£è¯­è€å¸ˆ æ€§ä»·æ¯”ç‰ˆï¼š pdd è²æ•™\né«˜ä»·ç‰ˆï¼š Cambly æ¬§ç¾å¤–æ•™\nå£è¯­ç»ƒä¹  Elsa Speak\nAI è¯­éŸ³æŠ€æœ¯ï¼Œå‘éŸ³çº æ­£ ä¸ªæ€§åŒ–å­¦ä¹ ï¼Œå¤§é‡çš„è¯¾ç¨‹ å®ç”¨æ€§å¼ºï¼Œæ—¥å¸¸å¯¹è¯åœºæ™¯ï¼ŒèŒåœºè‹±è¯­è®­ç»ƒ\nå†™ä½œç¯‡ ç§¯ç´¯è‡ªå·±çš„è¯­æ–™åº“\nå¥ä¹éƒ¨ï¼šhttps://julebu.co\næ”¹å˜ è§‚çœ‹çº¯è‹±æ–‡å­—å¹•çš„Youtubeã€Netflix è§†é¢‘ï¼Œ æ— å­—å¹•ç†è§£è®¡ç®—æœºç§‘å­¦é¢†åŸŸå†…çš„è‹±æ–‡è§†é¢‘ï¼Œ é˜…è¯»è‹±æ–‡ç‰ˆæŠ€æœ¯åšå®¢ã€ä¹¦ç±ã€‚\né›…æ€é˜…è¯»å‡åˆ†ï¼š8.0 å¬åŠ›å‡åˆ†ï¼š7.0\nTips æŠŠè‹±æ–‡å½“æˆå·¥å…·ï¼š æœ€å¥½çš„æƒ…å†µä¸‹ä¸æ˜¯å­¦ä¹ è‹±æ–‡ï¼Œè€Œæ˜¯ä½¿ç”¨è‹±æ–‡å­¦ä¹ è‡ªå·±å–œæ¬¢çš„ä¸œè¥¿ã€‚\nN+1 åŸåˆ™ å­¦è‹±è¯­å’Œå¥èº«ä¸­éƒ½éšå«ä¸€ç§â€œéš¾åº¦åˆ†çº§â€çš„æ–¹æ³•ã€‚æŠŠå½“å‰è‡ªèº«èƒ½å¤Ÿåšåˆ°çš„ç¨‹åº¦å†åŠ ä¸€ç‚¹ç‚¹éš¾åº¦ï¼Œä½œä¸ºç›®æ ‡ï¼ˆN+1ï¼Œè¸®è¸®è„šèƒ½å¤Ÿåˆ°ï¼‰ã€‚\næ¯”å¦‚å­¦è‹±è¯­ä¸­çš„â€œåšå¤§é‡æœ‰è¶£çš„å¯ç†è§£è¾“å…¥â€ï¼Œå¯¹åº”åˆ°å¥èº«ä¸Šå¯ä»¥å«â€œåšå¤§é‡æœ‰è¶£çš„å¯æ‰¿å—è®­ç»ƒâ€ï¼š\nä¸å½“å‰æ°´å¹³ç›¸åŒ¹é…çš„é‚£ä¸ªéš¾åº¦ï¼Œå°±åƒä¸€ä¸ªé’©å­ï¼ˆhookï¼‰ã€‚æ‰¾åˆ°é‚£ä¸ªhookï¼Œèµ°å‘æ›´ç²¾è¿›çš„åœ°æ–¹ã€‚\nç»†æƒ³ä¸€ä¸‹ï¼Œå…¶å®æˆ‘ä»¬ä»å°å­¦åˆ°å¤§å­¦çš„è¯¾ç¨‹åˆ†çº§ï¼Œæœ¬èº«å°±æ˜¯åœ¨å¸®æˆ‘ä»¬åšéš¾åº¦çš„ã€Œåˆ†çº§ã€ã€‚\nè”æƒ³ï¼šé‡åˆ°é—®é¢˜æ—¶ï¼Œå°è¯•ã€Œç›®æ ‡æ‹†è§£ã€ã€ã€Œåˆ†ç±»ã€ï¼Œæ‰¾åˆ°åˆé€‚çš„ N+1ã€‚\nAI \u0026amp;\u0026amp; Tool cursor .cursorrules .cursorrulesÂ is a powerful feature in Cursor AI that allows developers to define project-specific instructions for the AI.\nhttps://github.com/PatrickJS/awesome-cursorrules https://github.com/pontusab/cursor.directory\nä½¿ç”¨æŠ€å·§ å¯è§†åŒ– Explain *** ï¼Œcould you visualize itï¼Ÿ è¾“å‡ºä¸º Mermaid\nå¼€æºæ›¿ä»£å“ void https://voideditor.com/ github: github.com/voideditor/void\nç‰¹ç‚¹ï¼š\næ–‡ä»¶ç³»ç»Ÿæ„ŸçŸ¥ï¼šèƒ½å¤Ÿç†è§£å’Œå›ç­”æ•´ä¸ªä»£ç åº“çš„é—®é¢˜ï¼Œè‡ªåŠ¨æ„å»ºæ–‡ä»¶ç´¢å¼•ï¼Œæ— éœ€æ‰‹åŠ¨é€‰æ‹©ç›¸å…³æ–‡ä»¶ æŸ¥çœ‹å’Œç¼–è¾‘åº•å±‚æç¤ºï¼šå¯ä»¥æŸ¥çœ‹å’Œç¼–è¾‘èŠå¤©è®°å½•ä¸­çš„æ‰€æœ‰æç¤ºï¼Œå¤§å¤šæ•°é—­æºå·¥å…·æ²¡æœ‰è¿™ä¸ªåŠŸèƒ½ å¿«é€Ÿç¼–è¾‘ï¼šå³ä½¿æ–‡ä»¶éå¸¸é•¿ï¼ŒVoidä¹Ÿå¯ä»¥ç«‹å³åº”ç”¨æ›´æ”¹ï¼Œå®ƒä¼šæç¤ºAI ä»¥äººç±»çš„æ–¹å¼è¿›è¡Œæ›´æ”¹ï¼Œè€Œéé‡å†™æ•´ä¸ªæ–‡ä»¶ llm notebook https://notebooklm.google/\næ€»ç»“ youtube è§†é¢‘ï¼Œå¦‚æŠ€æœ¯æ•™ç¨‹ =\u0026gt; podcastã€note\nSelf learning/long-termlism pku cs self learning https://github.com/PKUFlyingPig/cs-self-learning\nlixiaolai https://github.com/ZuodaoTech/everyone-can-use-english https://github.com/selfteaching/the-craft-of-selfteaching\nTeach Yourself a Foreign Language https://sajforbes.nz/languageguide/introduction/\nlipu https://github.com/byoungd/English-level-up-tips\nHowToLiveLonger https://github.com/geekan/HowToLiveLonger\nQuizAI å®Œå–„çŸ¥è¯†ç‚¹ä½“ç³»ï¼Œ road map ä¸ªæ€§åŒ–æ¨è å¤ä¹ æœºåˆ¶ï¼ˆanki / duolingguoï¼‰ â€œä½œä¸ºä¸€åå®¶åº­æ•™å¸ˆï¼Œæˆ‘æƒ³åˆ†äº«ä¸€ä¸‹æˆ‘å¯¹èœœèœ‚è¯•å·çš„ä½¿ç”¨ä½“éªŒã€‚\næˆ‘åœ¨å­¦ç”Ÿæ—¶ä»£å°±å¾ˆæ³¨é‡é”™é¢˜çš„æ•´ç†ï¼Œæˆ‘è§‰å¾—åšè¿‡çš„é”™é¢˜éƒ½æ˜¯å®è—ï¼Œæˆ‘å¯ä»¥çŸ¥é“è‡ªå·±å“ªäº›çŸ¥è¯†ç‚¹æ¯”è¾ƒè–„å¼±ï¼Œå“ªäº›é¢˜å‹ä¸ç†Ÿæ‚‰ï¼Œé’ˆå¯¹æ€§åœ°ç»ƒä¹ æé«˜ã€‚é‚£ä¸ªæ—¶å€™æ•´ç†é”™é¢˜çš„æ–¹å¼æ˜¯æŠ„é¢˜æˆ–è€…æŠŠé¢˜ç›®å‰ªä¸‹æ¥ï¼Œæ²¡æœ‰å¥½çš„ç”Ÿäº§å·¥å…·ï¼Œæ•ˆç‡æ¯”è¾ƒä½ã€‚\nå½“æˆ‘æˆä¸ºä¸€åè€å¸ˆçš„æ—¶å€™ï¼Œæˆ‘ä¹Ÿä¼šè®©æˆ‘çš„å­¦ç”Ÿæ•´ç†é”™é¢˜ï¼Œä½†æˆ‘åˆå¸Œæœ›ä»–ä»¬èƒ½æé«˜æ•ˆç‡ï¼Œä¸è¦æŠŠæ—¶é—´èŠ±åœ¨æ— æ„ä¹‰çš„æŠ„é¢˜ä¸Šé¢ã€‚æˆ‘å°è¯•äº†å‡ ç§æ–¹æ³•ï¼Œæ¯”å¦‚å­¦è€Œæ€çš„é”™é¢˜æœºï¼Œå®ƒå¯ä»¥æŠŠé”™é¢˜ç›´æ¥æ‰“å°ä¸‹æ¥ï¼Œä½†åªå±€é™äºå­¦ä¹ æœºè‡ªå¸¦çš„é¢˜ç›®ï¼Œå¹³æ—¶ä½œä¸šä¸Šçš„é”™é¢˜å°±æ²¡æ³•æ‰“å°äº†ã€‚æˆ‘è¿˜ä¹°è¿‡ä½œä¸šå¸®çš„é”™é¢˜æ‰“å°æœºï¼Œå®ƒè”ç½‘åå¯ä»¥æ‰«æè¯•å·ä¸Šçš„é¢˜ç›®ï¼Œå»æ‰‹å†™ï¼Œå¹¶ç”¨ä¸“é—¨çš„æ‰“å°çº¸æ‰“å°å‡ºæ¥ï¼Œä½†æ¯æ¬¡éƒ½éœ€è¦è”ç½‘ï¼Œæ¯”è¾ƒå¤æ‚ï¼Œè€Œä¸”æ‰“å°å‡ºæ¥çš„å¢¨è¿¹æ—¶è€Œè¿‡é‡æ—¶è€Œè¿‡è½»ã€‚\nå½“æˆ‘ç”·æœ‹å‹ç»™æˆ‘ä»‹ç»èœœèœ‚è¯•å·çš„æ—¶å€™ï¼Œæˆ‘ç¡®å®æœ‰ä¸€ç§ç›¸è§æ¨æ™šçš„æ„Ÿè§‰ï¼Œå®ƒå¯ä»¥åšåˆ°æ‰«æå·å­ä¸Šçš„é¢˜ç›®ï¼Œå»æ‰‹å†™ï¼Œè¿æ¥æ‰“å°æœºç›´æ¥æŠŠé”™é¢˜æ‰“å°å‡ºæ¥ï¼ŒåŒæ—¶å…·å¤‡äº†æˆ‘æ‰€éœ€è¦çš„å‡ ç§åŠŸèƒ½ï¼Œå¾ˆæ–¹ä¾¿ä½¿ç”¨ã€‚\nä¸è¿‡æˆ‘æœ‰ä¸€ä¸ªå°å»ºè®®ï¼Œè¯†åˆ«ä¸åŒè¯­ç§çš„é¢˜ç›®æ—¶ï¼Œå¸Œæœ›è§£æèƒ½å¤Ÿæ›´è¯¦ç»†ä¸€ç‚¹ï¼Œæœ€å¥½èƒ½ç¿»è¯‘æˆä¸­æ–‡ï¼Œç‚¹å‡»æ¯ä¸€ä¸ªå•è¯å¯ä»¥æ˜¾ç¤ºä¸­æ–‡æ„æ€ã€‚â€\nQ\u0026amp;A ","permalink":"https://bleedkagax.github.io/post/share_11_14_1/","summary":"\u003ch1 id=\"share_11_14\"\u003eshare_11_14\u003c/h1\u003e\n\u003ch2 id=\"basic-info\"\u003eBasic Info\u003c/h2\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/share_11_14_1-43.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"fitness\"\u003eFitness\u003c/h2\u003e\n\u003ch3 id=\"è®­ç»ƒæ¦‚å†µ\"\u003eè®­ç»ƒæ¦‚å†µ\u003c/h3\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/share_11_14_1.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003ch3 id=\"å¾®ä¹ æƒ¯\"\u003eå¾®ä¹ æƒ¯\u003c/h3\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/share_11_14_1-1.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/share_11_14_1-2.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003ch3 id=\"ä»å¾’æ‰‹è®­ç»ƒåˆ°å¥èº«æˆ¿\"\u003eä»å¾’æ‰‹è®­ç»ƒåˆ°å¥èº«æˆ¿\u003c/h3\u003e\n\u003cp\u003eæ–°æ‰‹ä¸Šè·¯ï¼Œä»è§‚çœ‹å¥èº«è§†é¢‘å¼€å§‹ï¼Œ\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eå®æˆ˜ç±», è¯¦ç»†åŠ¨ä½œæ•™ç¨‹ï¼šå‡¯åœ£ç‹ \u003ca href=\"https://m.bilibili.com/space/2100737396\"\u003ehttps://m.bilibili.com/space/2100737396\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eæ—¥å¸¸ç±», å¥èº«ç»éªŒåˆ†äº«ï¼šçƒ§æ¯ä¸€åˆ‡å°±æ˜¯ç¾ \u003ca href=\"https://m.bilibili.com/space/1024129080\"\u003ehttps://m.bilibili.com/space/1024129080\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eç†è®ºç±», å¥èº«çŸ¥è¯†ç§‘æ™®ï¼šä»°æœ›å°¾è¿¹äº‘ \u003ca href=\"https://m.bilibili.com/space/1879203169\"\u003ehttps://m.bilibili.com/space/1879203169\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/share_11_14_1-3.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/share_11_14_1-4.png\" alt=\"\"  /\u003e\n\u003c/p\u003e","title":"share_11_14"},{"content":"Docker Guidelines Dockerfile Best Practices Use Official Base Images Why: Official images are maintained and frequently updated, ensuring reliability and security. How: FROM node:14-alpine Minimize Image Size Why: Smaller images lead to faster deployments and reduced storage costs.\nHow:\nUse minimal base images (e.g., Alpine Linux). Remove unnecessary packages and files. Combine commands to reduce layers. RUN apt-get update \u0026amp;\u0026amp; \\ apt-get install -y package1 package2 \u0026amp;\u0026amp; \\ rm -rf /var/lib/apt/lists/* Leverage Caching Why: Utilizing Dockerâ€™s layer caching speeds up builds.\nHow:\nOrder commands from least to most frequently changing. Place frequently changing commands towards the bottom. COPY package.json ./ RUN npm install COPY . . Use Multi-Stage Builds Why: Reduce final image size by excluding build dependencies. How: FROM golang:1.16 AS builder WORKDIR /app COPY . . RUN go build -o myapp FROM alpine:latest WORKDIR /root/ COPY --from=builder /app/myapp . CMD [\u0026#34;./myapp\u0026#34;] Optimize Layer Usage Why: Fewer layers can lead to more efficient images. How: Combine related commands using \u0026amp;\u0026amp;. Clean up temporary files within the same RUN statement. .dockerignore File Why: Excludes unnecessary files from the build context, speeding up builds and reducing image size. How: node_modules *.log .git Specify Exact Versions Why: Ensures consistent builds by avoiding unexpected updates. How: FROM python:3.8.10-slim Run as Non-Root User Why: Enhances security by minimizing the potential impact of container compromises. How: RUN useradd -m appuser USER appuser Image Versioning and Tagging Consistency: Always tag images with specific versions rather than latest.\ndocker build -t myapp:1.0.0 . Semantic Versioning: Use semantic versioning (MAJOR.MINOR.PATCH) to indicate changes.\nAutomated Tags: Integrate with CI/CD to automate version tagging based on commits or releases.\nSecurity Best Practices Regularly Update Images Action: Rebuild images with the latest base images and dependencies to include security patches. Scan Images for Vulnerabilities Tools: Use scanners like Clair, Trivy, or Docker Security Scanning. trivy image myapp:1.0.0 Limit Container Privileges Action:\nAvoid running containers as root. Use Dockerâ€™s --cap-drop and --cap-add to fine-tune capabilities. Enable read-only file systems when possible. docker run --cap-drop=ALL --read-only myapp:1.0.0 Use Secrets Management Action: Store sensitive data outside images using Docker Secrets or environment variables managed securely.\ndocker secret create db_password ./db_password.txt Resource Management Set Resource Limits Why: Prevent containers from consuming excessive resources, ensuring system stability. How: docker run -m 512m --cpus=\u0026#34;1.0\u0026#34; myapp:1.0.0 Monitor Resource Usage Tools: Utilize monitoring solutions like Prometheus, Grafana, or Docker Stats. docker stats Networking Use User-Defined Networks Why: Provides better isolation and DNS-based service discovery. How: docker network create mynetwork docker run --network=mynetwork myapp:1.0.0 Manage Port Exposure Action:\nOnly expose necessary ports. Use Dockerâ€™s port mapping to manage accessibility. docker run -p 8080:80 myapp:1.0.0 Data Management Use Volumes for Persistent Data Why: Ensures data persists beyond the container lifecycle. How: docker volume create mydata docker run -v mydata:/var/lib/data myapp:1.0.0 Avoid Storing Data in Images Action: Do not embed dynamic or persistent data within Docker images. Use volumes or external storage solutions instead. Naming Conventions Containers Format: \u0026lt;project\u0026gt;_\u0026lt;service\u0026gt;_\u0026lt;instance\u0026gt; Example: webapp_api_1 Images Format: \u0026lt;repository\u0026gt;/\u0026lt;image\u0026gt;:\u0026lt;tag\u0026gt; Example: mycompany/webapp:1.0.0 Networks and Volumes Format: \u0026lt;project\u0026gt;_\u0026lt;resource\u0026gt; Example: webapp_network, webapp_data Logging and Monitoring Centralize Logs Why: Simplifies log management and analysis. How: Use logging drivers or external systems like ELK Stack or Graylog. docker run --log-driver=json-file myapp:1.0.0 Implement Monitoring Solutions Tools: Prometheus, Grafana, Datadog, New Relic. Action: Monitor container metrics, application performance, and system health. Deployment Guidelines Use Orchestration Tools Tools: Kubernetes, Docker Swarm, Apache Mesos Why: Facilitates scalable, reliable deployments with features like load balancing, service discovery, and automated rollouts. Automate Deployments Action: Integrate Docker with CI/CD pipelines using tools like Jenkins, GitLab CI/CD, or GitHub Actions. Benefit: Ensures consistent and repeatable deployments. CI/CD Integration Automate Image Builds Action: Trigger Docker builds automatically on code commits or merges. Example (GitHub Actions): name: CI on: push: branches: [ main ] jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Build Docker Image run: docker build -t myapp:${{ github.sha }} . Implement Automated Testing Action: Run tests within Docker containers to ensure consistency. Benefit: Detect issues early in the development pipeline. Maintenance and Cleanup Regularly Prune Unused Resources Action: Remove dangling images, stopped containers, unused volumes, and networks. docker system prune -a Rotate and Backup Data Action: Implement data backup strategies for persistent volumes. Tools: rsync, Volume Backup Plugins, cloud storage solutions. Troubleshooting Tips Inspect Containers:\ndocker inspect \u0026lt;container_id\u0026gt; View Logs:\ndocker logs \u0026lt;container_id\u0026gt; Access Container Shell:\ndocker exec -it \u0026lt;container_id\u0026gt; /bin/sh Check Network Connectivity:\ndocker network inspect \u0026lt;network_name\u0026gt; Diagnose with Docker Events:\ndocker events Examples Sample Dockerfile # Use official Node.js LTS version FROM node:14-alpine # Set working directory WORKDIR /app # Copy package.json and install dependencies COPY package.json package-lock.json ./ RUN npm install --production # Copy application code COPY . . # Expose the application port EXPOSE 3000 # Define the entry point CMD [\u0026#34;node\u0026#34;, \u0026#34;server.js\u0026#34;] Docker Compose Example version: \u0026#39;3.8\u0026#39; services: web: build: . ports: - \u0026#34;3000:3000\u0026#34; volumes: - .:/app - web_data:/var/lib/web environment: NODE_ENV: production networks: - webnet db: image: postgres:13 restart: always environment: POSTGRES_USER: user POSTGRES_PASSWORD: password volumes: - db_data:/var/lib/postgresql/data networks: - webnet volumes: web_data: db_data: networks: webnet: Happy Dockering! ğŸš€\n","permalink":"https://bleedkagax.github.io/post/4_docker/","summary":"\u003ch1 id=\"docker-guidelines\"\u003eDocker Guidelines\u003c/h1\u003e\n\u003ch2 id=\"dockerfile-best-practices\"\u003eDockerfile Best Practices\u003c/h2\u003e\n\u003ch3 id=\"use-official-base-images\"\u003eUse Official Base Images\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eWhy\u003c/strong\u003e: Official images are maintained and frequently updated, ensuring reliability and security.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eHow\u003c/strong\u003e:\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-dockerfile\" data-lang=\"dockerfile\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eFROM\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e node:14-alpine\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"minimize-image-size\"\u003eMinimize Image Size\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eWhy\u003c/strong\u003e: Smaller images lead to faster deployments and reduced storage costs.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eHow\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eUse minimal base images (e.g., Alpine Linux).\u003c/li\u003e\n\u003cli\u003eRemove unnecessary packages and files.\u003c/li\u003e\n\u003cli\u003eCombine commands to reduce layers.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-dockerfile\" data-lang=\"dockerfile\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eRUN\u003c/span\u003e apt-get update \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e    apt-get install -y package1 package2 \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e    rm -rf /var/lib/apt/lists/*\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pr","title":"Docker"},{"content":"Introduction Kubernetes (k8s) is an open-source container orchestration platform that automates the deployment, scaling, and management of containerized applications.\nKubernetes Architecture Masters The master node manages the Kubernetes cluster. It coordinates all activities, such as scheduling, scaling, and updating applications.\nComponents: API Server: The front-end of the Kubernetes control plane. etcd: A distributed key-value store for configuration data. Controller Manager: Manages controllers that handle routine tasks. Scheduler: Assigns workloads to nodes based on resource availability and policies. Nodes Worker nodes run the containerized applications. Each node contains the necessary services to run Pods and communicate with the master node.\nComponents: kubelet: Ensures containers are running in a Pod. kube-proxy: Manages network routing for Kubernetes services. Container Runtime: Software responsible for running containers (e.g., Docker, containerd). Components Understanding the architecture is crucial for effective cluster management and troubleshooting.\nSetup and Installation Prerequisites Operating System: Linux distributions are commonly used. Hardware Requirements: Adequate CPU, memory, and storage. Networking: Proper network configuration for node communication. Installation Methods Minikube Ideal for local development and testing.\n# Install Minikube curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 sudo install minikube-linux-amd64 /usr/local/bin/minikube # Start Minikube minikube start kubeadm Suitable for setting up production-grade clusters.\n# Initialize Master Node sudo kubeadm init --pod-network-cidr=10.244.0.0/16 # Set up Kubernetes configuration mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config # Install a Pod network (e.g., Flannel) kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml Managed Kubernetes Services Managed services simplify cluster setup and management.\nOptions: Google Kubernetes Engine (GKE) Amazon Elastic Kubernetes Service (EKS) Azure Kubernetes Service (AKS) Alibaba Cloud Container Service Core Concepts Pods The smallest deployable units in Kubernetes, representing a single instance of a running process.\nFeatures: Can contain one or more containers. Share storage, network, and specifications. Services Define a logical set of Pods and a policy to access them.\nTypes: ClusterIP: Internal access within the cluster. NodePort: Exposes the service on each nodeâ€™s IP at a static port. LoadBalancer: Exposes the service externally using a cloud providerâ€™s load balancer. ExternalName: Maps a service to a DNS name. Deployments Provide declarative updates for Pods and ReplicaSets.\nFeatures: Manage rolling updates and rollbacks. Ensure desired state is maintained. ReplicaSets Ensure a specified number of Pod replicas are running at any given time.\nNamespaces Provide a way to divide cluster resources between multiple users.\nUse Cases: Environment segregation (e.g., dev, staging, production). Resource isolation. ConfigMaps and Secrets ConfigMaps: Store non-confidential configuration data. Secrets: Store sensitive information such as passwords and tokens. Best Practices Resource Management Resource Requests and Limits Define resource requirements to optimize scheduling and prevent resource contention.\nresources: requests: memory: \u0026#34;64Mi\u0026#34; cpu: \u0026#34;250m\u0026#34; limits: memory: \u0026#34;128Mi\u0026#34; cpu: \u0026#34;500m\u0026#34; Auto-scaling Utilize Kubernetesâ€™ auto-scaling features to handle varying workloads.\nHorizontal Pod Autoscaler (HPA)\napiVersion: autoscaling/v1 kind: HorizontalPodAutoscaler metadata: name: hpa-example spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: myapp minReplicas: 2 maxReplicas: 10 targetCPUUtilizationPercentage: 80 Vertical Pod Autoscaler (VPA)\nCluster Autoscaler\nNaming Conventions Maintain consistent and descriptive names for resources.\nFormat: \u0026lt;project\u0026gt;-\u0026lt;component\u0026gt;-\u0026lt;environment\u0026gt;-\u0026lt;instance\u0026gt; Example: webapp-api-prod-1 Configuration Management Store configurations separately using ConfigMaps and Secrets to maintain flexibility and security.\nVersion Control Manage Kubernetes manifests using version control systems like Git to track changes and enable collaboration.\nSecurity Best Practices RBAC (Role-Based Access Control) Control access to Kubernetes resources by defining roles and role bindings.\napiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: namespace: default name: pod-reader rules: - apiGroups: [\u0026#34;\u0026#34;] resources: [\u0026#34;pods\u0026#34;] verbs: [\u0026#34;get\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;list\u0026#34;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: read-pods namespace: default subjects: - kind: User name: jane apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: pod-reader apiGroup: rbac.authorization.k8s.io Network Policies Define how Pods communicate with each other and other network endpoints.\napiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: allow-same-namespace spec: podSelector: {} ingress: - from: - podSelector: {} Pod Security Policies Enforce security standards for Pods, such as restricting privileged containers.\napiVersion: policy/v1beta1 kind: PodSecurityPolicy metadata: name: restricted spec: privileged: false seLinux: rule: RunAsAny supplementalGroups: rule: RunAsAny runAsUser: rule: MustRunAsNonRoot fsGroup: rule: RunAsAny Image Security Use Trusted Images: Pull images from reputable sources. Scan for Vulnerabilities: Use tools like Trivy or Clair. Avoid Running as Root: Define non-root users in Dockerfiles. Secrets Management Use Kubernetes Secrets to manage sensitive data securely.\napiVersion: v1 kind: Secret metadata: name: db-secret type: Opaque data: username: YWRtaW4= # base64 encoded password: MWYyZDFlMmU2N2Rm Networking Service Types ClusterIP: Default type; accessible only within the cluster. NodePort: Exposes the service on each nodeâ€™s IP at a static port. LoadBalancer: Integrates with cloud provider load balancers. ExternalName: Maps the service to an external DNS name. Ingress Controllers Manage external access to services, typically HTTP.\nPopular Ingress Controllers: NGINX Ingress Controller Traefik HAProxy apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: example-ingress spec: rules: - host: example.com http: paths: - path: / pathType: Prefix backend: service: name: my-service port: number: 80 DNS Management Kubernetes provides internal DNS for service discovery. Ensure proper DNS setup for ClusterDNS.\nService Mesh Implement advanced networking features like traffic management, security, and observability.\nPopular Service Meshes: Istio Linkerd Consul Connect Storage Management Persistent Volumes (PVs) and Persistent Volume Claims (PVCs) Use PVs and PVCs to manage storage resources dynamically.\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc-example spec: accessModes: - ReadWriteOnce resources: requests: storage: 10Gi Storage Classes Define different storage backends and reclaim policies.\napiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: fast provisioner: kubernetes.io/aws-ebs parameters: type: gp2 Data Backup and Restore Implement backup strategies for persistent data using tools like Velero or Kasten.\nMonitoring and Logging Monitoring Tools Prometheus: Metrics collection and alerting. Grafana: Visualization of metrics. Kube-state-metrics: Kubernetes specific metrics. Logging Solutions ELK Stack (Elasticsearch, Logstash, Kibana) Fluentd Graylog Loki Alerting Set up alerts for critical metrics and events using Alertmanager or integrated tools with Prometheus.\nDeployment Strategies Rolling Updates Gradually replace Pods with new ones to ensure zero downtime.\napiVersion: apps/v1 kind: Deployment metadata: name: rolling-update-deployment spec: replicas: 3 strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 1 maxSurge: 1 selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: myapp-container image: myapp:v2 Blue/Green Deployments Maintain two environments (blue and green) and switch traffic between them during updates.\nCanary Releases Deploy new versions to a subset of users to monitor performance before a full rollout.\nCI/CD Integration Automated Builds and Deployments Integrate Kubernetes with CI/CD pipelines for automated testing and deployment.\nTools: Jenkins, GitLab CI/CD, GitHub Actions, Argo CD # Example GitHub Actions Workflow name: CI/CD Pipeline on: push: branches: [ main ] jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Build Docker Image run: docker build -t myapp:${{ github.sha }} . - name: Push to Registry run: docker push myapp:${{ github.sha }} deploy: runs-on: ubuntu-latest needs: build steps: - name: Deploy to Kubernetes uses: appleboy/k8s-action@v1.0.0 with: kubeconfig: ${{ secrets.KUBECONFIG }} args: kubectl set image deployment/myapp-deployment myapp=myapp:${{ github.sha }} GitOps Adopt Git-centric workflows using tools like Argo CD or Flux to manage deployments declaratively.\nTroubleshooting Tips Common Issues Pod Failing to Start: Check events and logs. Service Unreachable: Verify Service and Ingress configurations. Resource Limits Exceeded: Adjust requests and limits. Debugging Tools kubectl: Interact with Kubernetes clusters. kubectl describe pod \u0026lt;pod-name\u0026gt; kubectl logs \u0026lt;pod-name\u0026gt; kubectl exec -it \u0026lt;pod-name\u0026gt; -- /bin/bash k9s: Terminal UI to manage Kubernetes clusters. Lens: Kubernetes IDE for visual management. Examples Sample Deployment YAML apiVersion: apps/v1 kind: Deployment metadata: name: myapp-deployment labels: app: myapp spec: replicas: 3 selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: myapp-container image: myapp:1.0.0 ports: - containerPort: 80 env: - name: ENVIRONMENT value: \u0026#34;production\u0026#34; resources: requests: memory: \u0026#34;64Mi\u0026#34; cpu: \u0026#34;250m\u0026#34; limits: memory: \u0026#34;128Mi\u0026#34; cpu: \u0026#34;500m\u0026#34; Sample Service YAML apiVersion: v1 kind: Service metadata: name: myapp-service spec: selector: app: myapp ports: - protocol: TCP port: 80 targetPort: 80 type: LoadBalancer Happy Orchestrating! ğŸš€\n","permalink":"https://bleedkagax.github.io/post/5_k8s/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eKubernetes (k8s) is an open-source container orchestration platform that automates the deployment, scaling, and management of containerized applications.\u003c/p\u003e\n\u003ch2 id=\"kubernetes-architecture\"\u003eKubernetes Architecture\u003c/h2\u003e\n\u003ch3 id=\"masters\"\u003eMasters\u003c/h3\u003e\n\u003cp\u003eThe \u003cstrong\u003emaster node\u003c/strong\u003e manages the Kubernetes cluster. It coordinates all activities, such as scheduling, scaling, and updating applications.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eComponents\u003c/strong\u003e:\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eAPI Server\u003c/strong\u003e: The front-end of the Kubernetes control plane.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eetcd\u003c/strong\u003e: A distributed key-value store for configuration data.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eController Manager\u003c/strong\u003e: Manages controllers that handle routine tasks.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eScheduler\u003c/strong\u003e: Assigns workloads to nodes based on resource availability and policies.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"nodes\"\u003eNodes\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eWorker nodes\u003c/strong\u003e run the containerized applications. Each node contains the necessary services to run Pods and communicate with the master node.\u003c/p\u003e","title":"Kubernetes"},{"content":"Introduction to Lua Lua is a powerful, efficient, lightweight, embeddable scripting language. It is designed to be embedded in other applications, providing flexibility and extensibility. Lua is widely used in game development, embedded systems, web applications, and more due to its simple syntax, fast execution, and ease of integration.\nWhat is Lua? Key Features Lightweight and Fast: Lua is designed to have a small footprint and execute rapidly, making it ideal for performance-critical applications. Embeddable: Easily integrates with C and other programming languages, allowing developers to extend its capabilities. Simple Syntax: Clean and straightforward syntax that is easy to learn and use. Extensible: Provides powerful metaprogramming capabilities through metatables and metamethods. Powerful Data Structures: Uses tables as the primary data structure, enabling the creation of arrays, dictionaries, and more. First-Class Functions: Functions are first-class citizens, allowing for functional programming paradigms. Coroutines: Supports cooperative multitasking, enabling asynchronous programming. Use Cases Game Development: Scripting game logic, AI, and event handling. Embedded Systems: Providing scripting capabilities within hardware devices. Web Development: Enhancing web servers with dynamic content generation (e.g., OpenResty). Configuration: Scriptable configuration files for applications and services. Data Processing: Handling data transformations and manipulations. Prerequisites Before diving into Lua, ensure you have the following:\nBasic Programming Knowledge: Familiarity with programming concepts such as variables, control structures, and functions. Understanding of Scripting Languages: Experience with other scripting languages (e.g., Python, JavaScript) can be beneficial. Development Environment: Access to a computer with administrative privileges to install Lua and related tools. Installation Installing on Windows Download Lua:\nVisit the official Lua website. Download the Windows binaries from LuaBinaries. Extract the Files:\nExtract the downloaded ZIP or TAR.GZ file to a directory, e.g., C:\\Lua. Configure Environment Variables:\nOpen the System Properties. Navigate to Advanced System Settings \u0026gt; Environment Variables. Under System Variables, find and select Path, then click Edit. Click New and add the path to your Lua directory, e.g., C:\\Lua. Click OK to save changes. Verify Installation:\nOpen Command Prompt. Type lua -v and press Enter. You should see the Lua version information. Installing on macOS Using Homebrew:\nHomebrew is a popular package manager for macOS.\nInstall Homebrew: If you haven\u0026rsquo;t installed Homebrew, run:\n/bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34; Update Homebrew:\nbrew update Install Lua:\nbrew install lua Verify Installation:\nOpen Terminal. Type lua -v and press Enter. You should see the Lua version information. Installing on Linux Debian/Ubuntu Update Package List:\nsudo apt update Install Lua:\nsudo apt install lua5.3 Note: Replace lua5.3 with the desired version if necessary.\nVerify Installation:\nlua -v CentOS/RHEL Enable EPEL Repository:\nsudo yum install epel-release -y Install Lua:\nsudo yum install lua -y Verify Installation:\nlua -v Building from Source Building Lua from source allows customization and ensures you have the latest version.\nDownload Source Code:\nVisit the official Lua website. Download the latest Lua source tarball, e.g., lua-5.4.4.tar.gz. Extract the Files:\ntar -zxvf lua-5.4.4.tar.gz cd lua-5.4.4 Build Lua:\nmake linux test Note: Replace linux with your operating system if different (e.g., macosx).\nInstall Lua:\nsudo make install Verify Installation:\nlua -v Basic Syntax and Language Features Data Types Lua has a small set of data types:\nNil: Represents the absence of a useful value. Boolean: true or false. Number: Typically double-precision floating-point numbers. String: Immutable sequences of characters. Function: First-class values. Table: Associative arrays, the primary data structure. Userdata: C data types. Thread: Represents independent threads of execution (coroutines). Variables Variables in Lua are dynamically typed and do not require explicit declaration.\n-- Assigning values x = 10 -- Number name = \u0026#34;Lua\u0026#34; -- String isValid = true -- Boolean Operators Lua supports standard arithmetic, relational, logical, and concatenation operators.\n-- Arithmetic Operators sum = 5 + 3 -- 8 difference = 5 - 3 -- 2 product = 5 * 3 -- 15 quotient = 5 / 3 -- 1.666... remainder = 5 % 3 -- 2 power = 5 ^ 3 -- 125 -- Relational Operators print(5 \u0026gt; 3) -- true print(5 == 5) -- true print(5 ~= 3) -- true -- Logical Operators print(true and false) -- false print(true or false) -- true print(not true) -- false -- Concatenation Operator greeting = \u0026#34;Hello, \u0026#34; .. \u0026#34;Lua!\u0026#34; -- \u0026#34;Hello, Lua!\u0026#34; Control Structures Lua includes if, while, for, and repeat control structures.\nIf Statement if x \u0026gt; 0 then print(\u0026#34;Positive\u0026#34;) elseif x \u0026lt; 0 then print(\u0026#34;Negative\u0026#34;) else print(\u0026#34;Zero\u0026#34;) end While Loop i = 1 while i \u0026lt;= 5 do print(i) i = i + 1 end For Loop Numeric For Loop:\nfor i = 1, 5, 1 do print(i) end Generic For Loop (Iterating over Tables):\nfruits = {\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;} for index, value in ipairs(fruits) do print(index, value) end Repeat Until Loop i = 1 repeat print(i) i = i + 1 until i \u0026gt; 5 Functions Functions are first-class citizens and can be assigned to variables, passed as arguments, and returned from other functions.\n-- Defining a function function add(a, b) return a + b end -- Calling a function result = add(5, 3) -- 8 -- Anonymous function multiply = function(a, b) return a * b end result = multiply(4, 2) -- 8 Variable Arguments function sum(...) local s = 0 for _, v in ipairs({...}) do s = s + v end return s end print(sum(1, 2, 3, 4)) -- 10 Tables Tables are the only data structure in Lua and serve as arrays, dictionaries, objects, and more.\n-- Creating a table person = { name = \u0026#34;Alice\u0026#34;, age = 30, hobbies = {\u0026#34;reading\u0026#34;, \u0026#34;coding\u0026#34;, \u0026#34;hiking\u0026#34;} } -- Accessing table elements print(person.name) -- Alice print(person[\u0026#34;age\u0026#34;]) -- 30 print(person.hobbies[2]) -- coding -- Modifying table elements person.age = 31 person.hobbies[3] = \u0026#34;cycling\u0026#34; Metatables and Metamethods Metatables allow you to define custom behavior for tables through metamethods.\n-- Creating a metatable mt = { __add = function(a, b) return {value = a.value + b.value} end } -- Creating tables with metatables a = {value = 10} b = {value = 20} setmetatable(a, mt) setmetatable(b, mt) -- Using the __add metamethod c = a + b print(c.value) -- 30 Error Handling Lua uses pcall and xpcall for error handling.\nfunction riskyFunction() error(\u0026#34;Something went wrong!\u0026#34;) end -- Using pcall status, err = pcall(riskyFunction) if not status then print(\u0026#34;Error caught: \u0026#34;, err) end -- Using xpcall with a custom error handler function errorHandler(err) print(\u0026#34;Custom handler: \u0026#34;, err) end status, err = xpcall(riskyFunction, errorHandler) Advanced Features Coroutines Coroutines enable cooperative multitasking, allowing multiple functions to yield and resume execution.\nco = coroutine.create(function() for i = 1, 3 do print(\u0026#34;Coroutine iteration: \u0026#34; .. i) coroutine.yield() end end) print(coroutine.status(co)) -- suspended coroutine.resume(co) -- Coroutine iteration: 1 coroutine.resume(co) -- Coroutine iteration: 2 coroutine.resume(co) -- Coroutine iteration: 3 print(coroutine.status(co)) -- dead Module System Modules allow for code organization and reuse. Lua 5.1 used module and package.seeall, but it\u0026rsquo;s recommended to use tables for modules in newer versions.\n-- mymodule.lua local M = {} function M.greet(name) return \u0026#34;Hello, \u0026#34; .. name .. \u0026#34;!\u0026#34; end return M Using the Module:\nlocal mymodule = require \u0026#34;mymodule\u0026#34; print(mymodule.greet(\u0026#34;Lua\u0026#34;)) -- Hello, Lua! LuaJIT LuaJIT is a Just-In-Time Compiler for Lua, offering significant performance improvements.\nPerformance: LuaJIT can execute Lua code much faster than the standard interpreter. FFI Library: Allows calling C functions and using C data structures directly from Lua without writing C code. Example Using FFI:\nlocal ffi = require(\u0026#34;ffi\u0026#34;) ffi.cdef[[ double sin(double x); ]] print(ffi.C.sin(3.141592653589793 / 2)) -- 1.0 Working with Lua Input and Output Printing to Console print(\u0026#34;Hello, Lua!\u0026#34;) Reading from Console io.write(\u0026#34;Enter your name: \u0026#34;) name = io.read() print(\u0026#34;Hello, \u0026#34; .. name .. \u0026#34;!\u0026#34;) File Operations Opening and Reading a File file = io.open(\u0026#34;example.txt\u0026#34;, \u0026#34;r\u0026#34;) if file then content = file:read(\u0026#34;*a\u0026#34;) print(content) file:close() else print(\u0026#34;Failed to open file.\u0026#34;) end Writing to a File file = io.open(\u0026#34;output.txt\u0026#34;, \u0026#34;w\u0026#34;) if file then file:write(\u0026#34;Hello, Lua File I/O!\u0026#34;) file:close() else print(\u0026#34;Failed to open file for writing.\u0026#34;) end String Manipulation Lua provides robust string handling capabilities.\nstr = \u0026#34;Hello, Lua!\u0026#34; -- String concatenation greeting = str .. \u0026#34; How are you?\u0026#34; print(greeting) -- Hello, Lua! How are you? -- Substrings substr = string.sub(str, 8, 10) print(substr) -- Lua -- String length length = string.len(str) print(length) -- 11 -- String patterns (similar to regex) matched = string.match(str, \u0026#34;Lua\u0026#34;) print(matched) -- Lua Regular Expressions Lua uses pattern matching, which is simpler than full regex but powerful enough for many tasks.\ntext = \u0026#34;The quick brown fox jumps over the lazy dog.\u0026#34; -- Find all words for word in string.gmatch(text, \u0026#34;%a+\u0026#34;) do print(word) end -- Replace \u0026#39;dog\u0026#39; with \u0026#39;cat\u0026#39; new_text = string.gsub(text, \u0026#34;dog\u0026#34;, \u0026#34;cat\u0026#34;) print(new_text) -- The quick brown fox jumps over the lazy cat. Modules and Libraries Lua\u0026rsquo;s standard libraries provide essential functionalities.\nBasic Libraries: math for mathematical operations. string for string manipulation. table for table operations. io for input/output. os for operating system interactions. debug for debugging tools. -- Using the math library x = math.sqrt(16) print(x) -- 4 -- Using the table library t = {1, 2, 3} table.insert(t, 4) print(table.concat(t, \u0026#34;, \u0026#34;)) -- 1, 2, 3, 4 Interfacing with C Lua can interface with C, allowing for the extension of Lua with C functions for performance-critical tasks.\nLua C API The Lua C API enables embedding Lua in C applications or extending Lua with C functions.\nExample: Embedding Lua in C\n#include \u0026lt;lua.h\u0026gt; #include \u0026lt;lualib.h\u0026gt; #include \u0026lt;lauxlib.h\u0026gt; int main(void) { lua_State *L = luaL_newstate(); // Create Lua state luaL_openlibs(L); // Open standard libraries // Execute a Lua script if (luaL_dofile(L, \u0026#34;script.lua\u0026#34;) != LUA_OK) { const char *error = lua_tostring(L, -1); fprintf(stderr, \u0026#34;Error: %s\\n\u0026#34;, error); lua_close(L); return 1; } lua_close(L); return 0; } Example: Exposing a C Function to Lua\n#include \u0026lt;lua.h\u0026gt; #include \u0026lt;lualib.h\u0026gt; #include \u0026lt;lauxlib.h\u0026gt; // C function to be called from Lua int add(lua_State *L) { double a = luaL_checknumber(L, 1); double b = luaL_checknumber(L, 2); lua_pushnumber(L, a + b); return 1; // Number of return values } int main(void) { lua_State *L = luaL_newstate(); luaL_openlibs(L); // Register the C function lua_register(L, \u0026#34;add\u0026#34;, add); // Run a Lua script that uses the C function if (luaL_dofile(L, \u0026#34;use_add.lua\u0026#34;) != LUA_OK) { const char *error = lua_tostring(L, -1); fprintf(stderr, \u0026#34;Error: %s\\n\u0026#34;, error); lua_close(L); return 1; } lua_close(L); return 0; } Lua Script (use_add.lua):\nresult = add(5, 7) print(\u0026#34;Result:\u0026#34;, result) -- Result: 12 Writing C Extensions You can extend Lua by writing C functions and compiling them as dynamic libraries.\nExample: Creating a C Extension\nWrite the C Code (mylib.c):\n#include \u0026lt;lua.h\u0026gt; #include \u0026lt;lualib.h\u0026gt; #include \u0026lt;lauxlib.h\u0026gt; // C function to multiply two numbers int multiply(lua_State *L) { double a = luaL_checknumber(L, 1); double b = luaL_checknumber(L, 2); lua_pushnumber(L, a * b); return 1; } // Register functions static const struct luaL_Reg mylib[] = { {\u0026#34;multiply\u0026#34;, multiply}, {NULL, NULL} }; // Open the library int luaopen_mylib(lua_State *L) { luaL_newlib(L, mylib); return 1; } Compile the C Code:\nOn Linux/macOS:\ngcc -shared -o mylib.so -fPIC mylib.c -I/usr/include/lua5.3 On Windows:\nUse a compatible compiler to create a DLL.\nUse the Extension in Lua:\nLua Script (use_mylib.lua):\nlocal mylib = require(\u0026#34;mylib\u0026#34;) result = mylib.multiply(6, 7) print(\u0026#34;Multiply Result:\u0026#34;, result) -- Multiply Result: 42 Run the Lua Script:\nlua use_mylib.lua Examples Example 1: Simple Calculator -- calculator.lua function add(a, b) return a + b end function subtract(a, b) return a - b end function multiply(a, b) return a * b end function divide(a, b) if b == 0 then error(\u0026#34;Cannot divide by zero!\u0026#34;) end return a / b end print(\u0026#34;Sum:\u0026#34;, add(10, 5)) print(\u0026#34;Difference:\u0026#34;, subtract(10, 5)) print(\u0026#34;Product:\u0026#34;, multiply(10, 5)) print(\u0026#34;Quotient:\u0026#34;, divide(10, 5)) Output:\nSum: 15 Difference: 5 Product: 50 Quotient: 2 Example 2: Table Sorting -- sort_table.lua fruits = {\u0026#34;banana\u0026#34;, \u0026#34;apple\u0026#34;, \u0026#34;cherry\u0026#34;, \u0026#34;date\u0026#34;} table.sort(fruits) for i, fruit in ipairs(fruits) do print(i, fruit) end Output:\n1 apple 2 banana 3 cherry 4 date Example 3: Metatable Usage -- metatable_example.lua local obj = {value = 10} local mt = { __add = function(a, b) return {value = a.value + b.value} end } setmetatable(obj, mt) local obj2 = {value = 20} setmetatable(obj2, mt) local result = obj + obj2 print(result.value) -- 30 Interfacing with C Lua\u0026rsquo;s ability to interface with C allows for the extension of Lua with high-performance C code and the embedding of Lua within C applications.\nLua C API The Lua C API provides functions to interact with Lua states, load and execute Lua scripts, manipulate Lua variables, and define C functions callable from Lua.\nExample: Embedding Lua in a C Application #include \u0026lt;lua.h\u0026gt; #include \u0026lt;lualib.h\u0026gt; #include \u0026lt;lauxlib.h\u0026gt; int main(void) { // Create a new Lua state lua_State *L = luaL_newstate(); luaL_openlibs(L); // Open standard libraries // Execute a Lua script if (luaL_dofile(L, \u0026#34;script.lua\u0026#34;) != LUA_OK) { const char *error_msg = lua_tostring(L, -1); printf(\u0026#34;Error: %s\\n\u0026#34;, error_msg); lua_close(L); return 1; } // Close the Lua state lua_close(L); return 0; } Lua Script (script.lua):\nprint(\u0026#34;Hello from Lua!\u0026#34;) Compile and Run:\ngcc -o embed_lua embed_lua.c -llua5.3 -lm -ldl ./embed_lua Output:\nHello from Lua! Writing C Extensions Creating C extensions allows Lua scripts to leverage existing C libraries and high-performance code.\nExample: C Extension for String Reversal C Code (strreverse.c):\n#include \u0026lt;lua.h\u0026gt; #include \u0026lt;lualib.h\u0026gt; #include \u0026lt;lauxlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; // C function to reverse a string int l_strreverse(lua_State *L) { const char *str = luaL_checkstring(L, 1); size_t len = strlen(str); char *rev = (char *)malloc(len + 1); if (!rev) { return luaL_error(L, \u0026#34;Memory allocation failed\u0026#34;); } for (size_t i = 0; i \u0026lt; len; i++) { rev[i] = str[len - i - 1]; } rev[len] = \u0026#39;\\0\u0026#39;; lua_pushstring(L, rev); free(rev); return 1; // Number of return values } // Register functions static const struct luaL_Reg mylib [] = { {\u0026#34;reverse\u0026#34;, l_strreverse}, {NULL, NULL} }; int luaopen_mylib(lua_State *L) { luaL_newlib(L, mylib); return 1; } Compile the Extension:\ngcc -shared -fPIC -o mylib.so -I/usr/include/lua5.3 strreverse.c Lua Script (use_strreverse.lua):\nlocal mylib = require(\u0026#34;mylib\u0026#34;) local original = \u0026#34;Hello, Lua!\u0026#34; local reversed = mylib.reverse(original) print(\u0026#34;Original:\u0026#34;, original) print(\u0026#34;Reversed:\u0026#34;, reversed) Run the Lua Script:\nlua use_strreverse.lua Output:\nOriginal: Hello, Lua! Reversed: !auL ,olleH Examples Example 1: Simple Echo Server with Lua -- echo_server.lua local socket = require(\u0026#34;socket\u0026#34;) local server = assert(socket.bind(\u0026#34;*\u0026#34;, 12345)) local ip, port = server:getsockname() print(\u0026#34;Echo server running on \u0026#34; .. ip .. \u0026#34;:\u0026#34; .. port) while true do local client = server:accept() client:settimeout(10) local line, err = client:receive() if not err then client:send(line .. \u0026#34;\\n\u0026#34;) end client:close() end Run the Server:\nlua echo_server.lua Connect Using Telnet:\ntelnet localhost 12345 Interaction:\nTrying 127.0.0.1... Connected to localhost. Escape character is \u0026#39;^]\u0026#39;. Hello, Lua! Hello, Lua! Example 2: Simple Web Server with Lua and Socket -- web_server.lua local socket = require(\u0026#34;socket\u0026#34;) local server = assert(socket.bind(\u0026#34;*\u0026#34;, 8080)) local ip, port = server:getsockname() print(\u0026#34;Web server running on \u0026#34; .. ip .. \u0026#34;:\u0026#34; .. port) while true do local client = server:accept() client:settimeout(10) local request, err = client:receive() if not err then -- Simple HTTP response local response = \u0026#34;HTTP/1.1 200 OK\\r\\n\u0026#34; .. \u0026#34;Content-Type: text/plain\\r\\n\u0026#34; .. \u0026#34;Connection: close\\r\\n\\r\\n\u0026#34; .. \u0026#34;Hello, Lua Web Server!\u0026#34; client:send(response) end client:close() end Run the Server:\nlua web_server.lua Access via Browser:\nNavigate to http://localhost:8080/ to see \u0026ldquo;Hello, Lua Web Server!\u0026rdquo;\nScripting with Lua in Various Environments Embedded Systems Lua is lightweight and efficient, making it ideal for embedding in hardware devices like routers, IoT gadgets, and microcontrollers.\nExample: Lua in OpenWrt\nOpenWrt, a popular open-source router firmware, uses Lua for scripting:\n-- /usr/lib/lua/luci/controller/example.lua module(\u0026#34;luci.controller.example\u0026#34;, package.seeall) function index() entry({\u0026#34;admin\u0026#34;, \u0026#34;status\u0026#34;, \u0026#34;example\u0026#34;}, template(\u0026#34;status/example\u0026#34;), \u0026#34;Example\u0026#34;, 10) end Game Development Lua is extensively used in game development for scripting game logic, AI behaviors, and event handling.\nExample: Love2D\nLove2D is a popular game framework that uses Lua for scripting.\n-- main.lua function love.load() love.window.setTitle(\u0026#34;Hello, Lua Game!\u0026#34;) end function love.draw() love.graphics.print(\u0026#34;Welcome to Love2D!\u0026#34;, 400, 300) end Run the Game:\nPlace main.lua in a directory and run:\nlove path_to_your_game_directory Web Development Lua enhances web servers like Nginx through OpenResty, enabling high-performance web applications with dynamic content generation.\nExample: Basic OpenResty Application\n# /usr/local/openresty/nginx/conf/nginx.conf worker_processes 1; events { worker_connections 1024; } http { server { listen 8080; server_name localhost; location / { default_type \u0026#39;text/plain\u0026#39;; content_by_lua_block { ngx.say(\u0026#34;Hello from OpenResty and Lua!\u0026#34;) } } } } Run OpenResty:\nsudo openresty -c /usr/local/openresty/nginx/conf/nginx.conf Access via Browser:\nNavigate to http://localhost:8080/ to see \u0026ldquo;Hello from OpenResty and Lua!\u0026rdquo;\nBest Practices Adhering to best practices ensures your Lua code is efficient, maintainable, and robust.\nCode Organization Modules: Organize related functions and data into modules to promote reusability and readability. Naming Conventions: Use clear and consistent naming conventions for variables, functions, and modules. Documentation: Comment your code and provide documentation to explain complex logic and functionality. Error Handling Use pcall and xpcall: Safely handle errors without crashing your program. Graceful Degradation: Ensure your application can continue running or fail gracefully even when encountering errors. function safeDivide(a, b) if b == 0 then return nil, \u0026#34;Cannot divide by zero!\u0026#34; end return a / b, nil end result, err = safeDivide(10, 0) if not result then print(\u0026#34;Error:\u0026#34;, err) else print(result) end Performance Optimization Avoid Global Variables: Use local variables to reduce lookup time and improve performance. Efficient Table Usage: Preallocate tables when possible and use appropriate key types. Minimize Garbage Collection: Reuse tables and avoid creating unnecessary objects to reduce the frequency of garbage collection. -- Using local variables function compute() local sum = 0 for i = 1, 1000 do sum = sum + i end return sum end Security Practices Validate Inputs: Always validate and sanitize user inputs to prevent injection attacks. Restrict File Access: Limit file operations to necessary directories and enforce permission checks. Avoid Executing Untrusted Code: Do not execute Lua code from untrusted sources without proper validation. -- Input validation example function processInput(input) if type(input) ~= \u0026#34;string\u0026#34; or #input \u0026lt; 3 then error(\u0026#34;Invalid input\u0026#34;) end -- Proceed with processing end Debugging and Testing Effective debugging and testing are crucial for developing reliable Lua applications.\nDebugging Tools Print Statements: Use print() to output variable values and trace execution flow. Lua Debug Library: Provides functions for simple debugging tasks like setting breakpoints. -- Using the debug library function faultyFunction() local a = 10 local b = 0 local c = a / b -- Causes an error end function main() debug.debug() -- Enter interactive debug mode faultyFunction() end main() Integrated Development Environments (IDEs): Use IDEs like ZeroBrane Studio that offer built-in debugging support. Testing Techniques Unit Testing: Write tests for individual functions to ensure they work as expected. Integration Testing: Test how different modules interact with each other. Automated Testing: Use testing frameworks like busted for automated testing. Example: Unit Test with Busted\nInstall Busted:\nluarocks install busted Write a Test (test_calculator.lua):\n-- test_calculator.lua describe(\u0026#34;Calculator\u0026#34;, function() it(\u0026#34;adds two numbers\u0026#34;, function() assert.are.equal(5, add(2, 3)) end) it(\u0026#34;subtracts two numbers\u0026#34;, function() assert.are.equal(1, subtract(3, 2)) end) it(\u0026#34;handles division by zero\u0026#34;, function() local result, err = divide(5, 0) assert.is_nil(result) assert.are.equal(\u0026#34;Cannot divide by zero!\u0026#34;, err) end) end) Run the Tests:\nbusted test_calculator.lua Best Practices for Debugging Isolate Issues: Narrow down the source of the problem by isolating code segments. Use Descriptive Messages: Provide clear and descriptive error messages to aid in troubleshooting. Leverage External Tools: Utilize IDEs and debugging tools that offer advanced features like step-through execution and variable inspection. Performance Optimization Optimizing Lua code ensures efficient execution and resource utilization.\nEfficient Coding Practices Use Local Variables:\n-- Inefficient function sum(nums) local total = 0 for i = 1, #nums do total = total + nums[i] end return total end -- Efficient function sum(nums) local total = 0 for i = 1, #nums do total = total + nums[i] end return total end Note: The above example shows identical code; to emphasize, declare frequently accessed global variables as local.\n-- Inefficient global access print = print function greet(name) print(\u0026#34;Hello, \u0026#34; .. name) end -- Efficient local access local print = print function greet(name) print(\u0026#34;Hello, \u0026#34; .. name) end Minimize Table Lookups:\n-- Inefficient function getName(person) return person.name end -- Efficient local nameGetter = person.name function getName() return nameGetter end Reuse Tables:\n-- Avoid creating tables in loops local result = {} for i = 1, 1000 do table.insert(result, i * 2) end Garbage Collection Optimization Lua\u0026rsquo;s garbage collector can affect performance if not managed properly.\nAvoid Unnecessary Table Creation: Reuse tables instead of creating new ones. Explicitly Manage Garbage Collection: Tune garbage collector parameters if necessary. -- Adjust garbage collection settings collectgarbage(\u0026#34;setpause\u0026#34;, 110) collectgarbage(\u0026#34;setstepmul\u0026#34;, 200) Profiling and Benchmarking Use profiling tools to identify performance bottlenecks.\nLua Clock Library:\nlocal clock = os.clock function benchmark(func) local start = clock() func() local finish = clock() print(string.format(\u0026#34;Time taken: %.6f seconds\u0026#34;, finish - start)) end benchmark(function() local sum = 0 for i = 1, 1000000 do sum = sum + i end end) Profiler Libraries: Utilize libraries like LuaProfiler for detailed profiling.\nSecurity Considerations Ensuring the security of your Lua applications is paramount.\nInput Validation Always validate and sanitize user inputs to prevent injection attacks and unexpected behavior.\nfunction processInput(input) if type(input) ~= \u0026#34;string\u0026#34; or #input \u0026lt; 3 then error(\u0026#34;Invalid input\u0026#34;) end -- Proceed with processing end Secure Coding Practices Avoid Using load and loadstring on Untrusted Data:\n-- Insecure local func = load(user_input) func() -- Secure alternative -- Parse and validate input before executing Restrict File Access:\nLimit file operations to necessary directories and enforce permission checks.\nfunction readFile(filepath) -- Ensure the filepath is within allowed directories if not filepath:match(\u0026#34;^/safe/path/\u0026#34;) then error(\u0026#34;Access denied!\u0026#34;) end -- Proceed with reading the file end Protecting Against Common Vulnerabilities Code Injection: Avoid executing arbitrary code from untrusted sources. Buffer Overflows: Lua handles memory management internally, reducing the risk of buffer overflows. Resource Leaks: Ensure that resources like files and network connections are properly closed. Common Use Cases and Examples Example 1: Simple HTTP Server with LuaSocket -- simple_http_server.lua local socket = require(\u0026#34;socket\u0026#34;) local server = assert(socket.bind(\u0026#34;*\u0026#34;, 8080)) local ip, port = server:getsockname() print(\u0026#34;HTTP server running on \u0026#34; .. ip .. \u0026#34;:\u0026#34; .. port) while true do local client = server:accept() client:settimeout(10) local request, err = client:receive() if not err then -- Simple HTTP response local response = \u0026#34;HTTP/1.1 200 OK\\r\\n\u0026#34; .. \u0026#34;Content-Type: text/plain\\r\\n\u0026#34; .. \u0026#34;Connection: close\\r\\n\\r\\n\u0026#34; .. \u0026#34;Hello, Lua HTTP Server!\u0026#34; client:send(response) end client:close() end Run the Server:\nlua simple_http_server.lua Access via Browser:\nNavigate to http://localhost:8080/ to see \u0026ldquo;Hello, Lua HTTP Server!\u0026rdquo;\nExample 2: JSON Handling with Lua -- json_handling.lua local json = require(\u0026#34;dkjson\u0026#34;) local data = { name = \u0026#34;Lua\u0026#34;, version = \u0026#34;5.4\u0026#34;, features = {\u0026#34;lightweight\u0026#34;, \u0026#34;embeddable\u0026#34;, \u0026#34;fast\u0026#34;} } -- Encode to JSON local json_text = json.encode(data, { indent = true }) print(\u0026#34;Encoded JSON:\u0026#34;) print(json_text) -- Decode from JSON local decoded_data, pos, err = json.decode(json_text, 1, nil) if err then print(\u0026#34;Error:\u0026#34;, err) else print(\u0026#34;\\nDecoded Data:\u0026#34;) for key, value in pairs(decoded_data) do print(key, value) end end Run the Script:\nlua json_handling.lua Output:\nEncoded JSON: { \u0026#34;name\u0026#34;: \u0026#34;Lua\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;5.4\u0026#34;, \u0026#34;features\u0026#34;: [ \u0026#34;lightweight\u0026#34;, \u0026#34;embeddable\u0026#34;, \u0026#34;fast\u0026#34; ] } Decoded Data: name Lua version 5.4 features table: 0x55c7cdb4e040 Example 3: TCP Chat Server -- chat_server.lua local socket = require(\u0026#34;socket\u0026#34;) local server = assert(socket.bind(\u0026#34;*\u0026#34;, 12345)) local ip, port = server:getsockname() print(\u0026#34;Chat server running on \u0026#34; .. ip .. \u0026#34;:\u0026#34; .. port) clients = {} while true do local client = server:accept() client:settimeout(0) -- Non-blocking table.insert(clients, client) client:send(\u0026#34;Welcome to the Lua Chat Server!\\n\u0026#34;) print(\u0026#34;New client connected.\u0026#34;) end while true do for i, client in ipairs(clients) do local msg, err = client:receive() if msg then print(\u0026#34;Received:\u0026#34;, msg) -- Broadcast the message to all clients for _, other_client in ipairs(clients) do other_client:send(msg .. \u0026#34;\\n\u0026#34;) end elseif err == \u0026#34;closed\u0026#34; then table.remove(clients, i) print(\u0026#34;Client disconnected.\u0026#34;) end end socket.sleep(0.1) end Run the Server:\nlua chat_server.lua Connect Using Telnet:\ntelnet localhost 12345 Interaction:\nTrying 127.0.0.1... Connected to localhost. Escape character is \u0026#39;^]\u0026#39;. Welcome to the Lua Chat Server! Hello everyone! All connected clients will receive the \u0026ldquo;Hello everyone!\u0026rdquo; message.\nResources and Further Reading Official Documentation Lua Official Website: https://www.lua.org/ Lua Reference Manual: https://www.lua.org/manual/5.4/ Lua Users Wiki: http://lua-users.org/wiki/ LuaRocks (Package Manager): https://luarocks.org/ Books and Articles \u0026ldquo;Programming in Lua\u0026rdquo; by Roberto Ierusalimschy The definitive book on Lua, written by the language\u0026rsquo;s principal architect. \u0026ldquo;Lua 5.3 Reference Manual\u0026rdquo; by Roberto Ierusalimschy Comprehensive reference guide covering all aspects of Lua 5.3. \u0026ldquo;Lua Programming Gems\u0026rdquo; edited by Luiz Henrique de Figueiredo, Waldemar Celes, and Rogerio Viana A collection of articles and tutorials on advanced Lua programming topics. Online Tutorials and Courses Lua Tutorial by TutorialsPoint: https://www.tutorialspoint.com/lua/ Learn Lua in Y Minutes: https://learnxinyminutes.com/docs/lua/ Codecademy Lua Course: https://www.codecademy.com/learn/learn-lua Coursera Lua Courses: Search for Lua-related courses on Coursera. Community and Support Stack Overflow: https://stackoverflow.com/questions/tagged/lua Reddit r/lua: https://www.reddit.com/r/lua/ Lua Mailing Lists: https://www.lua.org/community.html Lua Users Forum: http://lua-users.org/forum/ GitHub Lua Repositories: Explore and contribute to Lua projects on GitHub. Conclusion Lua is a versatile and efficient scripting language that excels in embedding within applications, game development, web applications, and more. Its simple syntax, powerful features, and ease of integration make it a valuable tool for developers across various domains.\nThis comprehensive tutorial has covered everything from installation and basic syntax to advanced features and practical use cases. By mastering Lua, you can enhance your applications\u0026rsquo; flexibility, performance, and maintainability.\nKey Takeaways Lightweight and Fast: Lua\u0026rsquo;s minimalistic design ensures high performance and low resource consumption. Embeddable: Easily integrate Lua into C applications or extend Lua with C modules for enhanced functionality. Powerful Data Structures: Utilize tables for versatile data representation and manipulation. First-Class Functions and Metaprogramming: Leverage Lua\u0026rsquo;s functional programming capabilities and metatables for advanced programming paradigms. Robust Community and Resources: Benefit from a wealth of community support, libraries, and learning materials to continuously improve your Lua skills. Next Steps Practice Coding: Continuously write Lua scripts to reinforce your understanding and discover new features. Contribute to Open Source: Engage with the Lua community by contributing to open-source projects, enhancing your skills and building your portfolio. Explore Advanced Topics: Dive deeper into metatables, coroutines, and LuaJIT to unlock Lua\u0026rsquo;s full potential. Integrate with Applications: Embed Lua into your projects or use it to script configurations and automate tasks. Happy Lua Coding!\n","permalink":"https://bleedkagax.github.io/post/1_lua/","summary":"\u003ch2 id=\"introduction-to-lua\"\u003eIntroduction to Lua\u003c/h2\u003e\n\u003cp\u003eLua is a powerful, efficient, lightweight, embeddable scripting language. It is designed to be embedded in other applications, providing flexibility and extensibility. Lua is widely used in game development, embedded systems, web applications, and more due to its simple syntax, fast execution, and ease of integration.\u003c/p\u003e\n\u003ch2 id=\"what-is-lua\"\u003eWhat is Lua?\u003c/h2\u003e\n\u003ch3 id=\"key-features\"\u003eKey Features\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eLightweight and Fast:\u003c/strong\u003e Lua is designed to have a small footprint and execute rapidly, making it ideal for performance-critical applications.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEmbeddable:\u003c/strong\u003e Easily integrates with C and other programming languages, allowing developers to extend its capabilities.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSimple Syntax:\u003c/strong\u003e Clean and straightforward syntax that is easy to learn and use.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExtensible:\u003c/strong\u003e Provides powerful metaprogramming capabilities through metatables and metamethods.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePowerful Data Structures:\u003c/strong\u003e Uses tables as the primary data structure, enabling the creation of arrays, dictionaries, and more.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFirst-Class Functions:\u003c/strong\u003e Functions are first-class citizens, allowing for functional programming paradigms.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCoroutines:\u003c/strong\u003e Supports cooperative multitasking, enabling asynchronous programming.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"use-cases\"\u003eUse Cases\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eGame Development:\u003c/strong\u003e Scripting game logic, AI, and event handling.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEmbedded Systems:\u003c/strong\u003e Providing scripting capabilities within hardware devices.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWeb Development:\u003c/strong\u003e Enhancing web servers with dynamic content generation (e.g., OpenResty).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eConfiguration:\u003c/strong\u003e Scriptable configuration files for applications and services.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eData Processing:\u003c/strong\u003e Handling data transformations and manipulations.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"prerequisites\"\u003ePrerequisites\u003c/h2\u003e\n\u003cp\u003eBefore diving into Lua, ensure you have the following:\u003c/p\u003e","title":"Lua"},{"content":"Introduction to Nginx Nginx (pronounced as \u0026ldquo;Engine-X\u0026rdquo;) is a high-performance, open-source web server, reverse proxy server, and email (IMAP/POP3) proxy server. It is renowned for its ability to handle high concurrency, low memory usage, and exceptional speed, making it a popular choice for serving both static and dynamic content on the web.\nWhat is Nginx? Key Features High Performance: Ability to handle thousands of concurrent connections with minimal memory footprint. Reverse Proxying: Acts as an intermediary for requests from clients seeking resources from servers. Load Balancing: Distributes incoming traffic across multiple servers to ensure reliability and uptime. SSL/TLS Support: Provides secure connections using SSL/TLS protocols. Caching: Reduces server load and improves response times by caching responses from backend servers. Modular Architecture: Supports dynamic modules to extend its functionality. Static and Dynamic Content Serving: Efficiently serves static files and dynamically generated content. Use Cases Web Servers: Serving websites and web applications. Reverse Proxy: Forwarding requests to application servers like Node.js, Python, Ruby, etc. Load Balancer: Distributing traffic across multiple backend servers. API Gateway: Managing and routing API requests. Content Caching: Storing frequently accessed content to enhance performance. Prerequisites Before diving into Nginx, ensure you have the following:\nBasic Understanding of Web Servers: Familiarity with how web servers work. Command-Line Proficiency: Comfortable using the terminal/command prompt. Basic Networking Knowledge: Understanding of concepts like IP addresses, DNS, HTTP/HTTPS. Root/Sudo Access: Required for installing and configuring Nginx on servers. Installation Installing on Ubuntu/Debian Update Package List\nsudo apt update Install Nginx\nsudo apt install nginx Start and Enable Nginx\nsudo systemctl start nginx sudo systemctl enable nginx Verify Installation\nOpen your web browser and navigate to http://your_server_ip/. You should see the Nginx default welcome page.\nInstalling on CentOS/RHEL Install EPEL Repository\nsudo yum install epel-release -y Install Nginx\nsudo yum install nginx -y Start and Enable Nginx\nsudo systemctl start nginx sudo systemctl enable nginx Adjust Firewall\nAllow HTTP and HTTPS traffic.\nsudo firewall-cmd --permanent --add-service=http sudo firewall-cmd --permanent --add-service=https sudo firewall-cmd --reload Verify Installation\nNavigate to http://your_server_ip/ in your browser to see the Nginx default page.\nInstalling on macOS You can install Nginx on macOS using Homebrew.\nInstall Homebrew (if not already installed)\n/bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34; Install Nginx\nbrew install nginx Start Nginx\nbrew services start nginx Verify Installation\nOpen http://localhost:8080/ in your web browser to see the Nginx welcome page.\nBuilding from Source Building Nginx from source allows customization by enabling specific modules.\nInstall Dependencies\nsudo apt update sudo apt install -y build-essential libpcre3 libpcre3-dev zlib1g zlib1g-dev libssl-dev Download Nginx Source Code\nwget http://nginx.org/download/nginx-1.21.6.tar.gz tar -zxvf nginx-1.21.6.tar.gz cd nginx-1.21.6/ Configure Nginx\n./configure --prefix=/usr/local/nginx --with-http_ssl_module --prefix: Installation directory. --with-http_ssl_module: Enables SSL support. Compile and Install\nmake sudo make install Start Nginx\nsudo /usr/local/nginx/sbin/nginx Verify Installation\nVisit http://your_server_ip/ to see the Nginx welcome page.\nBasic Configuration Nginx Configuration File Structure Nginx configuration files are typically located at /etc/nginx/nginx.conf on Unix-based systems. The primary configuration is divided into several blocks:\nMain Context: Global settings. Events Block: Handles connection-related settings. HTTP Block: Configures web server settings, including server blocks. Server Blocks: Define virtual hosts/sites. Location Blocks: Specify how to handle different request URIs. Understanding the nginx.conf File Here is a breakdown of a typical nginx.conf file:\nuser www-data; worker_processes auto; pid /run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; # Logging access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; # Gzip Compression gzip on; gzip_types text/plain application/xml text/css application/javascript; # Server Block server { listen 80; server_name example.com www.example.com; root /var/www/html; index index.html index.htm index.nginx-debian.html; location / { try_files $uri $uri/ =404; } # Additional configurations... } # Additional server blocks... } Main Context: Sets user permissions, worker processes, and PID file location. Events Block: Configures connection-related settings like worker_connections. HTTP Block: Contains settings related to handling HTTP requests, including MIME types, logging, compression, and server blocks. Server Block: Defines settings for a virtual host, including ports, server names, root directory, index files, and location handling. Serving Static Content One of the fundamental uses of Nginx is to serve static files efficiently.\nBasic Server Block Here\u0026rsquo;s a simple server block configured to serve static content:\nserver { listen 80; server_name your_domain.com; root /var/www/your_domain; index index.html index.htm; location / { try_files $uri $uri/ =404; } } Setting Up Root and Index Files root: Specifies the root directory where your website files are located. index: Defines the default file to serve when a directory is requested. Example:\nserver { listen 80; server_name example.com; root /usr/share/nginx/html; index index.html index.htm; location / { try_files $uri $uri/ =404; } } Handling Dynamic Content Nginx can also handle dynamic content by forwarding requests to application servers.\nProxying Requests to Application Servers Use the proxy_pass directive to forward requests to backend servers like Node.js, Python, Ruby, etc.\nExample: Proxying to a Node.js Server\nserver { listen 80; server_name your_domain.com; location / { proxy_pass http://localhost:3000; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#39;upgrade\u0026#39;; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; } } Explanation:\nproxy_pass: Forwards all requests to the specified backend server. proxy_set_header: Sets custom headers to maintain the original client details and support WebSockets. proxy_cache_bypass: Ensures that cached content is bypassed when necessary. FastCGI and PHP Integration Nginx can serve PHP applications using FastCGI processors like PHP-FPM.\nExample: Configuring Nginx to Serve PHP with PHP-FPM\nInstall PHP and PHP-FPM\nsudo apt install php-fpm Configure Nginx Server Block\nserver { listen 80; server_name your_domain.com; root /var/www/your_domain; index index.php index.html index.htm; location / { try_files $uri $uri/ =404; } # Pass PHP scripts to FastCGI server location ~ \\.php$ { include snippets/fastcgi-php.conf; fastcgi_pass unix:/var/run/php/php7.4-fpm.sock; } # Deny access to .htaccess files location ~ /\\.ht { deny all; } } Explanation:\nlocation ~ .php$: Matches PHP files. include snippets/fastcgi-php.conf: Includes default FastCGI parameters. fastcgi_pass: Specifies the FastCGI server address and socket. deny all: Denies access to hidden files like .htaccess. Load Balancing Nginx can distribute incoming traffic across multiple backend servers to ensure reliability and improve performance.\nBasic Load Balancing Methods Round Robin (Default Method)\nDistributes requests sequentially across the backend servers.\nhttp { upstream backend { server backend1.example.com; server backend2.example.com; server backend3.example.com; } server { listen 80; server_name your_domain.com; location / { proxy_pass http://backend; } } } Least Connections\nSends requests to the server with the fewest active connections.\nhttp { upstream backend { least_conn; server backend1.example.com; server backend2.example.com; server backend3.example.com; } server { listen 80; server_name your_domain.com; location / { proxy_pass http://backend; } } } Explanation:\nleast_conn: Nginx directive to enable least connections load balancing. IP Hash\nEnsures that requests from the same client IP are always directed to the same backend server.\nhttp { upstream backend { ip_hash; server backend1.example.com; server backend2.example.com; server backend3.example.com; } server { listen 80; server_name your_domain.com; location / { proxy_pass http://backend; } } } Explanation:\nip_hash: Nginx directive to enable IP hash load balancing. Advanced Load Balancing Techniques Session Persistence\nEnsures that a user\u0026rsquo;s session is consistently routed to the same backend server.\nhttp { upstream backend { server backend1.example.com; server backend2.example.com; server backend3.example.com; } server { listen 80; server_name your_domain.com; location / { proxy_pass http://backend; proxy_set_header Cookie $http_cookie; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } } Explanation:\nproxy_set_header Cookie $http_cookie: Passes cookies to maintain session persistence. Health Checks\nAutomatically detects and removes unhealthy backend servers from the rotation.\nhttp { upstream backend { server backend1.example.com; server backend2.example.com; server backend3.example.com; # Health check parameters keepalive 32; } server { listen 80; server_name your_domain.com; location / { proxy_pass http://backend; proxy_http_version 1.1; proxy_set_header Connection \u0026#34;\u0026#34;; } } } Note: Nginx core does not support active health checks. For active health checks, consider using the Nginx Plus version or integrating with external tools like Consul.\nDynamic Load Balancing with Variables\nUse variables to dynamically select backend servers based on request attributes.\nhttp { upstream backend { server backend1.example.com; server backend2.example.com; } server { listen 80; server_name your_domain.com; location / { set $backend \u0026#34;\u0026#34;; if ($arg_site = \u0026#34;site1\u0026#34;) { set $backend \u0026#34;backend1.example.com\u0026#34;; } if ($arg_site = \u0026#34;site2\u0026#34;) { set $backend \u0026#34;backend2.example.com\u0026#34;; } proxy_pass http://$backend; } } } Security Best Practices Securing your Nginx server is crucial to protect your web applications and data.\nSSL/TLS Configuration Implement SSL/TLS to encrypt data between clients and your server.\nObtain SSL Certificates\nUsing Let\u0026rsquo;s Encrypt: Free SSL certificates via Certbot.\nsudo apt install certbot python3-certbot-nginx sudo certbot --nginx -d your_domain.com -d www.your_domain.com Configure SSL in Nginx\nserver { listen 443 ssl; server_name your_domain.com www.your_domain.com; ssl_certificate /etc/letsencrypt/live/your_domain.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/your_domain.com/privkey.pem; ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers HIGH:!aNULL:!MD5; location / { proxy_pass http://backend; # Additional proxy settings... } } server { listen 80; server_name your_domain.com www.your_domain.com; return 301 https://$host$request_uri; } Explanation:\nlisten 443 ssl;: Listens for HTTPS connections. ssl_certificate: Path to the SSL certificate. ssl_certificate_key: Path to the SSL certificate key. ssl_protocols: Specifies allowed TLS protocols. ssl_ciphers: Defines strong ciphers. Enable HTTP/2\nserver { listen 443 ssl http2; server_name your_domain.com www.your_domain.com; ssl_certificate /etc/letsencrypt/live/your_domain.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/your_domain.com/privkey.pem; ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers HIGH:!aNULL:!MD5; location / { proxy_pass http://backend; # Additional proxy settings... } } Explanation:\nhttp2: Enables HTTP/2 protocol for improved performance. Restricting Access Control access to sensitive resources and restrict unwanted traffic.\nRestrict Access by IP Address\nserver { listen 80; server_name your_domain.com; location /admin { allow 192.168.1.0/24; deny all; proxy_pass http://admin_backend; } location / { proxy_pass http://backend; } } Explanation:\nallow 192.168.1.0/24;: Allows access from the specified IP range. deny all;: Denies access to all other IPs. Password Protection with HTTP Basic Auth\nsudo apt install apache2-utils sudo htpasswd -c /etc/nginx/.htpasswd user1 Explanation:\napache2-utils: Provides htpasswd utility to create password files. htpasswd -c /etc/nginx/.htpasswd user1: Creates a new password file and adds user1. Nginx Configuration:\nserver { listen 80; server_name your_domain.com; location /secure { auth_basic \u0026#34;Restricted Area\u0026#34;; auth_basic_user_file /etc/nginx/.htpasswd; proxy_pass http://secure_backend; } location / { proxy_pass http://backend; } } Explanation:\nauth_basic: Enables basic authentication with a realm name. auth_basic_user_file: Specifies the path to the password file. Preventing Common Attacks DDoS Protection\nImplement rate limiting to mitigate DDoS attacks.\nhttp { limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; server { listen 80; server_name your_domain.com; location / { limit_req zone=one burst=5 nodelay; proxy_pass http://backend; } } } Explanation:\nlimit_req_zone: Defines a shared memory zone named one with a rate of 1 request per second. limit_req: Applies the rate limit to requests in the specified location. Preventing Clickjacking\nAdd X-Frame-Options header to prevent the website from being framed.\nserver { listen 80; server_name your_domain.com; add_header X-Frame-Options \u0026#34;SAMEORIGIN\u0026#34; always; location / { proxy_pass http://backend; } } Explanation:\nadd_header X-Frame-Options \u0026ldquo;SAMEORIGIN\u0026rdquo; always;: Prevents the site from being embedded in iframes from different origins. Content Security Policy (CSP)\nDefine a CSP to prevent cross-site scripting (XSS) and other code injection attacks.\nserver { listen 80; server_name your_domain.com; add_header Content-Security-Policy \u0026#34;default-src \u0026#39;self\u0026#39;; script-src \u0026#39;self\u0026#39; https://cdnjs.cloudflare.com;\u0026#34; always; location / { proxy_pass http://backend; } } Explanation:\nadd_header Content-Security-Policy: Sets the CSP header to restrict sources of content. Performance Optimization Enhance Nginx\u0026rsquo;s performance to handle high traffic efficiently.\nCaching Implement caching strategies to reduce server load and improve response times.\nProxy Caching\nCache responses from backend servers.\nConfiguration:\nhttp { proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m use_temp_path=off; server { listen 80; server_name your_domain.com; location /api/ { proxy_cache my_cache; proxy_pass http://backend; proxy_cache_valid 200 302 10m; proxy_cache_valid 404 1m; proxy_cache_use_stale error timeout updating; add_header X-Proxy-Cache $upstream_cache_status; } } } Explanation:\nproxy_cache_path: Defines cache storage path and parameters. proxy_cache: Enables caching for the specified location. proxy_cache_valid: Sets cache duration based on response statuses. proxy_cache_use_stale: Serves stale content under specific conditions. add_header X-Proxy-Cache: Adds a header indicating cache status. FastCGI Caching\nCache responses from FastCGI servers like PHP-FPM.\nConfiguration:\nhttp { fastcgi_cache_path /var/cache/nginx levels=1:2 keys_zone=fastcgi_cache:10m inactive=60m use_temp_path=off; server { listen 80; server_name your_domain.com; location ~ \\.php$ { fastcgi_pass unix:/var/run/php/php7.4-fpm.sock; include fastcgi_params; fastcgi_cache fastcgi_cache; fastcgi_cache_valid 200 302 10m; fastcgi_cache_valid 404 1m; fastcgi_cache_use_stale error timeout updating; add_header X-FastCGI-Cache $upstream_cache_status; } } } Explanation:\nfastcgi_cache_path: Defines FastCGI cache storage path and parameters. fastcgi_cache: Enables FastCGI caching for the specified location. Gzip Compression Enable gzip compression to reduce the size of responses and improve load times.\nConfiguration:\nhttp { gzip on; gzip_disable \u0026#34;msie6\u0026#34;; gzip_vary on; gzip_proxied any; gzip_comp_level 6; gzip_buffers 16 8k; gzip_http_version 1.1; gzip_types text/plain application/xml text/css application/javascript image/svg+xml; } Explanation:\ngzip on;: Enables gzip compression. gzip_disable \u0026ldquo;msie6\u0026rdquo;;: Disables gzip for old browsers. gzip_vary on;: Adds Vary: Accept-Encoding header. gzip_comp_level: Sets compression level (1-9). gzip_buffers: Defines buffer size for compression. gzip_http_version: Minimum HTTP version for gzip. gzip_types: Specifies MIME types to compress. Buffer Adjustments Adjust buffer sizes to optimize request and response handling.\nExample:\nhttp { client_max_body_size 50M; client_body_buffer_size 128k; large_client_header_buffers 4 16k; client_body_timeout 12; client_header_timeout 12; send_timeout 10; } Explanation:\nclient_max_body_size: Limits the maximum allowed size of the client request body. client_body_buffer_size: Sets the buffer size for reading client request body. large_client_header_buffers: Defines buffers for large client headers. client_body_timeout, client_header_timeout, send_timeout: Sets timeouts for reading client requests and sending responses. Rate Limiting Control the rate of incoming requests to prevent abuse and ensure quality of service.\nExample: Rate Limiting Using Shared Memory Zones\nhttp { limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; server { listen 80; server_name your_domain.com; location /api/ { limit_req zone=one burst=5 nodelay; proxy_pass http://backend; } } } Explanation:\nlimit_req_zone: Defines a shared memory zone for rate limiting based on the client IP. limit_req: Applies rate limiting to the specified location. Monitoring and Logging Effective monitoring and logging are essential for maintaining and troubleshooting your Nginx server.\nAccess Logs Access logs record all incoming requests, providing valuable insights into traffic patterns and user behavior.\nConfiguration:\nhttp { log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; } Explanation:\nlog_format: Defines the format of the log entries. access_log: Specifies the location and format of the access log. Error Logs Error logs capture server-side errors and issues, aiding in diagnosis and troubleshooting.\nConfiguration:\nhttp { error_log /var/log/nginx/error.log warn; } Explanation:\nerror_log: Specifies the location and log level (debug, info, notice, warn, error, crit, alert, emerg). Real-time Monitoring with ngx_http_stub_status_module The ngx_http_stub_status_module provides a simple status page displaying basic server metrics.\nConfiguration:\nEnable the Status Module\nEnsure the module is included during Nginx compilation. Most pre-built Nginx packages include this module by default.\nConfigure the Status Page\nserver { listen 8080; server_name localhost; location /nginx_status { stub_status; allow 127.0.0.1; # Allow only local access deny all; } } Access the Status Page\nNavigate to http://localhost:8080/nginx_status to view real-time metrics:\nActive connections: 291 server accepts handled requests 1526989 1526989 2983949 Reading: 12 Writing: 34 Waiting: 245 Explanation:\nActive connections: Current active connections. accepts/handled/requests: Total accepted, handled, and processed requests. Reading/Writing/Waiting: State of connections. Advanced Features Explore advanced functionalities of Nginx to streamline and enhance your web server capabilities.\nReverse Proxy Implementing Nginx as a reverse proxy allows it to handle all client requests and distribute them to appropriate backend servers.\nExample: Reverse Proxy Setup\nserver { listen 80; server_name your_domain.com; location / { proxy_pass http://backend_server; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } } Explanation:\nproxy_pass: Forwards requests to the specified backend server. proxy_set_header: Sets headers to preserve client information. Using Nginx as a Mail Proxy Nginx can function as a mail proxy for IMAP, POP3, and SMTP protocols.\nConfiguration Example for IMAP Proxy\nmail { server { listen 143; protocol imap; proxy_pass_error_message on; auth_http localhost:8080/auth; } } Explanation:\nmail: Defines mail-related configurations. server: Configures the mail server. listen: Specifies the port and protocol. proxy_pass_error_message: Enables forwarding of error messages from the backend. auth_http: Defines the authentication server. WebSockets Support Enable real-time, bidirectional communication using WebSockets.\nConfiguration Example: WebSockets with Nginx\nserver { listen 80; server_name your_domain.com; location /ws { proxy_pass http://backend_server; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;Upgrade\u0026#34;; proxy_set_header Host $host; } } Explanation:\nproxy_http_version 1.1: Sets HTTP version to 1.1 to support WebSockets. proxy_set_header Upgrade $http_upgrade;: Passes the Upgrade header. proxy_set_header Connection \u0026ldquo;Upgrade\u0026rdquo;;: Maintains the connection upgrade. HTTP/2 Support Implement HTTP/2 for improved performance with features like multiplexing, header compression, and server push.\nConfiguration Example: Enabling HTTP/2\nserver { listen 443 ssl http2; server_name your_domain.com; ssl_certificate /etc/ssl/certs/your_domain.com.crt; ssl_certificate_key /etc/ssl/private/your_domain.com.key; location / { proxy_pass http://backend; } } Explanation:\nhttp2: Enables HTTP/2 protocol on the listen directive. ssl_certificate \u0026amp; ssl_certificate_key: Required for HTTPS and HTTP/2. Automation with Nginx Automate configuration management and deployments to streamline operations.\nAutomated Configuration Reloads Automatically reload Nginx configurations without downtime.\nUsing nginx -t and nginx -s reload\nsudo nginx -t \u0026amp;\u0026amp; sudo nginx -s reload Explanation:\nnginx -t: Tests the configuration for syntax errors. nginx -s reload: Reloads Nginx without stopping the service. Integration with CI/CD Pipelines Integrate Nginx configuration deployments into CI/CD workflows for seamless updates.\nExample: GitLab CI/CD Configuration (.gitlab-ci.yml)\nstages: - test - deploy test_config: stage: test script: - sudo nginx -t only: - master deploy_production: stage: deploy script: - sudo nginx -s reload only: - master - tags Explanation:\ntest_config: Tests Nginx configuration on commit to master. deploy_production: Reloads Nginx after successful tests. Troubleshooting Identify and resolve common Nginx issues to maintain a healthy web server.\nCommon Issues and Solutions Nginx Not Starting\nCheck Configuration Syntax:\nsudo nginx -t Inspect Error Logs:\nsudo tail -f /var/log/nginx/error.log Solution: Fix any syntax errors or conflicts in the configuration file.\n403 Forbidden Error\nCause: Incorrect file permissions or missing index file.\nSolution: Ensure Nginx has read permissions to the root directory and that an index file exists.\nsudo chown -R www-data:www-data /var/www/your_domain sudo chmod -R 755 /var/www/your_domain 502 Bad Gateway\nCause: Backend server is down or misconfigured. Solution: Verify the backend server is running and accessible. Check Nginx proxy settings. 504 Gateway Timeout\nCause: Backend server is taking too long to respond.\nSolution: Increase timeout settings in Nginx and ensure backend server performance.\nlocation / { proxy_pass http://backend; proxy_read_timeout 300; proxy_connect_timeout 300; proxy_send_timeout 300; } Debugging Techniques Enable Debug Logging\nModify the error_log directive to include debug information.\nerror_log /var/log/nginx/error.log debug; Note: Debug logging can generateå¤§é‡æ—¥å¿—æ•°æ®ï¼Œåº”è°¨æ…ä½¿ç”¨ï¼Œé¿å…åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å¯ç”¨ã€‚\nUse curl for Testing\nTest server responses and behavior using curl.\ncurl -I http://your_domain.com/ curl -v http://your_domain.com/api Analyze Access Logs\nReview access logs to understand traffic patterns and identify anomalies.\nsudo tail -f /var/log/nginx/access.log Check System Resources\nEnsure the server has sufficient resources (CPU, memory, disk I/O).\ntop df -h Extending Nginx with Modules Enhance Nginxâ€™s capabilities by integrating additional modules.\nThird-Party Modules ngx_brotli\nAdds Brotli compression to Nginx.\nInstallation:\nClone the module repository.\ngit clone https://github.com/google/ngx_brotli.git cd ngx_brotli git submodule update --init Recompile Nginx with the module.\n./configure --add-module=/path/to/ngx_brotli make sudo make install ngx_pagespeed\nOptimizes web pages by automatically applying best practices.\nInstallation:\nDownload Pagespeed module.\nwget https://dl.google.com/dl/page-speed/psol/1.13.35.2-x64.tar.gz tar -xzvf 1.13.35.2-x64.tar.gz Recompile Nginx with Pagespeed.\n./configure --add-module=/path/to/ngx_pagespeed-1.13.35.2-beta make sudo make install Note: Third-party modules require recompiling Nginx from source. Consider using dynamic modules if supported.\nCustom Module Development Develop custom modules to extend Nginx functionality specific to your needs.\nUnderstand Nginx Module Architecture\nHandler Directives: Define how requests are processed. Configuration Directives: Customize module behavior. Context Types: Specify where directives can appear (http, server, location). Set Up Development Environment\nInstall development dependencies. Familiarize yourself with Nginx internals. Create a Basic Module\nExample: Hello World Module\n#include \u0026lt;ngx_config.h\u0026gt; #include \u0026lt;ngx_core.h\u0026gt; #include \u0026lt;ngx_http.h\u0026gt; static char *ngx_http_hello_world(ngx_conf_t *cf, ngx_command_t *cmd, void *conf); static ngx_int_t ngx_http_handler(ngx_http_request_t *r); static ngx_command_t ngx_http_hello_world_commands[] = { { ngx_string(\u0026#34;hello_world\u0026#34;), NGX_HTTP_MAIN_CONF | NGX_CONF_NOARGS, ngx_http_hello_world, 0, 0, NULL }, ngx_null_command }; static ngx_http_module_t ngx_http_hello_world_module_ctx = { NULL, // preconfiguration NULL, // postconfiguration NULL, // create main configuration NULL, // init main configuration NULL, // create server configuration NULL, // merge server configuration NULL, // create location configuration NULL // merge location configuration }; ngx_module_t ngx_http_hello_world_module = { NGX_MODULE_V1, \u0026amp;ngx_http_hello_world_module_ctx, ngx_http_hello_world_commands, NGX_HTTP_MODULE, NULL, // init master NULL, // init module NULL, // init process NULL, // init thread NULL, // exit thread NULL, // exit process NULL, // exit master NGX_MODULE_V1_PADDING }; static char *ngx_http_hello_world(ngx_conf_t *cf, ngx_command_t *cmd, void *conf) { ngx_http_core_loc_conf_t *clcf; // Get the core location config clcf = ngx_http_conf_get_module_loc_conf(cf, ngx_http_core_module); // Set the handler clcf-\u0026gt;handler = ngx_http_handler; return NGX_CONF_OK; } static ngx_int_t ngx_http_handler(ngx_http_request_t *r) { if (!(r-\u0026gt;method \u0026amp; NGX_HTTP_GET)) { return NGX_HTTP_NOT_ALLOWED; } ngx_str_t response = ngx_string(\u0026#34;Hello, Nginx Module!\u0026#34;); // Set response headers ngx_table_elt_t *h; h = ngx_list_push(\u0026amp;r-\u0026gt;headers_out.headers); if (h == NULL) { return NGX_HTTP_INTERNAL_SERVER_ERROR; } h-\u0026gt;key.len = sizeof(\u0026#34;Content-Type\u0026#34;) - 1; h-\u0026gt;key.data = (u_char *) \u0026#34;Content-Type\u0026#34;; h-\u0026gt;value.len = sizeof(\u0026#34;text/plain\u0026#34;) - 1; h-\u0026gt;value.data = (u_char *) \u0026#34;text/plain\u0026#34;; r-\u0026gt;headers_out.status = NGX_HTTP_OK; r-\u0026gt;headers_out.content_length_n = response.len; r-\u0026gt;headers_out.content_type = h-\u0026gt;value; // Send headers ngx_int_t rc = ngx_http_send_header(r); if (rc == NGX_ERROR || rc \u0026gt; NGX_OK || r-\u0026gt;header_only) { return rc; } // Create buffer ngx_buf_t *b = ngx_pcalloc(r-\u0026gt;pool, sizeof(ngx_buf_t)); if (b == NULL) { return NGX_HTTP_INTERNAL_SERVER_ERROR; } b-\u0026gt;pos = response.data; b-\u0026gt;last = response.data + response.len; b-\u0026gt;memory = 1; // content is in memory b-\u0026gt;last_buf = 1; // this is the last buffer in the response // Create chain link ngx_chain_t out; out.buf = b; out.next = NULL; return ngx_http_output_filter(r, \u0026amp;out); } Compile Nginx with the Custom Module\nDownload Nginx Source\nwget http://nginx.org/download/nginx-1.21.6.tar.gz tar -zxvf nginx-1.21.6.tar.gz cd nginx-1.21.6/ Copy Custom Module\nSave the custom module as ngx_http_hello_world_module.c in the Nginx source directory.\nConfigure Nginx with the Custom Module\n./configure --add-module=./ngx_http_hello_world_module make sudo make install Update Nginx Configuration to Use the Module\nserver { listen 80; server_name your_domain.com; location /hello { hello_world; } } Restart Nginx\nsudo nginx -s reload Test the Module\nNavigate to http://your_domain.com/hello and you should see \u0026ldquo;Hello, Nginx Module!\u0026rdquo; displayed.\nBenefits of Extending Nginx with Modules Customized Functionality: Tailor Nginx to meet specific application requirements. Enhanced Performance: Optimize request handling and processing. Improved Security: Implement custom security measures and protocols. Scalability: Introduce features that facilitate the scaling of web services. Resources and Further Reading Official Documentation Nginx Official Site: https://nginx.org/ Nginx Documentation: https://nginx.org/en/docs/ Nginx Wiki: https://www.nginx.com/resources/wiki/ Nginx Blog: https://www.nginx.com/blog/ Books and Articles \u0026ldquo;Nginx: A Practical Guide to High Performance\u0026rdquo; by Stephen Corona \u0026ldquo;Mastering Nginx\u0026rdquo; by Dimitri Aivaliotis \u0026ldquo;Nginx Cookbook\u0026rdquo; by Derek DeJonghe \u0026ldquo;Nginx Essentials\u0026rdquo; by Arun Kumar Maheshwari Official Nginx Blog Articles: Regularly updated with best practices and case studies. Online Tutorials and Courses DigitalOcean Nginx Tutorials: https://www.digitalocean.com/community/tags/nginx TutorialsPoint Nginx Tutorial: https://www.tutorialspoint.com/nginx/index.htm Udemy Nginx Courses: https://www.udemy.com/topic/nginx/ Coursera Web Server Management Courses: Search for Nginx-related courses. Community and Support Nginx Forums: https://forum.nginx.org/ Stack Overflow: Tag questions with nginx to get help from the community. Reddit r/nginx: https://www.reddit.com/r/nginx/ Nginx Slack: Join the official Nginx Slack workspace for real-time discussions (requires invitation). GitHub Issues: Report bugs or request features in the Nginx GitHub repository. Conclusion Nginx is a versatile and powerful tool that plays a pivotal role in modern web infrastructure. From serving high-traffic websites to acting as a robust reverse proxy and load balancer, its capabilities are extensive and continually evolving.\nThis comprehensive tutorial has walked you through the essential aspects of Nginx, including installation, configuration, security, performance optimization, and extending its functionality with modules. By mastering these concepts and practices, you can effectively harness Nginx to build scalable, high-performance, and secure web services.\nKey Takeaways Installation \u0026amp; Setup: Installing Nginx is straightforward across various operating systems, with comprehensive configuration options available. Configuration Mastery: Understanding the configuration file structure and directives is crucial for tailoring Nginx to your specific needs. Performance \u0026amp; Security: Implementing best practices in caching, compression, SSL/TLS, and access controls ensures optimal performance and robust security. Extensibility: Leveraging Nginxâ€™s modular architecture allows for customized enhancements and integrations, catering to a wide array of use cases. Continuous Learning: Nginx is continuously updated with new features and improvements. Staying abreast with official documentation, community discussions, and advanced topics will further deepen your expertise. Happy Nginx-ing!\n","permalink":"https://bleedkagax.github.io/post/0_nginx/","summary":"\u003ch2 id=\"introduction-to-nginx\"\u003eIntroduction to Nginx\u003c/h2\u003e\n\u003cp\u003eNginx (pronounced as \u0026ldquo;Engine-X\u0026rdquo;) is a high-performance, open-source web server, reverse proxy server, and email (IMAP/POP3) proxy server. It is renowned for its ability to handle high concurrency, low memory usage, and exceptional speed, making it a popular choice for serving both static and dynamic content on the web.\u003c/p\u003e\n\u003ch2 id=\"what-is-nginx\"\u003eWhat is Nginx?\u003c/h2\u003e\n\u003ch3 id=\"key-features\"\u003eKey Features\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eHigh Performance:\u003c/strong\u003e Ability to handle thousands of concurrent connections with minimal memory footprint.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReverse Proxying:\u003c/strong\u003e Acts as an intermediary for requests from clients seeking resources from servers.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLoad Balancing:\u003c/strong\u003e Distributes incoming traffic across multiple servers to ensure reliability and uptime.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSSL/TLS Support:\u003c/strong\u003e Provides secure connections using SSL/TLS protocols.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCaching:\u003c/strong\u003e Reduces server load and improves response times by caching responses from backend servers.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eModular Architecture:\u003c/strong\u003e Supports dynamic modules to extend its functionality.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStatic and Dynamic Content Serving:\u003c/strong\u003e Efficiently serves static files and dynamically generated content.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"use-cases\"\u003eUse Cases\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eWeb Servers:\u003c/strong\u003e Serving websites and web applications.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReverse Proxy:\u003c/strong\u003e Forwarding requests to application servers like Node.js, Python, Ruby, etc.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLoad Balancer:\u003c/strong\u003e Distributing traffic across multiple backend servers.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAPI Gateway:\u003c/strong\u003e Managing and routing API requests.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eContent Caching:\u003c/strong\u003e Storing frequently accessed content to enhance performance.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"prerequisites\"\u003ePrerequisites\u003c/h2\u003e\n\u003cp\u003eBefore diving into Nginx, ensure you have the following:\u003c/p\u003e","title":"Nginx"},{"content":"Introduction to OpenResty OpenResty is a dynamic web platform that integrates Nginx with the powerful Lua scripting language. It is designed to build scalable web applications, web services, and dynamic web gateways. By combining the high performance of Nginx with the flexibility of Lua, OpenResty enables developers to handle complex processing at the edge of the network.\nWhat is OpenResty? OpenResty extends Nginx by bundling it with a set of powerful Lua libraries and modules (known as LuaJIT). This allows embedding Lua scripts directly into the Nginx configuration, offering unparalleled flexibility for customizing request handling, routing, and response generation.\nKey Features High Performance: Leverages Nginx\u0026rsquo;s event-driven architecture and LuaJIT\u0026rsquo;s speed for efficient request handling. Flexibility: Lua scripting enables dynamic content generation, complex routing, and custom logic. Extensibility: Easily integrates with various databases, caching systems, and other backend services. Modular Architecture: OpenResty modules simplify common tasks like routing, authentication, and data processing. Prerequisites Before diving into OpenResty, ensure you have the following:\nBasic Knowledge of Nginx: Understanding Nginxâ€™s configuration and request-handling mechanisms. Familiarity with Lua: Basic knowledge of Lua programming language. Development Environment: Access to a Unix-based system (e.g., Linux or macOS) or Windows with a compatible environment. Installation Installing Dependencies Depending on your operating system, you may need to install certain dependencies before installing OpenResty.\nFor Ubuntu/Debian sudo apt-get update sudo apt-get install -y curl gnupg2 ca-certificates lsb-release For macOS Use Homebrew to install dependencies.\nbrew update brew install curl Installing OpenResty Using Official Packages (Recommended) For Ubuntu/Debian:\nAdd the OpenResty Repository:\nsudo apt-get install -y software-properties-common sudo add-apt-repository -y \u0026#34;deb https://openresty.org/package/ubuntu $(lsb_release -sc) main\u0026#34; Add the OpenResty GPG Key:\nwget -qO - https://openresty.org/package/pubkey.gpg | sudo apt-key add - Update the Package List and Install:\nsudo apt-get update sudo apt-get install -y openresty For macOS:\nUse Homebrew to install OpenResty.\nbrew install openresty/tap/openresty Building from Source Download the Source Code:\nwget https://openresty.org/download/openresty-VERSION.tar.gz tar zxvf openresty-VERSION.tar.gz cd openresty-VERSION/ Replace VERSION with the latest version number.\nConfigure and Compile:\n./configure --with-luajit make sudo make install Verifying Installation Check the installed OpenResty version.\nopenresty -v You should see output similar to:\nnginx version: openresty/1.19.3.1 Basic Configuration Understanding OpenRestyâ€™s Architecture OpenResty maintains Nginx\u0026rsquo;s event-driven, asynchronous architecture while introducing Lua scripting capabilities. The primary components include:\nNginx Core: Handles HTTP server functionality. LuaJIT: A Just-In-Time Compiler for Lua, providing high-speed execution. ngx_lua Module: Embeds Lua into Nginxâ€™s request-processing phases. Additional Modules: OpenResty bundles various modules for enhanced functionality. Configuring Nginx with Lua The configuration files for OpenResty are similar to standard Nginx configurations but include Lua directives.\nExample Configuration (/usr/local/openresty/nginx/conf/nginx.conf):\nworker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 8080; server_name localhost; location / { default_type \u0026#39;text/plain\u0026#39;; content_by_lua_block { ngx.say(\u0026#39;Hello, OpenResty!\u0026#39;) } } } } Starting OpenResty Use the following command to start the OpenResty server:\nsudo openresty -c /usr/local/openresty/nginx/conf/nginx.conf Visit http://localhost:8080/ in your browser to see the \u0026ldquo;Hello, OpenResty!\u0026rdquo; message.\nHello World Example Letâ€™s create a simple \u0026ldquo;Hello, World!\u0026rdquo; application using OpenResty.\nStep 1: Create a Configuration File Create a new configuration file or edit the existing one.\nsudo nano /usr/local/openresty/nginx/conf/nginx.conf Step 2: Add Lua Content Insert the following content within the server block.\nserver { listen 8080; server_name localhost; location /hello { default_type \u0026#39;text/plain\u0026#39;; content_by_lua_block { ngx.say(\u0026#39;Hello, World from OpenResty!\u0026#39;) } } } Step 3: Restart OpenResty sudo openresty -s reload -c /usr/local/openresty/nginx/conf/nginx.conf Step 4: Test the Endpoint Navigate to http://localhost:8080/hello to see the message.\nHandling Web Requests OpenResty excels at handling web requests with Lua scripts. Letâ€™s explore routing and processing different HTTP methods.\nRouting with Lua Implement dynamic routing using Lua.\nExample:\nserver { listen 8080; server_name localhost; location /api { content_by_lua_block { local request_path = ngx.var.uri if request_path == \u0026#34;/api/users\u0026#34; then ngx.say(\u0026#34;User List\u0026#34;) elseif request_path == \u0026#34;/api/orders\u0026#34; then ngx.say(\u0026#34;Order List\u0026#34;) else ngx.status = 404 ngx.say(\u0026#34;Not Found\u0026#34;) end } } } Processing HTTP Methods Handle different HTTP methods (GET, POST, PUT, DELETE).\nExample:\nserver { listen 8080; server_name localhost; location /api/resource { content_by_lua_block { local method = ngx.req.get_method() if method == \u0026#34;GET\u0026#34; then ngx.say(\u0026#34;Handling GET request\u0026#34;) elseif method == \u0026#34;POST\u0026#34; then ngx.say(\u0026#34;Handling POST request\u0026#34;) elseif method == \u0026#34;PUT\u0026#34; then ngx.say(\u0026#34;Handling PUT request\u0026#34;) elseif method == \u0026#34;DELETE\u0026#34; then ngx.say(\u0026#34;Handling DELETE request\u0026#34;) else ngx.status = 405 ngx.say(\u0026#34;Method Not Allowed\u0026#34;) end } } } Working with Lua in OpenResty Lua Modules and Libraries Leverage Lua modules to organize and reuse code.\nExample: Creating a Lua Module (/usr/local/openresty/lualib/my_module.lua):\n-- my_module.lua local _M = {} function _M.greet(name) return \u0026#34;Hello, \u0026#34; .. name .. \u0026#34;!\u0026#34; end return _M Using the Module in Nginx Configuration:\nserver { listen 8080; server_name localhost; location /greet { default_type \u0026#39;text/plain\u0026#39;; content_by_lua_block { local my_module = require \u0026#34;my_module\u0026#34; local message = my_module.greet(\u0026#34;OpenResty\u0026#34;) ngx.say(message) } } } Impact of LuaJIT LuaJIT is a Just-In-Time Compiler for Lua, providing significant performance improvements.\nBenefits:\nSpeed: Lua code runs at speeds comparable to C. Efficiency: Enables writing high-performance applications without sacrificing ease of development. Memory Management: Efficient memory usage, crucial for high-concurrency environments. Considerations:\nCompatibility: Ensure LuaJIT is compatible with the Lua code and libraries you intend to use. Limitations: Certain Lua features might be less efficient or unsupported; refer to LuaJIT documentation for specifics. Interacting with Databases OpenResty seamlessly integrates with databases using Lua libraries.\nConnecting to MySQL Use the lua-resty-mysql library to interact with MySQL databases.\nInstallation:\nEnsure you have LuaRocks installed, then install the library.\nsudo luarocks install lua-resty-mysql Configuration Example:\nserver { listen 8080; server_name localhost; location /users { content_by_lua_block { local mysql = require \u0026#34;resty.mysql\u0026#34; local db, err = mysql:new() if not db then ngx.say(\u0026#34;Failed to instantiate mysql: \u0026#34;, err) return end db:set_timeout(1000) -- 1 sec local ok, err, errno, sqlstate = db:connect{ host = \u0026#34;127.0.0.1\u0026#34;, port = 3306, database = \u0026#34;test_db\u0026#34;, user = \u0026#34;test_user\u0026#34;, password = \u0026#34;test_pass\u0026#34;, charset = \u0026#34;utf8\u0026#34;, max_packet_size = 1048576, } if not ok then ngx.say(\u0026#34;Failed to connect: \u0026#34;, err, \u0026#34;: \u0026#34;, errno, \u0026#34; \u0026#34;, sqlstate) return end local res, err, errno, sqlstate = db:query(\u0026#34;SELECT * FROM users\u0026#34;) if not res then ngx.say(\u0026#34;Bad result: \u0026#34;, err, \u0026#34;: \u0026#34;, errno, \u0026#34;: \u0026#34;, sqlstate, \u0026#34;.\u0026#34;) return end -- Put it into the connection pool of size 100, -- with 10 seconds max idle time local ok, err = db:set_keepalive(10000, 100) if not ok then ngx.say(\u0026#34;Failed to set keepalive: \u0026#34;, err) return end ngx.say(vim.inspect(res)) } } } Explanation:\nInstantiate MySQL Object: Create a new MySQL instance. Set Timeout: Define a timeout for the connection. Connect to Database: Provide necessary connection parameters. Execute Query: Perform SQL queries and handle results. Connection Pooling: Use set_keepalive to reuse connections. Connecting to Redis Use the lua-resty-redis library to interact with Redis.\nInstallation:\nsudo luarocks install lua-resty-redis Configuration Example:\nserver { listen 8080; server_name localhost; location /cache { content_by_lua_block { local redis = require \u0026#34;resty.redis\u0026#34; local red = redis:new() red:set_timeout(1000) -- 1 sec local ok, err = red:connect(\u0026#34;127.0.0.1\u0026#34;, 6379) if not ok then ngx.say(\u0026#34;Failed to connect: \u0026#34;, err) return end -- Optional: authenticate local res, err = red:auth(\u0026#34;your_password\u0026#34;) if not res then ngx.say(\u0026#34;Failed to authenticate: \u0026#34;, err) return end -- Set a key ok, err = red:set(\u0026#34;my_key\u0026#34;, \u0026#34;Hello, Redis!\u0026#34;) if not ok then ngx.say(\u0026#34;Failed to set key: \u0026#34;, err) return end -- Get the key res, err = red:get(\u0026#34;my_key\u0026#34;) if not res then ngx.say(\u0026#34;Failed to get key: \u0026#34;, err) return end if res == ngx.null then ngx.say(\u0026#34;Key not found.\u0026#34;) return end ngx.say(\u0026#34;Retrieved from Redis: \u0026#34;, res) -- Put it into the connection pool of size 100, -- with 10 seconds max idle time local ok, err = red:set_keepalive(10000, 100) if not ok then ngx.say(\u0026#34;Failed to set keepalive: \u0026#34;, err) return end } } } Explanation:\nInstantiate Redis Object: Create a new Redis instance. Set Timeout: Define a timeout for the connection. Connect to Redis Server: Provide Redis server address and port. Authenticate (Optional): Authenticate if Redis requires a password. Execute Commands: Perform Redis commands like SET and GET. Connection Pooling: Reuse connections using set_keepalive. Caching Strategies Implementing effective caching strategies can significantly enhance your application\u0026rsquo;s performance.\nUsing Lua for Caching Store frequently accessed data in memory to reduce database load.\nExample: Caching User Data\nserver { listen 8080; server_name localhost; location /user { content_by_lua_block { local redis = require \u0026#34;resty.redis\u0026#34; local cjson = require \u0026#34;cjson\u0026#34; local red = redis:new() red:set_timeout(1000) -- Connect to Redis local ok, err = red:connect(\u0026#34;127.0.0.1\u0026#34;, 6379) if not ok then ngx.log(ngx.ERR, \u0026#34;Failed to connect to Redis: \u0026#34;, err) ngx.exit(500) end -- Try to get user data from Redis local user_id = ngx.var.arg_id if not user_id then ngx.say(\u0026#34;User ID not provided\u0026#34;) return end local res, err = red:get(\u0026#34;user:\u0026#34; .. user_id) if res == ngx.null then -- Data not in cache, fetch from database (simulated) local user_data = { id = user_id, name = \u0026#34;John Doe\u0026#34;, email = \u0026#34;john.doe@example.com\u0026#34; } -- Simulate database delay ngx.sleep(0.1) -- Store in Redis with TTL of 60 seconds red:setex(\u0026#34;user:\u0026#34; .. user_id, 60, cjson.encode(user_data)) ngx.say(cjson.encode(user_data)) else -- Data found in cache ngx.say(res) end -- Set keepalive local ok, err = red:set_keepalive(10000, 100) if not ok then ngx.log(ngx.ERR, \u0026#34;Failed to set keepalive: \u0026#34;, err) return end } } } Explanation:\nAttempt to Retrieve Data from Redis: Check if user data is present in the Redis cache. Fetch from Database if Cache Miss: If not found, retrieve from the database (simulated here). Store Fetched Data in Redis: Cache the retrieved data with an expiration time (TTL). Respond to Client: Return the user data, either from cache or database. Utilizing Nginx Caching Leverage Nginx\u0026rsquo;s built-in caching mechanisms for static and dynamic content.\nExample: Caching Responses with proxy_cache\nhttp { proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m use_temp_path=off; server { listen 8080; server_name localhost; location /api { proxy_cache my_cache; proxy_pass http://backend_server; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; # Cache based on query parameters proxy_cache_key \u0026#34;$scheme$request_method$host$request_uri\u0026#34;; # Cache validity proxy_cache_valid 200 302 10m; proxy_cache_valid 404 1m; } } } Explanation:\nDefine Cache Path and Zone: Configure where and how Nginx stores cached data. Enable Caching in Location Block: Apply caching to specific routes or endpoints. Set Cache Keys: Define how cache entries are identified. Specify Cache Validity: Determine how long different response statuses are cached. Security Best Practices Ensuring the security of your OpenResty applications is paramount. Implement the following best practices to safeguard your applications.\nInput Validation Always validate and sanitize user inputs to prevent injections and other attacks.\nExample: Validating Query Parameters\nserver { listen 8080; server_name localhost; location /search { content_by_lua_block { local args = ngx.req.get_uri_args() local query = args.query if not query or #query \u0026lt; 3 then ngx.status = 400 ngx.say(\u0026#34;Invalid query parameter\u0026#34;) return end -- Proceed with processing ngx.say(\u0026#34;Search results for: \u0026#34;, query) } } } Securing Lua Scripts Restrict access to Lua scripts and handle errors gracefully.\nExample: Error Handling in Lua\nserver { listen 8080; server_name localhost; error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } location /data { content_by_lua_block { local status, err = pcall(function() -- Your Lua code here error(\u0026#34;Simulated error\u0026#34;) end) if not status then ngx.log(ngx.ERR, \u0026#34;Lua error: \u0026#34;, err) ngx.status = 500 ngx.say(\u0026#34;Internal Server Error\u0026#34;) end } } } Rate Limiting Prevent abuse by limiting the number of requests a client can make.\nExample: Implementing Rate Limiting with Lua\nhttp { lua_shared_dict limits 10m; server { listen 8080; server_name localhost; location /api/ { access_by_lua_block { local limit = require \u0026#34;resty.limit.req\u0026#34; local lim, err = limit.new(\u0026#34;limits\u0026#34;, 100, 200) -- 100 requests per second with burst of 200 if not lim then ngx.log(ngx.ERR, \u0026#34;failed to instantiate a resty.limit.req object: \u0026#34;, err) return ngx.exit(500) end local key = ngx.var.binary_remote_addr local delay, err = lim:incoming(key, true) if not delay then if err == \u0026#34;rejected\u0026#34; then return ngx.exit(429) end ngx.log(ngx.ERR, \u0026#34;failed to limit request: \u0026#34;, err) return ngx.exit(500) end if delay \u0026gt;= 0.001 then ngx.sleep(delay) end } proxy_pass http://backend_server; } } } Explanation:\nDefine Shared Dictionary: Allocate shared memory for storing rate-limiting data. Instantiate Rate Limiter: Use resty.limit.req to set request limits. Identify Clients: Use clientâ€™s IP address as the identifier. Enforce Limits: Allow or reject requests based on defined thresholds. Performance Optimization Optimize your OpenResty applications to handle high traffic efficiently.\nEfficient Lua Coding Write optimized Lua code to reduce execution time and memory usage.\nExample: Avoiding Unnecessary Table Creations\n-- Inefficient local function generate_users(n) local users = {} for i = 1, n do users[i] = {id = i, name = \u0026#34;User\u0026#34; .. i} end return users end -- Efficient local function generate_users(n) local users = {} for i = 1, n do users[i] = {id = i, name = \u0026#34;User\u0026#34; .. i} end return users end (Note: The above example shows a common pattern; optimize further as needed.)\nNginx Optimization Tweak Nginx settings for better performance.\nExample: Increasing Worker Connections\nworker_processes auto; events { worker_connections 4096; multi_accept on; } Explanation:\nworker_processes auto: Automatically sets the number of worker processes based on available CPU cores. worker_connections: Increases the number of simultaneous connections each worker can handle. multi_accept on: Workers accept all new connections at once, improving connection handling under heavy load. Debugging and Logging Effective debugging and logging are essential for maintaining and troubleshooting applications.\nSetting Up Logging Configure Nginx and Lua to log important events and errors.\nNginx Logging Configuration:\nhttp { log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; error_log /var/log/nginx/error.log warn; server { listen 8080; server_name localhost; location / { content_by_lua_block { ngx.log(ngx.INFO, \u0026#34;Handling request to /\u0026#34;) ngx.say(\u0026#34;Hello, OpenResty!\u0026#34;) } } } } Lua Logging:\nUse ngx.log to log messages at various levels (DEBUG, INFO, WARN, ERR, etc.).\nngx.log(ngx.INFO, \u0026#34;This is an informational message\u0026#34;) ngx.log(ngx.ERR, \u0026#34;This is an error message\u0026#34;) Debugging Lua Scripts Use LuaJITâ€™s built-in debugging tools and external libraries.\nUsing debug Library:\ncontent_by_lua_block { local function faulty_function() error(\u0026#34;Something went wrong!\u0026#34;) end local status, err = pcall(faulty_function) if not status then ngx.log(ngx.ERR, \u0026#34;Error: \u0026#34;, err) ngx.status = 500 ngx.say(\u0026#34;Internal Server Error\u0026#34;) end } External Libraries:\nLua Inspect: For inspecting variables and data structures. Mobdebug: For remote debugging with zero-brain. Example: Remote Debugging with Mobdebug\nInstall Mobdebug:\nluarocks install mobdebug Configure Lua Code:\ncontent_by_lua_block { local mobdebug = require \u0026#34;mobdebug\u0026#34; mobdebug.listen() -- Wait for debugger to connect -- Your Lua code here ngx.say(\u0026#34;Debugging OpenResty with Mobdebug\u0026#34;) } Connect Debugger:\nUse an IDE like ZeroBrane Studio to connect to Mobdebug.\nDeployment Deploy OpenResty applications efficiently to production environments.\nPreparing for Production Optimize Configuration:\nDisable unnecessary modules and logging. Fine-tune worker processes and connections. Secure the Server:\nUse HTTPS with TLS certificates. Implement firewall rules and security groups. Test Thoroughly:\nPerform load testing and stress testing. Ensure all functionalities work as expected. Managing Configuration Use environment variables and separate configuration files for different environments.\nExample: Using Environment Variables in Lua\ncontent_by_lua_block { local db_host = os.getenv(\u0026#34;DB_HOST\u0026#34;) or \u0026#34;127.0.0.1\u0026#34; local db_port = tonumber(os.getenv(\u0026#34;DB_PORT\u0026#34;)) or 3306 ngx.say(\u0026#34;Database Host: \u0026#34;, db_host) ngx.say(\u0026#34;Database Port: \u0026#34;, db_port) } Continuous Integration and Deployment (CI/CD) Automate the build, test, and deployment processes using CI/CD tools.\nExample: GitLab CI Configuration (.gitlab-ci.yml):\nstages: - build - test - deploy build: stage: build script: - echo \u0026#34;Building OpenResty application...\u0026#34; - # Add build commands here artifacts: paths: - build/ test: stage: test script: - echo \u0026#34;Running tests...\u0026#34; - # Add test commands here deploy: stage: deploy script: - echo \u0026#34;Deploying to production...\u0026#34; - ssh user@server \u0026#34;sudo systemctl restart openresty\u0026#34; only: - master Advanced Topics Microservices with OpenResty Leverage OpenResty for building microservices architectures.\nKey Considerations:\nService Isolation: Each microservice should handle a specific functionality. Inter-Service Communication: Use HTTP/HTTPS, gRPC, or message queues (e.g., Kafka) for communication between services. Service Discovery: Implement service discovery mechanisms to manage dynamic service instances. Load Balancing: Utilize Nginx\u0026rsquo;s load balancing features or service meshes like Istio. Example: Building a Simple Microservice\nserver { listen 8080; server_name localhost; location /service1 { content_by_lua_block { -- Service 1 logic ngx.say(\u0026#34;Response from Service 1\u0026#34;) } } location /service2 { content_by_lua_block { -- Service 2 logic ngx.say(\u0026#34;Response from Service 2\u0026#34;) } } } WebSockets Integration Enable real-time communication using WebSockets.\nExample: Handling WebSockets with Lua\nInstall lua-resty-websocket:\nsudo luarocks install lua-resty-websocket Configuration:\nserver { listen 8080; server_name localhost; location /ws { content_by_lua_block { local websocket = require \u0026#34;resty.websocket.server\u0026#34; local wb, err = websocket:new{ timeout = 5000, -- in milliseconds max_payload_len = 65535 } if not wb then ngx.log(ngx.ERR, \u0026#34;Failed to new websocket: \u0026#34;, err) return ngx.exit(444) end while true do local data, typ, err = wb:recv_frame() if not data then if err ~= \u0026#34;timeout\u0026#34; then ngx.log(ngx.ERR, \u0026#34;Failed to receive frame: \u0026#34;, err) wb:send_close(1002, \u0026#34;Failed to receive frame\u0026#34;) end return end if typ == \u0026#34;close\u0026#34; then local bytes, err = wb:send_close(1000) if not bytes then ngx.log(ngx.ERR, \u0026#34;Failed to send close: \u0026#34;, err) end return elseif typ == \u0026#34;ping\u0026#34; then local bytes, err = wb:send_pong() if not bytes then ngx.log(ngx.ERR, \u0026#34;Failed to send pong: \u0026#34;, err) end elseif typ == \u0026#34;pong\u0026#34; then -- handle pong elseif typ == \u0026#34;text\u0026#34; then -- Echo the received message local bytes, err = wb:send_text(data) if not bytes then ngx.log(ngx.ERR, \u0026#34;Failed to send text: \u0026#34;, err) return end elseif typ == \u0026#34;binary\u0026#34; then -- Handle binary data if needed end end } } } Explanation:\nEstablish WebSocket Connection: Upgrade the HTTP request to a WebSocket connection. Handle Frames: Receive and respond to different frame types (text, binary, ping, pong, close). Echo Messages: Echo back received text messages for demonstration. API Gateway with OpenResty Use OpenResty as an API Gateway to manage, route, and secure API traffic.\nKey Features:\nRouting and Load Balancing: Direct requests to appropriate backend services. Authentication and Authorization: Implement security measures to protect APIs. Rate Limiting: Control the rate of incoming requests. Caching and Compression: Optimize performance by caching responses and compressing data. Example: Simple API Gateway Configuration\nhttp { lua_shared_dict limits 10m; proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=my_cache:10m max_size=1g inactive=60m use_temp_path=off; server { listen 8080; server_name localhost; location /api/service1 { proxy_pass http://service1_backend; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; # Caching proxy_cache my_cache; proxy_cache_valid 200 302 10m; proxy_cache_valid 404 1m; } location /api/service2 { proxy_pass http://service2_backend; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; # Rate Limiting access_by_lua_block { -- Implement rate limiting logic } } location /auth { access_by_lua_block { -- Implement authentication logic } proxy_pass http://auth_backend; } } } Explanation:\nRouting: Direct API requests to respective backend services. Caching: Cache responses from service1_backend to improve performance. Rate Limiting: Apply rate limiting on service2_backend. Authentication: Add authentication checks for sensitive endpoints. Resources and Further Reading Official Documentation OpenResty Official Site: https://openresty.org/ OpenResty GitHub Repository: https://github.com/openresty/openresty LuaJIT Documentation: https://luajit.org/ lua-resty Libraries: https://github.com/openresty/lua-resty-* Books and Articles \u0026ldquo;OpenResty: High Performance Web Platform Using Lua\u0026rdquo; by Jay Huang \u0026ldquo;Programming OpenResty\u0026rdquo; by Noel Rappin \u0026ldquo;Mastering OpenResty\u0026rdquo; by Dr. Mai Phan and Jay Huang Online Tutorials and Courses OpenResty Tutorial by OpenResty.org: https://openresty.org/en/ OpenResty Introduction on DigitalOcean: https://www.digitalocean.com/community/tutorials/how-to-install-openresty-on-ubuntu-18-04 YouTube Video Tutorials: OpenResty Course - Understanding the Basics Advanced OpenResty Configurations Community and Support OpenResty Mailing List: Subscribe to stay updated with the latest news and updates. OpenResty Forums: Participate in discussions and seek help from the community. Stack Overflow: Tag questions with openresty or lua to get assistance. Gophers Slack: Join the Gophers Slack Workspace for real-time discussions and support. Conclusion OpenResty is a powerful platform that combines the robust capabilities of Nginx with the flexibility of Lua scripting. This comprehensive tutorial has walked you through the essentials of setting up, configuring, and optimizing OpenResty for various web applications. By mastering OpenResty, you can build high-performance, scalable, and secure web services tailored to your specific needs.\nRemember, the key to proficiency is consistent practice and active participation in the community. Leverage the resources provided, experiment with different configurations, and contribute to open-source projects to deepen your understanding and expertise in OpenResty.\nHappy Coding!\n","permalink":"https://bleedkagax.github.io/post/2_openresty/","summary":"\u003ch2 id=\"introduction-to-openresty\"\u003eIntroduction to OpenResty\u003c/h2\u003e\n\u003cp\u003eOpenResty is a dynamic web platform that integrates Nginx with the powerful Lua scripting language. It is designed to build scalable web applications, web services, and dynamic web gateways. By combining the high performance of Nginx with the flexibility of Lua, OpenResty enables developers to handle complex processing at the edge of the network.\u003c/p\u003e\n\u003ch2 id=\"what-is-openresty\"\u003eWhat is OpenResty?\u003c/h2\u003e\n\u003cp\u003eOpenResty extends Nginx by bundling it with a set of powerful Lua libraries and modules (known as LuaJIT). This allows embedding Lua scripts directly into the Nginx configuration, offering unparalleled flexibility for customizing request handling, routing, and response generation.\u003c/p\u003e","title":"Openresty"},{"content":"1. Strings Strings in Go are immutable sequences of bytes, typically used to represent UTF-8 encoded text.\nStructure type stringStruct struct { str unsafe.Pointer len int } Memory Layout stringStruct +----------------+ | str (uintptr) | ---\u0026gt; [byte array] | len (int) | +----------------+ Detailed Implementation Creation When a string literal is used, the compiler allocates the bytes in read-only memory. Runtime string creation (e.g., string concatenation) allocates new memory and copies bytes. Operations Substring: Creates a new stringStruct pointing to the same byte array, with adjusted str and len. Concatenation: Allocates a new byte array and copies contents from both strings. Comparison: Compares bytes lexicographically. Runtime Behavior Immutability: String contents cannot be changed after creation. This allows for safe concurrent access and efficient substring operations. UTF-8: Go source code is UTF-8, and string literals are interpreted as UTF-8. However, a string can contain arbitrary bytes. Conversion: Converting between strings and byte slices involves copying data. 2. Slices Slices provide a flexible, dynamic array-like interface.\nStructure type slice struct { array unsafe.Pointer len int cap int } Memory Layout slice +-------------------+ | array (uintptr) | ---\u0026gt; [underlying array] | len (int) | | cap (int) | +-------------------+ Detailed Implementation Creation make: Allocates a new array and sets up the slice structure. Literal: Compiler creates an array and sets up the slice structure. Slicing existing array/slice: Creates a new slice header pointing to the same array. Growth Algorithm When appending to a slice that exceeds its capacity:\nIf capacity \u0026lt; 1024, double the capacity. If capacity â‰¥ 1024, grow by 25%. Round up to the next size class (for better memory allocation). Append Operation Check if there\u0026rsquo;s enough capacity. If not, grow the slice (allocate new array, copy data). Copy new elements to the end of the slice. Update len (and possibly cap and array pointer). Runtime Behavior Bounds Checking: Go performs runtime bounds checking for all slice accesses. Copy: Uses optimized memory copy functions (potentially using SIMD instructions). GC Interaction: The garbage collector considers the entire capacity of a slice, not just its length. 3. Maps Maps in Go are implemented as hash tables with separate chaining for collision resolution.\nStructure type hmap struct { count int flags uint8 B uint8 noverflow uint16 hash0 uint32 buckets unsafe.Pointer oldbuckets unsafe.Pointer nevacuate uintptr extra *mapextra } type bmap struct { tophash [8]uint8 // followed by keys // followed by values // followed by an overflow pointer } Memory Layout hmap +-------------------+ | count | | flags | | B | | noverflow | | hash0 | | buckets -------|---\u0026gt; [array of 2^B pointers to bmap] | oldbuckets | | nevacuate | | extra | +-------------------+ bmap (bucket) +------------------+ | tophash [8]uint8 | +------------------+ | keys [8]KeyType| +------------------+ | values [8]ValType| +------------------+ | overflow *bmap | +------------------+ Detailed Implementation Hashing Each key type has a specific hash function. The hash is seeded with hash0 to prevent collision attacks. Lower B bits of the hash are used to select the bucket. Upper 8 bits are stored in tophash for quick comparisons. Lookup Compute the hash of the key. Use lower bits to find the bucket. Search the bucket (and overflow buckets) for matching tophash and key. Insertion Find the appropriate bucket. If the bucket is full, allocate an overflow bucket. Insert the key-value pair and update count. Deletion Find the key-value pair. Zero out the tophash, key, and value. Update count during the next map growth. Growth Triggered when load factor \u0026gt; 6.5 or too many overflow buckets. Allocate a new bucket array with 2^(B+1) buckets. Gradually move items from old buckets to new ones during subsequent operations. Runtime Behavior Concurrency: Maps are not safe for concurrent read/write access. Iteration: Map iteration order is randomized. Load Factor: Maintained around 6.5 items per bucket for performance. 4. Channels Channels provide a way for goroutines to communicate and synchronize.\nStructure type hchan struct { qcount uint dataqsiz uint buf unsafe.Pointer elemsize uint16 closed uint32 elemtype *_type sendx uint recvx uint recvq waitq sendq waitq lock mutex } Memory Layout hchan +-------------------+ | qcount | | dataqsiz | | buf ------|---\u0026gt; [circular buffer] | elemsize | | closed | | elemtype | | sendx | | recvx | | recvq ------|---\u0026gt; [waiting receivers] | sendq ------|---\u0026gt; [waiting senders] | lock | +-------------------+ Detailed Implementation Creation Allocate hchan struct. For buffered channels, allocate buffer. Send Operation Lock the channel. If channel is closed, panic. If receiver is waiting, transfer data directly. Else if buffer not full, copy data to buffer. Else park the goroutine in sendq. Unlock the channel. Receive Operation Lock the channel. If channel is empty and closed, return zero value. If sender is waiting, receive directly or from buffer. Else if data in buffer, receive from buffer. Else park the goroutine in recvq. Unlock the channel. Close Operation Lock the channel. Set closed to 1. Release all waiting goroutines. Unlock the channel. Runtime Behavior Blocking: Channel operations may cause goroutine scheduling. Fairness: Generally FIFO, but not guaranteed. Select: Uses special cases for efficiency (e.g., 2-case select). 5. Interfaces Interfaces in Go provide a way to specify behavior of types.\nStructure type iface struct { tab *itab data unsafe.Pointer } type itab struct { inter *interfacetype _type *_type hash uint32 _ [4]byte fun [1]uintptr } Memory Layout iface +----------------+ | tab *itab | ---\u0026gt; itab | data unsafe.Ptr| ---\u0026gt; concrete data +----------------+ itab +------------------+ | inter | | _type | | hash | | _ | | fun [1]uintptr | ---\u0026gt; [method table] +------------------+ Detailed Implementation Interface Assignment Check if type implements interface. Create or retrieve itab. Set up iface with itab and pointer to data. Method Call Access function pointer from itab.fun. Call function with data as receiver. Type Assertions Check _type in itab. If match, return data; else panic or return false. Runtime Behavior Dynamic Dispatch: Method calls use indirect function calls. Type Switch: Optimized for common cases. Empty Interface: Special fast-path for interface{}. ","permalink":"https://bleedkagax.github.io/post/1_go_data_structure/","summary":"\u003ch2 id=\"1-strings\"\u003e1. Strings\u003c/h2\u003e\n\u003cp\u003eStrings in Go are immutable sequences of bytes, typically used to represent UTF-8 encoded text.\u003c/p\u003e\n\u003ch3 id=\"structure\"\u003eStructure\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003etype\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003estringStruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#a6e22e\"\u003estr\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eunsafe\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003ePointer\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#a6e22e\"\u003elen\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"memory-layout\"\u003eMemory Layout\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003estringStruct\n+----------------+\n| str (uintptr)  | ---\u0026gt; [byte array]\n| len (int)      |\n+----------------+\n\u003c/code\u003e\u003c/pr","title":"Go's Common Data Structures"},{"content":"Binary Tree A binary tree is a tree data structure in which each node has at most two children, referred to as the left child and the right child.\nB-Tree A B-tree is a self-balancing tree data structure that maintains sorted data and allows searches, sequential access, insertions, and deletions in logarithmic time. It is optimized for systems that read and write large blocks of data.\nB+ Tree A B+ tree is an extension of a B-tree, optimized for systems that read and write large blocks of data. In a B+ tree, all keys and data are stored in the leaf nodes, while internal nodes only store keys for guiding the search.\nMySQL InnoDB: Bidirectional linked list\nB+ Tree Time Complexity Search Operation\nTime Complexity: O(log n) Explanation: In a B+ tree, search involves traversing from root to leaf The height of the tree is logarithmic to the number of elements Insertion Operation\nTime Complexity: O(log n) Includes search time to find the correct leaf node May involve splitting nodes if they\u0026rsquo;re full Deletion Operation\nTime Complexity: O(log n) Includes search time to find the element May involve merging or redistributing nodes Range Query\nTime Complexity: O(log n + m) Where \u0026rsquo;m\u0026rsquo; is the number of elements in the range Efficient due to linked leaf nodes Space Complexity\nO(n) where n is the number of elements Key Points:\nB+ trees maintain balance, ensuring consistent performance High fanout reduces tree height, improving efficiency Leaf nodes linked for fast sequential access ","permalink":"https://bleedkagax.github.io/post/1_tree/","summary":"\u003ch2 id=\"binary-tree\"\u003eBinary Tree\u003c/h2\u003e\n\u003cp\u003eA binary tree is a tree data structure in which each node has at most two children, referred to as the left child and the right child.\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/1_tree.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"b-tree\"\u003eB-Tree\u003c/h2\u003e\n\u003cp\u003eA B-tree is a self-balancing tree data structure that maintains sorted data and allows searches, sequential access, insertions, and deletions in logarithmic time. It is optimized for systems that read and write large blocks of data.\u003c/p\u003e","title":"Tree"},{"content":"What is the difference between an array and a linked list? Array:\nFixed size (in most languages) Contiguous memory allocation Fast random access Insertion/deletion is expensive (except at the end) Linked List:\nDynamic size Non-contiguous memory allocation Slow random access Fast insertion/deletion Explain the difference between a stack and a queue. Stack:\nLast-In-First-Out (LIFO) structure Push (insert) and pop (remove) operations occur at the same end Used for function calls, undo mechanisms, expression evaluation Queue:\nFirst-In-First-Out (FIFO) structure Enqueue (insert) at rear, dequeue (remove) from front Used for task scheduling, breadth-first search What is a binary search tree? A binary search tree is a binary tree data structure where each node has at most two children, referred to as the left child and the right child. For each node:\nAll nodes in the left subtree have values less than the node\u0026rsquo;s value All nodes in the right subtree have values greater than the node\u0026rsquo;s value This property allows for efficient searching, insertion, and deletion operations.\nExplain the concept of hashing and hash tables. Hashing is a technique used to uniquely identify a specific object from a group of similar objects. It involves using a hash function to map keys to indices of an array (hash table).\nHash Table:\nData structure that implements an associative array abstract data type Uses a hash function to compute an index into an array of buckets or slots What is a balanced tree and why is it important? A balanced tree is a binary tree structure in which the left and right subtrees of every node differ in height by no more than one. Examples include AVL trees and Red-Black trees.\nImportance:\nEnsures O(log n) time complexity for operations like insertion, deletion, and search Prevents degeneration into a linked list, which would result in O(n) time complexity Explain the difference between DFS and BFS. Depth-First Search (DFS):\nExplores as far as possible along each branch before backtracking Uses a stack (or recursion) Memory efficient for trees Can get trapped in infinite loops for graphs Breadth-First Search (BFS):\nExplores all the neighbor nodes at the present depth prior to moving to nodes at the next depth level Uses a queue Finds the shortest path in unweighted graphs Can be memory-intensive What is a heap data structure? A heap is a specialized tree-based data structure that satisfies the heap property:\nIn a max heap, for any given node C, if P is a parent node of C, then the key of P is greater than or equal to the key of C In a min heap, the key of P is less than or equal to the key of C Heaps are commonly used to implement priority queues and in sorting algorithms like heapsort.\nExplain the concept of dynamic programming. Dynamic programming is both a mathematical optimization method and a computer programming method. It works by breaking down a complex problem into simpler subproblems in a recursive manner.\nCharacteristics:\nOverlapping Subproblems Optimal Substructure Common examples:\nFibonacci sequence Longest Common Subsequence Knapsack problem What is a trie and what is it used for? A trie, also called digital tree or prefix tree, is a kind of search treeâ€”an ordered tree data structure used to store a dynamic set or associative array where the keys are usually strings.\nUses:\nAutocomplete Spell checkers IP routing tables Solving word games Explain the concept of a self-balancing tree. A self-balancing tree is a type of binary search tree that automatically keeps its height small in the face of arbitrary insertions and deletions. This ensures that operations like search, insert, and delete take O(log n) time.\nExamples:\nAVL trees Red-Black trees Splay trees These trees use rotations to maintain balance after insertions and deletions.\nWhat is the time complexity of common operations in different data structures? Array:\nAccess: O(1) Search: O(n) Insertion: O(n) Deletion: O(n) Linked List:\nAccess: O(n) Search: O(n) Insertion: O(1) Deletion: O(1) Binary Search Tree (balanced):\nSearch: O(log n) Insertion: O(log n) Deletion: O(log n) Hash Table:\nSearch: O(1) average, O(n) worst Insertion: O(1) average, O(n) worst Deletion: O(1) average, O(n) worst Explain the concept of a graph and its representations. A graph is a non-linear data structure consisting of nodes and edges. The nodes are sometimes also referred to as vertices and the edges are lines or arcs that connect any two nodes in the graph.\nRepresentations:\nAdjacency Matrix: 2D array of size V x V where V is the number of vertices Adjacency List: Array of linked lists Edge List: List of all edges in the graph What is the difference between a min-heap and a max-heap? Min-Heap:\nThe root node has the minimum value For any given node C, if P is a parent node of C, then the key of P is less than or equal to the key of C Max-Heap:\nThe root node has the maximum value For any given node C, if P is a parent node of C, then the key of P is greater than or equal to the key of C Both are commonly used to implement priority queues.\nExplain the concept of a B-tree. A B-tree is a self-balancing tree data structure that maintains sorted data and allows searches, sequential access, insertions, and deletions in logarithmic time. It is optimized for systems that read and write large blocks of data.\nProperties:\nAll leaves are at the same level A non-leaf node with k children contains k-1 keys Each node (except root) must contain at least t-1 keys, where t is the minimum degree of B-tree All nodes may contain at most 2t-1 keys B-trees are commonly used in databases and file systems.\nWhat is a skip list? A skip list is a probabilistic data structure that allows O(log n) search complexity as well as O(log n) insertion complexity within an ordered sequence of elements. It is created from a linked list by adding multiple layers of header nodes.\nAdvantages:\nPerforms as well as balanced trees Simpler to implement than balanced tree structures Explain the difference between internal and external sorting. Internal Sorting:\nAll data to be sorted is held in main memory Faster but limited by available RAM Examples: Quicksort, Mergesort, Heapsort External Sorting:\nUsed when data doesn\u0026rsquo;t fit into main memory and must reside in slower external memory (like a hard drive) Involves multiple steps, often using merge sort Example: External merge sort What is a bloom filter? boom_filters\nExplain the concept of a disjoint-set data structure. A disjoint-set data structure, also called a union-find data structure, keeps track of a set of elements partitioned into a number of disjoint (non-overlapping) subsets.\nOperations:\nFind: Determine which subset a particular element is in Union: Join two subsets into a single subset Uses:\nKruskal\u0026rsquo;s algorithm for finding minimum spanning trees Detecting cycles in graphs Path compression optimization ","permalink":"https://bleedkagax.github.io/post/0_data_structure_interview/","summary":"\u003ch2 id=\"what-is-the-difference-between-an-array-and-a-linked-list\"\u003eWhat is the difference between an array and a linked list?\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eArray:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFixed size (in most languages)\u003c/li\u003e\n\u003cli\u003eContiguous memory allocation\u003c/li\u003e\n\u003cli\u003eFast random access\u003c/li\u003e\n\u003cli\u003eInsertion/deletion is expensive (except at the end)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eLinked List:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDynamic size\u003c/li\u003e\n\u003cli\u003eNon-contiguous memory allocation\u003c/li\u003e\n\u003cli\u003eSlow random access\u003c/li\u003e\n\u003cli\u003eFast insertion/deletion\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"explain-the-difference-between-a-stack-and-a-queue\"\u003eExplain the difference between a stack and a queue.\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eStack:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLast-In-First-Out (LIFO) structure\u003c/li\u003e\n\u003cli\u003ePush (insert) and pop (remove) operations occur at the same end\u003c/li\u003e\n\u003cli\u003eUsed for function calls, undo mechanisms, expression evaluation\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eQueue:\u003c/p\u003e","title":"Data Structure Interview"},{"content":"What is Gin Web Framework? Gin is a lightweight, high-performance web framework for Go, inspired by Martini but with a focus on speed and efficiency.\nKey Features of Gin Gin is packed with features that make web development in Go both enjoyable and efficient. Here are some of its standout features:\n1. High Performance Gin is designed for speed. It outperforms many other Go frameworks by optimizing routing and minimizing middleware overhead, ensuring rapid request processing.\n2. Zero Dependencies With minimal external dependencies, Gin ensures that your projects remain lightweight and easy to maintain. This also reduces potential security vulnerabilities linked to third-party packages.\n3. Middleware Support Gin supports a plethora of middleware, allowing developers to plug in functionalities such as logging, authentication, error handling, and more with ease.\n4. Routing Gin offers a powerful yet simple routing system based on httprouter. It supports dynamic routing, parameter parsing, and grouping of routes for better organization.\n5. JSON Validation Built-in support for JSON validation ensures that incoming data is correctly formatted, reducing the risk of runtime errors and enhancing application reliability.\n6. Error Management Gin provides comprehensive error handling mechanisms, enabling developers to gracefully manage and respond to errors.\n7. Rendering Support for multiple rendering engines, including JSON, XML, YAML, HTML, and more, makes it versatile for various application needs.\n8. Extensibility Ginâ€™s modular architecture allows developers to extend its capabilities through custom middleware and plugins.\nWhy dose it outperforms many other Go frameworks ? 1. Optimized Routing a. Utilization of httprouter Gin is built on top of httprouter, a lightweight and high-performance HTTP request router optimized for speed. Here\u0026rsquo;s how httprouter contributes to Gin\u0026rsquo;s routing efficiency:\nTrie-Based Routing: httprouter uses a trie (prefix tree) data structure to store routes. This allows for constant time complexity (O(1)) for route matching, regardless of the number of routes, ensuring rapid request dispatching.\nEfficient Parameter Parsing: The router efficiently handles dynamic route parameters (e.g., /users/:id) without significant overhead, enabling quick extraction and utilization of these parameters in handlers.\nMinimal Memory Footprint: By avoiding unnecessary allocations and leveraging Go\u0026rsquo;s memory management, httprouter maintains a low memory footprint, which is crucial for high-concurrency environments.\nb. Static-Coding Optimizations Gin employs several static-coding optimizations to enhance routing performance:\nPrecompiled Routes: Routes are defined and compiled at the initialization phase, minimizing the processing required during runtime. This ensures that route matching is as fast as possible when handling incoming requests.\nMethod-Specific Routing Trees: Gin maintains separate routing trees for different HTTP methods (GET, POST, etc.), reducing the search space during route matching and speeding up the process.\nc. Avoidance of Reflection Unlike some frameworks that rely heavily on reflection for tasks like parameter binding and routing, Gin minimizes the use of reflection in its core routing logic. Reflection in Go is generally slower and can introduce performance penalties, especially under high load. By limiting reflection, Gin ensures that route matching remains swift and efficient.\n2. Minimized Middleware Overhead a. Lightweight Middleware Implementation Gin\u0026rsquo;s middleware architecture is designed to be as lightweight as possible:\nChaining Efficiency: Middleware in Gin is implemented as a chain of handler functions that are executed in sequence. The framework ensures that this chaining mechanism introduces minimal overhead, even when multiple middleware layers are involved.\nContext Reuse: Gin reuses the Context object across middleware and handlers to avoid unnecessary allocations. This reuse reduces memory overhead and speeds up request processing.\nb. Minimal Abstraction Layers Gin avoids excessive abstraction layers within its middleware system, which can slow down request handling. By keeping the middleware stack straightforward and free from unnecessary indirection, Gin ensures that each middleware function executes quickly without adding significant processing time.\nc. Selective Middleware Execution Gin allows developers to attach middleware to specific routes or route groups rather than globally. This selective execution means that only the necessary middleware functions are invoked for each request, avoiding the overhead of running irrelevant middleware for endpoints that don\u0026rsquo;t require them.\nd. Optimized Error Handling Error handling in Gin\u0026rsquo;s middleware is designed to be efficient. Rather than propagating errors through multiple layers with heavy processing, Gin provides streamlined mechanisms to catch and handle errors promptly, reducing the time spent on error management during request processing.\nWhy Choose Gin? Choosing the right web framework is pivotal for the success and scalability of your application. Here are compelling reasons why Gin stands out:\n1. Blazing Fast Performance Gin\u0026rsquo;s optimized architecture ensures that applications built with it run swiftly, making it ideal for high-concurrency scenarios such as APIs and microservices.\n2. Simplicity and Ease of Use Despite its powerful features, Gin maintains a straightforward API, allowing developers to get up to speed quickly without a steep learning curve.\n3. Robust Community and Support Gin boasts an active community that contributes to its growth, offers support, and maintains comprehensive documentation, making it easier to find solutions and best practices.\n4. Built for Production Gin\u0026rsquo;s stability and performance make it well-suited for production environments, ensuring that applications can handle real-world traffic and usage patterns.\n5. Seamless Integration Whether you need to integrate with databases, authentication services, or other APIs, Gin provides the flexibility and tools to do so seamlessly.\nSetting Up Gin Getting started with Gin is straightforward. Follow these steps to set up your development environment and create your first Gin application.\nPrerequisites Go Installed: Ensure you have Go installed on your system. You can download it from the official website. Go Environment: Set up your GOPATH and ensure your Go environment is correctly configured. Installation Use go get to install the Gin framework:\ngo get -u github.com/gin-gonic/gin This command fetches the Gin package and installs it in your Go workspace.\nVerifying the Installation Create a simple main.go file to verify the installation:\npackage main import \u0026#34;github.com/gin-gonic/gin\u0026#34; func main() { r := gin.Default() r.GET(\u0026#34;/ping\u0026#34;, func(c *gin.Context) { c.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;pong\u0026#34;, }) }) r.Run() // Defaults to :8080 } Run the application:\ngo run main.go Open your browser and navigate to http://localhost:8080/ping. You should see a JSON response:\n{ \u0026#34;message\u0026#34;: \u0026#34;pong\u0026#34; } Congratulations! You\u0026rsquo;ve successfully set up Gin and built your first web endpoint.\nBuilding Your First Gin Application Let\u0026rsquo;s expand on the basic example to create a more feature-rich application. We\u0026rsquo;ll build a simple RESTful API for managing tasks.\nProject Structure A clean project structure enhances maintainability and scalability. Here\u0026rsquo;s a recommended structure:\nmyapp/ â”œâ”€â”€ main.go â”œâ”€â”€ controllers/ â”‚ â””â”€â”€ task.go â”œâ”€â”€ models/ â”‚ â””â”€â”€ task.go â”œâ”€â”€ routes/ â”‚ â””â”€â”€ router.go â””â”€â”€ utils/ â””â”€â”€ logger.go Step 1: Define the Model Create a models/task.go file to define the Task model.\npackage models type Task struct { ID string `json:\u0026#34;id\u0026#34; binding:\u0026#34;required\u0026#34;` Title string `json:\u0026#34;title\u0026#34; binding:\u0026#34;required\u0026#34;` Status string `json:\u0026#34;status\u0026#34; binding:\u0026#34;required\u0026#34;` } Step 2: Create Controllers Create a controllers/task.go file to handle HTTP requests related to tasks.\npackage controllers import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;github.com/google/uuid\u0026#34; \u0026#34;myapp/models\u0026#34; ) var tasks = []models.Task{} func GetTasks(c *gin.Context) { c.JSON(http.StatusOK, tasks) } func CreateTask(c *gin.Context) { var newTask models.Task if err := c.ShouldBindJSON(\u0026amp;newTask); err != nil { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) return } newTask.ID = uuid.New().String() tasks = append(tasks, newTask) c.JSON(http.StatusCreated, newTask) } func GetTaskByID(c *gin.Context) { id := c.Param(\u0026#34;id\u0026#34;) for _, task := range tasks { if task.ID == id { c.JSON(http.StatusOK, task) return } } c.JSON(http.StatusNotFound, gin.H{\u0026#34;message\u0026#34;: \u0026#34;Task not found\u0026#34;}) } func UpdateTask(c *gin.Context) { id := c.Param(\u0026#34;id\u0026#34;) var updatedTask models.Task if err := c.ShouldBindJSON(\u0026amp;updatedTask); err != nil { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) return } for i, task := range tasks { if task.ID == id { tasks[i].Title = updatedTask.Title tasks[i].Status = updatedTask.Status c.JSON(http.StatusOK, tasks[i]) return } } c.JSON(http.StatusNotFound, gin.H{\u0026#34;message\u0026#34;: \u0026#34;Task not found\u0026#34;}) } func DeleteTask(c *gin.Context) { id := c.Param(\u0026#34;id\u0026#34;) for i, task := range tasks { if task.ID == id { tasks = append(tasks[:i], tasks[i+1:]...) c.JSON(http.StatusOK, gin.H{\u0026#34;message\u0026#34;: \u0026#34;Task deleted\u0026#34;}) return } } c.JSON(http.StatusNotFound, gin.H{\u0026#34;message\u0026#34;: \u0026#34;Task not found\u0026#34;}) } Note: For simplicity, this example uses an in-memory slice to store tasks. In a production environment, you\u0026rsquo;d integrate a database.\nStep 3: Define Routes Create a routes/router.go file to define the API endpoints.\npackage routes import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;myapp/controllers\u0026#34; ) func SetupRouter() *gin.Engine { r := gin.Default() api := r.Group(\u0026#34;/api\u0026#34;) { tasks := api.Group(\u0026#34;/tasks\u0026#34;) { tasks.GET(\u0026#34;/\u0026#34;, controllers.GetTasks) tasks.POST(\u0026#34;/\u0026#34;, controllers.CreateTask) tasks.GET(\u0026#34;/:id\u0026#34;, controllers.GetTaskByID) tasks.PUT(\u0026#34;/:id\u0026#34;, controllers.UpdateTask) tasks.DELETE(\u0026#34;/:id\u0026#34;, controllers.DeleteTask) } } return r } Step 4: Initialize the Application Update the main.go file to initialize the router and start the server.\npackage main import ( \u0026#34;myapp/routes\u0026#34; ) func main() { r := routes.SetupRouter() r.Run(\u0026#34;:8080\u0026#34;) // You can specify a different port if needed } Step 5: Testing the API Use tools like Postman or cURL to test the API endpoints.\nCreate a Task curl -X POST http://localhost:8080/api/tasks/ \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;title\u0026#34;:\u0026#34;Learn Gin\u0026#34;,\u0026#34;status\u0026#34;:\u0026#34;in-progress\u0026#34;}\u0026#39; Get All Tasks curl http://localhost:8080/api/tasks/ Get a Task by ID curl http://localhost:8080/api/tasks/{id} Update a Task curl -X PUT http://localhost:8080/api/tasks/{id} \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;title\u0026#34;:\u0026#34;Learn Gin Framework\u0026#34;,\u0026#34;status\u0026#34;:\u0026#34;completed\u0026#34;}\u0026#39; Delete a Task curl -X DELETE http://localhost:8080/api/tasks/{id} Advanced Features Once you\u0026rsquo;re comfortable with the basics, Gin offers advanced features to enhance your applications further.\n1. Middleware Middleware functions are executed before or after the main handler. They can perform tasks like logging, authentication, and error handling.\nExample: Logging Middleware\nfunc LoggerMiddleware() gin.HandlerFunc { return func(c *gin.Context) { // Before request log.Printf(\u0026#34;Incoming %s request to %s\u0026#34;, c.Request.Method, c.Request.URL.Path) c.Next() // After request log.Printf(\u0026#34;Response Status: %d\u0026#34;, c.Writer.Status()) } } func SetupRouter() *gin.Engine { r := gin.New() r.Use(LoggerMiddleware()) // ... rest of the routes return r } 2. Grouping Routes Grouping routes helps in organizing your API, especially when dealing with multiple versions or modules.\nExample: Versioned API\nv1 := r.Group(\u0026#34;/v1\u0026#34;) { v1.GET(\u0026#34;/tasks\u0026#34;, controllers.GetTasks) v1.POST(\u0026#34;/tasks\u0026#34;, controllers.CreateTask) } v2 := r.Group(\u0026#34;/v2\u0026#34;) { v2.GET(\u0026#34;/tasks\u0026#34;, controllers.GetTasksV2) // Different implementation for v2 v2.POST(\u0026#34;/tasks\u0026#34;, controllers.CreateTaskV2) } 3. Parameter Binding and Validation Gin provides comprehensive parameter binding and validation mechanisms, ensuring that incoming requests are correctly formatted.\nExample: Binding Query Parameters\ntype QueryParams struct { Page int `form:\u0026#34;page\u0026#34; binding:\u0026#34;required\u0026#34;` PerPage int `form:\u0026#34;per_page\u0026#34; binding:\u0026#34;required\u0026#34;` } func GetPaginatedTasks(c *gin.Context) { var q QueryParams if err := c.ShouldBindQuery(\u0026amp;q); err != nil { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) return } // Use q.Page and q.PerPage to fetch tasks } 4. Error Handling Gin allows for centralized error handling, making it easier to manage and respond to errors consistently.\nExample: Centralized Error Handler\nfunc ErrorHandlerMiddleware() gin.HandlerFunc { return func(c *gin.Context) { c.Next() if len(c.Errors) \u0026gt; 0 { c.JSON(-1, gin.H{\u0026#34;errors\u0026#34;: c.Errors}) } } } func SetupRouter() *gin.Engine { r := gin.New() r.Use(ErrorHandlerMiddleware()) // ... rest of the routes return r } 5. HTML Rendering While Gin is often used for APIs, it also supports HTML rendering, allowing you to build full-stack web applications.\nExample: Rendering HTML Templates\nfunc SetupRouter() *gin.Engine { r := gin.Default() r.LoadHTMLGlob(\u0026#34;templates/*\u0026#34;) r.GET(\u0026#34;/hello\u0026#34;, func(c *gin.Context) { c.HTML(http.StatusOK, \u0026#34;hello.html\u0026#34;, gin.H{ \u0026#34;title\u0026#34;: \u0026#34;Hello from Gin\u0026#34;, }) }) return r } templates/hello.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;{{ .title }}\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;{{ .title }}\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Welcome to your first Gin application!\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Best Practices To harness Ginâ€™s full potential and maintain a clean, efficient codebase, adhere to the following best practices:\n1. Organize Your Codebase Maintain a well-structured project layout separating concerns such as models, controllers, routes, and utilities. This enhances readability and maintainability.\n2. Use Environment Variables Leverage environment variables for configuration settings like database connections, API keys, and server ports. Tools like Viper can help manage configurations.\n3. Implement Proper Error Handling Always handle errors gracefully. Avoid exposing internal error details to clients, which can pose security risks.\n4. Leverage Middleware Use middleware for repetitive tasks such as logging, authentication, and rate limiting. This promotes DRY (Don\u0026rsquo;t Repeat Yourself) principles.\n5. Validate Input Data Ensure all incoming data is validated to prevent malformed requests from causing unexpected behavior or security vulnerabilities.\n6. Optimize Performance Use Ginâ€™s Built-in Logger: Optimize logging to monitor application performance and troubleshoot issues.\nEnable GZIP Compression: Reduce response sizes and improve client load times by enabling compression.\nr.Use(gin.Logger(), gin.Recovery(), gin.Gzip()) Leverage Caching: Implement caching strategies for frequently accessed data to minimize database load.\n7. Secure Your Application Use HTTPS: Always serve your application over HTTPS to encrypt data in transit. Implement Authentication and Authorization: Protect sensitive routes and data by ensuring only authorized users can access them. Prevent Common Vulnerabilities: Guard against SQL injection, cross-site scripting (XSS), and cross-site request forgery (CSRF) by sanitizing inputs and following security best practices. 8. Write Tests Develop unit and integration tests to ensure your application behaves as expected. Tools like Testify can aid in writing effective tests.\nExample: Testing a Handler\npackage controllers import ( \u0026#34;net/http\u0026#34; \u0026#34;net/http/httptest\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;github.com/stretchr/testify/assert\u0026#34; ) func TestGetTasks(t *testing.T) { router := gin.Default() router.GET(\u0026#34;/tasks\u0026#34;, GetTasks) req, _ := http.NewRequest(\u0026#34;GET\u0026#34;, \u0026#34;/tasks\u0026#34;, nil) resp := httptest.NewRecorder() router.ServeHTTP(resp, req) assert.Equal(t, http.StatusOK, resp.Code) assert.Contains(t, resp.Body.String(), \u0026#34;tasks\u0026#34;) } Conclusion The Gin Web Framework stands out as a powerful, efficient, and developer-friendly tool for building web applications and APIs in Go.\nResources Official Gin Documentation: https://github.com/gin-gonic/gin Gin Examples: https://github.com/gin-gonic/examples Go Documentation: https://golang.org/doc/ Viper Configuration Library: https://github.com/spf13/viper Testify Testing Framework: https://github.com/stretchr/testify Happy coding with Gin!\n","permalink":"https://bleedkagax.github.io/post/4_gin/","summary":"\u003ch2 id=\"what-is-gin-web-framework\"\u003eWhat is Gin Web Framework?\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eGin\u003c/strong\u003e is a lightweight, high-performance web framework for Go, inspired by Martini but with a focus on speed and efficiency.\u003c/p\u003e\n\u003ch2 id=\"key-features-of-gin\"\u003eKey Features of Gin\u003c/h2\u003e\n\u003cp\u003eGin is packed with features that make web development in Go both enjoyable and efficient. Here are some of its standout features:\u003c/p\u003e\n\u003ch3 id=\"1-high-performance\"\u003e1. \u003cstrong\u003eHigh Performance\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eGin is designed for speed. It outperforms many other Go frameworks by optimizing routing and minimizing middleware overhead, ensuring rapid request processing.\u003c/p\u003e","title":"Gin"},{"content":"Implementation Overview The ListenAndServe function is part of Go\u0026rsquo;s standard library in the net/http package. Its primary purpose is to start an HTTP server that listens on a specified address and handles incoming requests.\nfunc ListenAndServe(addr string, handler Handler) error { server := \u0026amp;Server{Addr: addr, Handler: handler} return server.ListenAndServe() } This function creates a Server instance and calls its ListenAndServe method.\nDetailed Implementation The core logic is in the Server.ListenAndServe and Server.Serve methods:\nfunc (srv *Server) ListenAndServe() error { if srv.shuttingDown() { return ErrServerClosed } addr := srv.Addr if addr == \u0026#34;\u0026#34; { addr = \u0026#34;:http\u0026#34; } ln, err := net.Listen(\u0026#34;tcp\u0026#34;, addr) if err != nil { return err } return srv.Serve(ln) } func (srv *Server) Serve(l net.Listener) error { // ... (initialization code omitted) for { rw, e := l.Accept() if e != nil { // ... (error handling omitted) } c := srv.newConn(rw) go c.serve(connCtx) } } Goroutine Usage Main Goroutine:\nThe ListenAndServe function runs in the calling goroutine (often the main goroutine). It enters an infinite loop in Serve, continuously accepting new connections. Per-Connection Goroutines:\nFor each accepted connection, a new goroutine is spawned (go c.serve(connCtx)). This allows concurrent handling of multiple client connections. No Separate Listener Goroutine:\nUnlike some server implementations, ListenAndServe doesn\u0026rsquo;t create a dedicated goroutine for listening. The listening and accepting of connections occur in the same goroutine that called ListenAndServe. Waiting Behavior Blocking Nature:\nListenAndServe is a blocking call. It doesn\u0026rsquo;t return until the server is closed or encounters an unrecoverable error. The main loop in Serve continuously waits for new connections via l.Accept(). Efficient Waiting:\nWhile waiting for connections, the goroutine is in a \u0026ldquo;sleep\u0026rdquo; state, not consuming CPU cycles. Go\u0026rsquo;s runtime uses efficient I/O polling mechanisms (like epoll or kqueue) under the hood. Error Handling and Shutdown:\nThe loop breaks and the function returns if Accept() returns a non-temporary error or if the server is shutting down. Resource Consumption CPU Usage:\nMinimal when waiting for connections, as the goroutine is mostly idle. Memory Usage:\nLow and constant for the main goroutine. Additional memory is used for each client connection goroutine. File Descriptors:\nOne for the listening socket, plus one for each active client connection. Scalability and Performance This design scales well, handling many concurrent connections efficiently. The single listening goroutine doesn\u0026rsquo;t become a bottleneck, as accepting connections is typically very fast. The per-connection goroutine model allows for high concurrency in request handling. Conclusion Go\u0026rsquo;s http.ListenAndServe implementation provides an efficient and scalable approach to running an HTTP server:\nIt uses goroutines effectively for concurrent connection handling. The main goroutine blocks efficiently, waiting for new connections without consuming significant resources. This design allows for simple usage in Go programs while providing robust performance for handling HTTP requests. ","permalink":"https://bleedkagax.github.io/post/2_go_listenandserve/","summary":"\u003ch2 id=\"implementation-overview\"\u003eImplementation Overview\u003c/h2\u003e\n\u003cp\u003eThe \u003ccode\u003eListenAndServe\u003c/code\u003e function is part of Go\u0026rsquo;s standard library in the \u003ccode\u003enet/http\u003c/code\u003e package. Its primary purpose is to start an HTTP server that listens on a specified address and handles incoming requests.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunc\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eListenAndServe\u003c/span\u003e(\u003cspan style=\"color:#a6e22e\"\u003eaddr\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003estring\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003ehandler\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eHandler\u003c/span\u003e) \u003cspan style=\"color:#66d9ef\"\u003eerror\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#a6e22e\"\u003eserver\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003eServer\u003c/span\u003e{\u003cspan style=\"color:#a6e22e\"\u003eAddr\u003c/span\u003e: \u003cspan style=\"color:#a6e22e\"\u003eaddr\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eHandler\u003c/span\u003e: \u003cspan style=\"color:#a6e22e\"\u003ehandler\u003c/span\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eserver\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003eListenAndServe\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pr","title":"Go's `http.ListenAndServe`"},{"content":"What is the OSI model? Physical Layer Data Link Layer Network Layer Transport Layer Session Layer Presentation Layer Application Layer Explain the difference between TCP and UDP. TCP (Transmission Control Protocol):\nConnection-oriented Reliable, ensures all data is received Flow control and congestion control Slower than UDP Used for applications requiring high reliability (e.g., file transfer, email) UDP (User Datagram Protocol):\nConnectionless Unreliable, doesn\u0026rsquo;t guarantee data delivery No flow control or congestion control Faster than TCP Used for applications that prioritize speed (e.g., video streaming, online gaming) What is DNS and how does it work? DNS (Domain Name System) is a hierarchical and decentralized naming system for computers, services, or other resources connected to the Internet or a private network. It translates human-readable domain names (e.g., www.example.com) into IP addresses.\nProcess:\nUser enters a URL in the browser Browser checks its cache for DNS record If not found, it queries the OS If still not found, it contacts a DNS resolver The resolver queries root servers, then TLD servers, then authoritative name servers The IP address is returned to the browser What is a subnet and subnet mask? A subnet is a logical subdivision of an IP network. A subnet mask is a 32-bit number that masks an IP address, and divides the IP address into network address and host address.\nSubnetting allows for more efficient use of IP addresses and improved network performance.\nExplain the concept of ARP (Address Resolution Protocol). ARP is a protocol used to map an IP address to a physical machine address (MAC address) in a local network.\nProcess:\nDevice wants to send a packet to an IP address It checks its ARP cache for the corresponding MAC address If not found, it broadcasts an ARP request The device with the matching IP address responds with its MAC address The sender updates its ARP cache and sends the packet What is the difference between a hub, switch, and router? Hub: Layer 1 device, broadcasts data to all ports Switch: Layer 2 device, forwards data to specific port based on MAC address Router: Layer 3 device, forwards data between different networks based on IP address Explain the three-way handshake in TCP. The three-way handshake is used to establish a TCP connection:\nSYN: Client sends a SYN packet to the server SYN-ACK: Server responds with a SYN-ACK packet ACK: Client sends an ACK packet to the server What is DHCP and what is it used for? DHCP (Dynamic Host Configuration Protocol) is a network management protocol used to dynamically assign an IP address to any device, or node, on a network so it can communicate using IP.\nDHCP automates and centrally manages these configurations rather than requiring network administrators to manually assign IP addresses to all network devices.\nDHCP Discover:Â The client broadcasts a request for an IP address. DHCP Offer:Â The DHCP server responds with an IP address offer. DHCP Request:Â The client requests the offered IP address. DHCP Acknowledge:Â The server confirms the IP address assignment. Explain the difference between IPv4 and IPv6. Feature IPv4 IPv6 Address Length 32-bit 128-bit Address Space ~4.3 billion unique addresses 340 undecillion (3.4 Ã— 10^38) addresses Notation Dot-decimal Hexadecimal with colons Example 192.168.1.1 2001:0db8:85a3:0000:0000:8a2e:0370:7334 What is NAT and why is it used? NAT (Network Address Translation) is a method of remapping one IP address space into another by modifying network address information in the IP header of packets while they are in transit across a traffic routing device.\nNAT is primarily used to:\nConserve IPv4 addresses Improve security by hiding internal network addresses Can multiple UDP sockets bind to the same IP and port? Yes, with conditions: Most operating systems allow multiple UDP sockets to bind to the same IP and port. This is often referred to as \u0026ldquo;socket reuse\u0026rdquo; or \u0026ldquo;address reuse\u0026rdquo;. Requires setting the SO_REUSEADDR socket option before binding. Can multiple TCP sockets bind to the same IP and port? Generally No, with exceptions: Typically, only one TCP socket can bind to a specific IP and port combination. Exceptions: Different IP addresses on the same port. Same IP, different ports. Using SO_REUSEADDR for sequential (not simultaneous) bindings. Can TCP and UDP bind to the same port? Yes: TCP and UDP use separate protocol stacks. A TCP socket and a UDP socket can bind to the same port number simultaneously. The operating system distinguishes between them based on the protocol. How TCP Ensures Reliable Transmission Sequence Numbers and Acknowledgments\nEach byte of data is assigned a sequence number Receiver acknowledges receipt of data by sending ACKs Retransmission\nSender retransmits data if ACK is not received within a timeout period Implements various retransmission strategies (e.g., fast retransmit) Checksums\nUsed to detect corrupted data Receiver discards corrupt segments and doesn\u0026rsquo;t acknowledge them Flow Control\nSliding window protocol Prevents sender from overwhelming receiver Congestion Control\nSlow start Congestion avoidance Fast recovery Connection Management\nThree-way handshake for connection establishment Four-way handshake for connection termination Ordered Data Transfer\nSegments are reassembled in correct order at the receiver Duplicate Data Detection\nReceiver identifies and discards duplicate segments What is the TCP four-way handshake for connection termination? FIN from initiator: Either the client or server can initiate the termination by sending a FIN (finish) packet. ACK from receiver: The receiving end acknowledges the FIN with an ACK packet. FIN from receiver: The receiving end then sends its own FIN packet to indicate it\u0026rsquo;s ready to close. ACK from initiator: The initiating end acknowledges this FIN with a final ACK. TCP TIME-WAIT After a connection is closed, the closing party enters a TIME-WAIT state. This state typically lasts for 2 * Maximum Segment Lifetime (MSL), usually around 2-4 minutes. The TIME-WAIT state serves two main purposes:\nEnsures that any delayed packets from the closed connection are handled properly and don\u0026rsquo;t interfere with new connections. Allows for proper closure of both sides of the connection, preventing potential issues with subsequent connections. How to implement a basic TCP-like protocol using UDPï¼Ÿ Connection Establishment Implement a three-way handshake similar to TCP\nSequence Numbers Assign sequence numbers to each packet Use these to detect packet loss and ensure correct ordering\nAcknowledgments Receiver sends acknowledgments for received packets Sender retransmits packets that aren\u0026rsquo;t acknowledged within a timeout period\nFlow Control Implement a simple sliding window protocol Receiver advertises available buffer space\nError Detection Use checksums or CRC to detect corrupted packets Discard or request retransmission of corrupted packets\nConnection Termination Implement a four-way handshake for connection termination\nHttp Keep-Alive In this example, the idle timeout is set to ten seconds and it can accept up to 100 HTTP requests before the HTTP Connection is forcibly closed.\nResponse\nHTTP/1.1 200 OK Connection: keep-alive Content-Type: text/html; chartset=utf-8 Keep-Alive: timeout=10, max=100 Session ID and Session Key Aspect Session ID Session Key Purpose Uniquely identifies a session between client and server. Secures communication or encrypts session data. Type A random string or token. A cryptographic key. Use Case Used to look up session data on the server. Used to encrypt/decrypt data during a session. Storage Stored in cookies (client) and server memory. Stored in memory (for encryption) or negotiated during SSL/TLS. Sensitive Info Does not contain sensitive info (just an ID). Contains sensitive info (used for encryption). Security Role Identifies the user\u0026rsquo;s session, but doesn\u0026rsquo;t secure data directly. Ensures data confidentiality and integrity. Tp99 Tp95 Tp90 It represents the value below which 95% of the observations in a dataset fall.\nSort the Data: Arrange all data points in ascending order.\nCalculate the Index: Use the formula: index = (n * 0.95) + 0.5, where n is the number of data points.\nIf the result is not a whole number, round up to the nearest integer. Find the Value: The TP95 is the value at the calculated index position in the sorted dataset.\nTcp Alive fuck byte çŸ­è§†é¢‘å»é‡ bloomè¿‡æ»¤å™¨ åŸç† ï¼Œredis ä¸­æ€ä¹ˆæ”¯æŒ rocksDB å¦‚ä½•ä¿è¯å¿«é€Ÿè¯»å†™ ç®€å†ä¸€è‡´æ€§å“ˆå¸Œ\n","permalink":"https://bleedkagax.github.io/post/0_network_interview/","summary":"\u003ch2 id=\"what-is-the-osi-model\"\u003eWhat is the OSI model?\u003c/h2\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/0_network_interview.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ePhysical Layer\u003c/li\u003e\n\u003cli\u003eData Link Layer\u003c/li\u003e\n\u003cli\u003eNetwork Layer\u003c/li\u003e\n\u003cli\u003eTransport Layer\u003c/li\u003e\n\u003cli\u003eSession Layer\u003c/li\u003e\n\u003cli\u003ePresentation Layer\u003c/li\u003e\n\u003cli\u003eApplication Layer\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"explain-the-difference-between-tcp-and-udp\"\u003eExplain the difference between TCP and UDP.\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTCP (Transmission Control Protocol):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eConnection-oriented\u003c/li\u003e\n\u003cli\u003eReliable, ensures all data is received\u003c/li\u003e\n\u003cli\u003eFlow control and congestion control\u003c/li\u003e\n\u003cli\u003eSlower than UDP\u003c/li\u003e\n\u003cli\u003eUsed for applications requiring high reliability (e.g., file transfer, email)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eUDP (User Datagram Protocol):\u003c/p\u003e","title":"Network Interview"},{"content":" Transmission Control Protocol (TCP) TCP Principles and Mechanisms Key features:\nConnection Establishment: Three-way handshake (SYN, SYN-ACK, ACK) Reliable Delivery: Acknowledgment and retransmission Flow Control: Sliding window mechanism Congestion Control: Slow start, congestion avoidance, fast retransmit, and fast recovery Ordered Data Transfer: Sequence numbers Error Detection: Checksum Example of TCP header:\n0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Source Port | Destination Port | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Acknowledgment Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Data | |U|A|P|R|S|F| | | Offset| Reserved |R|C|S|S|Y|I| Window | | | |G|K|H|T|N|N| | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Checksum | Urgent Pointer | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Options | Padding | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | data | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ TCP Performance Characteristics Throughput:\nAffected by Round-Trip Time (RTT) and packet loss Theoretical max: Window Size / RTT Latency:\nConnection setup time: 1.5 RTT (three-way handshake) Data transfer: At least 1 RTT per request-response cycle Reliability:\nGuaranteed delivery through acknowledgments and retransmissions Ordered delivery ensures data integrity Scalability:\nLimited by connection state maintenance on servers C10K problem: difficulty in handling 10,000+ concurrent connections TCP Use Cases and Limitations Use Cases:\nWeb browsing (HTTP) Email (SMTP, IMAP, POP3) File transfers (FTP, SFTP) Remote administration (SSH) Limitations:\nHead-of-line blocking in multiplexed scenarios Performance degradation in high-latency networks Overhead for small, frequent transmissions User Datagram Protocol (UDP) UDP Core Concepts Key features:\nConnectionless: No handshake required Unreliable: No guarantee of delivery, ordering, or duplicate protection Lightweight: Minimal protocol overhead Stateless: No connection state tracking UDP header structure:\n0 7 8 15 16 23 24 31 +--------+--------+--------+--------+ | Source | Destination | | Port | Port | +--------+--------+--------+--------+ | | | | Length | Checksum | +--------+--------+--------+--------+ | | data octets ... +---------------- ... UDP Performance Analysis Throughput:\nHigher potential throughput than TCP due to less overhead Not limited by congestion control mechanisms Latency:\nLower latency than TCP for initial data transfer (no handshake) Consistent latency due to lack of retransmission delays Packet Loss:\nNo built-in recovery from packet loss Application must implement its own reliability if needed Scalability:\nExcellent for broadcast and multicast scenarios Efficient for large numbers of small transactions UDP Applications and Constraints Applications:\nReal-time gaming Voice over IP (VoIP) Streaming media DNS lookups Constraints:\nLack of built-in reliability mechanisms No congestion control (potential for network flooding) Limited message size (65,507 bytes maximum) Hypertext Transfer Protocol (HTTP) http1_http2_http3\nWebSocket Protocol WebSocket Full-Duplex Communication WebSocket provides a persistent, full-duplex communication channel over a single TCP connection.\nKey features:\nBi-directional: Both client and server can send messages Low-latency: Reduced overhead after initial handshake Real-time: Immediate message delivery WebSocket Performance Metrics Connection Overhead:\nInitial handshake: Similar to HTTP Subsequent messages: Minimal frame overhead (2-14 bytes) Latency:\nLow latency for real-time updates No need for polling or long-polling Scalability:\nEfficient for large numbers of concurrent connections Challenges with very high connection counts (C10K problem) Bandwidth Usage:\nReduced compared to polling techniques Efficient for small, frequent updates WebSocket Use Cases and Limitations Use Cases:\nReal-time collaborative applications Live sports updates Financial trading platforms Multiplayer games Limitations:\nNot supported in older browsers Potential for abuse (e.g., bypassing same-origin policy) Challenges with load balancing and scaling Comparative Analysis Feature TCP UDP HTTP WebSocket Connection Connection-oriented Connectionless Connection-oriented Persistent connection Reliability Guaranteed delivery Best-effort Reliable (over TCP) Reliable (over TCP) Ordering Ordered delivery No ordering Ordered (HTTP/2 streams) Ordered Speed Moderate Fast Varies (1.1 vs 2 vs 3) Fast after handshake Overhead Moderate Low High (headers) Low after handshake Use Case Most internet apps Real-time, UDP Web, API Real-time, push ","permalink":"https://bleedkagax.github.io/post/1_network_protocols/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/1_network_protocols.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"transmission-control-protocol-tcp\"\u003eTransmission Control Protocol (TCP)\u003c/h2\u003e\n\u003ch3 id=\"tcp-principles-and-mechanisms\"\u003eTCP Principles and Mechanisms\u003c/h3\u003e\n\u003cp\u003eKey features:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eConnection Establishment\u003c/strong\u003e: Three-way handshake (SYN, SYN-ACK, ACK)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReliable Delivery\u003c/strong\u003e: Acknowledgment and retransmission\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFlow Control\u003c/strong\u003e: Sliding window mechanism\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCongestion Control\u003c/strong\u003e: Slow start, congestion avoidance, fast retransmit, and fast recovery\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOrdered Data Transfer\u003c/strong\u003e: Sequence numbers\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eError Detection\u003c/strong\u003e: Checksum\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eExample of TCP header:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e 0                   1                   2                   3\n 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|          Source Port          |       Destination Port        |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|                        Sequence Number                        |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|                    Acknowledgment Number                      |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|  Data |           |U|A|P|R|S|F|                               |\n| Offset| Reserved  |R|C|S|S|Y|I|            Window             |\n|       |           |G|K|H|T|N|N|                               |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|           Checksum            |         Urgent Pointer        |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|                    Options                    |    Padding    |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|                             data                              |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\u003c/code\u003e\u003c/pr","title":"Network Protocols"},{"content":"Explain the difference between a process and a thread. Process:\nIndependent execution unit Has its own memory space Heavyweight, more resources Isolated from other processes Thread:\nLightweight unit of execution within a process Shares memory space with other threads in the same process Less resource-intensive Can communicate easily with other threads in the same process How do processes and threads communicate Process communication methods:\nPipes and named pipes Shared memory Message queues Sockets Signals Thread communication methods:\nShared memory within the same process Mutex and semaphores for synchronization Condition variables Explain the concept of deadlock and its four necessary conditions. Deadlock is a situation where a set of processes are blocked because each process is holding a resource and waiting to acquire a resource held by another process.\nFour necessary conditions (Coffman conditions):\nMutual Exclusion: At least one resource must be held in a non-sharable mode Hold and Wait: A process must be holding at least one resource while waiting to acquire additional resources held by other processes No Preemption: Resources cannot be forcibly taken away from a process; they must be released voluntarily Circular Wait: A circular chain of two or more processes, each waiting for a resource held by the next member in the chain What is the purpose of paging in an operating system? Paging is a memory management scheme that eliminates the need for contiguous allocation of physical memory. It allows the physical address space of a process to be non-contiguous.\nBenefits:\nEfficient use of memory Supports virtual memory Simplifies memory allocation Paging Overview\n[Logical Address Space] [Page Table] [Physical Address Space] +------------------+ +----------+ +------------------+ | Page 0 | -----\u0026gt; | Frame 2 | --\u0026gt; | Frame 0 | +------------------+ +----------+ +------------------+ | Page 1 | -----\u0026gt; | Frame 4 | --\u0026gt; | Frame 1 | +------------------+ +----------+ +------------------+ | Page 2 | -----\u0026gt; | Frame 1 | --\u0026gt; | Frame 2 | +------------------+ +----------+ +------------------+ | Page 3 | -----\u0026gt; | Frame 7 | --\u0026gt; | Frame 3 | +------------------+ +----------+ +------------------+ | Frame 4 | +------------------+ | Frame 5 | +------------------+ | Frame 6 | +------------------+ | Frame 7 | +------------------+ Logical pages are mapped to physical frames through a page table. Note that pages can be stored in non-contiguous frames.\nAddress Translation\n[Logical Address] +----------------+----------------+ | Page No. | Offset | +----------------+----------------+ | | | | V | [Page Table] | +----------------+ | | Frame Number | | +----------------+ | | | | | V V +----------------+----------------+ | Frame Number | Offset | +----------------+----------------+ [Physical Address] Virtual Memory with Paging\n[Virtual Address Space] [Physical Memory] [Disk Storage] +------------------+ +---------------+ +-------------+ | Page 0 | ---\u0026gt; | Frame 0 | | Page 3 | +------------------+ +---------------+ +-------------+ | Page 1 | ---\u0026gt; | Frame 2 | | Page 5 | +------------------+ +---------------+ +-------------+ | Page 2 | ---\u0026gt; | Frame 1 | | Page 6 | +------------------+ +---------------+ +-------------+ | Page 3 | --. | Frame 3 | | ... | +------------------+ | +---------------+ +-------------+ | Page 4 | ---\u0026gt; | Frame 4 | +------------------+ +---------------+ | Page 5 | --. +------------------+ | | Page 6 | --. +------------------+ Paging supports virtual memory. Some pages are in physical memory, while others are stored on disk and can be swapped in when needed.\nExplain the difference between preemptive and non-preemptive scheduling. Preemptive Scheduling:\nThe CPU can be taken away from a process before it finishes its burst time Better for time-sharing systems Can lead to race conditions if not properly managed Non-preemptive Scheduling:\nOnce the CPU has been allocated to a process, the process keeps it until it releases the CPU either by terminating or by switching to the waiting state Simpler to implement Can lead to poor response time for interactive processes What is a system call? A system call is the programmatic way in which a computer program requests a service from the kernel of the operating system. System calls provide an essential interface between a process and the operating system.\nExamples of system calls:\nFile operations (open, read, write, close) Process control (fork, exec, exit) Device management Information maintenance Communication Explain the concept of thrashing. Thrashing is a condition where excessive paging operations are taking place. It occurs when a computer\u0026rsquo;s virtual memory subsystem is in a constant state of paging, rapidly exchanging data in memory for data on disk, to the exclusion of most application-level processing.\nCauses:\nInsufficient physical memory Poor page replacement algorithms Large working sets What is the purpose of a semaphore? A semaphore is a variable or abstract data type used to control access to a common resource by multiple processes in a concurrent system. It\u0026rsquo;s used for process synchronization and to solve critical section problems.\nTypes:\nBinary Semaphore (mutex): Can have only 0 or 1 as value Counting Semaphore: Can have any non-negative value What is memory fragmentation, how does it occur, and how is it solved? Memory fragmentation refers to the condition where memory space is broken into small, unusable blocks, reducing overall memory utilization efficiency.\nHow it occurs:\nExternal fragmentation: Frequent allocation and deallocation of memory blocks leaves small, unusable gaps between allocated blocks Internal fragmentation: Fixed-size memory allocation schemes may allocate more memory than required, leaving unused space within allocated blocks Solutions:\nCompaction: Relocating allocated memory blocks to create larger contiguous free spaces Paging: Dividing memory into fixed-size pages, eliminating external fragmentation Memory pools: Pre-allocating fixed-size memory blocks for specific uses Garbage collection: Automatically freeing unused memory and reorganizing remaining objects What are virtual memory and physical memory in operating systems? Virtual memory is an abstraction of physical memory that provides each process with the illusion of having its own large, contiguous address space.\nPhysical memory refers to the actual RAM(Random-access memory) installed in a computer.\nKey points:\nVirtual memory allows programs to use more memory than physically available It maps virtual addresses to physical addresses or disk storage Enables memory protection between processes Simplifies memory management for programmers Explain kernel mode and user mode in operating systems Kernel mode and user mode are privilege levels in which code executes:\nKernel mode:\nHas unrestricted access to hardware and system resources Can execute privileged instructions Used by the operating system kernel and device drivers User mode:\nHas limited access to system resources Cannot execute privileged instructions directly Used by application programs Switching between modes:\nSystem calls trigger a switch from user mode to kernel mode Return from system calls switches back to user mode ","permalink":"https://bleedkagax.github.io/post/0_operating_system_interview/","summary":"\u003ch2 id=\"explain-the-difference-between-a-process-and-a-thread\"\u003eExplain the difference between a process and a thread.\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eProcess:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIndependent execution unit\u003c/li\u003e\n\u003cli\u003eHas its own memory space\u003c/li\u003e\n\u003cli\u003eHeavyweight, more resources\u003c/li\u003e\n\u003cli\u003eIsolated from other processes\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThread:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLightweight unit of execution within a process\u003c/li\u003e\n\u003cli\u003eShares memory space with other threads in the same process\u003c/li\u003e\n\u003cli\u003eLess resource-intensive\u003c/li\u003e\n\u003cli\u003eCan communicate easily with other threads in the same process\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"how-do-processes-and-threads-communicate\"\u003eHow do processes and threads communicate\u003c/h2\u003e\n\u003cp\u003eProcess communication methods:\u003c/p\u003e","title":"Operating System Interview"},{"content":"What is a Subnet? A subnet is a way to divide a large network into smaller, more manageable pieces. Think of it like dividing a big city into neighborhoods. Each subnet (neighborhood) has its own group of devices (houses), but all are still part of the same overall network (city).\nWhat is a Subnet Mask? A subnet mask is a number used to help identify which part of an IP address belongs to the network (city) and which part identifies the device (house). Itâ€™s like a divider that separates the network part from the device part in an IP address.\nSimple Example: IP Address and Subnet Mask Letâ€™s say you have the following IP address and subnet mask:\nIP Address: 192.168.1.10 Subnet Mask: 255.255.255.0 This IP address and subnet mask help identify:\nWhat network this device is in (like which city it belongs to). What device it is within that network (like which house in the city). Visual Breakdown of IP Address and Subnet Mask Letâ€™s break down the IP address and subnet mask using a visual approach:\nStep 1: Convert IP Address to Binary An IP address is made up of four numbers (each between 0 and 255). In binary, the IP address 192.168.1.10 becomes:\n192 . 168 . 1 . 10 11000000 . 10101000 . 00000001 . 00001010 Step 2: Convert Subnet Mask to Binary The subnet mask 255.255.255.0 also has four numbers. In binary, it looks like this:\n255 . 255 . 255 . 0 11111111 . 11111111 . 11111111 . 00000000 Step 3: Identify Network and Host Parts A subnet mask is used to divide the IP address into two parts:\nNetwork part: The part of the IP address that identifies the network (like identifying which city). Host part: The part that identifies the specific device within that network (like identifying the specific house). In the subnet mask 255.255.255.0, the 1s represent the network part, and the 0s represent the host part. So, for the IP address 192.168.1.10:\nNetwork Part: 192.168.1 (because the first three sections are covered by the 1s in the subnet mask). Host Part: 10 (the last section is covered by the 0s in the subnet mask). Diagram: How Subnet Mask Divides IP Address Hereâ€™s a simple visual showing how the subnet mask divides the IP address:\nIP Address: 192.168.1.10 Subnet Mask: 255.255.255.0 Binary IP: 11000000.10101000.00000001.00001010 Binary Mask: 11111111.11111111.11111111.00000000 Network Part: 11000000.10101000.00000001 (192.168.1) Host Part: 00001010 (10) The first 24 bits (the 1s in the subnet mask) represent the network. The last 8 bits (the 0s) represent the host. Visualizing a Network with Subnets Letâ€™s say you have a large network (192.168.1.0/24), which consists of all the IP addresses from 192.168.1.0 to 192.168.1.255. You can divide this large network into smaller subnets.\nThe notation /24 is part of something called CIDR notation, which stands for Classless Inter-Domain Routing. CIDR notation is a shorthand way to represent the subnet mask.\nThe number after the / (in this case, 24) tells us how many bits are used for the network portion of the IP address.\nFor example, if you use a subnet mask like 255.255.255.192, it will break the network into smaller subnets, each with fewer devices.\nExample: Dividing the Network Main Network: 192.168.1.0/24 Subnet 1: 192.168.1.0/26 Subnet 2: 192.168.1.64/26 Subnet 3: 192.168.1.128/26 Subnet 4: 192.168.1.192/26 Each subnet has its own range of IP addresses and can have its own devices. This way, you can better manage the network traffic and security.\nKey Points Subnet: Think of it as a smaller group within a large network. Subnet Mask: A tool that divides the IP address into a network part and a host part. Network Part: The part of the IP address that identifies which network the device belongs to. Host Part: The part of the IP address that identifies the specific device in the network. ","permalink":"https://bleedkagax.github.io/post/2_subnet/","summary":"\u003ch2 id=\"what-is-a-subnet\"\u003eWhat is a Subnet?\u003c/h2\u003e\n\u003cp\u003eA \u003cstrong\u003esubnet\u003c/strong\u003e is a way to divide a large network into smaller, more manageable pieces. Think of it like dividing a big city into neighborhoods. Each subnet (neighborhood) has its own group of devices (houses), but all are still part of the same overall network (city).\u003c/p\u003e\n\u003ch2 id=\"what-is-a-subnet-mask\"\u003eWhat is a Subnet Mask?\u003c/h2\u003e\n\u003cp\u003eA \u003cstrong\u003esubnet mask\u003c/strong\u003e is a number used to help identify which part of an IP address belongs to the \u003cstrong\u003enetwork\u003c/strong\u003e (city) and which part identifies the \u003cstrong\u003edevice\u003c/strong\u003e (house). Itâ€™s like a divider that separates the network part from the device part in an IP address.\u003c/p\u003e","title":"Subnet and Subnet"},{"content":"epoll (Linux): An Efficient I/O Multiplexing Mechanism epoll operates on an event-driven model, meaning it only notifies the application when an event occurs on a specific file descriptor, unlike select and poll which poll all descriptors regardless of activity. This drastically reduces overhead, especially when managing numerous connections.\nKey Features and Functionality The core functionality revolves around three system calls:\nepoll_create(size): Creates an epoll instance and returns an epoll file descriptor. While size was initially used to hint at the number of file descriptors, modern kernels largely ignore it.\nepoll_ctl(epfd, op, fd, event): Manages the set of file descriptors monitored by the epoll instance (epfd). op specifies the operation (ADD, MODIFY, or DELETE), fd is the file descriptor to manage, and event defines the events of interest (read, write, error, etc.).\nepoll_wait(epfd, events, maxevents, timeout): Waits for events on the registered file descriptors. It blocks until at least one event occurs or a timeout expires. events is a pre-allocated array where epoll_wait populates information about the triggered events. maxevents specifies the maximum number of events to return.\nScalability and Efficiency epoll\u0026rsquo;s efficiency stems from its use of a kernel-level data structure (often a red-black tree) to manage monitored file descriptors. This allows it to handle a massive number of descriptors with minimal performance degradation, a significant advantage over select and poll, which suffer from performance bottlenecks as the number of descriptors grows.\nEdge-Triggered vs. Level-Triggered epoll offers two triggering modes:\nLevel-triggered: epoll_wait returns an event as long as the condition (e.g., data available for reading) persists. If the application doesn\u0026rsquo;t process the event immediately, epoll_wait will continue to return it.\nEdge-triggered: epoll_wait only returns an event when the condition transitions from false to true. This is more efficient but requires careful handling to ensure no events are missed. The application must process all available data in a single epoll_wait cycle.\nUse Cases epoll is extensively used in high-performance network servers and applications requiring efficient management of numerous concurrent connections or I/O operations. Its scalability and event-driven nature make it a crucial component in many modern network architectures.\n","permalink":"https://bleedkagax.github.io/post/1_epoll/","summary":"\u003ch1 id=\"epoll-linux-an-efficient-io-multiplexing-mechanism\"\u003e\u003ccode\u003eepoll\u003c/code\u003e (Linux): An Efficient I/O Multiplexing Mechanism\u003c/h1\u003e\n\u003cp\u003e\u003ccode\u003eepoll\u003c/code\u003e operates on an event-driven model, meaning it only notifies the application when an event occurs on a specific file descriptor, unlike \u003ccode\u003eselect\u003c/code\u003e and \u003ccode\u003epoll\u003c/code\u003e which poll all descriptors regardless of activity. This drastically reduces overhead, especially when managing numerous connections.\u003c/p\u003e\n\u003ch2 id=\"key-features-and-functionality\"\u003eKey Features and Functionality\u003c/h2\u003e\n\u003cp\u003eThe core functionality revolves around three system calls:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ccode\u003eepoll_create(size)\u003c/code\u003e:\u003c/strong\u003e Creates an \u003ccode\u003eepoll\u003c/code\u003e instance and returns an \u003ccode\u003eepoll\u003c/code\u003e file descriptor.  While \u003ccode\u003esize\u003c/code\u003e was initially used to hint at the number of file descriptors, modern kernels largely ignore it.\u003c/p\u003e","title":"Epoll"},{"content":"SQL Transaction Isolation Levels Transaction isolation levels define the degree to which the operations in one transaction are visible to other concurrent transactions and the types of reads and writes that are allowed.\nComparison Table Isolation Level Dirty Read Non-repeatable Read Phantom Read READ UNCOMMITTED Yes Yes Yes READ COMMITTED No Yes Yes REPEATABLE READ No No Yes SERIALIZABLE No No No Explanation of Isolation Levels 1. READ UNCOMMITTED This is the lowest isolation level. Transactions can read data that has been modified by other transactions but not yet committed.\nAllows dirty reads, non-repeatable reads, and phantom reads Provides the highest level of concurrency Least consistent data state 2. READ COMMITTED This level guarantees that any data read was committed at the moment it was read. It prevents dirty reads.\nPrevents dirty reads Allows non-repeatable reads and phantom reads Each consistent read sets and reads its own fresh snapshot 3. REPEATABLE READ This level guarantees that any data read cannot change if the transaction reads it again. It prevents non-repeatable reads.\nPrevents dirty reads and non-repeatable reads Allows phantom reads All consistent reads within the same transaction read the snapshot established by the first read 4. SERIALIZABLE This is the highest isolation level. Transactions are executed as if they were run sequentially.\nPrevents dirty reads, non-repeatable reads, and phantom reads Provides the highest level of isolation May significantly impact performance due to increased locking Phenomena Explained Dirty Read: A transaction reads data that has not yet been committed. Non-repeatable Read: A transaction reads the same row twice and gets different data each time. Phantom Read: A transaction re-executes a query returning a set of rows that satisfy a search condition and finds that the set of rows satisfying the condition has changed due to another recently-committed transaction. ","permalink":"https://bleedkagax.github.io/post/2_mysql_isolation_levels/","summary":"\u003ch1 id=\"sql-transaction-isolation-levels\"\u003eSQL Transaction Isolation Levels\u003c/h1\u003e\n\u003cp\u003eTransaction isolation levels define the degree to which the operations in one transaction are visible to other concurrent transactions and the types of reads and writes that are allowed.\u003c/p\u003e\n\u003ch2 id=\"comparison-table\"\u003eComparison Table\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003eIsolation Level\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003eDirty Read\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003eNon-repeatable Read\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003ePhantom Read\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eREAD UNCOMMITTED\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eYes\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eYes\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eYes\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eREAD COMMITTED\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eNo\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eYes\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eYes\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eREPEATABLE READ\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eNo\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eNo\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eYes\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eSERIALIZABLE\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eNo\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eNo\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eNo\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"explanation-of-isolation-levels\"\u003eExplanation of Isolation Levels\u003c/h2\u003e\n\u003ch3 id=\"1-read-uncommitted\"\u003e1. READ UNCOMMITTED\u003c/h3\u003e\n\u003cp\u003eThis is the lowest isolation level. Transactions can read data that has been modified by other transactions but not yet committed.\u003c/p\u003e","title":"MySQL's Transaction Isolation Levels"},{"content":"Overview EVAL and EVALSHA are Redis commands used to execute Lua scripts within the Redis server. They differ primarily in how they handle script loading and execution:\nEVAL: This command takes the Lua script as an argument. Redis parses and hashes the script every time EVAL is called. This adds overhead, especially for frequently executed scripts.\nEVALSHA: This command takes the SHA1 hash of the Lua script as an argument. Redis retrieves the script from its internal cache using this hash. If the script is found, it\u0026rsquo;s executed directly, bypassing the parsing and hashing steps. This results in significantly faster execution times for frequently used scripts.\nKey Differences Summarized Feature EVAL EVALSHA Script Input Lua script as a string SHA1 hash of the Lua script Script Parsing Parses and hashes the script each time Retrieves from cache; no parsing Performance Slower, especially for frequent use Faster for frequently used scripts Script Cache No reliance on script cache Relies on script cache; error if miss Error Handling No specific error for cache miss Returns error if script not in cache When to Use Which EVAL: Use for testing, debugging, or scripts that are executed infrequently. It\u0026rsquo;s simpler to use since you don\u0026rsquo;t need to manage script hashes.\nEVALSHA: Use for frequently executed scripts to optimize performance. This requires a prior step to load the script using SCRIPT LOAD to obtain its SHA1 hash.\nExample Let\u0026rsquo;s say you have a Lua script to increment a counter:\nredis.call(\u0026#39;INCR\u0026#39;, KEYS[1]) Using EVAL: EVAL \u0026#34;redis.call(\u0026#39;INCR\u0026#39;, KEYS[1])\u0026#34; 1 mykey Using EVALSHA: a. Load the script and get the SHA1 hash:\nSCRIPT LOAD \u0026#34;redis.call(\u0026#39;INCR\u0026#39;, KEYS[1])\u0026#34; Redis computes the script\u0026rsquo;s SHA1 hash and stores both the script and its hash in an internal cache.\nThis returns the SHA1 hash (e.g., a1b2c3d4e5f6...).\nb. Execute using the hash:\nEVALSHA a1b2c3d4e5f6... 1 mykey Remember to replace a1b2c3d4e5f6... with the actual SHA1 hash. EVALSHA will be significantly faster if this script is executed repeatedly. However, if the script is not in the cache, EVALSHA will fail. Therefore, robust error handling is crucial in production environments. A common strategy is to use EVALSHA first and fall back to EVAL if it fails.\n","permalink":"https://bleedkagax.github.io/post/3_eval_and_evalsha/","summary":"\u003ch1 id=\"overview\"\u003eOverview\u003c/h1\u003e\n\u003cp\u003e\u003ccode\u003eEVAL\u003c/code\u003e and \u003ccode\u003eEVALSHA\u003c/code\u003e are Redis commands used to execute Lua scripts within the Redis server.  They differ primarily in how they handle script loading and execution:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ccode\u003eEVAL\u003c/code\u003e:\u003c/strong\u003e This command takes the Lua script as an argument.  Redis parses and hashes the script every time \u003ccode\u003eEVAL\u003c/code\u003e is called.  This adds overhead, especially for frequently executed scripts.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ccode\u003eEVALSHA\u003c/code\u003e:\u003c/strong\u003e This command takes the SHA1 hash of the Lua script as an argument.  Redis retrieves the script from its internal cache using this hash.  If the script is found, it\u0026rsquo;s executed directly, bypassing the parsing and hashing steps.  This results in significantly faster execution times for frequently used scripts.\u003c/p\u003e","title":"Eval and Evalsha"},{"content":"How does Go handel memory allocation Memory Allocator Overview The Go memory allocator uses a hierarchical structure:\nHeap: The main memory area where dynamically allocated objects reside. Spans: Large blocks of memory (usually 8KB) used to allocate objects. Objects: Individual allocated pieces of memory. graph TD Heap --\u0026gt; Span1[Span 1] Heap --\u0026gt; Span2[Span 2] Heap --\u0026gt; Span3[Span 3] Span1 --\u0026gt; Obj1[Object 1] Span1 --\u0026gt; Obj2[Object 2] Span2 --\u0026gt; Obj3[Object 3] Span2 --\u0026gt; Obj4[Object 4] Span3 --\u0026gt; Obj5[Object 5] Size Classes Go uses size classes to group objects of similar sizes. This reduces fragmentation and improves allocation speed.\nThere are about 70 size classes, ranging from 8 bytes to 32KB. Each size class has its own free list of available objects. Example of size classes:\nvar class_to_size = [_NumSizeClasses]uint16{ 0, 8, 16, 24, 32, 48, 64, 80, // ... more sizes ... 32768, } TCMalloc Inspiration Go\u0026rsquo;s allocator is inspired by TCMalloc (Thread-Caching Malloc), with some key differences:\nPer-P Caches: Instead of per-thread caches, Go uses per-P (processor) caches. Goroutine Stacks: Special handling for goroutine stacks, which can grow and shrink. GC Integration: Tight integration with the garbage collector. Allocation Process For small objects (â‰¤32KB): a. Check the P\u0026rsquo;s mcache for a free object in the appropriate size class. b. If mcache is empty, refill it from the central cache (mcentral). c. If mcentral is empty, allocate a new span from the heap.\nFor large objects (\u0026gt;32KB):\nAllocate directly from the heap, rounded up to a multiple of the page size. Stack Allocation Go uses stack allocation for objects that don\u0026rsquo;t escape to the heap:\nEscape analysis determines if an object can be stack-allocated. Stack objects have very low allocation/deallocation costs. Stacks can grow and shrink as needed. Example of stack vs heap allocation:\nfunc stackAlloc() int { x := 5 // x is allocated on the stack return x } func heapAlloc() *int { x := new(int) // x is allocated on the heap *x = 5 return x } Developers can use theÂ -gcflags \u0026quot;-m\u0026quot;Â option when building or running their Go programs to see how escape analysis has determined memory allocation for variables.\nFor example:\ngo build -gcflags \u0026#34;-m\u0026#34; main.go Tiny Allocations Go has a special optimization for tiny allocations (objects â‰¤16 bytes):\nMultiple tiny objects can be packed into a single memory block. This significantly reduces memory overhead for small objects. Large Object Allocation Large objects (\u0026gt;32KB) are handled differently:\nAllocated directly from the heap. Use a separate free list for efficient reuse. May trigger immediate garbage collection if the heap grows too much. Memory Profiling Go provides built-in support for memory profiling:\nUse runtime/pprof package or go test -memprofile flag. Analyze with go tool pprof for detailed memory usage information. ","permalink":"https://bleedkagax.github.io/post/8_go_memory_allocation/","summary":"\u003ch3 id=\"how-does-go-handel-memory-allocation\"\u003eHow does Go handel memory allocation\u003c/h3\u003e\n\u003ch4 id=\"memory-allocator-overview\"\u003eMemory Allocator Overview\u003c/h4\u003e\n\u003cp\u003eThe Go memory allocator uses a hierarchical structure:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eHeap\u003c/strong\u003e: The main memory area where dynamically allocated objects reside.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSpans\u003c/strong\u003e: Large blocks of memory (usually 8KB) used to allocate objects.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eObjects\u003c/strong\u003e: Individual allocated pieces of memory.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre class=\"mermaid\"\u003e\n    graph TD\n\t    Heap --\u0026gt; Span1[Span 1]\n\t    Heap --\u0026gt; Span2[Span 2]\n\t    Heap --\u0026gt; Span3[Span 3]\n\t    Span1 --\u0026gt; Obj1[Object 1]\n\t    Span1 --\u0026gt; Obj2[Object 2]\n\t    Span2 --\u0026gt; Obj3[Object 3]\n\t    Span2 --\u0026gt; Obj4[Object 4]\n\t    Span3 --\u0026gt; Obj5[Object 5]\n\u003c/pr","title":"Go Memory Allocation"},{"content":"Redlock Algorithm: Distributed Lock Management Introduction The Redlock algorithm is a distributed lock algorithm designed to provide a reliable locking mechanism in distributed systems. It was proposed by the Redis community as a way to implement distributed locks using multiple independent Redis instances.\nPurpose The main purpose of the Redlock algorithm is to ensure that:\nMutual exclusion is guaranteed Deadlock free operation is possible Fault tolerance is achieved up to a certain degree Algorithm Overview The Redlock algorithm uses multiple Redis instances (typically 5) to achieve consensus on lock acquisition and release. The basic idea is to acquire the lock in the majority of the instances to consider it as a successful lock acquisition.\nDetailed Steps Lock Acquisition Get the current time in milliseconds. Try to acquire the lock in all N Redis instances sequentially: Use a timeout for each instance that is small compared to the total lock auto-release time. If the instance is unavailable, immediately try the next instance. Calculate the time elapsed to acquire the locks. The lock is considered acquired if: The lock was acquired in the majority of instances (at least N/2 + 1) The total time elapsed is less than the lock validity time If the lock was acquired, its validity time is considered to be the initial validity time minus the time elapsed. If the lock was not acquired in the majority of instances, try to unlock all instances. Lock Release To release the lock, the client sends an unlock command to all instances, regardless of whether it was able to lock all of them during the acquisition phase or not.\nKey Considerations Clock Drift: The algorithm assumes that the clock drift between nodes is small. Timing: The validity time of the lock should be much larger than the network latency and the clock drift between nodes. Fault Tolerance: The system can tolerate at most N/2 - 1 failed nodes. Advantages High reliability due to multiple Redis instances Resistant to split-brain scenarios Does not require strong consistency between Redis nodes Disadvantages Complexity in implementation and management Increased latency due to communication with multiple Redis instances Potential for reduced availability if multiple Redis instances fail Example Implementation (Pseudocode) def acquire_lock(resource, lock_timeout): start_time = current_time_millis() for redis_instance in redis_instances: try: success = redis_instance.set(resource, unique_value, nx=True, px=lock_timeout) if success: acquired_instances.append(redis_instance) except ConnectionError: continue elapsed_time = current_time_millis() - start_time if len(acquired_instances) \u0026gt;= (N/2 + 1) and elapsed_time \u0026lt; lock_timeout: return True, lock_timeout - elapsed_time else: release_lock(resource, acquired_instances) return False, 0 def release_lock(resource, acquired_instances): for redis_instance in acquired_instances: redis_instance.delete(resource) Conclusion The Redlock algorithm provides a robust solution for distributed lock management, particularly suitable for scenarios where high reliability and fault tolerance are required. However, its complexity and potential performance impact should be carefully considered before implementation.\n","permalink":"https://bleedkagax.github.io/post/4_redlock_algorithm/","summary":"\u003ch1 id=\"redlock-algorithm-distributed-lock-management\"\u003eRedlock Algorithm: Distributed Lock Management\u003c/h1\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eThe Redlock algorithm is a distributed lock algorithm designed to provide a reliable locking mechanism in distributed systems. It was proposed by the Redis community as a way to implement distributed locks using multiple independent Redis instances.\u003c/p\u003e\n\u003ch2 id=\"purpose\"\u003ePurpose\u003c/h2\u003e\n\u003cp\u003eThe main purpose of the Redlock algorithm is to ensure that:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eMutual exclusion is guaranteed\u003c/li\u003e\n\u003cli\u003eDeadlock free operation is possible\u003c/li\u003e\n\u003cli\u003eFault tolerance is achieved up to a certain degree\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"algorithm-overview\"\u003eAlgorithm Overview\u003c/h2\u003e\n\u003cp\u003eThe Redlock algorithm uses multiple Redis instances (typically 5) to achieve consensus on lock acquisition and release. The basic idea is to acquire the lock in the majority of the instances to consider it as a successful lock acquisition.\u003c/p\u003e","title":"Redlock Algorithm"},{"content":"What is the GPM model in Go? GMP Model The GMP model is the cornerstone of Go\u0026rsquo;s runtime scheduler.\nG (Goroutine):\nRepresents a goroutine, which is a lightweight thread of execution. Contains the stack, the instruction pointer, and other information important for scheduling. Many Gs can exist at the same time. P (Processor):\nRepresents a logical processor, which can be thought of as a context for scheduling. Acts as a local scheduler, managing a queue of runnable goroutines. The number of Ps is typically equal to GOMAXPROCS, which by default is the number of CPU cores available. M (Machine):\nRepresents an OS thread. The Go runtime manages a pool of Ms. Ms execute the code of runnable goroutines. graph TD G[Goroutine] --\u0026gt; P[Processor] P --\u0026gt; M[Machine] M --\u0026gt; OS[Operating System] subgraph \u0026#34;GMP Model\u0026#34; G P M end OS Goroutine Scheduling flowchart TD GRQ[Global Run Queue] --\u0026gt; |schedule| P1[Processor P1] GRQ --\u0026gt; |schedule| P2[Processor P2] P1 --\u0026gt; |run| G1[Goroutine 1] P1 --\u0026gt; |run| G2[Goroutine 2] P2 --\u0026gt; |run| G3[Goroutine 3] P2 --\u0026gt; |run| G4[Goroutine 4] P1 -.-\u0026gt; |work stealing| P2 P2 -.-\u0026gt; |work stealing| P1 M1[Machine M1] --\u0026gt; P1 M2[Machine M2] --\u0026gt; P2 G5[New Goroutine] -.-\u0026gt; |enqueue| GRQ G6[Blocked Goroutine] -.-\u0026gt; |wake up| GRQ Scheduler Data Structures Global Run Queue (GRQ)\nHolds runnable goroutines not assigned to any P Represented by sched.runq in the runtime Used when local run queues are full or during work stealing Implemented as a lock-free ring buffer Local Run Queue (LRQ)\nEach P has its own LRQ Holds goroutines assigned to that P Implemented as a circular queue with a fixed size of 256 When full, half of the goroutines are moved to the GRQ Idle M List\nTracks idle OS threads Managed by the scheduler Used to quickly find an M when a goroutine becomes runnable Idle P List\nMaintains idle P structures Used when allocating P to new M Helps in quick P acquisition for waiting Ms Scheduling Algorithm When a new goroutine is created:\nIf there\u0026rsquo;s space in the current P\u0026rsquo;s local run queue, add it there Otherwise, add it to the global run queue When a P needs to find a goroutine to run:\nCheck its local run queue first If empty, check the global run queue If still empty, try to steal work from other Ps When a goroutine blocks (e.g., on I/O or channel operations):\nThe current M will detach from its P Another M will pick up the P and continue running goroutines When a goroutine unblocks:\nIt\u0026rsquo;s placed back on a run queue (local or global) If there\u0026rsquo;s an idle P, it may be scheduled immediately Advanced Scheduling Concepts Preemption Go uses a combination of cooperative and preemptive scheduling:\nCooperative Scheduling\nGoroutines yield control at certain points (e.g., function calls, channel operations) Implemented through checks in the compiler-generated code Preemptive Scheduling\nIntroduced in Go 1.14 for long-running goroutines Uses asynchronous preemption via signals (SIGURG on Unix systems) Allows interruption of CPU-bound goroutines Work Stealing Work stealing is a technique used by the Go scheduler to balance load across processors:\nWhen a P\u0026rsquo;s local run queue is empty, it attempts to steal work from other Ps The stealing process is randomized to avoid contention If stealing fails, the P checks the global run queue and network poller Implementation details:\nUses a random starting point to avoid always stealing from the same P Steals half of the victim\u0026rsquo;s local run queue to minimize future stealing Syscall Handling When a goroutine makes a syscall, special handling is required to ensure efficient use of resources:\nThe M running the goroutine enters syscall mode The P is detached from the M to allow other goroutines to run If there are no idle Ms, a new M may be created to run the P When the syscall completes, the goroutine is rescheduled Spinning Threads The Go scheduler uses spinning threads to reduce latency:\nSome Ms may spin instead of going to sleep immediately Spinning Ms check for new work frequently This helps in quickly responding to newly runnable goroutines The number of spinning Ms is limited to avoid wasting CPU Spinning states:\nSpinning looking for work Spinning waiting for GRQ lock Runtime Hooks and Tracing Go provides several hooks and tracing capabilities for advanced scheduling analysis:\nRuntime Tracing\nEnabled with runtime/trace package Provides detailed information about goroutine scheduling, GC, and more Scheduler Tracing\nEnabled with GODEBUG=schedtrace=X environment variable Prints scheduler state every X milliseconds Execution Tracing\nUses runtime.Trace() and runtime.StopTrace() functions Allows for custom tracing points in code Example of using runtime tracing:\npackage main import ( \u0026#34;os\u0026#34; \u0026#34;runtime/trace\u0026#34; ) func main() { // Create a trace file f, err := os.Create(\u0026#34;trace.out\u0026#34;) if err != nil { panic(err) } defer f.Close() // Start tracing err = trace.Start(f) if err != nil { panic(err) } defer trace.Stop() // Your program logic here for i := 0; i \u0026lt; 10; i++ { go func() { // Some work }() } // Wait for goroutines to finish // ... } To analyze the trace:\ngo tool trace trace.out ","permalink":"https://bleedkagax.github.io/post/7_go_gmp_model/","summary":"\u003ch3 id=\"what-is-the-gpm-model-in-go\"\u003eWhat is the GPM model in Go?\u003c/h3\u003e\n\u003ch4 id=\"gmp-model\"\u003eGMP Model\u003c/h4\u003e\n\u003cp\u003eThe GMP model is the cornerstone of Go\u0026rsquo;s runtime scheduler.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eG (Goroutine)\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRepresents a goroutine, which is a lightweight thread of execution.\u003c/li\u003e\n\u003cli\u003eContains the stack, the instruction pointer, and other information important for scheduling.\u003c/li\u003e\n\u003cli\u003eMany Gs can exist at the same time.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eP (Processor)\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRepresents a logical processor, which can be thought of as a context for scheduling.\u003c/li\u003e\n\u003cli\u003eActs as a local scheduler, managing a queue of runnable goroutines.\u003c/li\u003e\n\u003cli\u003eThe number of Ps is typically equal to \u003ccode\u003eGOMAXPROCS\u003c/code\u003e, which by default is the number of CPU cores available.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eM (Machine)\u003c/strong\u003e:\u003c/p\u003e","title":"Go's GMP Model"},{"content":"How does Go handle dependencies? Go uses a module system for dependency management. The go.mod file specifies the module\u0026rsquo;s dependencies and their versions. The go get command is used to download and install dependencies.\nWhat is the difference between go run and go build ? Feature go run go build Purpose Compile and run in one step Compile to a permanent executable Output Temporary executable (deleted) Permanent executable on disk Use Case Quick testing of small programs Building applications for deployment Performance Slower due to temporary compilation Faster execution of compiled binary Debugging Limited debugging capabilities Supports debugging and profiling Configuration Options None Various options for customization Use go run for quick tests and development. Use go build for creating deployable binaries. What is a goroutine? A goroutine is a lightweight thread managed by the Go runtime. It allows concurrent execution of functions or methods. Goroutines are created using the go keyword followed by a function call.\nWhat is a channel in Go? A channel is a typed conduit through which you can send and receive values with the channel operator \u0026lt;-. Channels are used for communication and synchronization between goroutines.\nWhat is the difference between unbuffered and buffered channels? Unbuffered channels: Sending and receiving operations block until the other side is ready. Buffered channels: Have a capacity and can hold that many values before blocking. How do you handle errors in Go? Go doesn\u0026rsquo;t have exceptions. Instead, it uses multiple return values, with the last value typically being an error type. The error interface is used to represent error conditions.\nWhat are slices in Go? Slices are dynamic, flexible view into arrays. They consist of a pointer to an array, a length, and a capacity. Slices can be resized using the append function.\nWhat is the purpose of the init() function? The init() function is used for initialization tasks. It\u0026rsquo;s automatically executed before the main() function. Each file can have multiple init() functions.\nHow does Go support object-oriented programming? Go doesn\u0026rsquo;t have classes but uses structs with methods to achieve object-oriented design. It supports composition over inheritance.\nWhat are methods in Go? Methods are functions associated with a particular type. They have a receiver argument that appears between the func keyword and the method name.\nHow do you achieve inheritance in Go? Go doesn\u0026rsquo;t support inheritance directly. Instead, it uses composition and embedding to reuse code.\nWhat are interfaces in Go? Interfaces are named collections of method signatures. They provide a way to specify the behavior of an object.\nHow does Go implement polymorphism? Go achieves polymorphism through interfaces. Any type that implements all the methods of an interface implicitly satisfies that interface.\nWhat is the difference between concurrency and parallelism? Concurrency is about managing multiple tasks that run in overlapping time periods, while parallelism is about tasks that run simultaneously.\nHow does Go handle race conditions? Understanding Race Conditions A race condition typically happens in scenarios where two or more goroutines attempt to read and write to the same variable simultaneously. This can lead to unpredictable behavior. For example, consider two goroutines incrementing a shared counter.\nDetecting Race Conditions Go provides a built-in race detector that can be enabled during compilation. You can run your program with the -race flag:\ngo run -race main.go Preventing Race Conditions a. Mutexes: The sync.Mutex type allows you to lock and unlock access to shared resources. b. Channels: Channels can also be used for synchronization by ensuring that only one goroutine writes to a variable at a time. c. Atomic Operations: For simple operations like incrementing a counter, you can use the sync/atomic package.\nWhat is a mutex in Go? A mutex (mutual exclusion) is used to provide a locking mechanism to ensure that only one goroutine is accessing a section of code at any given time.\nHow can you limit the number of goroutines running concurrently? A semaphore pattern with buffered channels Use the sync.WaitGroup How does Go handle slice growth when capacity is insufficient? When a slice\u0026rsquo;s length reaches its capacity and more elements need to be added, Go allocates a new underlying array.\nCapacity check:\nGo checks if the current capacity is sufficient for the operation. If len(slice) == cap(slice), it means the slice has reached its capacity. New array allocation:\nIf capacity is insufficient, Go allocates a new, larger underlying array. The size of the new array is typically double the current capacity. For very large slices, the growth factor may be smaller to avoid excessive memory usage. Copy elements:\nAll existing elements are copied from the old array to the new array. Update slice header:\nThe slice header is updated to point to the new underlying array. The capacity is set to the size of the new array. The length is increased to accommodate the new element(s). Growth algorithm:\nThe exact growth algorithm can vary between Go versions, but it generally follows this pattern: If the current capacity is less than 1024, double it. If it\u0026rsquo;s greater than or equal to 1024, grow by 25%. Performance implications:\nGrowing a slice can be an expensive operation due to memory allocation and copying. To minimize this cost, it\u0026rsquo;s often beneficial to pre-allocate slices with a known capacity. Use copy() function for explicit control over slice growth and to avoid unexpected sharing of underlying arrays. Garbage collection:\nThe old array becomes eligible for garbage collection once it\u0026rsquo;s no longer referenced. What is escape analysis in Go? Escape analysis is the process by which the Go compiler determines whether a variable\u0026rsquo;s lifetime extends beyond its local scope. This helps in deciding whether to allocate the variable on the stack or the heap.\nHow do you write tests in Go? Go has a built-in testing framework. Test files are named with a _test.go suffix. Test functions start with Test and take *testing.T as an argument.\nWhat is table-driven testing? Table-driven testing is a technique where multiple test cases are defined in a slice or map, and a single test function iterates over these cases.\nWhat is the purpose of the go vet command? go vet examines Go source code and reports suspicious constructs, such as Printf calls with mismatched arguments.\nHow do you document Go code? Go uses godoc for documentation. Comments preceding package declarations and top-level declarations are extracted as documentation.\nWhat are the empty interface and type assertions? The empty interface interface{} can hold values of any type. Type assertions provide access to an interface value\u0026rsquo;s underlying concrete value.\nHow does Go support generics? As of Go 1.18, Go supports generics using type parameters. This allows writing functions and data structures that can work with multiple types.\nHow does Go handle panics? Panic:\nA panic is triggered by runtime errors, such as accessing an out-of-bounds array or dereferencing a nil pointer. When a panic occurs, the program stops executing the current function and begins unwinding the stack, executing deferred functions in Last In, First Out (LIFO) order. If no deferred function handles the panic, the program terminates and prints an error message. Defer:\nThe defer statement schedules a function call to be executed after the surrounding function returns. Recover:\nThe recover function stops the panic\u0026rsquo;s propagation and returns the value passed to panic. It must be called within a deferred function to be effective; otherwise, it returns nil. package main import ( \u0026#34;fmt\u0026#34; ) func recoverFromPanic() { if r := recover(); r != nil { fmt.Println(\u0026#34;Recovered from panic:\u0026#34;, r) } } func riskyFunction() { defer recoverFromPanic() // Defer recovery function fmt.Println(\u0026#34;Executing risky function...\u0026#34;) panic(\u0026#34;Something went wrong!\u0026#34;) // Trigger a panic } func main() { fmt.Println(\u0026#34;Start\u0026#34;) riskyFunction() fmt.Println(\u0026#34;End\u0026#34;) // This line won\u0026#39;t be reached due to panic } // Output: // Start // Executing risky function... // Recovered from panic: Something went wrong! How do you handle configuration in Go applications? Common approaches include:\nCommand-line flags Environment variables Configuration files (JSON, YAML, TOML) Combination of the above using libraries like Viper What are some common concurrency patterns in Go? Worker pools Fan-out, fan-in Pipeline Cancellation and timeouts using context 1. Worker Pools Definition: A worker pool is a design pattern where a fixed number of goroutines (workers) are created to process tasks from a queue concurrently. Implementation: Tasks are sent to a channel, and idle workers pick them up for execution. This approach limits the number of concurrent tasks, helping to manage resource usage effectively. Benefits: Reduces overhead from creating and destroying goroutines for each task. Allows for better control over concurrency and resource consumption. 2. Fan-Out, Fan-In Fan-Out: This pattern involves distributing tasks across multiple goroutines to parallelize work. For example, multiple workers can read from the same input source (like a channel). Fan-In: This pattern combines results from multiple goroutines into a single channel. It helps in aggregating results while maintaining simplicity in handling outputs. Use Case: Useful in scenarios where tasks can be processed independently and results need to be collected. 3. Pipeline Definition: In the pipeline pattern, data flows through a series of processing stages, with each stage handled by a separate goroutine. Implementation: Each stage reads from one channel and writes to another, creating a chain of processing steps. Benefits: Enables separation of concerns by breaking down complex processing into manageable stages. Facilitates concurrent processing at each stage, improving throughput. 4. Cancellation and Timeouts Using Context Context Package: Go\u0026rsquo;s context package provides a way to manage cancellation signals and timeouts across goroutines. Usage: You can create contexts that carry deadlines or cancellation signals, allowing goroutines to check for termination requests and clean up resources accordingly. Benefits: Helps prevent resource leaks by ensuring that goroutines can exit gracefully when no longer needed. Simplifies managing timeouts for operations like network requests or long-running computations. How does Go support cross-compilation? Go supports cross-compilation by setting the GOOS and GOARCH environment variables before building.\nGOOS=linux GOARCH=amd64 go build What is context.Context and when would you use it? context.Context is used to carry deadlines, cancellation signals, and request-scoped values across API boundaries and between processes. It helps manage long-running operations and allows for graceful cancellation.\nExample:\nctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() select { case \u0026lt;-time.After(2 * time.Second): fmt.Println(\u0026#34;operation completed\u0026#34;) case \u0026lt;-ctx.Done(): fmt.Println(\u0026#34;operation cancelled:\u0026#34;, ctx.Err()) } Explain the concept of goroutine safety and how to achieve it. Goroutine safety refers to the ability of a function, variable, or data structure to be safely accessed by multiple goroutines concurrently without data races or other concurrency issues. To achieve goroutine safety:\nUse channels for communication between goroutines. Employ synchronization primitives like sync.Mutex and sync.RWMutex to protect shared resources. Avoid sharing mutable state between goroutines whenever possible. What is the purpose of the select statement in Go? The select statement is used to wait on multiple channel operations. It allows a goroutine to wait on multiple communication operations and proceeds with the first one that becomes ready. If multiple operations are ready, it selects one at random.\nExample:\nselect { case msg := \u0026lt;-ch1: fmt.Println(\u0026#34;Received message:\u0026#34;, msg) case ch2 \u0026lt;- someValue: fmt.Println(\u0026#34;Sent value to ch2\u0026#34;) default: fmt.Println(\u0026#34;No communication was ready\u0026#34;) } Explain the concept of goroutine leaks and how to avoid them. Goroutine leaks occur when a goroutine is created but never terminates or is never collected by the garbage collector.\nTo avoid goroutine leaks:\nEnsure that all created goroutines are properly terminated when they are no longer needed. Use context.Context to signal cancellation and termination of goroutines. Properly handle and close channels to prevent goroutines from waiting indefinitely. What is the purpose of the reflect package in Go? Inspecting the type and value of variables at runtime. Creating and modifying variables dynamically. Calling methods and functions with dynamic arguments. Explain the concept of type embedding in Go. Type embedding is a way to achieve composition in Go. It allows you to embed a type (called an anonymous field) within another type. The embedded type\u0026rsquo;s methods are then promoted to the embedding type, making them accessible as if they were defined on the embedding type itself.\nExample:\ntype Person struct { Name string } func (p *Person) Introduce() { fmt.Printf(\u0026#34;Hello, my name is %s\\n\u0026#34;, p.Name) } type Student struct { *Person Grade int } student := \u0026amp;Student{ Person: \u0026amp;Person{\u0026#34;John\u0026#34;}, Grade: A, } student.Introduce() // Calls Person.Introduce() Explain the concept of function literals and closures in Go. In Go, function literals are anonymous functions that can be assigned to variables or passed as arguments to other functions. Closures are function literals that can access variables from an enclosing function, even after the enclosing function has returned.\nExample:\nfunc adder() func(int) int { sum := 0 return func(x int) int { sum += x return sum } } myAdder := adder() fmt.Println(myAdder(1)) // Output: 1 fmt.Println(myAdder(2)) // Output: 3 fmt.Println(myAdder(3)) // Output: 6 Why Closures Can Access Enclosing Variables Variable Capture\nWhen a closure is created, it captures the variables from its surrounding environment (the enclosing function). This means that the closure holds references to these variables, allowing it to access and modify them even after the enclosing function has exited. The variables it captures may be allocated on the heap instead of the stack.\nLifetime of Variables\nThe captured variables persist in memory as long as the closure is accessible. This is crucial because it allows the closure to maintain state across multiple invocations. For example, if a closure is used as a counter, it can remember the count between calls.\nMemory Management:\nGo\u0026rsquo;s garbage collector manages these captured variables. As long as there are references to the closure, the memory for the captured variables remains allocated. Once the closure is no longer accessible, the garbage collector can reclaim that memory.\nWhat is the purpose of the unsafe package in Go? The unsafe package provides functionality for low-level memory manipulation and type conversions. It allows you to bypass type safety and perform operations that are normally not allowed by the Go type system.\nExample:\ntype Person struct { Name string Age int } p := \u0026amp;Person{\u0026#34;John\u0026#34;, 30} ptrToAge := unsafe.Pointer(uintptr(unsafe.Pointer(p)) + unsafe.Offsetof(p.Age)) *(*int)(ptrToAge) = 31 Explain the concept of function composition in Go. Function composition is the act of combining simple functions to build more complex ones.\nExample:\nfunc square(x int) int { return x * x } func double(x int) int { return x * 2 } func compose(f, g func(int) int) func(int) int { return func(x int) int { return f(g(x)) } } squareAndDouble := compose(square, double) fmt.Println(squareAndDouble(3)) // Output: 36 What is the purpose of the fmt package in Go? The fmt package provides functions for formatting and printing output. It supports printing of various data types, including integers, floats, strings, and custom types. The package also provides functions for reading input from the user.\nExample:\nname := \u0026#34;John\u0026#34; age := 30 fmt.Printf(\u0026#34;Name: %s, Age: %d\\n\u0026#34;, name, age) Explain the concept of method overriding in Go. Embed a type within another type and promote the embedded type\u0026rsquo;s methods to the embedding type.\nExample:\ntype Animal struct { Name string } func (a *Animal) Speak() { fmt.Printf(\u0026#34;%s speaks\\n\u0026#34;, a.Name) } type Dog struct { *Animal } func (d *Dog) Speak() { fmt.Printf(\u0026#34;%s barks\\n\u0026#34;, d.Name) } dog := \u0026amp;Dog{\u0026amp;Animal{\u0026#34;Buddy\u0026#34;}} dog.Speak() // Calls Dog.Speak() dog.Animal.Speak() // Calls Animal.Speak() What is the purpose of the os package in Go? The os package provides a platform-independent interface to operating system functionality.\nworking with files, directories, processes, and environment variables. standard input, output, and error streams. Example:\nfile, err := os.Open(\u0026#34;file.txt\u0026#34;) if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) return } defer file.Close() data := make([]byte, 1024) _, err = file.Read(data) if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) return } fmt.Println(\u0026#34;File contents:\u0026#34;, string(data)) Explain the concept of method sets and pointer receivers in Go. In Go, a type\u0026rsquo;s method set determines which methods can be called on values of that type. The method set is affected by whether the receiver is a pointer or a value:\nFor a value receiver, the method set includes all methods with a value receiver.\nFor a pointer receiver, the method set includes all methods with a pointer receiver or a value receiver.\nExample:\ntype Person struct { Name string } func (p *Person) Introduce() { fmt.Printf(\u0026#34;Hello, my name is %s\\n\u0026#34;, p.Name) } func main() { p1 := \u0026amp;Person{\u0026#34;John\u0026#34;} p1.Introduce() // OK p2 := Person{\u0026#34;Jane\u0026#34;} p2.Introduce() // OK } What is the purpose of the io package in Go? The io package provides basic interfaces for I/O (input/output) operations. It includes:\nio.Reader: Used for reading data from a source.\nio.Writer: Used for writing data to a destination.\nio.Closer: Used for closing an I/O resource.\nThe package also provides utility functions for working with I/O operations, such as io.Copy, io.ReadFull, and io.WriteString.\nExample:\nreader := strings.NewReader(\u0026#34;Hello, World!\u0026#34;) writer := os.Stdout _, err := io.Copy(writer, reader) if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) } Explain the concept of type assertions in Go. Type assertions are used to extract an interface value\u0026rsquo;s concrete type. They provide a way to safely convert an interface{} value to a specific type. If the conversion is successful, the type assertion returns the value of the specified type; otherwise, it returns the zero value of the specified type and a boolean indicating whether the conversion was successful.\nWhy shouldn\u0026rsquo;t we use a large number of goroutines? Using a large number of goroutines can lead to several issues:\nResource consumption: Each goroutine requires memory allocation. While goroutines are lightweight compared to OS threads, they still consume memory. Creating too many can lead to excessive memory usage.\nScheduling overhead: The Go runtime needs to manage and schedule all active goroutines. With a very large number of goroutines, the overhead of scheduling can become significant, potentially impacting performance.\nContention for shared resources: More goroutines may lead to increased contention for shared resources such as locks, channels, or other synchronization primitives.\nReduced performance: Paradoxically, creating too many goroutines can lead to decreased overall performance due to the above factors.\nDifficulty in debugging: A program with an excessive number of goroutines can be harder to debug and reason about.\nIs there a limit to the number of goroutines that can be created in Go? There is no hard limit on the number of goroutines that can be created in Go. However, practical limits exist due to several factors:\nAvailable system memory: Each goroutine requires a small amount of memory for its stack (typically starting at 2KB). Creating millions of goroutines could potentially exhaust available memory.\nOS resources: While goroutines are managed by the Go runtime, they still rely on underlying OS resources. The number of file descriptors or other OS-level limits could potentially be a bottleneck.\nGo runtime\u0026rsquo;s management capabilities: The Go scheduler needs to manage all these goroutines. While it\u0026rsquo;s highly efficient, there could be performance implications when dealing with an extremely large number of goroutines.\nApplication design: The practical limit often depends on the specific application\u0026rsquo;s design and requirements.\nWhat concurrency mechanisms does Golang support? Goroutines:\nLightweight threads managed by the Go runtime. Created with the go keyword. Allow concurrent execution of functions. Channels:\nProvide a way for goroutines to communicate and synchronize. Can be buffered or unbuffered. Follow the \u0026ldquo;Don\u0026rsquo;t communicate by sharing memory; share memory by communicating\u0026rdquo; principle. Select Statement:\nAllows a goroutine to wait on multiple channel operations. Provides non-blocking communication on channels. Sync Package:\nMutex and RWMutex for mutual exclusion. WaitGroup for waiting for a collection of goroutines to finish. Once for one-time initialization. Cond for waiting for/announcing condition changes. Atomic Operations:\nThe sync/atomic package provides atomic operations for primitive types. Context Package:\nProvides a way to carry deadlines, cancellation signals, and request-scoped values across API boundaries and between goroutines. Worker Pools:\nWhile not a built-in mechanism, it\u0026rsquo;s a common pattern in Go for managing concurrency. How does Go utilize channels for communication? \u0026ldquo;Don\u0026rsquo;t communicate by sharing memory; share memory by communicating.\u0026rdquo;\nCreation:\nChannels are created using the make function: ch := make(chan int) // Unbuffered channel ch := make(chan int, 5) // Buffered channel with capacity 5 Sending Data:\nData is sent to a channel using the \u0026lt;- operator: ch \u0026lt;- 42 // Send value 42 to channel ch Receiving Data:\nData is received from a channel using the \u0026lt;- operator: value := \u0026lt;-ch // Receive value from channel ch Closing Channels:\nChannels can be closed to indicate no more values will be sent: close(ch) Range Over Channels:\nYou can use a for range loop to receive values until the channel is closed: for value := range ch { // Process value } Select Statement:\nUsed to handle multiple channel operations: select { case v1 := \u0026lt;-ch1: // Handle value from ch1 case ch2 \u0026lt;- v2: // Send v2 to ch2 default: // Do something else if all channel operations would block } Directional Channels:\nChannels can be declared as send-only or receive-only: var sendCh chan\u0026lt;- int // Send-only channel var recvCh \u0026lt;-chan int // Receive-only channel Synchronization:\nUnbuffered channels provide synchronization between sender and receiver. Signaling:\nChannels can be used to signal events between goroutines. Fan-out and Fan-in Patterns:\nMultiple goroutines can read from a single channel (fan-out) or write to a single channel (fan-in). Worker Pools: Channels are often used to implement worker pools for concurrent task processing. Timeouts: Combined with the time.After function, channels can implement timeouts in operations. What\u0026rsquo;s the difference between buffered and unbuffered channels? Unbuffered Channels:\nCapacity: Have no capacity (or a capacity of 0). Synchronization: Provide synchronization between sender and receiver. Blocking: Send operation blocks until a receiver is ready. Receive operation blocks until a sender sends a value. Use Case: Best for direct communication where you want the sender and receiver to rendezvous. Creation: ch := make(chan int) Buffered Channels:\nCapacity: Have a defined capacity greater than 0. Asynchronous: Allow for asynchronous communication up to the buffer size. Blocking: Send operation only blocks when the buffer is full. Receive operation only blocks when the buffer is empty. Use Case: Useful when you want to decouple sender and receiver, or to implement a producer-consumer pattern with some slack. Creation: ch := make(chan int, capacity) What is the implementation principle of channels? Data Structure:\nChannels are implemented as a circular queue (ring buffer). The structure includes pointers to the buffer, send and receive indices, and other metadata. Mutex:\nA mutex is used to ensure thread-safety for operations on the channel. Semaphores:\nTwo semaphores are used: one for senders and one for receivers. These manage blocking and waking of goroutines. Goroutine Queues:\nSeparate queues are maintained for blocked senders and receivers. Buffer:\nFor buffered channels, a slice is used to store the buffered elements. Unbuffered channels have a buffer of size 0. Send Operation:\nIf the channel is full (or unbuffered with no receiver), the sender blocks. The value is copied to the receiver or to the buffer. If receivers are waiting, one is woken up. Receive Operation:\nIf the channel is empty and no senders are ready, the receiver blocks. The value is copied from the sender or from the buffer. If senders are waiting, one is woken up. Close Operation:\nSets a flag indicating the channel is closed. Wakes up all blocked receivers. Causes future send operations to panic. What issues can arise with a closed channel? Panic on Send:\nSending on a closed channel causes a panic. close(ch) ch \u0026lt;- 1 // This will panic Immediate Return on Receive:\nReceiving from a closed channel immediately returns the zero value of the channel\u0026rsquo;s type and false as the second return value. close(ch) value, ok := \u0026lt;-ch // value will be zero value, ok will be false Nil Channel Behavior:\nClosing a nil channel causes a panic. var ch chan int close(ch) // This will panic Double Close:\nClosing an already closed channel causes a panic. close(ch) close(ch) // This will panic How can parallel goroutines be implemented? Using WaitGroups:\nvar wg sync.WaitGroup for i := 0; i \u0026lt; numTasks; i++ { wg.Add(1) go func(id int) { defer wg.Done() // Task logic here }(i) } wg.Wait() Worker Pools:\nfunc worker(id int, jobs \u0026lt;-chan int, results chan\u0026lt;- int) { for j := range jobs { results \u0026lt;- j * 2 } } const numWorkers = 3 jobs := make(chan int, 100) results := make(chan int, 100) for w := 1; w \u0026lt;= numWorkers; w++ { go worker(w, jobs, results) } for j := 1; j \u0026lt;= 100; j++ { jobs \u0026lt;- j } close(jobs) for a := 1; a \u0026lt;= 100; a++ { \u0026lt;-results } Using GOMAXPROCS:\nruntime.GOMAXPROCS(runtime.NumCPU()) Fan-Out, Fan-In Pattern:\nfunc fanOut(input \u0026lt;-chan int, workers int) []\u0026lt;-chan int { outputs := make([]\u0026lt;-chan int, workers) for i := 0; i \u0026lt; workers; i++ { outputs[i] = worker(input) } return outputs } func fanIn(channels ...\u0026lt;-chan int) \u0026lt;-chan int { var wg sync.WaitGroup out := make(chan int) for _, c := range channels { wg.Add(1) go func(ch \u0026lt;-chan int) { defer wg.Done() for n := range ch { out \u0026lt;- n } }(c) } go func() { wg.Wait() close(out) }() return out } How to gracefully closing channels in Go a. Using sync.Once to ensure closing only once type DataChannel struct { ch chan int once sync.Once } func (dc *DataChannel) Close() { dc.once.Do(func() { close(dc.ch) }) } b. Using a dedicated close signal channel func worker(done \u0026lt;-chan struct{}) { for { select { case \u0026lt;-done: return default: // Do work } } } func main() { done := make(chan struct{}) go worker(done) // Some time later close(done) } c. Using context for control package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { ctx, cancel := context.WithCancel(context.Background()) defer cancel() // Ensure resources are freed ch := make(chan int) go func() { for i := 0; i \u0026lt; 5; i++ { select { case \u0026lt;-ctx.Done(): // Listen for cancellation fmt.Println(\u0026#34;Goroutine cancelled, closing channel.\u0026#34;) close(ch) // Close the channel when cancelled return case ch \u0026lt;- i: // Send data to channel } } close(ch) // Close the channel after sending all data }() // Simulate some condition to cancel time.Sleep(2 * time.Second) cancel() // Cancel the context for value := range ch { // Read values until the channel is closed fmt.Println(value) } fmt.Println(\u0026#34;Channel closed.\u0026#34;) } How to Prevent Closing a Channel Multiple Times and Notify Other Channels in Go 1. Use a Wrapper Struct with Mutex Create a struct that wraps the channel and includes a mutex to ensure safe closure.\ntype SafeChannel struct { ch chan int closed bool mutex sync.Mutex } 2. Use sync.Once for Closing Utilize sync.Once to ensure the channel is closed only once.\n3. Implement a notification mechanism using sync.Cond package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { var mu sync.Mutex cond := sync.NewCond(\u0026amp;mu) // Goroutine that waits for notification go func() { mu.Lock() defer mu.Unlock() fmt.Println(\u0026#34;Waiting for notification...\u0026#34;) cond.Wait() fmt.Println(\u0026#34;Received notification!\u0026#34;) }() // Simulate some work before sending notification mu.Lock() fmt.Println(\u0026#34;Sending notification...\u0026#34;) cond.Signal() // Notify the waiting goroutine mu.Unlock() // Wait for user input before exiting var input string fmt.Scanln(\u0026amp;input) } Are locks in Go reentrant? No, locks in Go (specifically sync.Mutex and sync.RWMutex) are not reentrant.\nDefinition of Reentrant Lock: A reentrant lock (also known as a recursive lock) is a lock that can be acquired multiple times by the same goroutine without causing a deadlock.\nGo\u0026rsquo;s Mutex Behavior:\nIf a goroutine tries to lock a sync.Mutex that it has already locked, it will deadlock. This applies to both sync.Mutex and sync.RWMutex. Will It Wait Indefinitely If It Cannot Acquire the Lock? Yes, if a goroutine attempts to acquire a lock that is already held by another goroutine, it will block and wait indefinitely until the lock becomes available.\nHow to Implement a Timeout Lock? use a combination of channels and context.\ncontext.WithTimeout\nHow do new and make allocate memory in Go, and what are the underlying principles? 1. new Functionality: new allocates memory for a type and initializes it to the zero value, returning a pointer to that type. Usage: p := new(int) // p is a pointer to an int initialized to 0 Underlying Principles: Memory allocated by new can be on the heap or stack, typically on the stack unless escape analysis determines it should be on the heap. It only allocates memory without performing any initialization beyond setting it to zero. 2. make Functionality: make is used to initialize slices, maps, and channels, returning the corresponding value (not a pointer). Usage: s := make([]int, 10, 100) // Creates a slice of length 10 and capacity 100 Underlying Principles: make not only allocates memory but also sets up the internal structure (like length and capacity) for slices, maps, or channels. It generally allocates memory on the heap to ensure proper initialization of these composite data types. How to design a map in Go without using the built-in map function? Create a bucket structure:\ntype bucket struct { key string value interface{} next *bucket } Define the map structure:\ntype HashMap struct { buckets []*bucket size int } Implement a hash function:\nfunc hash(s string) int { h := 0 for i := 0; i \u0026lt; len(s); i++ { h = 31*h + int(s[i]) } return h } Implement basic operations:\nSet:\nfunc (hm *HashMap) Set(key string, value interface{}) { index := hash(key) % len(hm.buckets) for b := hm.buckets[index]; b != nil; b = b.next { if b.key == key { b.value = value return } } hm.buckets[index] = \u0026amp;bucket{key, value, hm.buckets[index]} hm.size++ } Get:\nfunc (hm *HashMap) Get(key string) (interface{}, bool) { index := hash(key) % len(hm.buckets) for b := hm.buckets[index]; b != nil; b = b.next { if b.key == key { return b.value, true } } return nil, false } Implement resizing:\nCreate a method to resize the hash map when it becomes too full. Typically, you\u0026rsquo;d double the size of the buckets array and rehash all existing entries. Add additional methods like Delete, Size, Clear, etc.\nCan Go slices and strings be directly converted? Yes, Go allows direct conversion between slices of bytes and strings, but with some important considerations:\nSlice to String Conversion:\nbyteSlice := []byte{\u0026#39;H\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;o\u0026#39;} str := string(byteSlice) This is a cheap operation that doesn\u0026rsquo;t copy the underlying data. The resulting string shares the same backing array as the slice. String to Slice Conversion:\nstr := \u0026#34;Hello\u0026#34; byteSlice := []byte(str) This creates a copy of the string\u0026rsquo;s data. Necessary because strings in Go are immutable, while slices are mutable. How many key comparisons are required to find a key in a Go map? Typically 1-2 Comparisons:\nSingle Entry Buckets: Only one comparison is needed. Minimal Collisions: In scenarios with rare collisions, an additional second comparison might be required. Slice as map key in Go? No\nMap keys must be comparable types in Go. Slices are not comparable types. This restriction exists because slices are mutable and contain references to underlying arrays. Empty struct in Golang Definition: An empty struct is declared as struct{}. Size: Empty structs occupy 0 bytes of storage. Common uses: As map keys when you only care about the key\u0026rsquo;s existence As channel elements when you only need synchronization Implementing sets Can they be copied to each other? Can they be explicitly type-converted? What is the relationship between them? Function types with identical signatures:\nIn Go, function types are determined by their signatures. When using the same function type or anonymous functions, function types with identical signatures are completely equivalent and can be directly assigned and copied to each other.\nImpact of type aliases:\nFunctions defined using different type aliases, even with identical signatures, are considered different types. In this case, explicit type conversion is required for assignment between them.\nExplicit type conversion:\nWhen necessary, explicit type conversion can be used to convert a value of one function type to another function type with an identical signature.\nContainer package List (container/list): A doubly linked list implementation Usage: import \u0026#34;container/list\u0026#34; l := list.New() l.PushBack(1) l.PushFront(2) for e := l.Front(); e != nil; e = e.Next() { fmt.Println(e.Value) } Ring (container/ring): A circular list implementation Usage: import \u0026#34;container/ring\u0026#34; r := ring.New(5) for i := 0; i \u0026lt; r.Len(); i++ { r.Value = i r = r.Next() } r.Do(func(p interface{}) { fmt.Println(p) }) Heap (container/heap): A heap implementation (priority queue) Requires implementing the heap.Interface Usage: import \u0026#34;container/heap\u0026#34; type IntHeap []int func (h IntHeap) Len() int { return len(h) } func (h IntHeap) Less(i, j int) bool { return h[i] \u0026lt; h[j] } func (h IntHeap) Swap(i, j int) { h[i], h[j] = h[j], h[i] } func (h *IntHeap) Push(x interface{}) { *h = append(*h, x.(int)) } func (h *IntHeap) Pop() interface{} { old := *h n := len(old) x := old[n-1] *h = old[0 : n-1] return x } h := \u0026amp;IntHeap{2, 1, 5} heap.Init(h) heap.Push(h, 3) fmt.Printf(\u0026#34;minimum: %d\\n\u0026#34;, (*h)[0]) ","permalink":"https://bleedkagax.github.io/post/0_go_interview/","summary":"\u003ch3 id=\"how-does-go-handle-dependencies\"\u003eHow does Go handle dependencies?\u003c/h3\u003e\n\u003cp\u003eGo uses a module system for dependency management. The \u003ccode\u003ego.mod\u003c/code\u003e file specifies the module\u0026rsquo;s dependencies and their versions. The \u003ccode\u003ego get\u003c/code\u003e command is used to download and install dependencies.\u003c/p\u003e\n\u003ch3 id=\"what-is-the-difference-between-go-run-and-go-build-\"\u003eWhat is the difference between \u003ccode\u003ego run\u003c/code\u003e and \u003ccode\u003ego build\u003c/code\u003e ?\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003eFeature\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e\u003ccode\u003ego run\u003c/code\u003e\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e\u003ccode\u003ego build\u003c/code\u003e\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003cstrong\u003ePurpose\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eCompile and run in one step\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eCompile to a permanent executable\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003cstrong\u003eOutput\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eTemporary executable (deleted)\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003ePermanent executable on disk\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003cstrong\u003eUse Case\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eQuick testing of small programs\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eBuilding applications for deployment\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003cstrong\u003ePerformance\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eSlower due to temporary compilation\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eFaster execution of compiled binary\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003cstrong\u003eDebugging\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eLimited debugging capabilities\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eSupports debugging and profiling\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003cstrong\u003eConfiguration Options\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eNone\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eVarious options for customization\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cul\u003e\n\u003cli\u003eUse \u003cstrong\u003e\u003ccode\u003ego run\u003c/code\u003e\u003c/strong\u003e for quick tests and development.\u003c/li\u003e\n\u003cli\u003eUse \u003cstrong\u003e\u003ccode\u003ego build\u003c/code\u003e\u003c/strong\u003e for creating deployable binaries.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"what-is-a-goroutine\"\u003eWhat is a goroutine?\u003c/h3\u003e\n\u003cp\u003eA goroutine is a lightweight thread managed by the Go runtime. It allows concurrent execution of functions or methods. Goroutines are created using the \u003ccode\u003ego\u003c/code\u003e keyword followed by a function call.\u003c/p\u003e","title":"Golang Interview"},{"content":"How to Solve Cache Penetration? Cache penetration occurs when requests for non-existent data bypass the cache and hit the database repeatedly. Solutions include:\nCaching Empty Results: Store empty results for non-existent keys with a short expiration time. Bloom Filters: Use a Bloom filter to check if a key exists before querying the database. Rate Limiting: Limit requests for certain keys to prevent overwhelming the database with requests for non-existent data. How to Solve Cache Avalanche? Cache avalanche involves a massive number of database hits due to the simultaneous expiration of many cache entries or a cache server failure.\nWhile rate limiting (a solution for cache penetration) can helpÂ mitigateÂ the impact of a cache avalanche by reducing the load on the database, it doesn\u0026rsquo;t prevent the avalanche itself. The core of solving a cache avalanche lies in different strategies:\nStaggered Expiration:Â Instead of setting the same expiration time for all cache entries, vary the expiration times slightly to prevent mass simultaneous expirations. Cache Clustering/Redundancy:Â Use multiple cache servers to distribute the load and provide redundancy. If one server fails, others can continue serving requests. Cache Pre-warming:Â For frequently accessed data, proactively load it into the cache before it\u0026rsquo;s requested. Circuit Breakers:Â Implement circuit breakers to prevent cascading failures. If the database becomes overloaded, the circuit breaker can temporarily stop sending requests to it, preventing further overload. What Are the Communication Methods Between Different Services? Different services can communicate through various methods:\nHTTP/REST APIs: Synchronous communication using standard HTTP methods. gRPC: High-performance RPC framework using HTTP/2. Message Queues: Asynchronous communication via message brokers like RabbitMQ or Kafka. WebSockets: For real-time bidirectional communication between clients and servers. What Are the Steps Involved in an RPC Call? An RPC call typically involves these steps:\nThe client sends an RPC request to the server. The client stub serializes the request into a suitable format (e.g., JSON or Protobuf). The request is sent over the network to the server. The server receives and deserializes the request. The server processes the request and prepares a response. The response is serialized and sent back to the client. The client stub deserializes the response for use. How Can Performance Tuning Be Done in RPC Frameworks? To optimize performance in RPC frameworks:\nUse efficient serialization formats (e.g., Protobuf). Implement connection pooling to reuse connections. Use asynchronous calls where possible to avoid blocking. Optimize network latency through compression or batching requests. Which RPC Frameworks Have You Used? Commonly used RPC frameworks include:\ngRPC: A modern high-performance framework developed by Google. Apache Thrift: A cross-language framework developed by Facebook. Dubbo: A Java-based RPC framework from Alibaba. JSON-RPC: A remote procedure call protocol encoded in JSON. Describe Circuit Breaker, Rate Limiting, Downgrading, and Avalanche Effects Circuit Breaker: Prevents repeated calls to failing services by temporarily blocking requests until they recover. Rate Limiting: Controls how often users can access resources within a specified timeframe to prevent abuse or overload. Downgrading: Provides fallback mechanisms when certain features are unavailable or degraded due to failures. Avalanche Effect: Occurs when multiple dependent services fail simultaneously due to cascading failures from one service\u0026rsquo;s downtime. What Open Source Frameworks Do You Know for Circuit Breaking and Downgrading? Notable open-source frameworks include:\nHystrix: A circuit breaker library from Netflix designed for fault tolerance in distributed systems. Resilience4j: A lightweight alternative for Java applications providing circuit breaking capabilities. Sentinel: An open-source project from Alibaba that provides circuit breaking and rate limiting features. What Are the Differences Between Docker and Virtual Machines? Feature Docker Virtual Machine Operating System Shares host OS kernel Requires separate OS per VM Performance Lightweight with faster startup times Heavier due to full OS overhead Portability Highly portable across environments Less portable due to size Resource Usage More efficient resource utilization Consumes more resources What Problems Does Service Mesh Solve? Service mesh addresses challenges in microservices architectures such as:\nService discovery Load balancing Traffic management Security (e.g., authentication) Observability (e.g., monitoring and tracing) By abstracting these concerns away from application code, service mesh allows developers to focus on business logic while ensuring robust inter-service communication.\nHow does a service mesh work? A service mesh simplifies inter-service communication in a microservices architecture by abstracting it into a dedicated infrastructure layer. This layer uses network proxies, often called sidecars, deployed alongside each service. All traffic flows through these proxies.\nThe mesh comprises two key components:\nData Plane:Â This consists of the sidecar proxies. They intercept requests, establish secure connections, and handle low-level messaging, including features like circuit breaking and retries. Core functionality such as load balancing, service discovery, and routing resides here.\nControl Plane:Â This acts as the central management layer. Administrators use it to define and configure services, including endpoints, routing rules, load balancing, and security settings. The control plane distributes this configuration to the data plane proxies, allowing for dynamic adjustments without service restarts. It typically includes a service registry, automatic service discovery, and telemetry data collection.\nWhat Technologies Are Related to DevOps? Key technologies related to DevOps include:\nVersion Control Systems: Git, SVN Continuous Integration/Continuous Deployment (CI/CD): Jenkins, GitLab CI Containerization: Docker, Kubernetes Configuration Management Tools: Ansible, Puppet Monitoring Tools: Prometheus, Grafana Infrastructure as Code (IaC): Terraform What is microservices architecture? Microservices architecture is an approach to developing a single application as a suite of small, independently deployable services. Each service runs in its own process and communicates with lightweight mechanisms, often HTTP-based APIs.\nWhat is serverless computing? Serverless computing is a cloud computing model where the cloud provider manages the infrastructure, automatically provisioning and scaling servers as needed. Developers focus on writing code in the form of functions, which are executed in response to events.\nWhat are the main HTTP methods used in RESTful APIs? GET: Retrieve a resource POST: Create a new resource PUT: Update an existing resource DELETE: Remove a resource PATCH: Partially modify a resource What is OAuth and how does it work? OAuth is an open standard for access delegation. It allows users to grant third-party applications access to their resources without sharing their credentials. It works by issuing access tokens to third-party clients with the approval of the resource owner.\nWhat is CORS and why is it important? CORS (Cross-Origin Resource Sharing) is a security mechanism that allows a web page from one domain to request resources from another domain. It\u0026rsquo;s important for enabling secure cross-origin data transfers in web applications.\nWhat is SQL injection and how can it be prevented? SQL injection is a code injection technique used to attack data-driven applications. It can be prevented by using parameterized queries, prepared statements, and input validation.\nWhat is horizontal scaling vs vertical scaling? Horizontal scaling (scaling out): Adding more machines to a system Vertical scaling (scaling up): Adding more power (CPU, RAM) to an existing machine Explain the concept of Infrastructure as Code (IaC). Infrastructure as Code is the practice of managing and provisioning computing infrastructure through machine-readable definition files, rather than physical hardware configuration or interactive configuration tools.\nExample: Configuring a Network using Ansible\nAnsible is another popular IaC tool, often used for configuration management. This example shows how Ansible can configure a network device (e.g., a router) using a playbook.\nExplain the CAP theorem. The CAP theorem states that it is impossible for a distributed data store to simultaneously provide more than two out of the following three guarantees:\nConsistency Availability Partition tolerance What is Blue/Green Deployments Blue/Green Deployment is a way to update software with almost no downtime:\nYou have two identical environments: Blue and Green. Blue is currently live and serving users. You update the Green environment with the new version. You test Green to make sure it works correctly. You quickly switch all user traffic from Blue to Green. Green is now live, and Blue becomes idle. If something goes wrong, you can easily switch back to Blue.\nThis method reduces risks and makes it easy to roll back if needed, but it does require more server resources.\nWhat tools can be used for data collection? ELK Stack (Elasticsearch, Logstash, Kibana):\nLogstash is a powerful data collection component. It can collect data from various sources and send it to Elasticsearch for search and analysis. Filebeat:\nA lightweight tool for reading data from log files. Particularly suitable for collecting log data already written to files. Can send data to Logstash or Elasticsearch for processing. Fluentd:\nAn open-source data collector. Supports functionality extension through plugins. Can collect data from multiple sources and forward it. Apache Kafka:\nWhile primarily used for stream data processing, its Producer API can be used for data collection. Suitable for high-throughput data processing. Combined with Kafka Streams or other consumer applications, it can implement powerful real-time data processing systems. What are the key principles of BI (Business Intelligence) data reporting? Data Collection:\nFrontend, backend, Database transactions Data Transmission:\nReal-time transmission: Using WebSocket or HTTP requests to send data immediately. Batch transmission: Sending collected data periodically to reduce network overhead. Data Reception:\nAPI endpoints: Providing interfaces to receive reported data. Message queues: Using middleware like Kafka to receive data. Data Processing:\nData cleansing: Removing invalid or duplicate data. Data transformation: Converting raw data into formats suitable for analysis. Data aggregation: Summarizing data to generate statistical information. Data Storage:\nData warehouses: Using systems like Hive or Snowflake to store large volumes of structured data. Time-series databases: Employing databases like InfluxDB for time-series data. Data Analysis:\nOLAP analysis: Using tools like Druid for multi-dimensional data analysis. Machine learning: Applying algorithms to discover patterns and trends in data. Data Visualization:\nDashboards: Creating intuitive data presentation interfaces using tools like Tableau or PowerBI. Report generation: Automatically generating periodic reports. Data Security:\nEncryption: Protecting sensitive data in transit and at rest. Access control: Ensuring only authorized personnel can access the data. Data Governance:\nMetadata management: Maintaining descriptive information about the data. Data quality control: Ensuring data accuracy and consistency. Certainly! I\u0026rsquo;ll organize the information into an English markdown table format and include the question at the top.\nWhat are the differences between Cookies, Sessions, and Tokens? Feature Cookie Session Token Storage Location Client-side (browser) Server-side Client-side (usually localStorage or sessionStorage) Main Purpose Store small amounts of data on client, remember user preferences or login status Store user session-related information Authentication and authorization, especially in stateless APIs Security Relatively low, can be modified or stolen by client Higher, data stored on server, client only keeps session ID Higher, can contain encrypted information, not easily tampered with Expiration Can set expiration time, supports long-term storage Usually short-lived, expires on user logout or inactivity Flexible, can be set for short-term or long-term validity Cross-domain Support Not supported by default Not supported Supported Scalability Limited in distributed systems Challenges in distributed systems Well-suited for distributed systems and microservices State Stateful Stateful Stateless Size Limit Limited (usually 4KB) Depends on server configuration Can be larger, but should be kept small for efficiency Vulnerability to XSS Vulnerable if not secured properly Less vulnerable (if cookie-based sessions are properly secured) Less vulnerable, but still needs proper handling Implementation Complexity Simple Moderate Can be complex, especially with refresh tokens What are the main differences between single token and double token authentication? Feature Single Token Double Token Structure Uses one token for authentication Uses two tokens: access token and refresh token Token Types Typically just an access token Access token (short-lived) and refresh token (long-lived) Lifespan Usually longer-lived to reduce frequent logins Access token is short-lived, refresh token is long-lived Security Potentially less secure if compromised More secure, access tokens expire quickly, refresh tokens can be invalidated User Experience May require more frequent logins if kept short-lived Provides seamless re-authentication without user intervention Revocation Requires blacklisting or waiting for expiration Can revoke refresh tokens to log out users across all devices Implementation Complexity Simpler to implement More complex, requires managing two types of tokens API Calls Every API call uses the same token Uses access token for API calls, refresh token only for getting new access tokens Storage Typically stored in local storage or session storage Access token in memory, refresh token in secure HTTP-only cookie or secure storage ","permalink":"https://bleedkagax.github.io/post/0_system_design/","summary":"\u003ch2 id=\"how-to-solve-cache-penetration\"\u003eHow to Solve Cache Penetration?\u003c/h2\u003e\n\u003cp\u003eCache penetration occurs when requests for non-existent data bypass the cache and hit the database repeatedly. Solutions include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eCaching Empty Results\u003c/strong\u003e: Store empty results for non-existent keys with a short expiration time.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBloom Filters\u003c/strong\u003e: Use a Bloom filter to check if a key exists before querying the database.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRate Limiting\u003c/strong\u003e: Limit requests for certain keys to prevent overwhelming the database with requests for non-existent data.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"how-to-solve-cache-avalanche\"\u003eHow to Solve Cache Avalanche?\u003c/h2\u003e\n\u003cp\u003eCache avalanche involves a massive number of database hits due to the simultaneous expiration of many cache entries or a cache server failure.\u003c/p\u003e","title":"System Design"},{"content":"Overview of Pprof pprof is a tool that comes with Go\u0026rsquo;s standard library and is used for collecting and viewing profiling data. It can collect different types of profiles including:\nCPU Profile: Measures where the program spends most of its time. Memory Profile: Measures the amount of memory allocated and retained. Block Profile: Measures where the program spends time waiting for synchronization primitives. Mutex Profile: Measures contention on mutexes. Setting Up pprof To use pprof, you need to import the net/http/pprof package and set up HTTP server to serve the profiling data.\nStep 1: Import the pprof Package import ( \u0026#34;net/http\u0026#34; _ \u0026#34;net/http/pprof\u0026#34; // This blank import enables the HTTP endpoints for `pprof` ) Step 2: Start the HTTP Server func main() { go func() { // The ListenAndServe function starts the HTTP server. It never returns. // We use `log.Fatal` here to ensure that the program will exit if the server fails to start. log.Fatal(http.ListenAndServe(\u0026#34;localhost:6060\u0026#34;, nil)) }() // Your application logic here... } Writing Code to Profile For demonstration, we\u0026rsquo;ll use a CPU-intensive function.\nfunc expensiveFunction() { for i := 0; i \u0026lt; 1000000; i++ { // Simulating some CPU intensive computation } } func main() { go func() { log.Fatal(http.ListenAndServe(\u0026#34;localhost:6060\u0026#34;, nil)) }() // Call the function multiple times to simulate CPU usage for i := 0; i \u0026lt; 10; i++ { expensiveFunction() } } Profiling the Application After running your program, you can access the pprof HTTP endpoints at http://localhost:6060/debug/pprof/.\nProfiling CPU Usage Generate a CPU profile by visiting http://localhost:6060/debug/pprof/profile in your browser. Capture the profile by setting the duration for which you want to collect the profile. For example, you can set it to 30 seconds. Profiling Memory Usage Generate a memory profile by visiting http://localhost:6060/debug/pprof/heap in your browser. Capture the profile and download the snapshot. Analyzing the Profile Use the go tool pprof command to analyze the profile.\nAnalyzing CPU Profile go tool pprof http://localhost:6060/debug/pprof/profile Use various commands to explore the data:\ntop: Lists the top functions by self or total CPU time. list \u0026lt;function_name\u0026gt;: Shows the source code of a specific function. web: Opens an interactive web visualization of the call graph. Analyzing Memory Profile go tool pprof http://localhost:6060/debug/pprof/heap Analyzing concurrency performance Step 1: EnableÂ pprofÂ HTTP Endpoints import ( \u0026#34;net/http\u0026#34; _ \u0026#34;net/http/pprof\u0026#34; // This blank import enables the HTTP endpoints for `pprof` \u0026#34;log\u0026#34; \u0026#34;time\u0026#34; ) func startProfiler() { // Start the HTTP server on a different goroutine go func() { log.Println(http.ListenAndServe(\u0026#34;localhost:6060\u0026#34;, nil)) }() } Step 2: Write Concurrent Code Create a Go program that uses concurrency features like goroutines and channels.\nfunc worker(id int, done chan bool) { for { // Simulating work by sleeping for a bit. time.Sleep(time.Millisecond * 10) // Log the work being processed. log.Printf(\u0026#34;Worker %d is processing\\n\u0026#34;, id) // Signal that the work is done. done \u0026lt;- true } } func main() { startProfiler() numWorkers := 10000 done := make(chan bool, numWorkers) for i := 0; i \u0026lt; numWorkers; i++ { go worker(i, done) } for i := 0; i \u0026lt; numWorkers; i++ { \u0026lt;-done } } Step 3: Collect Concurrency Profiles Mutex Profile Run the Mutex Profiler: Access http://localhost:6060/debug/pprof/mutex to view the mutex profile, which shows contention points for mutexes.\ngo tool pprof http://localhost:6060/debug/pprof/mutex Analyze Contention: Look for high contention values, which indicate that goroutines are frequently blocked waiting for a mutex.\nGoroutine Profile Run the Goroutine Profiler: Access http://localhost:6060/debug/pprof/goroutine to get a report of all current goroutines.\ngo tool pprof http://localhost:6060/debug/pprof/goroutine Analyze Goroutine Counts: Check for an unusually high number of goroutines, which might indicate a leak.\nStep 4: UseÂ pprofÂ to Analyze Data Use the top list web command\n(pprof) top Showing nodes accounting for 77021, 96.14% of 80112 total top - 15:25:56 up 1:15, 0 users, load average: 2.18, 2.84, 2.41 Tasks: 17 total, 1 running, 15 sleeping, 0 stopped, 1 zombie %Cpu(s): 50.1 us, 11.5 sy, 0.0 ni, 37.4 id, 0.0 wa, 0.0 hi, 1.0 si, 0.0 st MiB Mem : 7950.9 total, 4956.1 free, 2293.5 used, 701.4 buff/cache MiB Swap: 0.0 total, 0.0 free, 0.0 used. 5196.8 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 135 user 20 0 1717788 847608 10480 S 4.3 10.4 2:34.51 node 6 user 20 0 954168 88244 9608 S 3.0 1.1 1:21.68 node 295 user 20 0 899088 16332 1264 S 0.0 0.2 0:00.99 nodemon 324 user 20 0 503980 12852 0 S 0.0 0.2 0:00.49 nixd 439 user 20 0 684016 73544 0 S 0.0 0.9 0:00.87 nixd-attrset-ev 3949 user 20 0 223960 2840 1952 S 0.0 0.0 0:00.06 bash 7542 user 20 0 1524220 75852 0 S 0.0 0.9 0:10.57 gopls 9074 user 20 0 223960 2560 1668 S 0.0 0.0 0:00.09 bash Step 5: Optimize Concurrency Reduce Lock Contention: Redesign your code to reduce the need for locking or use finer-grained locks. Optimize Channel Usage: Ensure that channel operations are efficient and that goroutines are not blocked waiting for channel operations unnecessarily. Limit Goroutine Creation: Use a pool of worker goroutines or limit the creation of new goroutines. Avoid Blocking Operations: Ensure that blocking operations are handled correctly and do not unnecessarily block other goroutines. Conclusion pprof is a powerful tool for understanding and optimizing the performance of your Go applications.\nAdditional Resources Go pprof documentation Go pprof GitHub repository ","permalink":"https://bleedkagax.github.io/post/3_go_pprof/","summary":"\u003ch1 id=\"overview-of-pprof\"\u003eOverview of Pprof\u003c/h1\u003e\n\u003cp\u003e\u003ccode\u003epprof\u003c/code\u003e is a tool that comes with Go\u0026rsquo;s standard library and is used for collecting and viewing profiling data. It can collect different types of profiles including:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eCPU Profile\u003c/strong\u003e: Measures where the program spends most of its time.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMemory Profile\u003c/strong\u003e: Measures the amount of memory allocated and retained.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBlock Profile\u003c/strong\u003e: Measures where the program spends time waiting for synchronization primitives.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMutex Profile\u003c/strong\u003e: Measures contention on mutexes.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"setting-up-pprof\"\u003eSetting Up pprof\u003c/h1\u003e\n\u003cp\u003eTo use \u003ccode\u003epprof\u003c/code\u003e, you need to import the \u003ccode\u003enet/http/pprof\u003c/code\u003e package and set up HTTP server to serve the profiling data.\u003c/p\u003e","title":"Go Pprof"},{"content":"Comprehensive Technical Analysis: Redis, Pika, and Codis Introduction In the realm of distributed data storage and caching systems, Redis, Pika, and Codis represent three distinct approaches to solving scalability, persistence, and performance challenges. This comprehensive analysis delves deep into the architectures, features, and use cases of these systems, providing detailed code examples and visual representations to facilitate a thorough understanding.\nRedis Redis (Remote Dictionary Server) is an open-source, in-memory data structure store that has become a cornerstone in modern application architectures. Its versatility allows it to function as a database, cache, message broker, and queue.\nRedis Core Architecture Redis follows a single-threaded, event-driven model using an I/O multiplexing technique.\ngraph TD A[Client Connections] --\u0026gt; B[Event Loop] B --\u0026gt; C[Command Processing] C --\u0026gt; D[In-Memory Data Structures] D --\u0026gt; E[Persistence Layer] B --\u0026gt; F[Replication] B --\u0026gt; G[Pub/Sub] B --\u0026gt; H[Transactions] The event loop efficiently handles multiple client connections using mechanisms like epoll (Linux) or kqueue (BSD).\nKey components:\nEvent Loop: Manages I/O events and timers Command Processing: Executes Redis commands In-Memory Data Structures: Stores and manipulates data Persistence Layer: Handles RDB and AOF persistence Replication: Manages master-slave replication Pub/Sub: Implements publish/subscribe messaging Transactions: Handles atomic command execution Redis Data Structures and Implementations Redis offers a rich set of data structures, each with specific use cases and internal implementations:\nStrings Implementation: Simple dynamic string (SDS) Use case: Caching, counters, bit operations SET key \u0026#34;Hello, Redis!\u0026#34; GET key INCR counter SETBIT flag 10 1 Lists Implementation: Linked list or ziplist (for small lists) Use case: Message queues, recent items lists LPUSH mylist \u0026#34;item1\u0026#34; \u0026#34;item2\u0026#34; RPOP mylist LRANGE mylist 0 -1 Sets Implementation: Hash table or intset (for small integer sets) Use case: Unique items, relations between objects SADD myset \u0026#34;member1\u0026#34; \u0026#34;member2\u0026#34; SMEMBERS myset SINTER set1 set2 Sorted Sets Implementation: Skip list and hash table Use case: Leaderboards, priority queues ZADD leaderboard 100 \u0026#34;player1\u0026#34; 200 \u0026#34;player2\u0026#34; ZRANGE leaderboard 0 -1 WITHSCORES Hashes Implementation: Hash table or ziplist (for small hashes) Use case: Object representation, field-value pairs HSET user:1 name \u0026#34;John\u0026#34; age 30 HGETALL user:1 Bitmaps and HyperLogLogs Implementation: Special encoding of string keys Use case: Space-efficient storage of boolean information, cardinality estimation SETBIT visitors 10 1 BITCOUNT visitors PFADD unique_visitors \u0026#34;user1\u0026#34; \u0026#34;user2\u0026#34; PFCOUNT unique_visitors Streams Implementation: Radix tree Use case: Log storage, time-series data XADD mystream * sensor-id 1234 temperature 19.8 XRANGE mystream - + Redis Persistence Mechanisms Redis offers two primary persistence options:\nRDB (Redis Database) Point-in-time snapshots of the dataset Compact single-file format Suitable for backups and disaster recovery save 900 1 save 300 10 save 60 10000 AOF (Append-Only File) Logs every write operation Higher durability Supports background rewrite for log compaction appendonly yes appendfsync everysec auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb Implementation details:\nRDB uses fork() to create a child process for snapshotting AOF uses a write buffer and background fsync for performance Redis Replication and High Availability Redis supports master-slave replication for high availability and read scalability.\ngraph TD A[Master] --\u0026gt;|Sync| B[Slave 1] A --\u0026gt;|Sync| C[Slave 2] A --\u0026gt;|Sync| D[Slave 3] E[Sentinel 1] --\u0026gt;|Monitor| A E --\u0026gt;|Monitor| B E --\u0026gt;|Monitor| C E --\u0026gt;|Monitor| D F[Sentinel 2] --\u0026gt;|Monitor| A F --\u0026gt;|Monitor| B F --\u0026gt;|Monitor| C F --\u0026gt;|Monitor| D G[Sentinel 3] --\u0026gt;|Monitor| A G --\u0026gt;|Monitor| B G --\u0026gt;|Monitor| C G --\u0026gt;|Monitor| D Key features:\nAsynchronous replication Partial resynchronization for efficiency Redis Sentinel for automatic failover Configuration example:\n# On slave slaveof 192.168.1.100 6379 slave-read-only yes # Sentinel configuration sentinel monitor mymaster 192.168.1.100 6379 2 sentinel down-after-milliseconds mymaster 5000 sentinel failover-timeout mymaster 60000 Redis Clustering and Sharding Redis Cluster provides a way to run a Redis installation where data is automatically sharded across multiple Redis nodes.\ngraph TD A[Client] --\u0026gt; B[Redis Cluster] B --\u0026gt; C[Node 1 \u0026lt;br/\u0026gt; 0-5460] B --\u0026gt; D[Node 2 \u0026lt;br/\u0026gt; 5461-10922] B --\u0026gt; E[Node 3 \u0026lt;br/\u0026gt; 10923-16383] C \u0026lt;--\u0026gt;|Gossip| D D \u0026lt;--\u0026gt;|Gossip| E E \u0026lt;--\u0026gt;|Gossip| C C --\u0026gt; F[Replica 1] D --\u0026gt; G[Replica 2] E --\u0026gt; H[Replica 3] Key features:\n16384 hash slots distributed across nodes Client-side sharding using CRC16 Automatic failover and resharding Cluster setup example:\nredis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 \\ 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 \\ --cluster-replicas 1 Redis Transactions and Lua Scripting Redis supports transactions and Lua scripting for complex operations.\nTransactions Allows execution of a group of commands in a single step Provides optimistic locking with WATCH command MULTI INCR foo INCR bar EXEC Lua Scripting Allows execution of complex operations atomically Scripts are executed using SHA1 digest for efficiency EVAL \u0026#34;return redis.call(\u0026#39;SET\u0026#39;, KEYS[1], ARGV[1])\u0026#34; 1 mykey myvalue Redis Pub/Sub and Streams Redis provides publish/subscribe messaging and a more advanced streams data structure.\nPub/Sub Allows for real-time messaging between publishers and subscribers SUBSCRIBE channel1 channel2 PUBLISH channel1 \u0026#34;Hello, subscribers!\u0026#34; Streams Append-only log data structure Supports consumer groups for parallel processing XADD mystream * field1 value1 field2 value2 XREAD COUNT 2 STREAMS mystream 0-0 Redis Memory Management and Eviction Policies Redis manages memory carefully and provides eviction policies for when memory limits are reached.\nMemory management techniques:\nJemalloc memory allocator Memory sharing between instances (copy-on-write) Eviction policies:\nvolatile-lru allkeys-lru volatile-random allkeys-random volatile-ttl noeviction Configuration example:\nmaxmemory 100mb maxmemory-policy allkeys-lru Pika Pika is a persistent huge storage service, compatible with the Redis protocol but designed to handle datasets larger than memory.\nPika Architecture and Design Principles Pika uses a multi-threaded architecture with RocksDB as its storage engine.\ngraph TD A[Client Connections] --\u0026gt; B[Network Thread] B --\u0026gt; C[Worker Threads] C --\u0026gt; D[RocksDB Storage Engine] D --\u0026gt; E[Disk Storage] F[Backup Thread] --\u0026gt; D G[Compact Thread] --\u0026gt; D Key components:\nNetwork Thread: Handles client connections and command parsing Worker Threads: Execute commands and interact with RocksDB RocksDB Storage Engine: Manages data persistence and retrieval Backup Thread: Handles asynchronous backups Compact Thread: Manages RocksDB compaction Pika Storage Engine: RocksDB Integration Pika leverages RocksDB for efficient storage and retrieval of large datasets.\nKey features:\nLog-structured merge-tree (LSM) based storage Efficient range queries and compactions Write-ahead logging for durability RocksDB configuration example:\nrocksdb::Options options; options.create_if_missing = true; options.write_buffer_size = 64 * 1024 * 1024; // 64MB options.max_write_buffer_number = 3; options.target_file_size_base = 32 * 1024 * 1024; // 32MB options.max_background_compactions = 4; options.max_background_flushes = 2; options.compression = rocksdb::kSnappyCompression; Pika Thread Model and Concurrency Pika uses a multi-threaded model to improve performance and concurrency.\ngraph TD A[Client Requests] --\u0026gt; B[Dispatch Thread] B --\u0026gt; C[Worker Thread 1] B --\u0026gt; D[Worker Thread 2] B --\u0026gt; E[Worker Thread N] C --\u0026gt; F[RocksDB] D --\u0026gt; F E --\u0026gt; F Implementation details:\nThread pool for handling client requests Lock-free data structures for inter-thread communication Fine-grained locking for concurrent access to data structures Pika Data Structures and Redis Compatibility Pika supports most Redis data structures and commands, with some limitations.\nSupported data structures:\nStrings Hashes Lists Sets Sorted Sets Example of using Pika with a Redis client:\nimport redis p = redis.Redis(host=\u0026#39;localhost\u0026#39;, port=9221, db=0) # String operations p.set(\u0026#39;key\u0026#39;, \u0026#39;value\u0026#39;) print(p.get(\u0026#39;key\u0026#39;)) # Hash operations p.hset(\u0026#39;hash\u0026#39;, \u0026#39;field1\u0026#39;, \u0026#39;value1\u0026#39;) p.hset(\u0026#39;hash\u0026#39;, \u0026#39;field2\u0026#39;, \u0026#39;value2\u0026#39;) print(p.hgetall(\u0026#39;hash\u0026#39;)) # List operations p.lpush(\u0026#39;list\u0026#39;, \u0026#39;item1\u0026#39;, \u0026#39;item2\u0026#39;, \u0026#39;item3\u0026#39;) print(p.lrange(\u0026#39;list\u0026#39;, 0, -1)) Pika Replication and Consistency Pika supports master-slave replication for high availability and data consistency.\ngraph TD A[Master] --\u0026gt;|Binary Log| B[Slave 1] A --\u0026gt;|Binary Log| C[Slave 2] A --\u0026gt;|Binary Log| D[Slave 3] Replication features:\nAsynchronous replication Full and incremental sync support Configurable sync speed limit Configuration example:\n# On master slave-read-only no # On slave slaveof 192.168.1.100 9221 slave-read-only yes Pika Backup and Recovery Pika provides mechanisms for backup and recovery to ensure data durability.\nBackup methods:\nFull Backup: Complete snapshot of the database Incremental Backup: Only changes since the last backup Recovery process:\nStop Pika server Replace data directory with backup Start Pika server Backup command example:\n./pika_tools -t backup -s ./pika.conf Pika Performance Optimization Techniques Pika employs various techniques to optimize performance:\nWrite Amplification Reduction: Careful tuning of RocksDB parameters Read Amplification Reduction: Use of bloom filters and cache Compaction Optimization: Background compaction and level-based compaction Memory Management: Efficient use of block cache and index cache RocksDB tuning example:\nrocksdb::BlockBasedTableOptions table_options; table_options.block_cache = rocksdb::NewLRUCache(100 * 1024 * 1024); // 100MB cache table_options.filter_policy.reset(rocksdb::NewBloomFilterPolicy(10)); rocksdb::Options options; options.table_factory.reset(NewBlockBasedTableFactory(table_options)); options.optimize_filters_for_hits = true; options.level_compaction_dynamic_level_bytes = true; Codis Codis is a proxy-based Redis cluster solution that supports dynamic scaling and provides high availability.\nCodis System Architecture and Components Codis consists of several key components working together to provide a scalable Redis cluster solution.\ngraph TD A[Client] --\u0026gt; B[Codis Proxy] B --\u0026gt; C[Redis 1] B --\u0026gt; D[Redis 2] B --\u0026gt; E[Redis N] F[Codis Dashboard] --\u0026gt; B F --\u0026gt; C F --\u0026gt; D F --\u0026gt; E G[Zookeeper/Etcd] --\u0026gt; F H[Codis FE] --\u0026gt; F I[Codis Admin] --\u0026gt; F Key components:\nCodis Proxy: Stateless proxy that routes requests to the correct Redis instance Codis Dashboard: Manages the cluster topology and handles administrative tasks Codis FE: Web interface for cluster management Zookeeper/Etcd: Distributed configuration and coordination service Redis Instances: Actual data storage nodes Codis Proxy Design and Implementation The Codis Proxy is a core component that handles request routing and connection management.\ngraph TD A[Client Connections] --\u0026gt; B[Connection Pool] B --\u0026gt; C[Request Parser] C --\u0026gt; D[Router] D --\u0026gt; E[Backend Connection Pool] E --\u0026gt; F[Redis Instances] Key features:\nSupports pipelining and multiplexing Implements consistent hashing for request routing Handles connection pooling for efficient resource utilization Proxy configuration example:\nproduct_name = \u0026#34;test\u0026#34; product_auth = \u0026#34;\u0026#34; proxy_id = \u0026#34;proxy_1\u0026#34; admin_addr = \u0026#34;0.0.0.0:11080\u0026#34; proto_type = \u0026#34;tcp4\u0026#34; proxy_addr = \u0026#34;0.0.0.0:19000\u0026#34; jodis_addr = \u0026#34;zookeeper:2181\u0026#34; jodis_timeout = 10 jodis_compatible = false session_break_on_failure = false Codis Data Sharding and Rebalancing Codis uses pre-sharding and dynamic slot allocation for data distribution.\ngraph TD A[1024 Slots] --\u0026gt; B[Group 1] A --\u0026gt; C[Group 2] A --\u0026gt; D[Group N] B --\u0026gt; E[Redis 1] B --\u0026gt; F[Redis 1 Slave] C --\u0026gt; G[Redis 2] C --\u0026gt; H[Redis 2 Slave] D --\u0026gt; I[Redis N] D --\u0026gt; J[Redis N Slave] Sharding details:\n1024 slots pre-defined Slots can be migrated between groups Each group contains a master-slave pair of Redis instances Rebalancing process:\nInitiate rebalance through Codis Dashboard Slots are gradually migrated between groups Proxies update their routing table in real-time Codis High Availability and Fault Tolerance Codis provides high availability through redundancy and automatic failover.\ngraph TD A[Codis Dashboard] --\u0026gt; B[Group 1] A --\u0026gt; C[Group 2] A --\u0026gt; D[Group N] B --\u0026gt; E[Redis Master] B --\u0026gt; F[Redis Slave] C --\u0026gt; G[Redis Master] C --\u0026gt; H[Redis Slave] D --\u0026gt; I[Redis Master] D --\u0026gt; J[Redis Slave] K[Zookeeper/Etcd] --\u0026gt; A High availability features:\nAutomatic failover within groups Multiple Codis Proxies for load balancing Zookeeper/Etcd for configuration consistency Failover process:\nDashboard detects master failure Promote slave to master Update routing information in Zookeeper/Etcd Proxies update their routing table Codis Scaling and Online Migration Codis supports online scaling without downtime.\nScaling process:\nAdd new Redis instances to the cluster Create new groups in Codis Dashboard Initiate slot migration from existing groups to new groups Proxies automatically update routing information Migration command example:\ncodis-admin --dashboard=localhost:18080 --rebalance --confirm Codis Monitoring and Management Codis provides tools for monitoring and managing the cluster.\nMonitoring features:\nCodis FE web interface Prometheus integration for metrics Grafana dashboards for visualization Management tasks:\nAdding/removing nodes Manual failover Slot migration Configuration updates Codis Compatibility and Limitations While Codis is highly compatible with Redis, it has some limitations:\nMulti-key operations are limited to keys in the same slot Some Redis commands are not supported (e.g., KEYS, MOVE, MIGRATE) Custom support required for some language clients Client usage example (Python):\nfrom codis import CodisConnectionPool pool = CodisConnectionPool(host=\u0026#39;localhost\u0026#39;, port=19000, db=0) c = pool.get_connection() c.set(\u0026#39;key\u0026#39;, \u0026#39;value\u0026#39;) print(c.get(\u0026#39;key\u0026#39;)) c.hset(\u0026#39;hash\u0026#39;, \u0026#39;field\u0026#39;, \u0026#39;value\u0026#39;) print(c.hgetall(\u0026#39;hash\u0026#39;)) Comparative Analysis Performance Benchmarks Benchmark results for 100-byte SET/GET operations (operations per second):\ngraph TD A[Redis] --\u0026gt;|150k| B[SET] A --\u0026gt;|200k| C[GET] D[Pika] --\u0026gt;|80k| B D --\u0026gt;|100k| C E[Codis] --\u0026gt;|130k| B E --\u0026gt;|180k| C Note: These are approximate values and can vary based on hardware and configuration.\nUse Case Scenarios Redis:\nHigh-performance caching Real-time analytics Session storage Leaderboards and counters Pika:\nLarge datasets exceeding memory limits Persistent key-value storage Write-heavy workloads Codis:\nLarge-scale Redis deployments Need for horizontal scaling High availability requirements Scalability and Reliability Comparison Feature Redis Pika Codis Vertical Scaling Excellent Good Good Horizontal Scaling Limited (Redis Cluster) Limited Excellent Data Persistence Optional (RDB/AOF) Always On (RocksDB) Inherited from Redis High Availability Through Sentinel Master-Slave Built-in Automatic Failover Yes (with Sentinel) Manual Yes Online Scaling Limited Limited Yes Operational Complexity Redis:\nSimple for single instance Moderate complexity for Redis Cluster Pika:\nModerate complexity Requires RocksDB tuning for optimal performance Codis:\nHigher complexity Requires management of multiple components Conclusion Redis, Pika, and Codis each offer unique solutions to different data storage and caching challenges:\nRedis excels in high-performance, in-memory operations and is ideal for scenarios where data fits in memory. Pika offers a good balance between performance and large dataset support, making it suitable for applications that need to persist data larger than available memory. Codis provides a scalable Redis cluster solution, ideal for large-scale deployments that require horizontal scaling and high availability. ","permalink":"https://bleedkagax.github.io/post/1_redis_pika_codis/","summary":"\u003ch1 id=\"comprehensive-technical-analysis-redis-pika-and-codis\"\u003eComprehensive Technical Analysis: Redis, Pika, and Codis\u003c/h1\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn the realm of distributed data storage and caching systems, Redis, Pika, and Codis represent three distinct approaches to solving scalability, persistence, and performance challenges. This comprehensive analysis delves deep into the architectures, features, and use cases of these systems, providing detailed code examples and visual representations to facilitate a thorough understanding.\u003c/p\u003e\n\u003ch2 id=\"redis\"\u003eRedis\u003c/h2\u003e\n\u003cp\u003eRedis (Remote Dictionary Server) is an open-source, in-memory data structure store that has become a cornerstone in modern application architectures. Its versatility allows it to function as a database, cache, message broker, and queue.\u003c/p\u003e","title":"Redis, Pika, and Codis"},{"content":" GIT CHEAT SHEET CREATE Clone an existing repository: $ git clone ssh://user@domain.com/repo.git Create a new local repository: $ git init LOCAL CHANGES Changed files in your working directory: $ git status Changes to tracked files: $ git diff Add all current changes to the next commit: $ git add . Add some changes in \u0026lt;file\u0026gt; to the next commit: $ git add -p \u0026lt;file\u0026gt; Commit all local changes in tracked files: $ git commit -a Commit previously staged changes: $ git commit Change the last commit (do not amend published commits!): $ git commit --amend COMMIT HISTORY Show all commits, starting with the newest: $ git log Show changes over time for a specific file: $ git log -p \u0026lt;file\u0026gt; Who changed what and when in \u0026lt;file\u0026gt;: $ git blame \u0026lt;file\u0026gt; BRANCHES \u0026amp; TAGS List all existing branches: $ git branch -av Switch HEAD branch: $ git switch \u0026lt;branch\u0026gt; Create a new branch based on your current HEAD: $ git branch \u0026lt;new-branch\u0026gt; Create a new tracking branch based on a remote branch: $ git checkout --track \u0026lt;remote/branch\u0026gt; Delete a local branch: $ git branch -d \u0026lt;branch\u0026gt; Mark the current commit with a tag: $ git tag \u0026lt;tag-name\u0026gt; UPDATE \u0026amp; PUBLISH List all currently configured remotes: $ git remote -v Show information about a remote: $ git remote show \u0026lt;remote\u0026gt; Add new remote repository, named \u0026lt;remote\u0026gt;: $ git remote add \u0026lt;shortname\u0026gt; \u0026lt;url\u0026gt; Download all changes from \u0026lt;remote\u0026gt;, but don\u0026rsquo;t integrate into HEAD: $ git fetch \u0026lt;remote\u0026gt; Download changes and directly merge/integrate into HEAD: $ git pull \u0026lt;remote\u0026gt; \u0026lt;branch\u0026gt; Publish local changes on a remote: $ git push \u0026lt;remote\u0026gt; \u0026lt;branch\u0026gt; Delete a branch on the remote: $ git push \u0026lt;remote\u0026gt; --delete \u0026lt;branch\u0026gt; Publish your tags: $ git push --tags MERGE \u0026amp; REBASE Merge \u0026lt;branch\u0026gt; into your current HEAD: $ git merge \u0026lt;branch\u0026gt; Rebase your current HEAD onto \u0026lt;branch\u0026gt; (do not rebase published commits!): $ git rebase \u0026lt;branch\u0026gt; Abort a rebase: $ git rebase --abort Continue a rebase after resolving conflicts: $ git rebase --continue Use your configured merge tool to solve conflicts: $ git mergetool Use your editor to manually solve conflicts and (after resolving) mark file as resolved: $ git add \u0026lt;resolved-file\u0026gt; $ git rm \u0026lt;resolved-file\u0026gt; UNDO Discard all local changes in your working directory: $ git reset --hard HEAD Discard local changes in a specific file: $ git checkout HEAD \u0026lt;file\u0026gt; Revert a commit (by producing a new commit with contrary changes): $ git revert \u0026lt;commit\u0026gt; Reset your HEAD pointer to a previous commit\u0026hellip;and discard all changes since then: $ git reset --hard \u0026lt;commit\u0026gt; \u0026hellip;and preserve all changes as unstaged changes: $ git reset \u0026lt;commit\u0026gt; \u0026hellip;and preserve uncommitted local changes: $ git reset --keep \u0026lt;commit\u0026gt; ","permalink":"https://bleedkagax.github.io/post/0_git/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/0_git.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/0_git-1.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003ch1 id=\"git-cheat-sheet\"\u003eGIT CHEAT SHEET\u003c/h1\u003e\n\u003ch2 id=\"create\"\u003eCREATE\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eClone an existing repository:\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e$ git clone ssh://user@domain.com/repo.git\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/li\u003e\n\u003cli\u003eCreate a new local repository:\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e$ git init\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"local-changes\"\u003eLOCAL CHANGES\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eChanged files in your working directory:\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e$ git status\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pr","title":"Git"},{"content":"How does garbage collection work in Go? Garbage Collection Go uses a concurrent, tri-color mark-and-sweep garbage collector with write barriers.\nGarbage Collection Phases Mark Setup: Preparation for marking phase. Marking: Identifying live objects. Mark Termination: Completion of marking phase. Sweep: Reclaiming memory from dead objects. graph LR A[Mark Setup] --\u0026gt; B[Marking] B --\u0026gt; C[Mark Termination] C --\u0026gt; D[Sweep] D --\u0026gt; A Tri-Color Algorithm Objects are divided into three sets:\nWhite: Potentially garbage objects. Gray: Objects to be scanned. Black: Live objects, all pointers scanned. The algorithm ensures that no black object points to a white object when marking is complete.\nWrite Barriers Write barriers ensure correctness of the tri-color invariant during concurrent marking.\nGo implements write barriers primarily through compiler instrumentation and runtime support.\nCompiler instrumentation:\nThe Go compiler (specifically the SSA backend) inserts write barrier calls at appropriate points in the code. This happens during the compilation phase, not at runtime. Runtime support:\nThe actual write barrier logic is implemented in the Go runtime, written in Go and assembly. For performance, the core write barrier is implemented in assembly. Write barrier function:\nThe main write barrier function is writebarrierptr, implemented in assembly for each architecture. There\u0026rsquo;s also a Go version (gcWriteBarrier) for debugging and non-optimized builds. Barrier activation:\nWrite barriers are only active during the marking phase of garbage collection. A global variable writeBarrier.enabled controls whether barriers are active. Barrier logic:\nWhen active, the write barrier ensures that if a pointer is written to a black (already marked) object, the pointed-to object is marked gray. This prevents a black object from pointing to a white (unmarked) object without the collector\u0026rsquo;s knowledge. Optimizations:\nGo uses a hybrid write barrier combining Dijkstra and Yuasa approaches. The compiler performs static analysis to eliminate unnecessary barriers. GC Triggers Go\u0026rsquo;s GC can be triggered by various events:\nAutomatic: Based on heap growth (target is 100% heap growth). Forced: By calling runtime.GC(). Pacing: GC runs to meet target heap size and CPU utilization. GC Tuning Go provides several environment variables and runtime functions for GC tuning:\nGOGC: Sets the initial garbage collection target percentage. GOMEMLIMIT: Sets a soft memory limit for the heap. Example of setting GC percentage programmatically:\nimport \u0026#34;runtime/debug\u0026#34; func main() { // Set GC target to 50% :`X`Â MB =\u0026gt; `1.5 * X`Â MB debug.SetGCPercent(50) // Run your program... } Sweeping After marking, sweeping reclaims memory from dead objects:\nSpans with no live objects are returned to the heap. Spans with some live objects have their free lists rebuilt. Sweeping is done concurrently and on-demand. ","permalink":"https://bleedkagax.github.io/post/6_go_garbage_collection/","summary":"\u003ch3 id=\"how-does-garbage-collection-work-in-go\"\u003eHow does garbage collection work in Go?\u003c/h3\u003e\n\u003ch4 id=\"garbage-collection\"\u003eGarbage Collection\u003c/h4\u003e\n\u003cp\u003eGo uses a concurrent, tri-color mark-and-sweep garbage collector with write barriers.\u003c/p\u003e\n\u003ch4 id=\"garbage-collection-phases\"\u003eGarbage Collection Phases\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eMark Setup\u003c/strong\u003e: Preparation for marking phase.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMarking\u003c/strong\u003e: Identifying live objects.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMark Termination\u003c/strong\u003e: Completion of marking phase.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSweep\u003c/strong\u003e: Reclaiming memory from dead objects.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre class=\"mermaid\"\u003e\n    graph LR\n\t    A[Mark Setup] --\u0026gt; B[Marking]\n\t    B --\u0026gt; C[Mark Termination]\n\t    C --\u0026gt; D[Sweep]\n\t    D --\u0026gt; A\n\u003c/pr","title":"Go Garbage Collection"},{"content":"sync.Mutex // Mutex provides mutual exclusion for shared resources. type Mutex struct { state int32 // State of the mutex (locked/unlocked) sema uint32 // Semaphore for blocking goroutines } // Lock acquires the mutex, blocking if necessary. func (m *Mutex) Lock() { // Check if already locked; if so, block until unlocked. } // Unlock releases the mutex. func (m *Mutex) Unlock() { // Update state and unblock waiting goroutines if any. } Mechanism: Uses atomic operations to manage state and semaphore to block goroutines.\nsync.RWMutex // RWMutex allows multiple readers or one writer. type RWMutex struct { w Mutex // Mutex for exclusive access by writers readers int32 // Count of active readers readerSem uint32 // Semaphore for managing reader access writerSem uint32 // Semaphore for managing writer access } // RLock acquires a read lock, allowing multiple concurrent readers. func (rw *RWMutex) RLock() { // Increment reader count; block if a writer is active. } // RUnlock releases a read lock. func (rw *RWMutex) RUnlock() { // Decrement reader count and unblock if necessary. } // Lock acquires an exclusive write lock. func (rw *RWMutex) Lock() { // Block all readers and wait for exclusive access. } // Unlock releases the write lock. func (rw *RWMutex) Unlock() { // Release exclusive access and notify waiting readers/writers. } Mechanism: Combines a mutex with counters and semaphores to manage read/write access efficiently.\nsync.WaitGroup // WaitGroup waits for a collection of goroutines to finish executing. type WaitGroup struct { noCopy noCopy // Prevent copying of WaitGroup state1 [1]uint32 // Atomic state tracking active goroutines done uint32 // Count of completed goroutines sema uint32 // Semaphore for blocking } // Add increments the WaitGroup counter by n. func (wg *WaitGroup) Add(n int) { // Increment counter; block if necessary based on done count. } // Done decrements the WaitGroup counter by one. func (wg *WaitGroup) Done() { // Increment done count; signal if all goroutines are done. } // Wait blocks until the WaitGroup counter is zero. func (wg *WaitGroup) Wait() { // Block until all added goroutines call Done(). } Mechanism: Utilizes atomic operations and a semaphore to manage synchronization among multiple goroutines.\nsync.Once // Once ensures that a function is executed only once. type Once struct { m Mutex // Mutex for synchronization done uint32 // Flag indicating if function has been called } // Do executes the function f only once. func (o *Once) Do(f func()) { o.m.Lock() // Lock to ensure exclusive access if o.done == 0 { // Check if function has been executed f() // Call the function o.done = 1 // Mark as executed } o.m.Unlock() // Unlock after execution } Mechanism: Uses a mutex to ensure that the wrapped function is executed only once, regardless of how many times Do() is called.\nsync.Cond // Cond provides a way for goroutines to wait for conditions to be met. type Cond struct { noCopy noCopy // Prevent copying of Cond L *Mutex // Locker that must be held when calling Wait or Signal notify notifyList // List of waiting goroutines } // Wait atomically releases the mutex and waits for notification. func (c *Cond) Wait() { c.L.Unlock() // Unlock before waiting to avoid deadlock // Block until notified by Signal or Broadcast. } // Signal wakes one waiting goroutine, if any. func (c *Cond) Signal() { // Notify one waiting goroutine to wake up. } // Broadcast wakes all waiting goroutines, if any. func (c *Cond) Broadcast() { // Notify all waiting goroutines to wake up. } Mechanism: Uses an associated mutex to manage access and a notification system to wake up blocked goroutines based on conditions.\nsync.Map Structure type Map struct { mu Mutex read atomic.Value // readOnly dirty map[interface{}]*entry misses int } type readOnly struct { m map[interface{}]*entry amended bool } type entry struct { p unsafe.Pointer // *interface{} } mu: A mutex used to protect access toÂ read andÂ dirty. read: A read-only data structure supporting concurrent reads using atomic operations. It stores aÂ readOnly structure, which is a native map. TheÂ amended attribute marks whether theÂ read andÂ dirty data are consistent. dirty: A native map for reading and writing data, requiring locking to ensure data security. misses: A counter tracking how many times the read operation fails. entry: It contains a pointerÂ p that points to the value stored for the element (key). Load Check read map first (lock-free) If not found and amended is true, lock and check dirty map Increment misses counter if needed Store Try to update existing entry in read map (lock-free) If not possible, lock and update dirty map If amended is false, copy read to dirty before updating Delete Try to mark entry as deleted in read map (lock-free) If not possible, lock and delete from dirty map LoadOrStore Combines Load and Store operations efficiently\n","permalink":"https://bleedkagax.github.io/post/5_sync/","summary":"\u003ch2 id=\"syncmutex\"\u003e\u003ccode\u003esync.Mutex\u003c/code\u003e\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e// Mutex provides mutual exclusion for shared resources.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003etype\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eMutex\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#a6e22e\"\u003estate\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eint32\u003c/span\u003e   \u003cspan style=\"color:#75715e\"\u003e// State of the mutex (locked/unlocked)\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e    \u003cspan style=\"color:#a6e22e\"\u003esema\u003c/span\u003e  \u003cspan style=\"color:#66d9ef\"\u003euint32\u003c/span\u003e  \u003cspan style=\"color:#75715e\"\u003e// Semaphore for blocking goroutines\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e// Lock acquires the mutex, blocking if necessary.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003efunc\u003c/span\u003e (\u003cspan style=\"color:#a6e22e\"\u003em\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003eMutex\u003c/span\u003e) \u003cspan style=\"color:#a6e22e\"\u003eLock\u003c/span\u003e() {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#75715e\"\u003e// Check if already locked; if so, block until unlocked.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e// Unlock releases the mutex.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003efunc\u003c/span\u003e (\u003cspan style=\"color:#a6e22e\"\u003em\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003eMutex\u003c/span\u003e) \u003cspan style=\"color:#a6e22e\"\u003eUnlock\u003c/span\u003e() {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#75715e\"\u003e// Update state and unblock waiting goroutines if any.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pr","title":"Go's Sync"},{"content":"direct-to-storage architecture\narchitecture with Kafka as intermediate buffer\nWhat is Jaeger? Jaeger is an open-source, end-to-end distributed tracing system. It helps monitor and troubleshoot transactions in complex, microservices-based architectures.\nWhat problem does distributed tracing solve? Distributed tracing helps in understanding the flow of requests through a distributed system, identifying performance bottlenecks, and diagnosing issues in microservices architectures.\nWhat are the main components of Jaeger? The main components of Jaeger are:\nJaeger Client Jaeger Agent Jaeger Collector Query Service Ingester Jaeger UI What is a span in the context of Jaeger? A span represents a logical unit of work in Jaeger. It has an operation name, start time, and duration. Spans may be nested to form a trace tree.\nHow does Jaeger relate to OpenTracing? Jaeger is compatible with OpenTracing, which is a vendor-neutral API for distributed tracing. Jaeger implements the OpenTracing specification.\nWhat sampling strategies does Jaeger support? Jaeger supports several sampling strategies:\nConstant (sample a fixed percentage of traces) Probabilistic (sample a percentage of traces with probability) Rate Limiting (sample up to a fixed number of traces per second) Remote (sampling decisions made by a remote service) How does Jaeger handle data storage? Jaeger can store trace data in various backends, including Cassandra, Elasticsearch, and in-memory storage.\nWhat is the purpose of the Jaeger Agent? The Jaeger Agent is a network daemon that listens for spans sent over UDP, batches them, and sends them to the Collector. It\u0026rsquo;s meant to be placed on the same host as the instrumented application.\nHow does Jaeger support multiple languages? Jaeger provides client libraries for various programming languages, including Java, Go, Python, Node.js, C++, and others. These libraries implement the OpenTracing API.\nWhat is the difference between metrics and traces? Metrics are aggregated data about system behavior, while traces provide detailed information about individual transactions across a distributed system. Metrics are typically used for alerting and high-level system health, while traces are used for in-depth problem diagnosis.\nHow does Jaeger handle high cardinality data? Jaeger uses adaptive sampling techniques to manage high cardinality data. It also allows for custom sampling strategies to be implemented.\nWhat is the role of the Jaeger Collector? The Jaeger Collector receives traces from Jaeger Agents and runs them through a processing pipeline. This pipeline validates traces, indexes them, performs any transformations, and finally stores them.\nHow can you integrate Jaeger with Kubernetes? Jaeger can be deployed on Kubernetes using Kubernetes operators. It can also leverage Kubernetes\u0026rsquo; service discovery mechanisms for automatic configuration.\nWhat is the difference between logs, metrics, and traces? Logs are detailed records of discrete events Metrics are numeric measurements taken over time Traces show the path of a request through a distributed system Jaeger focuses on traces, while systems like Prometheus handle metrics.\nHow does Jaeger handle trace context propagation? Jaeger uses trace context propagation to pass trace information between services. This is typically done by passing certain HTTP headers between services.\n","permalink":"https://bleedkagax.github.io/post/1_jaeger/","summary":"\u003cp\u003edirect-to-storage architecture\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/1_jaeger.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003earchitecture with Kafka as intermediate buffer\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/1_jaeger-1.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"what-is-jaeger\"\u003eWhat is Jaeger?\u003c/h2\u003e\n\u003cp\u003eJaeger is an open-source, end-to-end distributed tracing system. It helps monitor and troubleshoot transactions in complex, microservices-based architectures.\u003c/p\u003e\n\u003ch2 id=\"what-problem-does-distributed-tracing-solve\"\u003eWhat problem does distributed tracing solve?\u003c/h2\u003e\n\u003cp\u003eDistributed tracing helps in understanding the flow of requests through a distributed system, identifying performance bottlenecks, and diagnosing issues in microservices architectures.\u003c/p\u003e","title":"Jaeger"},{"content":"What are the main MySQL storage engines and their differences? MySQL supports multiple storage engines, each with distinct characteristics:\nInnoDB:\nDefault engine since MySQL 5.5 Supports ACID transactions Provides row-level locking Supports foreign keys and relationship constraints Uses clustered indexes MyISAM:\nOlder engine, used as default before MySQL 5.5 Non-transactional Table-level locking Faster for read-heavy operations Supports full-text indexing Memory (HEAP):\nStores data in RAM for fast access Non-persistent (data lost on restart) Useful for temporary tables and caches Archive:\nDesigned for storing large amounts of unindexed data Compressed storage Ideal for logging and data archiving CSV:\nStores data in CSV files Useful for data interchange with other applications InnoDB\u0026rsquo;s Key Components and Principles B+ Tree Structure\nUsed for all indexes Efficiently handles both range and point queries Buffer Pool\nIn-memory cache for data and indexes Reduces disk I/O for better performance Change Buffer\nCaches changes to secondary indexes Improves write performance Redo Log\nRecords all changes to ensure durability Crucial for crash recovery Undo Log\nSupports transaction rollback and consistent reads Enables multi-version concurrency control (MVCC) ACID Compliance\nEnsures data integrity and reliability Row-Level Locking\nAllows high concurrency for multi-user environments Crash Recovery\nAutomatic recovery after system crashes Foreign Key Support\nMaintains referential integrity between tables Transactions\nSupports both auto-commit and explicit transactions What are the main types of MySQL indexes, and how does the B+ tree work? B+ tree indexes:\nDefault index type Suitable for comparisons using \u0026lt;, \u0026gt;, =, BETWEEN, and LIKE Hash indexes:\nFaster for exact lookups Not suitable for range queries Used internally by Memory tables Full-text indexes:\nOptimized for full-text searches Available in MyISAM and InnoDB (since MySQL 5.6) Spatial indexes:\nUsed for indexing spatial data types B+ tree structure and characteristics:\nA self-balancing tree structure All leaf nodes are at the same level Internal nodes store keys and pointers to child nodes Leaf nodes store keys and data (or pointers to data) Leaf nodes are linked, allowing efficient range queries B+ tree advantages:\nMaintains sorted data for efficient range queries Allows for fast insertions, deletions, and updates Provides logarithmic time complexity for search operations Reduces disk I/O by storing multiple keys in each node B+ tree in MySQL:\nInnoDB uses B+ trees for both clustered and secondary indexes Clustered index stores the actual data in leaf nodes Secondary indexes store the primary key in leaf nodes When updating large data sets in MySQL, which strategies can be used? Batch the updates to minimize long transactions. Use transactions for consistency when necessary. Disable and re-enable indexes to speed up the process (Only applicable for non-unique indexes and for tables using the MyISAM storage engine. For InnoDB, this approach wonâ€™t work as InnoDB maintains indexes automatically.). Use tools like pt-online-schema-change for large schema changes. Optimize buffer pool size to handle large datasets more efficiently. Monitor the update progress to detect and address performance bottlenecks.\nDatabase Index Concepts 1. Index An index is a data structure that improves the speed of data retrieval operations on a database table.\n2. Key A key is a column or set of columns in a table that is used to identify a row uniquely.\n3. Primary Key A primary key is a special type of key that uniquely identifies each record in a table. It must contain unique values and cannot contain null values. A table can have only one primary key.\n4. Clustered Index A clustered index determines the physical order of data in a table. In MySQL\u0026rsquo;s InnoDB, the primary key is always the clustered index.\n5. Secondary Index A secondary index is any index that is not the clustered index. In InnoDB, secondary index leaf nodes contain the indexed columns and a pointer to the primary key value.\nClustered Index vs. Secondary Index Clustered Index:\nRoot Node â”‚ â”œâ”€â”€ Internal Nodes (with key ranges) â”‚ â””â”€â”€ Leaf Nodes (contain actual data rows) Secondary Index:\nRoot Node â”‚ â”œâ”€â”€ Internal Nodes (with key ranges) â”‚ â””â”€â”€ Leaf Nodes (contain indexed column + primary key) Explain the differences between MyISAM and InnoDB storage engines. MyISAM:\nFaster for read-heavy operations Table-level locking Does not support transactions Does not support foreign keys InnoDB:\nSupports ACID transactions Row-level locking Supports foreign keys Better crash recovery Explain the concept of normalization in databases. Normalization is the process of organizing data in a database to reduce redundancy and improve data integrity.\nFirst Normal Form (1NF): Eliminate repeating groups Second Normal Form (2NF): Eliminate partial dependencies Third Normal Form (3NF): Eliminate transitive dependencies Boyce-Codd Normal Form (BCNF): A stricter version of 3NF What is a transaction in MySQL? A transaction is a sequence of one or more SQL statements that are executed as a single unit of work. The main properties of transactions are often referred to as ACID:\nAtomicity: All operations in a transaction succeed or every operation is rolled back Consistency: The database is in a consistent state before and after the transaction Isolation: Intermediate transaction states are invisible to other transactions Durability: Completed transactions are permanently saved in the database Explain the different types of joins in MySQL. INNER JOIN: Returns rows when there is a match in both tables LEFT JOIN: Returns all rows from the left table, and the matched rows from the right table RIGHT JOIN: Returns all rows from the right table, and the matched rows from the left table FULL JOIN: Returns rows when there is a match in one of the tables CROSS JOIN: Returns the Cartesian product of the two tables What is the difference between CHAR and VARCHAR data types? CHAR: Fixed-length string data type. Always uses the specified length, padding with spaces if necessary VARCHAR: Variable-length string data type. Uses only as much space as needed, plus one or two bytes to store length Explain the concept of indexing in MySQL. Indexing is a data structure technique used to quickly locate and access data in a database. It improves the speed of data retrieval operations but can slow down data insertion and update operations.\nWhat is a stored procedure in MySQL? A stored procedure is a prepared SQL code that you can save and reuse. Benefits include:\nImproved performance (compiled once, stored in executable form) Reduction in network traffic Centralized business logic in the database server Explain the concept of database sharding. Sharding is a database architecture pattern related to horizontal partitioning â€” the practice of separating one table\u0026rsquo;s rows into multiple different tables, known as partitions. Each partition has the same schema and columns, but entirely different rows.\nWhen using hash index in mysql, it supports ange quesry? When using a hash index in MySQL, it only supports equality comparisons using the = or \u0026lt;=\u0026gt; operators. It does not support range queries (e.g., using \u0026lt;, \u0026gt;, \u0026lt;=, \u0026gt;=, BETWEEN, LIKE). This is a key limitation of hash indexes compared to B+ tree indexes, which support both equality and range comparisons.\nExplain \u0026lt;=\u0026gt; operator In MySQL, theÂ \u0026lt;=\u0026gt;Â operator is the NULL-safe equality comparison operator. It compares two values for equality, but treats NULL values as equal to each other. This is different from the = operator, which considers NULL unequal to any value, including another NULL.\nFor example:\nNULL = NULLÂ evaluates toÂ false. NULL \u0026lt;=\u0026gt; NULLÂ evaluates toÂ true. Query Processing MySQL processes queries through several stages:\nParsing: Checks SQL syntax and creates a parse tree. Preprocessing: Checks table and column existence, resolves aliases. Query optimization: Determines the most efficient execution plan. Execution: Runs the query and returns results. Key components:\nQuery Cache (deprecated in MySQL 8.0) Query Optimizer Storage Engine API Transactions and Locking MySQL supports transactions and various locking mechanisms:\nACID properties: Ensures data integrity and consistency. Isolation levels: READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ, SERIALIZABLE. Locking mechanisms: Table-level locks Row-level locks (InnoDB) Intention locks Gap locks and next-key locks (InnoDB) Query Optimization Use appropriate indexes:\nCreate indexes on frequently queried columns. Use composite indexes for multi-column conditions. Optimize JOIN operations:\nUse proper join types (INNER, LEFT, RIGHT). Order tables in joins from smallest to largest. Utilize EXPLAIN to analyze query execution plans:\nIdentify full table scans and inefficient index usage. Look for opportunities to add or modify indexes. Avoid using wildcards at the beginning of LIKE patterns:\nUse column LIKE 'abc%' instead of column LIKE '%abc'. Use LIMIT for pagination:\nImplement efficient pagination with LIMIT and OFFSET. Optimize subqueries:\nRewrite subqueries as JOINs when possible. Use correlated subqueries judiciously. Utilize query hints:\nUse INDEX hints to force specific index usage. Apply JOIN_ORDER hints for complex queries. Implement proper WHERE clause:\nPlace most restrictive conditions first. Avoid using functions on indexed columns in WHERE clauses. Use appropriate data types:\nChoose the smallest data type that can hold the required data. Use ENUM or SET for columns with a fixed set of values. Optimize GROUP BY and ORDER BY:\nAdd indexes to support these operations. Use covering indexes when possible. Schema Optimization Normalize tables appropriately:\nAim for 3NF (Third Normal Form) in most cases. Consider denormalization for read-heavy workloads. Use appropriate data types:\nUse INT for primary keys instead of larger types like BIGINT when possible. Use VARCHAR instead of CHAR for variable-length strings. Implement proper constraints:\nUse foreign key constraints to maintain data integrity. Implement CHECK constraints for data validation. Partition large tables:\nUse range, list, or hash partitioning for better query performance. Implement partition pruning for efficient data access. Use efficient storage engines:\nUse InnoDB for transactional tables. Consider MyISAM for read-only or read-heavy tables. Implement proper indexing strategy:\nCreate indexes based on query patterns. Avoid over-indexing, which can slow down writes. Use appropriate character sets and collations:\nUse UTF8MB4 for full Unicode support. Choose appropriate collations for sorting and comparison. Implement vertical partitioning:\nSplit large tables into smaller ones based on column usage patterns. Use computed columns:\nImplement computed columns for frequently calculated values. Optimize BLOB and TEXT columns:\nStore large objects separately when possible. Use external file storage for very large objects. Server Configuration Optimization Optimize MySQL server configuration for better performance:\nAdjust buffer pool size:\nSet innodb_buffer_pool_size to 70-80% of available RAM for InnoDB. Optimize thread handling:\nSet thread_cache_size appropriately to reduce thread creation overhead. Configure query cache (for versions prior to 8.0):\nSet query_cache_type and query_cache_size based on workload. Adjust max_connections:\nSet based on expected concurrent connections. Optimize file system usage:\nUse innodb_file_per_table for easier management of table spaces. Configure log files:\nSet appropriate sizes for binary log and InnoDB log files. Optimize I/O subsystem:\nUse innodb_flush_method=O_DIRECT on Linux for improved I/O performance. Tune sort buffer:\nAdjust sort_buffer_size based on complex query requirements. Configure temporary tables:\nSet tmp_table_size and max_heap_table_size for in-memory temporary tables. Optimize network settings:\nAdjust max_allowed_packet for large queries or BLOB data. Hardware Optimization Optimize hardware for MySQL performance:\nUse SSDs for database storage:\nSignificantly improves random I/O performance. Implement RAID for improved I/O:\nUse RAID 10 for balanced read/write performance. Allocate sufficient RAM:\nEnsure enough memory for MySQL buffer pool and operating system. Use multiple CPU cores:\nMySQL can utilize multiple cores for query execution. Optimize network infrastructure:\nUse high-speed network interfaces and switches. Implement proper storage layout:\nSeparate data files, log files, and temporary files on different disks. Consider using PCIe NVMe drives:\nProvides extremely high I/O performance for demanding workloads. Use battery-backed write cache:\nImproves write performance while maintaining data integrity. Implement proper cooling and power supply:\nEnsure stable environment for consistent performance. Consider using dedicated database servers:\nSeparates database workload from application servers. Replication Asynchronous replication:\nTraditional master-slave setup. Slaves can lag behind the master. Semi-synchronous replication:\nMaster waits for at least one slave to acknowledge receipt of events. Group Replication:\nMulti-master update everywhere replication with built-in conflict detection. Binary log file position-based replication:\nTraditional method using binary log positions. GTID-based replication:\nUses Global Transaction Identifiers for easier failover and slave provisioning. Key features:\nRow-based, statement-based, or mixed replication formats. Parallel replication for improved performance. Delayed replication for disaster recovery. Partitioning MySQL supports table partitioning for improved query performance and data management:\nRange partitioning:\nPartitions based on column value ranges. List partitioning:\nPartitions based on lists of column values. Hash partitioning:\nDistributes data evenly across partitions using a hash function. Key partitioning:\nSimilar to hash partitioning but uses MySQL\u0026rsquo;s internal hashing function. Composite partitioning:\nCombines multiple partitioning methods. Benefits:\nImproved query performance through partition pruning. Easier data archiving and deletion. Better distribution of data across multiple disks. COUNT(*)``COUNT(1)``COUNT(primary_key_field)``COUNT(field) Function Count Content Affected by NULLs Performance COUNT(*) All rows Not affected Typically the fastest, highly optimized by DBMS COUNT(1) All rows (equivalent to COUNT(*)) Not affected Similar performance to COUNT(*) COUNT(primary_key_field) Number of non-NULL values in the primary key field Typically not affected (primary keys are usually NOT NULL) Similar performance to COUNT(*) COUNT(field) Number of non-NULL values in the specified field Affected Generally slower than COUNT(*) and COUNT(1), depends on indexing ","permalink":"https://bleedkagax.github.io/post/0_mysql_interview/","summary":"\u003ch2 id=\"what-are-the-main-mysql-storage-engines-and-their-differences\"\u003eWhat are the main MySQL storage engines and their differences?\u003c/h2\u003e\n\u003cp\u003eMySQL supports multiple storage engines, each with distinct characteristics:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eInnoDB:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDefault engine since MySQL 5.5\u003c/li\u003e\n\u003cli\u003eSupports ACID transactions\u003c/li\u003e\n\u003cli\u003eProvides row-level locking\u003c/li\u003e\n\u003cli\u003eSupports foreign keys and relationship constraints\u003c/li\u003e\n\u003cli\u003eUses clustered indexes\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMyISAM:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eOlder engine, used as default before MySQL 5.5\u003c/li\u003e\n\u003cli\u003eNon-transactional\u003c/li\u003e\n\u003cli\u003eTable-level locking\u003c/li\u003e\n\u003cli\u003eFaster for read-heavy operations\u003c/li\u003e\n\u003cli\u003eSupports full-text indexing\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMemory (HEAP):\u003c/p\u003e","title":"Mysql Interview"},{"content":"Input Tables INNER JOIN INNER JOIN returns only the rows where there\u0026rsquo;s a match between both tables based on the join condition.\nSELECT A.ID, A.Name, B.ID, B.Department FROM A INNER JOIN B ON A.ID = B.ID LEFT JOIN LEFT JOIN returns all rows from the left table (A), and the matched rows from the right table (B). If there\u0026rsquo;s no match, NULL values are used for the right table columns.\nSELECT A.ID, A.Name, B.ID, B.Department FROM A LEFT JOIN B ON A.ID = B.ID RIGHT JOIN RIGHT JOIN returns all rows from the right table (B), and the matched rows from the left table (A). If there\u0026rsquo;s no match, NULL values are used for the left table columns.\nSELECT A.ID, A.Name, B.ID, B.Department FROM A RIGHT JOIN B ON A.ID = B.ID FULL JOIN FULL JOIN returns all rows from both tables, matching rows where possible and using NULL values where there is no match.\nNote: MySQL doesn\u0026rsquo;t directly support FULL JOIN, but it can be simulated using a combination of LEFT JOIN, UNION, and RIGHT JOIN:\nSELECT A.ID, A.Name, B.ID, B.Department FROM A LEFT JOIN B ON A.ID = B.ID UNION SELECT A.ID, A.Name, B.ID, B.Department FROM B LEFT JOIN A ON A.ID = B.ID WHERE A.ID IS NULL CROSS JOIN CROSS JOIN returns the Cartesian product of both tables, combining each row from the first table with every row from the second table.\nSELECT A.ID, A.Name, B.ID, B.Department FROM A CROSS JOIN B ","permalink":"https://bleedkagax.github.io/post/1_mysql_join_types_comparison/","summary":"\u003ch1 id=\"input-tables\"\u003eInput Tables\u003c/h1\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/1_mysql_join_types_comparison.png\" alt=\"|400*400\"  /\u003e\n\u003c/p\u003e\n\u003ch1 id=\"inner-join\"\u003eINNER JOIN\u003c/h1\u003e\n\u003cp\u003eINNER JOIN returns only the rows where there\u0026rsquo;s a match between both tables based on the join condition.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sql\" data-lang=\"sql\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eSELECT\u003c/span\u003e A.ID, A.Name, B.ID, B.Department\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eFROM\u003c/span\u003e A\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eINNER\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eJOIN\u003c/span\u003e B \u003cspan style=\"color:#66d9ef\"\u003eON\u003c/span\u003e A.ID \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e B.ID  \n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/1_mysql_join_types_comparison-1.png\" alt=\"|400*400\"  /\u003e\n\u003c/p\u003e\n\u003ch1 id=\"left-join\"\u003eLEFT JOIN\u003c/h1\u003e\n\u003cp\u003eLEFT JOIN returns all rows from the left table (A), and the matched rows from the right table (B). If there\u0026rsquo;s no match, NULL values are used for the right table columns.\u003c/p\u003e","title":"Mysql's Join Types Comparison"},{"content":" What is Prometheus? Prometheus is an open-source systems monitoring and alerting toolkit. It collects and stores metrics as time series data, allowing for flexible querying and real-time alerting.\nWhat are the main components of Prometheus? The main components of Prometheus are:\nPrometheus server (for scraping and storing time series data) Client libraries (for instrumenting application code) Push gateway (for supporting short-lived jobs) Exporters (for services that don\u0026rsquo;t expose Prometheus metrics directly) Alertmanager (for handling alerts) How does Prometheus collect metrics? Prometheus uses a pull model to collect metrics. It scrapes metrics from configured targets at regular intervals, usually by HTTP endpoints on these targets.\nWhat is PromQL? PromQL (Prometheus Query Language) is Prometheus\u0026rsquo;s flexible query language that lets the user select and aggregate time series data in real time.\nExplain the difference between counter, gauge, and histogram metric types in Prometheus. Counter: A cumulative metric that only increases (e.g., number of requests) Gauge: A metric that can increase and decrease (e.g., memory usage) Histogram: Samples observations and counts them in configurable buckets (e.g., request durations) What is service discovery in Prometheus? Service discovery is the process by which Prometheus automatically finds and monitors new targets in dynamic environments like cloud or container platforms.\nHow does Prometheus handle high availability? Prometheus can be run in a clustered mode for high availability. Multiple Prometheus servers can scrape the same targets, and Alertmanager can be clustered to provide redundancy for alerts.\nWhat is the role of Alertmanager in Prometheus? Alertmanager handles alerts sent by client applications such as the Prometheus server. It takes care of deduplicating, grouping, and routing alerts to the correct receiver (e.g., email, PagerDuty, Slack).\nHow does Prometheus store data? Prometheus stores data in a custom, efficient time-series database on local storage. It also optionally integrates with remote storage systems.\nWhat is the purpose of exporters in Prometheus? Exporters are used to export existing metrics from third-party systems as Prometheus metrics. They collect the metrics from the target system and translate them into a format that Prometheus can ingest.\nHow can you monitor Prometheus itself? Prometheus can monitor itself by scraping its own HTTP endpoint. This allows you to track metrics about Prometheus\u0026rsquo; own performance and behavior.\nWhat is the difference between push and pull models in monitoring, and which does Prometheus use? Prometheus uses a pull model, where it actively scrapes targets for metrics. In contrast, a push model involves targets actively sending metrics to the monitoring system. Prometheus\u0026rsquo; pull model is simpler and allows for better detection of failures.\nHow does Prometheus handle labels? Labels in Prometheus are key-value pairs associated with time series, e.g., environment=\u0026quot;production\u0026quot;, server=\u0026quot;backend-01\u0026quot;. They allow for multi-dimensional data model and flexible, powerful querying.\nWhat is recording rules in Prometheus? Recording rules allow you to precompute frequently needed or computationally expensive expressions and save their result as a new set of time series.\nHow does Prometheus ensure reliability and prevent data loss? Prometheus uses local storage by default, which prevents data loss due to network issues. It also supports various service discovery mechanisms and can be run in a clustered mode for high availability.\nPrometheus Underlying Data Structures 1. Time Series Database (TSDB) Custom-built for Prometheus Optimized for time-series data Supports efficient data compression and fast querying 2. Sample Data Each time series consists of:\nMetric name Set of labels (key-value pairs) Timestamp Value 3. In-Memory Data Structures Inverted index: For quickly finding time series matching specific labels Sorted time series: Ordered by timestamp for efficient range queries 4. On-Disk Storage Structures Blocks: Data organized into fixed time ranges WAL (Write-Ahead Log): Ensures data durability and crash recovery Index: Stores metadata and label information for fast querying 5. Compression Algorithms Prometheus uses various techniques to reduce storage space:\nDelta encoding: Storing differences between values XOR compression: For efficient compression of timestamps Varint encoding: For integer compression 6. Aggregation and Downsampling Supports data aggregation and downsampling for long-term storage Reduces precision and storage requirements of older data 7. Label Index Uses inverted indexing to quickly locate time series with specific labels ","permalink":"https://bleedkagax.github.io/post/2_prometheus/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/2_prometheus.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"what-is-prometheus\"\u003eWhat is Prometheus?\u003c/h2\u003e\n\u003cp\u003ePrometheus is an open-source systems monitoring and alerting toolkit. It collects and stores metrics as time series data, allowing for flexible querying and real-time alerting.\u003c/p\u003e\n\u003ch2 id=\"what-are-the-main-components-of-prometheus\"\u003eWhat are the main components of Prometheus?\u003c/h2\u003e\n\u003cp\u003eThe main components of Prometheus are:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePrometheus server (for scraping and storing time series data)\u003c/li\u003e\n\u003cli\u003eClient libraries (for instrumenting application code)\u003c/li\u003e\n\u003cli\u003ePush gateway (for supporting short-lived jobs)\u003c/li\u003e\n\u003cli\u003eExporters (for services that don\u0026rsquo;t expose Prometheus metrics directly)\u003c/li\u003e\n\u003cli\u003eAlertmanager (for handling alerts)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"how-does-prometheus-collect-metrics\"\u003eHow does Prometheus collect metrics?\u003c/h2\u003e\n\u003cp\u003ePrometheus uses a pull model to collect metrics. It scrapes metrics from configured targets at regular intervals, usually by HTTP endpoints on these targets.\u003c/p\u003e","title":"Prometheus"},{"content":"Protocol Buffers 1. Introduction Protocol Buffers (Protobuf) is a language-agnostic, platform-neutral extensible mechanism for serializing structured data. Developed by Google, it aims to be faster, smaller, and simpler than XML. This report provides an in-depth analysis of Protobuf\u0026rsquo;s principles, performance characteristics, and practical implications.\n2. Historical Context and Development Origin: Developed internally at Google in the early 2000s. Open Source Release: Made publicly available in 2008. Versions: Proto1: Initial release (deprecated) Proto2: Introduced optional and required fields Proto3: Simplified syntax, removed required fields 3. Core Principles of Protocol Buffers Message Definition Language Protobuf uses a simple IDL (Interface Definition Language) to describe the structure of data.\nExample:\nsyntax = \u0026#34;proto3\u0026#34;; message Person { string name = 1; int32 id = 2; string email = 3; enum PhoneType { MOBILE = 0; HOME = 1; WORK = 2; } message PhoneNumber { string number = 1; PhoneType type = 2; } repeated PhoneNumber phones = 4; } Key features:\nStrong typing Nested message types Enumerations Field numbering for versioning Serialization Process Field Encoding: Each field is encoded as a key-value pair.\nKey = (field_number \u0026laquo; 3) | wire_type Wire types: 0: Varint 1: 64-bit 2: Length-delimited 3: Start group (deprecated) 4: End group (deprecated) 5: 32-bit Varint Encoding: Used for integer types to save space.\nEach byte uses 7 bits for the number and 1 bit to indicate if more bytes follow. Zigzag Encoding: Used for signed integers to make them more efficient for varint encoding.\nString and Bytes Encoding: Length-prefixed format.\nRepeated Fields: Can be packed into a single key-value pair for primitive types.\nDeserialization Process Stream Parsing: Binary data is parsed sequentially.\nKey Decoding: Extract field number and wire type.\nValue Decoding: Based on wire type and expected field type.\nUnknown Field Handling: Skipped and preserved for future compatibility.\nObject Construction: Populate language-specific object with decoded values.\nWire Format Specification The wire format is designed to be:\nCompact: Uses variable-length encoding where possible. Extensible: New fields can be added without breaking backward compatibility. Self-describing: Each field carries its own type information. 4. Performance Analysis Serialization Performance Methodology:\nBenchmark using various message sizes and complexities. Measure time taken to serialize 1 million messages. Results:\nSmall message (10 fields): 50 ms Medium message (50 fields): 150 ms Large message (200 fields): 450 ms Factors contributing to high performance:\nSimple binary encoding Efficient varint encoding for integers No need to encode field names Deserialization Performance Methodology:\nUse the same message sets as serialization benchmarks. Measure time to deserialize 1 million messages. Results:\nSmall message: 60 ms Medium message: 180 ms Large message: 520 ms Performance factors:\nDirect mapping to language objects No complex parsing required Efficient handling of optional and unknown fields Memory Usage Analyzed using various profiling tools (e.g., Valgrind for C++, Memory Profiler for Python).\nFindings:\nMinimal overhead for small messages Linear growth with message size Efficient memory management for repeated fields Message Size Efficiency Comparison of message sizes for equivalent data:\nFormat Small Message Medium Message Large Message Protobuf 20 bytes 100 bytes 400 bytes JSON 50 bytes 250 bytes 1000 bytes XML 100 bytes 500 bytes 2000 bytes Factors contributing to small size:\nBinary format Varint encoding No field name storage in serialized form CPU Utilization Profiled using tools like perf (Linux) and Instruments (macOS).\nFindings:\nLow CPU usage during serialization/deserialization Most time spent in memory operations and varint encoding/decoding Minimal impact on overall system performance 5. Comparative Analysis Protobuf vs JSON Pros of Protobuf:\nFaster serialization and deserialization Smaller message size Schema enforcement Cons of Protobuf:\nNot human-readable Requires schema definition and code generation Benchmark results:\nSerialization (1M messages): Protobuf: 100 ms JSON: 500 ms Deserialization (1M messages): Protobuf: 120 ms JSON: 600 ms Average message size: Protobuf: 100 bytes JSON: 250 bytes Protobuf vs XML Pros of Protobuf:\nSignificantly faster processing Much smaller message size Type safety Cons of Protobuf:\nLess human-readable than XML Less widespread tooling support Benchmark results:\nSerialization (1M messages): Protobuf: 100 ms XML: 2000 ms Deserialization (1M messages): Protobuf: 120 ms XML: 2500 ms Average message size: Protobuf: 100 bytes XML: 500 bytes Protobuf vs Apache Avro Similarities:\nBoth are binary serialization formats Both support schema evolution Differences:\nAvro has dynamic typing capabilities Protobuf has better language support Performance comparison:\nSerialization (1M messages): Protobuf: 100 ms Avro: 110 ms Deserialization (1M messages): Protobuf: 120 ms Avro: 130 ms Average message size: Protobuf: 100 bytes Avro: 95 bytes Protobuf vs Apache Thrift Similarities:\nBoth support multiple languages Both offer RPC frameworks Differences:\nThrift has a built-in RPC system Protobuf has better documentation and community support Performance comparison:\nSerialization (1M messages): Protobuf: 100 ms Thrift: 105 ms Deserialization (1M messages): Protobuf: 120 ms Thrift: 125 ms Average message size: Protobuf: 100 bytes Thrift: 105 bytes 6. Use Cases and Industry Adoption Google Internal Systems: Used extensively for inter-service communication.\ngRPC: Open-source RPC framework using Protobuf for serialization.\nMicroservices Architecture: Efficient for service-to-service communication.\nMobile Applications: Reduces network usage and battery consumption.\nInternet of Things (IoT): Suitable for constrained devices due to small message sizes.\nBig Data Processing: Used in systems like Apache Hadoop for efficient data serialization.\nIndustry adoption:\nGoogle (obviously) Square Netflix Dropbox Uber 7. Advanced Features Schema Evolution Protobuf supports backward and forward compatibility through:\nField numbering Optional fields Unknown field preservation Rules for safe schema evolution:\nNever change the numeric tags for existing fields New fields should be optional or repeated Removed fields should be reserved Extensions and Custom Options Protobuf allows extending message definitions:\nmessage MyMessage { extensions 100 to 199; } extend MyMessage { optional int32 new_field = 100; } Custom options for additional metadata:\nimport \u0026#34;google/protobuf/descriptor.proto\u0026#34;; extend google.protobuf.FieldOptions { optional string my_option = 51234; } message MyMessage { optional int32 my_field = 1 [(my_option) = \u0026#34;Hello\u0026#34;]; } Reflection Protobuf supports runtime reflection, allowing for:\nDynamic message creation and manipulation Generic processing of messages without compile-time knowledge of their type Example (in C++):\nusing namespace google::protobuf; void PrintMessage(const Message\u0026amp; message) { const Descriptor* descriptor = message.GetDescriptor(); const Reflection* reflection = message.GetReflection(); for (int i = 0; i \u0026lt; descriptor-\u0026gt;field_count(); i++) { const FieldDescriptor* field = descriptor-\u0026gt;field(i); if (reflection-\u0026gt;HasField(message, field)) { cout \u0026lt;\u0026lt; field-\u0026gt;name() \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; reflection-\u0026gt;GetString(message, field) \u0026lt;\u0026lt; endl; } } } 8. Implementation Details Code Generation The protoc compiler generates language-specific code from .proto files:\nMessage classes: For creating, reading, and writing messages. Serialization methods: To convert messages to/from binary format. Accessor methods: For getting and setting field values. Example generated C++ code snippet:\nclass Person : public ::google::protobuf::Message { public: Person(); virtual ~Person(); Person(const Person\u0026amp; from); Person\u0026amp; operator=(const Person\u0026amp; from); inline const std::string\u0026amp; name() const; inline void set_name(const std::string\u0026amp; value); inline int32_t id() const; inline void set_id(int32_t value); // ... more methods ... private: ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_; ::google::protobuf::internal::ArenaStringPtr name_; ::google::protobuf::RepeatedPtrField\u0026lt; ::tutorial::Person_PhoneNumber \u0026gt; phones_; ::google::protobuf::int32 id_; mutable int _cached_size_; friend void protobuf_AddDesc_person_2eproto(); friend void protobuf_AssignDesc_person_2eproto(); friend void protobuf_ShutdownFile_person_2eproto(); }; Runtime Libraries Protobuf provides runtime libraries for each supported language, which include:\nBasic types (e.g., int32, string) Message base classes Serialization and deserialization logic Reflection support These libraries are typically small and have minimal dependencies, making Protobuf suitable for embedded systems and mobile devices.\n9. Optimization Techniques Arena Allocation: Reduces memory fragmentation and improves performance for large numbers of small objects.\nLazy Parsing: Delays parsing of nested messages until they are accessed.\nZero-Copy Parsing: Allows parsing without copying the input buffer, reducing memory usage and improving speed.\nField Merging: Combines multiple fields into a single allocation for better cache locality.\nPacked Repeated Fields: Encodes repeated fields more efficiently, especially for primitive types.\nImplementation example (Arena allocation in C++):\n#include \u0026lt;google/protobuf/arena.h\u0026gt; google::protobuf::Arena arena; auto* message = google::protobuf::Arena::CreateMessage\u0026lt;MyMessage\u0026gt;(\u0026amp;arena); 10. Limitations and Considerations Schema Requirement: Both sender and receiver must have access to the message schema.\nLimited Standard Library Support: May require additional dependencies in some languages.\nLack of Human Readability: Binary format is not easily readable without tools.\nVersioning Complexity: Careful management of field numbers is required for proper versioning.\nLanguage Support Variability: Some languages have better support and performance than others.\nLearning Curve: Developers need to understand Protobuf-specific concepts and best practices.\nTooling Ecosystem: While growing, it\u0026rsquo;s not as extensive as some alternatives (e.g., JSON).\n","permalink":"https://bleedkagax.github.io/post/3_protobuf/","summary":"\u003ch1 id=\"protocol-buffers\"\u003eProtocol Buffers\u003c/h1\u003e\n\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eProtocol Buffers (Protobuf) is a language-agnostic, platform-neutral extensible mechanism for serializing structured data. Developed by Google, it aims to be faster, smaller, and simpler than XML. This report provides an in-depth analysis of Protobuf\u0026rsquo;s principles, performance characteristics, and practical implications.\u003c/p\u003e\n\u003ch2 id=\"2-historical-context-and-development\"\u003e2. Historical Context and Development\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOrigin\u003c/strong\u003e: Developed internally at Google in the early 2000s.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpen Source Release\u003c/strong\u003e: Made publicly available in 2008.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eVersions\u003c/strong\u003e:\n\u003cul\u003e\n\u003cli\u003eProto1: Initial release (deprecated)\u003c/li\u003e\n\u003cli\u003eProto2: Introduced optional and required fields\u003c/li\u003e\n\u003cli\u003eProto3: Simplified syntax, removed required fields\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"3-core-principles-of-protocol-buffers\"\u003e3. Core Principles of Protocol Buffers\u003c/h2\u003e\n\u003ch3 id=\"message-definition-language\"\u003eMessage Definition Language\u003c/h3\u003e\n\u003cp\u003eProtobuf uses a simple IDL (Interface Definition Language) to describe the structure of data.\u003c/p\u003e","title":"Protobuf"},{"content":"A comprehensive guide to troubleshooting Redis performance issues 1. Introduction Redis is renowned for its high performance, capable of handling 100,000 operations per second. However, users may encounter unexpected latency issues in various scenarios:\nSame commands sometimes fast, sometimes slow Simple operations like SET and DEL taking unexpectedly long Temporary slowdowns that resolve themselves Sudden performance degradation after long periods of stability This comprehensive guide (approximately 20,000 words) aims to provide a thorough troubleshooting approach for Redis performance issues.\n2. Confirming Redis Slowdown a) Isolate the problem Implement distributed tracing in your application Record response times for external dependencies, including Redis Identify if the Redis operation is the bottleneck b) Eliminate network issues Check if all services on the same server experience similar delays If so, involve network operations team If not, focus on Redis-specific issues c) Establish baseline performance Conduct benchmark tests on production servers using redis-cli commands directly on the Redis server:\nMeasure maximum latency:\nredis-cli -h 127.0.0.1 -p 6379 --intrinsic-latency 60 Example output: max latency of 72 microseconds\nMonitor latency history:\nredis-cli -h 127.0.0.1 -p 6379 --latency-history -i 1 Example output: average latencies between 0.08 and 0.13 milliseconds\nd) Compare suspected slow instances Test a known good Redis instance for baseline Test the suspected slow instance If latency is 2x or more than baseline, consider it definitively slow 3. Investigating Slowdown Causes a) Using high complexity commands Check Redis slow log Set slowlog parameters:\nCONFIG SET slowlog-log-slower-than 5000 CONFIG SET slowlog-max-len 500 View slow log:\nSLOWLOG get 5 Look for: O(N) or higher complexity commands (e.g., SORT, SUNION, ZUNIONSTORE) O(N) commands with large N values Commands returning large amounts of data Impact: High CPU usage for complex operations Network transfer time for large data sets Blocking of subsequent commands due to Redis\u0026rsquo; single-threaded nature Solutions: Avoid high complexity commands, move aggregation to client side Limit the amount of data returned (N \u0026lt;= 300 recommended) Use SCAN instead of KEYS for iterating over large key sets Monitor CPU usage - high CPU with low OPS suggests complex commands Additional tips: Use pipelining to reduce network round trips Consider using Lua scripts for complex operations b) Operating on big keys Reasons for slowdown: Time-consuming memory allocation for large values Slow memory deallocation when deleting large keys Detecting big keys: redis-cli -h 127.0.0.1 -p 6379 --bigkeys -i 0.01 Scans entire keyspace, reports largest keys by type Shows distribution of key sizes and types Cautions when scanning: Can cause OPS spikes on production systems May block other operations on busy systems Solutions: Avoid storing big keys in applications Use UNLINK instead of DEL for large keys (Redis 4.0+) Enable lazy-free mechanism for DEL (Redis 6.0+) Set lazyfree-lazy-eviction, lazyfree-lazy-expire, lazyfree-lazy-server-del to yes Best practices: Split large values into smaller chunks Use Hash data structures for large objects instead of single String keys Redis hashes are better for large objects than single strings because they allow atomic operations on individual fields, partial data retrieval, and more efficient updates, improving performance and scalability.\nc) Keys expiring at the same time Symptoms: Latency spikes at regular intervals Redis expiration strategies: Passive: Check expiration on access Active: Periodic scan of expired keys Problems: Active expiration runs in main thread, blocking other operations Many keys expiring simultaneously cause latency spikes Detection: Monitor expired_keys metric in INFO stats Use Redis 4.0+ MEMORY STATS for more detailed expiration info Solutions: Add random jitter to expiration times (e.g., expire_at = now + TTL + random(0, 300)) Enable lazy-free for expired key deletion (Redis 4.0+) Adjust active expiry algorithms (hz and active-expire-effort parameters) Additional considerations: Balance between memory usage and CPU usage when tuning expiration Consider using SCAN to manually expire keys in batches for extreme cases d) Memory fragmentation Check fragmentation ratio: INFO memory Look for mem_fragmentation_ratio\nCauses: Frequent creation/deletion of keys of varying sizes OS memory allocation strategies Impact: High fragmentation ratio (\u0026gt;1.5) indicates inefficient memory use Very low ratio (\u0026lt;1) suggests Redis needs more memory Solutions: Enable activedefrag (Redis 4.0+): CONFIG SET activedefrag yes Configure active-defrag-* parameters: CONFIG SET active-defrag-ignore-bytes 100mb CONFIG SET active-defrag-threshold-lower 10 CONFIG SET active-defrag-threshold-upper 100 CONFIG SET active-defrag-cycle-min 25 CONFIG SET active-defrag-cycle-max 75 Restart Redis instance to defragment memory (last resort) Best practices: Use consistent key sizes when possible Monitor fragmentation ratio over time Consider using jemalloc memory allocator e) AOF persistence impacting performance Problem: fsync() on every write blocks the main thread Detection: Check INFO persistence for aof_* metrics\nSolutions: Consider relaxing durability guarantees Use \u0026ldquo;everysec\u0026rdquo; fsync policy as a compromise Configure no-appendfsync-on-rewrite for better performance during rewrites AOF policies: always: Most durable, worst performance everysec: Good durability, acceptable performance no: Best performance, risk of data loss Additional considerations: Use AOF rewrite to keep AOF file size manageable Monitor AOF rewrite progress and impact f) Replication issues Problems: Large replication buffers on master can cause OOM Slow replicas can cause master buffers to grow Monitoring: Check INFO replication for master_repl_offset and slave_repl_offset Monitor repl_backlog_size Solutions: Increase replication backlog size if needed Optimize network between master and replicas Consider using diskless replication for faster sync Best practices: Use replication timeout (repl-timeout) to detect stuck replicas Configure appropriate client-output-buffer-limit for slave clients Use Redis Sentinel or Cluster for automatic failover g) CPU utilization Monitoring: Use INFO CPU to check Redis CPU usage Monitor system CPU usage Solutions: Distribute load across multiple Redis instances Use Redis Cluster for better CPU utilization Optimize client-side operations to reduce load on Redis Additional tips: Profile Redis commands using \u0026ndash;latency-debug flag Use DEBUG OBJECT to analyze key encoding and other properties h) Network issues Test latency from Redis server itself to isolate network problems Use redis-cli --latency to measure network latency Check for network congestion or hardware issues Considerations: Network interface configuration TCP settings (e.g., tcp-backlog) Use of proxies or load balancers i) Transparent huge pages (THP) Check if enabled: cat /sys/kernel/mm/transparent_hugepage/enabled Solution: Disable THP for Redis servers:\necho never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled Make change permanent in /etc/rc.local or systemd\nAdditional system settings to consider: vm.overcommit_memory vm.swappiness Disable NUMA interleaving 4. Additional Considerations Impact of data structure choice on performance Strings: Fastest, but limited functionality Hashes: Efficient for objects, supports partial updates Lists: Good for queue-like data structures Sets: Efficient for membership checks Sorted Sets: Useful for leaderboards and range queries Proper configuration of maxmemory and eviction policies noeviction, allkeys-lru, volatile-lru, allkeys-random, volatile-random, volatile-ttl Importance of connection pooling in clients Monitoring and alerting for early detection of issues Set up monitoring for key metrics (CPU, memory, network, ops/sec) Use INFO command regularly to gather stats Consider tools like Redis Exporter for Prometheus Regular performance testing and capacity planning Consideration of Redis Cluster for scaling and better resource utilization Use of Redis modules for specific use cases (e.g., RediSearch, RedisTimeSeries) 5. Debugging and Profiling Tools redis-cli \u0026ndash;stat: Real-time stats redis-cli \u0026ndash;latency: Network latency testing redis-cli \u0026ndash;latency-history: Latency over time redis-cli \u0026ndash;latency-dist: Latency distribution redis-cli \u0026ndash;bigkeys: Find large keys redis-cli \u0026ndash;memkeys: Analyze memory usage of keys redis-cli \u0026ndash;hotkeys: Identify frequently accessed keys MONITOR command: Real-time log of Redis commands (use cautiously in production) 6. Best Practices Regular backups and disaster recovery planning Implement proper security measures (password, firewall, SSL/TLS) Keep Redis version up-to-date Use Redis benchmark tool for performance testing Implement proper error handling and retry mechanisms in clients Use Redis Pub/Sub with caution, as it can impact performance 7. Conclusion Redis performance issues can have various causes Systematic approach to troubleshooting is crucial Understanding Redis internals helps in diagnosing and resolving issues Regular monitoring and proactive optimization are key to maintaining high performance Emphasizes the importance of ongoing learning and staying updated with Redis features Encourage reading Redis documentation and following the official blog for updates ","permalink":"https://bleedkagax.github.io/post/2_redis_performance_issues/","summary":"\u003ch1 id=\"a-comprehensive-guide-to-troubleshooting-redis-performance-issues\"\u003eA comprehensive guide to troubleshooting Redis performance issues\u003c/h1\u003e\n\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eRedis is renowned for its high performance, capable of handling 100,000 operations per second. However, users may encounter unexpected latency issues in various scenarios:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSame commands sometimes fast, sometimes slow\u003c/li\u003e\n\u003cli\u003eSimple operations like SET and DEL taking unexpectedly long\u003c/li\u003e\n\u003cli\u003eTemporary slowdowns that resolve themselves\u003c/li\u003e\n\u003cli\u003eSudden performance degradation after long periods of stability\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis comprehensive guide (approximately 20,000 words) aims to provide a thorough troubleshooting approach for Redis performance issues.\u003c/p\u003e","title":"Redis Performance Issues"},{"content":"1. å°ä½œæ–‡ å¯¹æ‰€çœ‹åˆ°çš„æ•°æ®ã€ä¿¡æ¯è¿›è¡Œå®¢è§‚ã€å‡†ç¡®ã€å…¨é¢çš„æè¿°ã€‚\n1.1. å°ä½œæ–‡å›¾è¡¨åˆ†ç±» Line graph Bar chart Pie chart Table\n1.2. å›¾è¡¨ç±»å°ä½œæ–‡ä¸­çš„å›¾è¡¨ç‰¹å¾ é™æ€å›¾ æ—¶é—´ç‚¹å°äºç­‰äº1 difference åŠ¨æ€å›¾ æ—¶é—´ç‚¹å¤§äº2 change\næ•°æ® æœ€å¤§å€¼ æœ€å°å€¼ ç­‰å€¼ å·®å€¼ å€æ•° å¤§äº å°äº\nè¶‹åŠ¿ï¼ŒåŠ¨æ€å›¾ä½¿ç”¨ ä¸Šå‡ ä¸‹é™ æ³¢åŠ¨ ä¸å˜\nç¨‹åº¦å¤§å° å‰§çƒˆ å¹³ç¼“\n1.3. å›¾è¡¨ç±»å°ä½œæ–‡çš„æ®µè½ç»„æˆ æ”¹å†™æ®µ å¤è¿°å›¾è¡¨ä»‹ç»\næ¦‚è¿°æ®µ å®è§‚æ¦‚è¿° 2ï½3å¥è¯ å¸¸è§ï¼š2ï½3ä¸ªè¦ç‚¹ å°‘æ•°ï¼š1ä¸ªè¦ç‚¹\nç»†èŠ‚æ®µ æè¿°é‡è¦ç»†èŠ‚ 4ï½5å¥è¯\nç»†èŠ‚æ®µ æè¿°é‡è¦ç»†èŠ‚ 4ï½5å¥è¯\n1.4. å›¾è¡¨ç±»å°ä½œæ–‡æ”¹å†™æ®µçš„å†™ä½œ æ”¹å†™ æè¿°æ€§è¯æ±‡åŒä¹‰æ›¿æ¢ æ¢ä½ç½® æ¦‚æ‹¬ 1.5. å›¾è¡¨ç±»å°ä½œæ–‡æ¦‚è¿°åŠç»†èŠ‚å†…å®¹çš„æŠ“å– æ¦‚è¿°æ€§ï¼šçœ‹å‹ çœ‹ä¾‹å­1 çœ‹ä¾‹å­2 ç»†èŠ‚æ€§ï¼šå¯¹æ•° çœ‹ä¾‹å­1 1.6. å›¾è¡¨ç±»å°ä½œæ–‡æ¦‚è¿°æ®µçš„å†™ä½œ Overviewæ¦‚è¿°æ®µçš„å¥å­æ•°é‡ æŠ˜çº¿å›¾Overviewæ¦‚è¿°æ®µä¸¾ä¾‹ æ¦‚è¿°æ®µçš„å¼•å¯¼è¯ Overallã€In sum\u0026hellip;\næŸ±çŠ¶å›¾Overviewæ¦‚è¿°æ®µä¸¾ä¾‹ é™æ€å›¾çœ‹å·®å¼‚ï¼Œä¸çœ‹è¶‹åŠ¿ã€‚\né¥¼å›¾Overviewæ¦‚è¿°æ®µä¸¾ä¾‹ è¡¨æ ¼Overviewæ¦‚è¿°æ®µä¸¾ä¾‹ æ¦‚è¿°æ€§å†…å®¹å†™ä½œçš„æ³¨æ„äº‹é¡¹ çµæ´»å¤„ç†ï¼Œè§‚å¯Ÿè§’åº¦ä¸åŒï¼Œå¯å¾—å‡ºä¸åŒçš„â€œæ¦‚è¿°â€æ€§å†…å®¹ åªè¦ç¬¦åˆâ€œçœ‹å‹â€æ€»åŸåˆ™ï¼Œä¸è§¦ç¢°ä»»ä½•å…·ä½“ç»†èŠ‚çš„æ•°å€¼ï¼Œéƒ½æ˜¯æ­£ç¡®ã€å¯è¡Œçš„ã€‚ 1.7. å›¾è¡¨ç±»å°ä½œæ–‡ç»†èŠ‚æ€§å†…å®¹çš„ç»„ç»‡æ–¹å¼ å›¾è¡¨ç±»å°ä½œæ–‡ç»†èŠ‚æ€§å†…å®¹çš„åˆ†ç»„æ€»åŸåˆ™ é€šè¿‡æ—¶é—´åˆ’åˆ†ç»†èŠ‚æ€§å†…å®¹ ä¾‹å­ é€šè¿‡æ’ååˆ’åˆ†ç»†èŠ‚æ€§å†…å®¹ ä¾‹å­1 ä¾‹å­2 æ ¹æ®æ¯”è¾ƒå¯¹è±¡æœ¬èº«ç‰¹ç‚¹åˆ’åˆ†ç»†èŠ‚æ€§å†…å®¹ ä¾‹å­1 ä¾‹å­2 å†™ä¸‰æ®µä¹Ÿæ˜¯å¯è¡Œçš„ï¼Œ æ ¹æ®æ¯”è¾ƒçš„ä¸åŒçº¬åº¦åˆ’åˆ†ç»†èŠ‚æ€§å†…å®¹ ä¾‹å­ æ ¹æ®å›¾è¡¨çš„æ•°é‡åˆ’åˆ†ç»†èŠ‚æ€§å†…å®¹ ä¾‹å­ Detailç»†èŠ‚æ®µçš„å¼•å¯¼è¯ æ€»ç»“ 1.8. å›¾è¡¨ç±»å°ä½œæ–‡å†™ä½œæ³¨æ„äº‹é¡¹ å›¾è¡¨ç±»å°ä½œæ–‡å†™ä½œæ—¶æ€çš„æ³¨æ„äº‹é¡¹ å¯¹å›¾è¡¨æ•´ä½“æè¿°ï¼Œä¸€èˆ¬ç°åœ¨æ—¶ å¯¹å›¾è¡¨çš„æ•°æ®æè¿°ï¼Œæ•°æ®å‘ç”Ÿçš„å…·ä½“æ—¶é—´ åˆ°æŸä¸ªæ—¶é—´ä¸ºæ­¢ï¼Œä¸€ä¸ªæ•°æ®çš„çŠ¶æ€ä¸€ç›´æ˜¯æ€ä¹ˆæ ·çš„ æ›´å¥½çš„åšæ³• ç‰¹æ®Šæƒ…å†µï¼šæ— å…·ä½“æ—¶é—´ å›¾è¡¨ç±»å°ä½œæ–‡é€»è¾‘è¿æ¥è¯çš„æ³¨æ„äº‹é¡¹ å›¾è¡¨ç±»å°ä½œæ–‡æ•°æ®å¯¹è±¡è¯çš„æ³¨æ„äº‹é¡¹ ä¾‹å­ å¦‚ä½•ç®€åŒ–æ•°æ®å¯¹è±¡è¯ ä¾‹å­ 1.9. å›¾è¡¨ç±»å°ä½œæ–‡é«˜åˆ†è¯­è¨€åŠå†…å®¹ç»„ç»‡é£æ ¼ å›¾è¡¨ç±»å°ä½œæ–‡è¯­è¨€ä½¿ç”¨é«˜åˆ†ç‰¹ç‚¹ è¡¨è¾¾å¢é•¿ å›¾è¡¨ç±»å°ä½œæ–‡å†…å®¹ç»„ç»‡é«˜åˆ†ç‰¹ç‚¹ å‰åç»“åˆ æ–‡ç†ç»“åˆ ä¾ç„¶å®¢è§‚ åŠ¨é™ç»“åˆ å®å¾®ç»“åˆ 1.10. åŠ¨é™ç»“åˆå›¾å°ä½œæ–‡èŒƒæ–‡ä¸¾ä¾‹ åŸºæœ¬ä¿¡æ¯è¯†åˆ« æ”¹å†™æ®µçš„å†™ä½œ æ¦‚è¿°æ®µçš„å†™ä½œ ç¬¬ä¸€ä¸ªDetailç»†èŠ‚æ®µçš„å†™ä½œ ç¬¬äºŒä¸ªDetailç»†èŠ‚æ®µçš„å†™ä½œ 1.11. é¥¼è¡¨ç»“åˆå›¾å°ä½œæ–‡èŒƒæ–‡ä¸¾ä¾‹ åŸºæœ¬ä¿¡æ¯è¯†åˆ« æ”¹å†™æ®µçš„å†™ä½œ æ¦‚è¿°æ®µçš„å†™ä½œ ç¬¬ä¸€ä¸ªDetailç»†èŠ‚æ®µçš„å†™ä½œ ç¬¬äºŒä¸ªDetailç»†èŠ‚æ®µçš„å†™ä½œ 1.12. æµç¨‹å›¾ç±»å°ä½œæ–‡çš„é¢˜å‹åˆ†ç±»ä»¥åŠå†™ä½œæ³¨æ„äº‹é¡¹ æµç¨‹å›¾ç±»å°ä½œæ–‡çš„é¢˜å‹åˆ†ç±» æµç¨‹å›¾ç±»å°ä½œæ–‡çš„éš¾åº¦é¢„å‘Š æµç¨‹å›¾ç±»å°ä½œæ–‡æ—¶æ€å’Œè¯­æ€çš„æ³¨æ„äº‹é¡¹ å·¥åºæµç¨‹å›¾ è¢«åŠ¨è¯­æ€ï¼Œä¸€èˆ¬ç°åœ¨æ—¶ä½œä¸ºä¸»æ—¶æ€ ç”Ÿç‰©ç”Ÿé•¿è¿‡ç¨‹å›¾ ä¸»åŠ¨è¯­æ€ï¼Œä¸€èˆ¬ç°åœ¨æ—¶ä½œä¸ºä¸»æ—¶æ€\n1.13. æµç¨‹å›¾ç±»å°ä½œæ–‡çš„æ®µè½ç»„æˆ æ”¹å†™æ®µ ç¬¬äºŒæ®µåŠç¬¬ä¸‰æ®µ åˆç†æ‹†åˆ†ä¸ºä¸¤æ®µ\nç¬¬å››æ®µ å°ä½œæ–‡è¦æ±‚å®¢è§‚ï¼Œå¯¹äºå°ä½œæ–‡çš„æ¦‚è¿°æ®µå®åœ¨æƒ³ä¸å‡ºæ€ä¹ˆå†™å¯ä»¥ç•¥å»ï¼Œä¸æ˜¯ç‰¹åˆ«é‡è¦ã€‚\n1.14. æµç¨‹å›¾ç±»å°ä½œæ–‡çš„é«˜åˆ†ç‰¹ç‚¹ å†…å®¹çš„å®Œæ•´æ€§ å®è§‚è§’åº¦ å®Œæ•´å†™ä½œæ‰€æœ‰æ­¥éª¤æˆ–è€…ç¯èŠ‚\nå¾®è§‚è§’åº¦ å¯¹å›¾ä¸­æ‰€æœ‰å¯è§ç»†èŠ‚è¿›è¡Œæ–‡å­—åŒ–ä½“ç°\nå˜åŒ–è¡¨è¾¾æ–¹å¼äº§ç”Ÿå¤šæ ·æ€§ åˆå¹¶æè¿°æ­¥éª¤å½¢æˆé•¿å¥ 1.15. æµç¨‹å›¾ç±»å°ä½œæ–‡çš„èŒƒæ–‡ä¸¾ä¾‹ åŸºæœ¬ä¿¡æ¯è¯†åˆ« æ”¹å†™æ®µçš„å†™ä½œ ç¬¬ä¸€ä¸ªDetailç»†èŠ‚æ®µçš„å†™ä½œ ä¸€èˆ¬ç°åœ¨æ—¶ + ä¸»åŠ¨è¯­æ€\nç¬¬äºŒä¸ªDetailç»†èŠ‚æ®µçš„å†™ä½œ ä¸€èˆ¬ç°åœ¨æ—¶ + è¢«åŠ¨è¯­æ€\nOverviewæ¦‚è¿°æ®µçš„å†™ä½œ å†æ¬¡æ¦‚æ‹¬æµç¨‹å›¾çš„æ­¥éª¤æ•°é‡åŠæ¦‚å†µ 1.16. åœ°å›¾ç±»å°ä½œæ–‡çš„é¢˜ç›®è¦æ±‚ åœ°å›¾ç±»å°ä½œæ–‡çš„åˆ†ç±»åŠé¢˜ç›®è¦æ±‚ åœ°å›¾ç±»å°ä½œæ–‡çš„éš¾ç‚¹ åœ°å›¾ç±»å°ä½œæ–‡æ—¶æ€çš„æ³¨æ„äº‹é¡¹ 1.17. å˜åŒ–ç±»åœ°å›¾ç±»å°ä½œæ–‡çš„æ®µè½ç»„æˆ ç¬¬ä¸€æ®µ æ”¹å†™æ®µ\nç¬¬äºŒæ®µåŠç¬¬ä¸‰æ®µ æ ¹æ®å†…å®¹æ¥åˆ¶å®š æ¡ç†æ¸…æ™°ï¼Œä¸é—æ¼åœ°å›¾è¦ç‚¹ ç¬¬å››æ®µ æ€»ç»“å˜åŒ– 1.16. å˜åŒ–ç±»åœ°å›¾ç±»å°ä½œæ–‡çš„èŒƒæ–‡ä¸¾ä¾‹ åŸºæœ¬ä¿¡æ¯è¯†åˆ« æ”¹å†™æ®µçš„å†™ä½œ ç¬¬ä¸€ä¸ªDetailç»†èŠ‚æ®µçš„å†™ä½œ æ³¨æ„æ—¶æ€ ç¬¬äºŒä¸ªDetailç»†èŠ‚æ®µçš„å†™ä½œ Overviewæ¦‚è¿°æ®µçš„å†™ä½œ å¤§ä½œæ–‡ å¤§ä½œæ–‡é¢˜å‹åˆ†ç±» å¤§ä½œæ–‡è¯é¢˜åˆ†ç±» å¤§ä½œæ–‡æŒ‡ä»¤åˆ†ç±» å¤§ä½œæ–‡æŒ‡ä»¤å¯¹åº”çš„æ–‡ä½“é£æ ¼ ä¸¤ç§æ˜“æ··çš„å¤§ä½œæ–‡æŒ‡ä»¤ç±»å‹ å¤§ä½œæ–‡è¯„åˆ†æ ‡å‡†-Task Response ä¿è¯è¡Œæ–‡ç»“æ„çš„å®Œæ•´å’Œæ­£ç¡® å›åº”ä¸åŒé¢˜å‹çš„ç‰¹å®šè¦æ±‚ å±•å¼€å……åˆ† å……è¶³çš„å­—æ•° å¤§ä½œæ–‡è¯„åˆ†æ ‡å‡†-Coherence and Cohesion Coherence and Cohesion é«˜åˆ†è¦æ±‚ é€’è¿›å…³ç³»è¿æ¥è¯ å› æœå…³ç³»è¿æ¥è¯ æŒ‡ä»£å…³ç³»è¿æ¥è¯ è½¬æŠ˜ã€è®©æ­¥å…³ç³»è¿æ¥è¯ è½¬æŠ˜ï¼šçŸ›ç›¾çŠ¶æ€çš„å¯¹ç«‹ è®©æ­¥ï¼šå·®å¼‚çŠ¶æ€çš„ä¸»æ¬¡ ç±»æ¯”å…³ç³»è¿æ¥è¯ æ¡ä»¶å…³ç³»è¿æ¥è¯ æ€»ç»“å…³ç³»è¿æ¥è¯ å¤§ä½œæ–‡è¯„åˆ†æ ‡å‡†-Lexical Resources Lexical Resources é«˜åˆ†è¦æ±‚ å¤§ä½œæ–‡è¯„åˆ†æ ‡å‡†-Grammatical Range and Accuracy å¥å‹çš„çµæ´»æ€§åŠå‡†ç¡®æ€§ Error Free ä»æ— åˆ°æœ‰æ„å»ºå¤§ä½œæ–‡çš„äº”ä¸ªæ­¥éª¤ è¯»é¢˜å®¡é¢˜ æ„å»ºæ€»è®ºç‚¹åŠåˆ†è®ºç‚¹ å¼€å¤´æ®µ å±•å¼€æ®µ ç»“å°¾æ®µ å¤§ä½œæ–‡å®¡é¢˜æ–¹æ³•åŠæ³¨æ„äº‹é¡¹ å¤§ä½œæ–‡è¯é¢˜å®¡é¢˜çš„æ³¨æ„äº‹é¡¹ å¤§ä½œæ–‡è¯é¢˜çš„é‡å¿ƒ Argumentç±»å‹å¤§ä½œæ–‡æ€»è§‚ç‚¹çš„4ç§æ¨¡å¼ ä¸€è¾¹å€’æ€åº¦ è®©æ­¥å‹ä¸­ç«‹æ€åº¦ å¯¹ç«‹å‹ä¸­ç«‹æ€åº¦ å…±å­˜å‹ä¸­ç«‹æ€åº¦ å¤§ä½œæ–‡å±•å¼€æ®µ1+2+1æˆ–1+3+1çš„æ¨¡å¼é€‰æ‹© å¤§ä½œæ–‡å±•å¼€æ®µå†…éƒ¨çš„å†…å®¹ç»„æˆ 1+2+1æˆ–1+3+1çš„æ¨¡å¼é€‰æ‹© è§‚ç‚¹å‹/å¥½åå‹å¤§ä½œæ–‡åˆ†è®ºç‚¹çš„æ„å»ºæ–¹å¼ è§‚ç‚¹å‹å¤§ä½œæ–‡åˆ†è®ºç‚¹çš„æ„å»ºåŸºç¡€ åŒºåˆ†ä¸»å®¢ä½“ï¼Ÿ éƒ½å¯ä»¥ï¼ 3Cåˆ†è§£æ³• ç»§ç»­åˆ†è§£ è§‚ç‚¹å‹å¤§ä½œæ–‡åˆ†è®ºç‚¹åŠæ€»è®ºç‚¹çš„ç»„åˆæ¨¡å¼ è§‚ç‚¹å‹å¤§ä½œæ–‡åˆ†è®ºç‚¹åŠæ€»è®ºç‚¹çš„è§†è§’ å¥½åå‹å¤§ä½œæ–‡åˆ†è®ºç‚¹çš„æ„å»ºæ–¹å¼ åŸºæœ¬å’Œè§‚ç‚¹å‹å¤§ä½œæ–‡ä¸€æ · è§‚ç‚¹å‹/å¥½åå‹å¤§ä½œæ–‡ä¸­ç«‹å‹æ€åº¦æ³¨æ„äº‹é¡¹ è®©æ­¥å‹ä¸­ç«‹æ€åº¦çš„å†™ä½œæ³¨æ„äº‹é¡¹ å¯¹ç«‹å‹ä¸­ç«‹æ€åº¦çš„å†™ä½œæ³¨æ„äº‹é¡¹ å…±å­˜å‹ä¸­ç«‹æ€åº¦çš„å†™ä½œæ³¨æ„äº‹é¡¹ å«æœ‰ç‰¹æ®Šå…³é”®è¯çš„è§‚ç‚¹å‹/å¥½åå‹å¤§ä½œæ–‡åˆ†è®ºç‚¹çš„æ„å»ºæ–¹å¼ å«æœ‰å¹¶åˆ—ã€æ¯”è¾ƒã€å¯¹æ¯”å…³ç³»é¢˜ç›®çš„ç ´é¢˜ å«æœ‰å› æœå…³ç³»é¢˜ç›®çš„ç ´é¢˜ å«æœ‰ç¨‹åº¦å…³é”®è¯é¢˜ç›®çš„ç ´é¢˜ è®¨è®ºå‹å¤§ä½œæ–‡åˆ†è®ºç‚¹çš„æ„å»ºæ–¹å¼ è®¨è®ºå‹å¤§ä½œæ–‡åˆ†è®ºç‚¹çš„åˆ†é… Discuss both views éƒ¨åˆ†çš„åˆ†è®ºç‚¹çš„æ„å»º ä»¥ç»“è®ºæ–¹å¼ç»™å‡ºæˆ‘çš„çœ‹æ³• ä»¥å»¶ä¼¸æ–¹å¼ç»™å‡ºæˆ‘çš„çœ‹æ³• æ–¹æ³•1 æ–¹æ³•2 æ€»è§‚ç‚¹ä»¥åŠåˆ†è®ºç‚¹çš„è§†è§’ æ¯”è¾ƒå‹å¤§ä½œæ–‡åˆ†è®ºç‚¹çš„æ„å»ºæ–¹å¼ æŠ¥å‘Šå‹/æ··æ­å‹å¤§ä½œæ–‡åˆ†è®ºç‚¹çš„æ„å»ºæ–¹å¼ æŠ¥å‘Šå‹ æ··æ­å‹ å¤§ä½œæ–‡å¼€å¤´æ®µåŠç»“å°¾æ®µçš„å†™ä½œ Argumentç±»å¼€å¤´æ®µ Reportç±»å¼€å¤´æ®µ ç»“å°¾æ®µ å¤§ä½œæ–‡å±•å¼€æ®µçš„å†™ä½œ å…ƒç´ 1 è®ºè¿° å…ƒç´ 2 ä¾‹å­ å…ƒç´ 3 ç»†èŠ‚ å±•å¼€æ®µå†…å®¹ç»„æˆ å¤§ä½œæ–‡ä¸­ä¾‹å­å’Œç»†èŠ‚çš„è¿›ä¸€æ­¥è¯´æ˜ å¤§ä½œæ–‡åˆæ ¼çš„ä¾‹å­çš„é£æ ¼ç‰¹ç‚¹ å¤§ä½œæ–‡ä¾‹å­çš„å†™ä½œæ‰‹æ³• ä¾‹å­å’Œç»†èŠ‚ä¸è®ºè¯é“¾æ¡çš„ä½ç½®å…³ç³» ä»æ— åˆ°æœ‰æ„å»ºä¸€ç¯‡å®Œæ•´çš„è§‚ç‚¹å‹å¤§ä½œæ–‡ ä¸¾ä¾‹ æŠŠè®ºè¯è¦ç‚¹å†™é•¿çš„æ–¹æ³•å’Œæ³¨æ„äº‹é¡¹ æ„å»ºå¥å­çš„åŸºæœ¬åŸåˆ™ æŠŠè®ºè¯é“¾æ¡å†™é•¿çš„æœ€åŸºæœ¬é€»è¾‘ æŠŠè®ºè¯é“¾æ¡å†™é•¿çš„é”¦ä¸Šæ·»èŠ±çš„é€»è¾‘ ","permalink":"https://bleedkagax.github.io/post/writing-skills/","summary":"\u003ch1 id=\"1-å°ä½œæ–‡\"\u003e1. å°ä½œæ–‡\u003c/h1\u003e\n\u003cp\u003eå¯¹æ‰€çœ‹åˆ°çš„æ•°æ®ã€ä¿¡æ¯è¿›è¡Œå®¢è§‚ã€å‡†ç¡®ã€å…¨é¢çš„æè¿°ã€‚\u003c/p\u003e\n\u003ch2 id=\"11-å°ä½œæ–‡å›¾è¡¨åˆ†ç±»\"\u003e1.1. å°ä½œæ–‡å›¾è¡¨åˆ†ç±»\u003c/h2\u003e\n\u003cp\u003eLine graph\nBar chart\nPie chart\nTable\u003c/p\u003e\n\u003ch2 id=\"12-å›¾è¡¨ç±»å°ä½œæ–‡ä¸­çš„å›¾è¡¨ç‰¹å¾\"\u003e1.2. å›¾è¡¨ç±»å°ä½œæ–‡ä¸­çš„å›¾è¡¨ç‰¹å¾\u003c/h2\u003e\n\u003cp\u003eé™æ€å›¾ æ—¶é—´ç‚¹å°äºç­‰äº1 difference\nåŠ¨æ€å›¾ æ—¶é—´ç‚¹å¤§äº2 change\u003c/p\u003e\n\u003ch3 id=\"æ•°æ®\"\u003eæ•°æ®\u003c/h3\u003e\n\u003cp\u003eæœ€å¤§å€¼ æœ€å°å€¼ ç­‰å€¼ å·®å€¼ å€æ•° å¤§äº å°äº\u003c/p\u003e\n\u003ch3 id=\"è¶‹åŠ¿åŠ¨æ€å›¾ä½¿ç”¨\"\u003eè¶‹åŠ¿ï¼ŒåŠ¨æ€å›¾ä½¿ç”¨\u003c/h3\u003e\n\u003cp\u003eä¸Šå‡ ä¸‹é™ æ³¢åŠ¨ ä¸å˜\u003c/p\u003e\n\u003ch3 id=\"ç¨‹åº¦å¤§å°\"\u003eç¨‹åº¦å¤§å°\u003c/h3\u003e\n\u003cp\u003eå‰§çƒˆ å¹³ç¼“\u003c/p\u003e\n\u003ch2 id=\"13-å›¾è¡¨ç±»å°ä½œæ–‡çš„æ®µè½ç»„æˆ\"\u003e1.3. å›¾è¡¨ç±»å°ä½œæ–‡çš„æ®µè½ç»„æˆ\u003c/h2\u003e\n\u003ch3 id=\"æ”¹å†™æ®µ\"\u003eæ”¹å†™æ®µ\u003c/h3\u003e\n\u003cp\u003eå¤è¿°å›¾è¡¨ä»‹ç»\u003c/p\u003e\n\u003ch3 id=\"æ¦‚è¿°æ®µ\"\u003eæ¦‚è¿°æ®µ\u003c/h3\u003e\n\u003cp\u003eå®è§‚æ¦‚è¿°\n2ï½3å¥è¯\nå¸¸è§ï¼š2ï½3ä¸ªè¦ç‚¹\nå°‘æ•°ï¼š1ä¸ªè¦ç‚¹\u003c/p\u003e\n\u003ch3 id=\"ç»†èŠ‚æ®µ\"\u003eç»†èŠ‚æ®µ\u003c/h3\u003e\n\u003cp\u003eæè¿°é‡è¦ç»†èŠ‚\n4ï½5å¥è¯\u003c/p\u003e\n\u003ch3 id=\"ç»†èŠ‚æ®µ-1\"\u003eç»†èŠ‚æ®µ\u003c/h3\u003e\n\u003cp\u003eæè¿°é‡è¦ç»†èŠ‚\n4ï½5å¥è¯\u003c/p\u003e","title":"writing skills"},{"content":"ã€å›¾è¡¨ç±»å°ä½œæ–‡è¡¥å……è¡¨è¾¾ã€‘ ã€è¡¨è¾¾ï¼šç¨‹åº¦ã€‘ ç¨‹åº¦ é€æ¸çš„ slightly modestly gradually\nç¨³å®šçš„ steadily sustained\næ˜¾è‘—çš„ noticeably remarkably markedly\nå·¨å¤§çš„ significantly remarkably dramatically rapidly sharply\nå¤§é‡çš„/å°‘é‡çš„ a great/signifcant/major proportion (of\u0026hellip;) (only) a fraction (of\u0026hellip;)\næœ€å¤§é‡/å°‘é‡ greatest/most significant proportion (of\u0026hellip;) smallest/least significant proportion (of\u0026hellip;)\nä»¥ä¸åŒçš„ç¨‹åº¦ to different/varying degrees\nã€è¡¨è¾¾ï¼šåˆ†åˆ«çš„ã€‘ åˆ†åˆ«çš„ respectively each\nã€è¡¨è¾¾ï¼šå¹´é¾„ã€‘ year old years old people of 18-24 years old\nyear old 18-24 year old people\naged people aged 18-24\nyear olds 18-24 year olds\nrange within the age range of 18-24\néšç€å¹´çºªçš„å¢é•¿ Figure A declined with (increasing) age. Figure A increased as age increases.\nã€è¡¨è¾¾ï¼šæ’åã€‘ ç¬¬ä¸€ç¬¬äºŒ ranked the first place highest\nå€’æ•°ç¬¬ä¸€ç¬¬äºŒ second/third-least\nâ€œæœ€â€ éœ€è¦ç»“åˆè¯­å¢ƒæ¥å†™å‡ºâ€œæœ€â€çš„å†…å®¹ï¼š Choice A was the most popular\u0026hellip; Choice A was the most energy-efficient\u0026hellip;\nâ€æœ€â€œä¹‹ä¸€ one of the most/least\u0026hellip;\nã€è¡¨è¾¾ï¼šæ—¶é—´ã€‘ once/twice once a day daily everyday on a daily basis once daily\ntwice a day twice daily\nonce a month monthly once per month on a monthly basis\ntwice a month semi/bi-monthly once every two weeks\nonce a year annually yearly once annually every twelve months\ntwice a year biannually semi-annually every six months/half year twice annually\nonce a daily or more daily or more frequent X at least daily X at a daily rate or higher daily and above\nmore than one multiple several\nyear 2004 2004 The year 2004\n2000å¹´ä»£ The 2000s\nin 2004 during the year 2004 in the year 2004 as of 2004\n1992-1998 during the period of 1992 to 1998 during the 7-year period during the first/initial/beginning/last/final 7-year period during the recorded period from 1992 to 1998 between 1992 and 1998 over the span/course of 1992 to 1998\nby 2004 by the year 2004\nuntil 2004 prior/by/till 2004 before the year 2004\néšç€æ—¶é—´ over/with time\nåœ¨æ—¶é—´æ®µé‡Œ åœ¨æ•´ä¸ªæ—¶é—´é‡Œ throughout the entire period over the entire timeline during the whole duration\nåœ¨ä¸€æ®µæ—¶é—´é‡Œ throughout/during the 10-year period (from\u0026hellip;to\u0026hellip;)\nä¸€èˆ¬å°†æ¥æ—¶ is expected/projected to\u0026hellip; will\u0026hellip; is likely to be\u0026hellip;\nã€è¡¨è¾¾ï¼šå›¾ä¸­æ‰€ç¤ºã€‘ å›¾ä¸­æ‰€ç¤º labelled \u0026ldquo;X\u0026rdquo; on the graph/diagram\nã€è¡¨è¾¾ï¼šæ— è¡¨ä¹‰çš„å¼•å¯¼è¯ã€‘ æ— è¡¨ä¹‰çš„å¼•å¯¼è¯ é€šå¸¸ä½äºæ®µè½å¼€å¤´ï¼Œè¿æ¥ç‰¹å¾æ˜æ˜¾çš„æ•°æ®ï¼š It is clear/noticeable that We can see that\nã€è¡¨è¾¾ï¼šç»„åˆ«ã€‘ ç»„åˆ« (among) group of X (among) X group\nåœ¨ä¸åŒç»„åˆ«ä¹‹é—´ across different groups\n","permalink":"https://bleedkagax.github.io/post/chart-essay/","summary":"\u003ch1 id=\"å›¾è¡¨ç±»å°ä½œæ–‡è¡¥å……è¡¨è¾¾\"\u003e\u003cstrong\u003eã€å›¾è¡¨ç±»å°ä½œæ–‡è¡¥å……è¡¨è¾¾ã€‘\u003c/strong\u003e\u003c/h1\u003e\n\u003ch1 id=\"è¡¨è¾¾ç¨‹åº¦\"\u003e\u003cstrong\u003eã€è¡¨è¾¾ï¼šç¨‹åº¦ã€‘\u003c/strong\u003e\u003c/h1\u003e\n\u003ch2 id=\"ç¨‹åº¦\"\u003e\u003cstrong\u003eç¨‹åº¦\u003c/strong\u003e\u003c/h2\u003e\n\u003ch3 id=\"é€æ¸çš„\"\u003e\u003cstrong\u003eé€æ¸çš„\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eslightly\nmodestly\ngradually\u003c/p\u003e\n\u003ch3 id=\"ç¨³å®šçš„\"\u003e\u003cstrong\u003eç¨³å®šçš„\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003esteadily\nsustained\u003c/p\u003e\n\u003ch3 id=\"æ˜¾è‘—çš„\"\u003e\u003cstrong\u003eæ˜¾è‘—çš„\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003enoticeably\nremarkably\nmarkedly\u003c/p\u003e\n\u003ch3 id=\"å·¨å¤§çš„\"\u003e\u003cstrong\u003eå·¨å¤§çš„\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003esignificantly\nremarkably\ndramatically\nrapidly\nsharply\u003c/p\u003e\n\u003ch2 id=\"å¤§é‡çš„å°‘é‡çš„\"\u003e\u003cstrong\u003eå¤§é‡çš„/å°‘é‡çš„\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003ea great/signifcant/major proportion (of\u0026hellip;)\n(only) a fraction (of\u0026hellip;)\u003c/p\u003e\n\u003ch2 id=\"æœ€å¤§é‡å°‘é‡\"\u003e\u003cstrong\u003eæœ€å¤§é‡/å°‘é‡\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003egreatest/most significant proportion (of\u0026hellip;)\nsmallest/least significant proportion (of\u0026hellip;)\u003c/p\u003e\n\u003ch2 id=\"ä»¥ä¸åŒçš„ç¨‹åº¦\"\u003e\u003cstrong\u003eä»¥ä¸åŒçš„ç¨‹åº¦\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eto different/varying degrees\u003c/p\u003e\n\u003ch1 id=\"è¡¨è¾¾åˆ†åˆ«çš„\"\u003e\u003cstrong\u003eã€è¡¨è¾¾ï¼šåˆ†åˆ«çš„ã€‘\u003c/strong\u003e\u003c/h1\u003e\n\u003ch2 id=\"åˆ†åˆ«çš„\"\u003e\u003cstrong\u003eåˆ†åˆ«çš„\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003erespectively\neach\u003c/p\u003e\n\u003ch1 id=\"è¡¨è¾¾å¹´é¾„\"\u003e\u003cstrong\u003eã€è¡¨è¾¾ï¼šå¹´é¾„ã€‘\u003c/strong\u003e\u003c/h1\u003e\n\u003ch2 id=\"year-old\"\u003e\u003cstrong\u003eyear old\u003c/strong\u003e\u003c/h2\u003e\n\u003ch3 id=\"years-old\"\u003e\u003cstrong\u003eyears old\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003epeople of 18-24 years old\u003c/p\u003e","title":"chart essay"},{"content":"Stretching pectoralis major and pectoralis minor Stretching the anterior shoulder girdle External rotation with internal rotation of the shoulder joint Internal rotation with external rotation of the shoulder joint Assisted Humeral Push-Up and Lateral Raise\n","permalink":"https://bleedkagax.github.io/post/correction-of-anterior-humerus/","summary":"\u003cp\u003eStretching pectoralis major and pectoralis minor\nStretching the anterior shoulder girdle\nExternal rotation with internal rotation of the shoulder joint\nInternal rotation with external rotation of the shoulder joint\nAssisted Humeral Push-Up and Lateral Raise\u003c/p\u003e","title":"correction of anterior humerus"},{"content":"ä¸€ã€é¢å‘å¯¹è±¡ ç¨‹åºè®¾è®¡ ç®€ä»‹ å¯¹è±¡ä¹‹é—´çš„å…³ç³»\nä¾èµ–:å¯¹ç±» B è¿›è¡Œä¿®æ”¹ä¼šå½±å“åˆ°ç±» A ã€‚\nå…³è”:å¯¹è±¡ A çŸ¥é“å¯¹è±¡ Bã€‚ç±» A ä¾èµ–äºç±» Bã€‚\nèšåˆ:å¯¹è±¡AçŸ¥é“å¯¹è±¡Bä¸”ç”±Bæ„æˆã€‚ç±»Aä¾èµ–äºç±»Bã€‚\nç»„åˆ:å¯¹è±¡ A çŸ¥é“å¯¹è±¡ Bã€ç”± B æ„æˆè€Œä¸”ç®¡ç†ç€ B çš„ç”Ÿå‘½å‘¨ æœŸã€‚ç±» A ä¾èµ–äºç±» Bã€‚\nå®ç°: ç±» A å®šä¹‰çš„æ–¹æ³•ç”±æ¥å£ B å£°æ˜ã€‚ å¯¹è±¡ A å¯è¢«è§†ä¸ºå¯¹è±¡ Bã€‚ç±» A ä¾èµ–äºç±» Bã€‚\nç»§æ‰¿: ç±» A ç»§æ‰¿ç±» B çš„æ¥å£å’Œå®ç°ï¼Œ ä½†æ˜¯å¯ä»¥å¯¹å…¶è¿›è¡Œæ‰© å±•ã€‚å¯¹è±¡ A å¯è¢«è§†ä¸ºå¯¹è±¡ Bã€‚ç±» A ä¾èµ–äºç±» Bã€‚\näºŒã€è®¾è®¡æ¨¡å¼ç®€ä»‹ è®¾è®¡æ¨¡å¼æ˜¯é’ˆå¯¹è½¯ä»¶è®¾è®¡ä¸­å¸¸è§é—®é¢˜çš„å·¥å…·ç®±ï¼Œ å…¶ä¸­çš„å·¥å…· å°±æ˜¯å„ç§ç»è¿‡å®è·µéªŒè¯çš„è§£å†³æ–¹æ¡ˆã€‚\nåˆ›å»ºå‹æ¨¡å¼æä¾›åˆ›å»ºå¯¹è±¡çš„æœºåˆ¶ï¼Œ å¢åŠ å·²æœ‰ä»£ç çš„çµæ´»æ€§å’Œå¯å¤ç”¨æ€§ã€‚\nç»“æ„å‹æ¨¡å¼ä»‹ç»å¦‚ä½•å°†å¯¹è±¡å’Œç±»ç»„è£…æˆè¾ƒå¤§çš„ç»“æ„ï¼Œ å¹¶åŒæ—¶ä¿æŒç»“æ„çš„çµæ´»å’Œé«˜æ•ˆã€‚\nè¡Œä¸ºæ¨¡å¼è´Ÿè´£å¯¹è±¡é—´çš„é«˜æ•ˆæ²Ÿé€šå’ŒèŒè´£å§”æ´¾ã€‚\nä¸‰ã€è½¯ä»¶è®¾è®¡åŸåˆ™ ä¼˜ç§€è®¾è®¡çš„ç‰¹å¾\nä»£ç å¤ç”¨\nä»£ç å¤ç”¨æ˜¯å‡å°‘å¼€å‘æˆæœ¬æ—¶æœ€å¸¸ç”¨çš„æ–¹å¼ä¹‹ä¸€ã€‚\nå¤ç”¨çš„ä¸‰ä¸ªå±‚æ¬¡ï¼š\nåœ¨æœ€åº•å±‚ï¼Œ å¤ç”¨ç±»: ç±»åº“ã€å®¹å™¨ç­‰ï¼›\næ¡†æ¶ä½äºæœ€é«˜å±‚ï¼›\nè¿˜æœ‰ä¸€ä¸ªä¸­é—´å±‚æ¬¡ï¼šè®¾è®¡æ¨¡å¼ï¼Œæ¯”æ¡†æ¶æ›´å°ä¸”æ›´æŠ½è±¡ã€‚\nä¸­é—´å±‚æ¬¡çš„ä¼˜ç‚¹ï¼šè®¾è®¡æ¨¡å¼æ¯”æ¡†æ¶çš„é£é™©å°ï¼Œèƒ½ç‹¬ç«‹äºå…·ä½“ä»£ç å¤ç”¨è®¾è®¡æ€æƒ³å’Œç†å¿µã€‚\næ‰©å±•æ€§\nå˜åŒ–æ˜¯ç¨‹åºå‘˜ç”Ÿå‘½ä¸­å”¯ä¸€ä¸å˜çš„äº‹æƒ…ã€‚\nåœ¨è®¾è®¡ç¨‹åºæ¶æ„æ—¶ï¼Œ æ‰€æœ‰æœ‰ç»éªŒçš„å¼€å‘è€…ä¼šå°½é‡é€‰æ‹©æ”¯æŒæœªæ¥ä»»ä½•å¯èƒ½å˜æ›´çš„æ–¹å¼ã€‚\nè®¾è®¡åŸåˆ™\nå°è£…å˜åŒ–çš„å†…å®¹\næ‰¾åˆ°ç¨‹åºä¸­çš„å˜åŒ–å†…å®¹å¹¶å°†å…¶ä¸ä¸å˜çš„å†…å®¹åŒºåˆ†å¼€ï¼Œå°†å˜æ›´é€ æˆçš„å½±å“æœ€å°åŒ–ã€‚\næ–¹æ³•å±‚é¢çš„å°è£…\nä¿®æ”¹å‰ç¨ç‡è®¡ç®—ä»£ç å’Œæ–¹æ³•çš„å…¶ä»–ä»£ç æ··æ‚åœ¨ä¸€èµ·ã€‚\nä¿®æ”¹åä½ å¯é€šè¿‡è°ƒç”¨æŒ‡å®šæ–¹æ³•è·å–ç¨ç‡ã€‚\nç±»å±‚é¢çš„å°è£…\n**ä¿®æ”¹å‰:**åœ¨ è®¢å• Order ç±»ä¸­è®¡ç®—ç¨é‡‘ã€‚\n**ä¿®æ”¹å:**å¯¹è®¢å•ç±»éšè—ç¨é‡‘è®¡ç®—ã€‚\nå››ã€é¢å‘æ¥å£è¿›è¡Œå¼€å‘ï¼Œè€Œä¸æ˜¯é¢å‘å®ç° é¢å‘æ¥å£è¿›è¡Œå¼€å‘ï¼Œè€Œä¸æ˜¯é¢å‘å®ç°; ä¾èµ–äºæŠ½è±¡ç±» å‹ï¼Œ è€Œä¸æ˜¯å…·ä½“ç±»ã€‚\nEg1\næŠ½å–æ¥å£å‰åçš„å¯¹æ¯”ï¼šå³ä¾§çš„ä»£ç è¦æ¯”å·¦ä¾§æ›´åŠ çµæ´»ï¼Œ ä½†ä¹Ÿ æ›´åŠ å¤æ‚ã€‚\nEg2\né€šè¿‡æ¥å£ä¸å¯¹è±¡äº¤äº’è¦æ¯” ä¾èµ–äºå…¶å…·ä½“ç±»çš„å¥½å¤„æ›´å¤šã€‚\n**ä¿®æ”¹å‰:**æ‰€æœ‰ç±»éƒ½ç´§å¯†è€¦åˆã€‚\n**ä¼˜åŒ–:**å¤šæ€æœºåˆ¶èƒ½å¸®åŠ©æˆ‘ä»¬ç®€åŒ–ä»£ç ï¼Œä½†å…¬å¸ç±»çš„å…¶ä»–éƒ¨åˆ†ä»ç„¶ä¾èµ–äºå…·ä½“çš„é›‡å‘˜ç±»ã€‚\n**ä¿®æ”¹å:**å…¬å¸ç±»çš„ä¸»è¦æ–¹æ³•ç‹¬ç«‹äºå…·ä½“çš„é›‡å‘˜ç±»ã€‚é›‡å‘˜å¯¹è±¡å°†åœ¨å…·ä½“å…¬å¸å­ç±»ä¸­åˆ›å»ºã€‚\nè¿™å°±æ˜¯å·¥å‚æ–¹æ³•æ¨¡å¼çš„ä¸€ä¸ªç¤ºä¾‹ã€‚\nç»„åˆä¼˜äºç»§æ‰¿\nç»§æ‰¿å¸¦æ¥çš„é—®é¢˜ï¼š\nå­ç±»ä¸èƒ½å‡å°‘è¶…ç±»çš„æ¥å£\nåœ¨é‡å†™æ–¹æ³•æ—¶ï¼Œ ä½ éœ€è¦ç¡®ä¿æ–°è¡Œä¸ºä¸å…¶åŸºç±»ä¸­çš„ç‰ˆæœ¬å…¼å®¹ã€‚\nç»§æ‰¿æ‰“ç ´äº†è¶…ç±»çš„å°è£…\nå­ç±»ä¸è¶…ç±»ç´§å¯†è€¦åˆ\n**é€šè¿‡ç»§æ‰¿å¤ç”¨ä»£ç å¯èƒ½å¯¼è‡´å¹³è¡Œç»§æ‰¿ä½“ç³»çš„äº§ç”Ÿã€‚**ç»§æ‰¿é€šå¸¸ä»…å‘ç”Ÿåœ¨ä¸€ä¸ªç»´åº¦ä¸­ã€‚åªè¦å‡ºç°äº†ä¸¤ä¸ªä»¥ä¸Šçš„ç»´åº¦ï¼Œ ä½ å°±å¿…é¡»åˆ›å»ºæ•°é‡å·¨å¤§çš„ç±»ç»„åˆï¼Œ ä»è€Œä½¿ç±»å±‚æ¬¡ç»“æ„è†¨èƒ€åˆ°ä¸å¯æ€è®®çš„ç¨‹åº¦ã€‚\nç»„åˆæ˜¯ä»£æ›¿ç»§æ‰¿çš„ä¸€ç§æ–¹æ³•ï¼Œè¿™ä¸ªåŸåˆ™ä¹Ÿèƒ½åº”ç”¨äºèšåˆã€‚\n**ç»§æ‰¿:**åœ¨å¤šä¸ªç»´åº¦ä¸Šæ‰©å±•ä¸€ä¸ªç±»(æ±½è½¦ç±»å‹ Ã— å¼•æ“ç±»å‹ Ã— é©¾é©¶ç±»å‹)å¯èƒ½ä¼šå¯¼è‡´å­ç±»ç»„åˆçš„æ•°é‡çˆ†ç‚¸ã€‚\n**ç»„åˆ:**å°†ä¸åŒ\u0026quot;ç»´åº¦\u0026quot;çš„åŠŸèƒ½æŠ½å–åˆ°å„è‡ªçš„ç±»å±‚æ¬¡ç»“æ„ä¸­ã€‚\nä¸Šè¿°ç±»çš„ç»“æ„ç±»ä¼¼äºç­–ç•¥æ¨¡å¼ã€‚\näº”ã€SOLID åŸåˆ™ å•ä¸€èŒè´£åŸåˆ™\nSingle Responsibility Principle\nä¿®æ”¹ä¸€ä¸ªç±»çš„åŸå› åªèƒ½æœ‰ä¸€ä¸ªã€‚\n**ä¿®æ”¹å‰:**ç±»ä¸­åŒ…å«å¤šä¸ªä¸åŒçš„è¡Œä¸ºã€‚\n**ä¿®æ”¹å:**é¢å¤–è¡Œä¸ºæœ‰äº†å®ƒä»¬è‡ªå·±çš„ç±»ã€‚\nå¼€é—­åŸåˆ™\nOpen/closed Principle\nå¯¹äºæ‰©å±•ï¼Œç±»åº”è¯¥æ˜¯\u0026quot;å¼€æ”¾\u0026quot;çš„ï¼›å¯¹äºä¿®æ”¹ï¼Œç±»åˆ™åº”æ˜¯\u0026quot;å°é—­\u0026quot;çš„ã€‚\næœ¬åŸåˆ™çš„ä¸»è¦ç†å¿µæ˜¯åœ¨å®ç°æ–°åŠŸèƒ½æ—¶èƒ½ä¿æŒå·²æœ‰ä»£ç ä¸å˜ã€‚\nå¦‚æœä¸€ä¸ªç±»å·²ç»å®Œæˆå¼€å‘ã€æµ‹è¯•å’Œå®¡æ ¸å·¥ä½œï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨çš„è¯ï¼Œé‚£ä¹ˆä¿®æ”¹æ˜¯æœ‰é£é™©çš„ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ªå­ç±»å¹¶é‡å†™åŸå§‹ç±»çš„éƒ¨åˆ† å†…å®¹ä»¥å®Œæˆä¸åŒçš„è¡Œä¸ºã€‚\nå¦‚æœè¿™ä¸ªç±»æ˜¯æœ‰ç¼ºé™·çš„ï¼Œç›´æ¥å¯¹å…¶è¿›è¡Œä¿®å¤å³å¯ï¼Œä¸è¦ä¸ºå®ƒåˆ›å»ºå­ç±»ã€‚ å­ç±»ä¸åº”è¯¥å¯¹å…¶çˆ¶ç±»çš„é—®é¢˜è´Ÿè´£ã€‚\n**ä¿®æ”¹å‰:**åœ¨ç¨‹åºä¸­æ·»åŠ æ–°çš„è¿è¾“æ–¹å¼æ—¶ï¼Œä½ å¿…é¡»å¯¹è®¢å•ç±»è¿›è¡Œä¿®æ”¹ã€‚\nä½¿ç”¨ç­–ç•¥æ¨¡å¼ï¼š\n**ä¿®æ”¹å:**æ·»åŠ æ–°çš„è¿è¾“æ–¹å¼ä¸éœ€è¦ä¿®æ”¹å·²æœ‰çš„ç±»ã€‚\né‡Œæ°æ›¿æ¢åŸåˆ™\nLiskov Substitution Principle\nå½“ä½ æ‰©å±•ä¸€ä¸ªç±»æ—¶ï¼Œ è®°ä½ä½ åº”è¯¥è¦èƒ½åœ¨ä¸ä¿®æ”¹å®¢æˆ·ç«¯ä»£ç çš„æƒ…å†µä¸‹å°†å­ç±»çš„å¯¹è±¡ä½œä¸ºçˆ¶ç±»å¯¹è±¡è¿›è¡Œä¼ é€’ã€‚\nè¿™æ„å‘³ç€å­ç±»å¿…é¡»ä¿æŒä¸çˆ¶ç±»è¡Œä¸ºçš„å…¼å®¹ã€‚ åœ¨é‡å†™ä¸€ä¸ªæ–¹æ³•æ—¶ï¼Œ ä½ è¦å¯¹åŸºç±»è¡Œä¸ºè¿›è¡Œæ‰©å±•ï¼Œ è€Œä¸æ˜¯å°†å…¶å®Œå…¨æ›¿æ¢ã€‚\næ›¿ä»£åŸåˆ™åŒ…å«ä¸€ ç»„å¯¹å­ç±»(ç‰¹åˆ«æ˜¯å…¶æ–¹æ³•)çš„å½¢å¼è¦æ±‚\n1. å­ç±»æ–¹æ³•çš„å‚æ•°ç±»å‹å¿…é¡»ä¸å…¶è¶…ç±»çš„å‚æ•°ç±»å‹ç›¸åŒ¹é…æˆ–æ›´åŠ æŠ½è±¡ã€‚\nå‡è®¾æŸä¸ªç±»æœ‰ä¸ªæ–¹æ³•ç”¨äºç»™çŒ«å’ªå–‚é£Ÿ: feed(Cat c) ã€‚ å®¢æˆ·ç«¯ä»£ç æ€»æ˜¯ä¼šå°†\u0026quot;çŒ«(cat)\u0026quot; å¯¹è±¡ä¼ é€’ç»™è¯¥æ–¹æ³•ã€‚\nå¥½çš„æ–¹å¼\nåˆ›å»ºäº†ä¸€ä¸ªå­ç±»å¹¶é‡å†™äº†å‰é¢çš„æ–¹æ³•ï¼Œä½¿å…¶èƒ½å¤Ÿç»™ä»»ä½•\u0026quot;åŠ¨ç‰©(animalï¼Œå³\u0026rsquo;çŒ«\u0026rsquo;çš„è¶…ç±»)\u0026ldquo;å–‚é£Ÿ: feed(Animal c) ã€‚å°†ä¸€ä¸ªå­ç±»å¯¹è±¡è€Œéè¶…ç±»å¯¹è±¡ä¼ é€’ç»™å®¢æˆ·ç«¯ä»£ç ï¼Œç¨‹åºä»å°†æ­£å¸¸å·¥ä½œã€‚\nä¸å¥½çš„æ–¹å¼\nåˆ›å»ºäº†å¦ä¸€ä¸ªå­ç±»ä¸”é™åˆ¶å–‚é£Ÿæ–¹æ³•ä»…æ¥å— \u0026ldquo;å­ŸåŠ æ‹‰çŒ« (BengalCatï¼Œ ä¸€ä¸ª \u0026lsquo;çŒ«\u0026rsquo; çš„å­ç±»)\u0026quot;:feed(BengalCat c) ã€‚æ— æ³•ä¸ºä¼ é€’ç»™å®¢æˆ·ç«¯çš„æ™®é€šçŒ«æä¾›æœåŠ¡ï¼Œä»è€Œå°†ç ´åæ‰€æœ‰ç›¸å…³çš„åŠŸèƒ½ã€‚\n2. å­ç±»æ–¹æ³•çš„è¿”å›å€¼ç±»å‹å¿…é¡»ä¸è¶…ç±»æ–¹æ³•çš„è¿”å›å€¼ç±»å‹æˆ–æ˜¯å…¶å­ç±»åˆ«ç›¸åŒ¹é…ã€‚\nå¯¹äºè¿”å›å€¼ç±»å‹çš„è¦æ±‚ä¸å¯¹äºå‚æ•°ç±»å‹çš„è¦æ±‚ç›¸åã€‚\nå‡å¦‚ä½ çš„ä¸€ä¸ªç±»ä¸­æœ‰ä¸€ä¸ªæ–¹æ³• buyCat(): Cat ã€‚ å®¢æˆ·ç«¯ä»£ç æ‰§è¡Œè¯¥æ–¹æ³•åçš„é¢„æœŸè¿”å›ç»“æœæ˜¯ä»»æ„ç±»å‹çš„\u0026quot;çŒ«\u0026rdquo;ã€‚\nå¥½çš„æ–¹å¼\nå­ç±»å°†è¯¥æ–¹æ³•é‡å†™ä¸º: buyCat(): BengalCat ï¼Œå­ŸåŠ æ‹‰çŒ«æ˜¯çŒ«ï¼Œæ­£å¸¸ã€‚\nä¸å¥½çš„æ–¹å¼\nå­ç±»å°†è¯¥æ–¹æ³•é‡å†™ä¸º: buyCat(): Animal ã€‚ ç°åœ¨å®¢æˆ·ç«¯ä»£ç å°†ä¼šå‡ºé”™ï¼Œ å› ä¸ºå®ƒè·å¾—çš„æ˜¯è‡ªå·±æœªçŸ¥çš„åŠ¨ç‰©ç§ç±»(çŸ­å» é³„ ? ç†Š ?)ï¼Œ ä¸é€‚ç”¨äºä¸ºä¸€åª \u0026quot; çŒ« \u0026quot; è€Œè®¾è®¡çš„ç»“æ„ã€‚\nç¼–ç¨‹è¯­è¨€ä¸–ç•Œä¸­çš„å¦ä¸€ä¸ªåä¾‹æ˜¯åŠ¨æ€ç±»å‹: åŸºç¡€æ–¹æ³•è¿”å›ä¸€ ä¸ªå­—ç¬¦ä¸²ï¼Œ ä½†é‡å†™åçš„æ–¹æ³•åˆ™è¿”å›ä¸€ä¸ªæ•°å­—ã€‚\n3. å­ç±»ä¸­çš„æ–¹æ³•ä¸åº”æŠ›å‡ºåŸºç¡€æ–¹æ³•é¢„æœŸä¹‹å¤–çš„å¼‚å¸¸ç±»å‹ã€‚\nå¼‚å¸¸ç±»å‹å¿…é¡»ä¸åŸºç¡€æ–¹æ³•èƒ½æŠ›å‡ºçš„å¼‚å¸¸æˆ–æ˜¯å…¶å­ç±»åˆ«ç›¸åŒ¹é…ï¼Œé˜²æ­¢é¢„æœŸä¹‹å¤–çš„ä»£ç ç©¿é€å®¢æˆ·ç«¯çš„é˜²å¾¡ä»£ç ã€‚å¯¹äºç»å¤§éƒ¨åˆ†ç°ä»£ç¼–ç¨‹è¯­è¨€ï¼Œ ç‰¹åˆ«æ˜¯é™æ€ç±»å‹çš„ç¼–ç¨‹è¯­è¨€(Java å’Œ C# ç­‰ç­‰)ï¼Œ è¿™äº›è§„åˆ™å·²å†…ç½®äºå…¶ä¸­ã€‚\n4. å­ç±»ä¸åº”è¯¥åŠ å¼ºå…¶å‰ç½®æ¡ä»¶ã€‚\nä¾‹å¦‚ï¼ŒåŸºç±»çš„æ–¹æ³•æœ‰ä¸€ä¸ª int ç±»å‹çš„å‚æ•°ã€‚ å¦‚æœå­ç±»é‡å†™è¯¥æ–¹æ³•æ—¶ï¼Œ è¦æ±‚ä¼ é€’ç»™è¯¥æ–¹æ³•çš„ å‚æ•°å€¼å¿…é¡»ä¸ºæ­£æ•°(å¦‚æœè¯¥å€¼ä¸ºè´Ÿåˆ™æŠ›å‡ºå¼‚å¸¸)ï¼Œ è¿™å°±æ˜¯åŠ å¼ºäº†å‰ç½®æ¡ä»¶ã€‚\n5. å­ç±»ä¸èƒ½å‰Šå¼±å…¶åç½®æ¡ä»¶ã€‚\nå‡å¦‚ä½ çš„æŸä¸ªç±»ä¸­æœ‰ä¸ªæ–¹æ³•éœ€è¦ä½¿ç”¨æ•°æ®åº“ï¼Œ è¯¥æ–¹æ³•åº”è¯¥åœ¨æ¥æ”¶åˆ°è¿”å›å€¼åå…³é—­æ‰€æœ‰æ´»è·ƒçš„æ•°æ®åº“è¿æ¥ã€‚\nä½ åˆ›å»ºäº†ä¸€ä¸ªå­ç±»å¹¶å¯¹å…¶è¿›è¡Œäº†ä¿®æ”¹ï¼Œ ä½¿å¾—æ•°æ®åº“ä¿æŒè¿æ¥ä»¥ä¾¿é‡ç”¨ã€‚ä½†å®¢æˆ·ç«¯å¯èƒ½å¯¹ä½ çš„æ„å›¾ä¸€æ— æ‰€çŸ¥ã€‚\n6. è¶…ç±»çš„ä¸å˜é‡å¿…é¡»ä¿ç•™ã€‚\nä¸å˜é‡æ˜¯è®©å¯¹è±¡æœ‰æ„ä¹‰çš„æ¡ä»¶ã€‚ä¾‹å¦‚ï¼Œ çŒ«çš„ä¸å˜é‡ æ˜¯æœ‰å››æ¡è…¿ã€ ä¸€æ¡å°¾å·´å’Œèƒ½å¤Ÿå–µå–µå«ç­‰ã€‚ä¸å˜é‡è®©äººç–‘æƒ‘çš„åœ°æ–¹åœ¨äºå®ƒä»¬æ—¢å¯é€šè¿‡æ¥å£å¥‘çº¦æˆ–æ–¹æ³•å†…çš„ä¸€ç»„æ–­è¨€æ¥æ˜ç¡®å®šä¹‰ï¼Œåˆå¯æš—å«åœ¨ç‰¹å®šçš„å•å…ƒæµ‹è¯•å’Œå®¢æˆ·ä»£ç é¢„æœŸä¸­ã€‚ä½ å¯èƒ½ä¼šè¯¯è§£æˆ–æ²¡æœ‰æ„è¯†åˆ°ä¸€ä¸ªå¤æ‚ç±»ä¸­çš„æ‰€æœ‰ä¸å˜é‡ã€‚å› æ­¤ï¼Œæ‰©å±•ä¸€ä¸ªç±»çš„æœ€å®‰å…¨åšæ³•æ˜¯å¼•å…¥æ–°çš„æˆå‘˜å˜é‡å’Œæ–¹æ³•ï¼Œä½†å®é™…ä¸Šå¹¶éæ€»æ˜¯å¯è¡Œã€‚\n7. å­ç±»ä¸èƒ½ä¿®æ”¹è¶…ç±»ä¸­ç§æœ‰æˆå‘˜å˜é‡çš„å€¼ã€‚\næœ‰äº›ç¼–ç¨‹è¯­è¨€å…è®¸é€šè¿‡åå°„æœºåˆ¶æ¥è®¿é—®ç±»çš„ç§æœ‰æˆå‘˜ã€‚è¿˜æœ‰ä¸€äº›è¯­è¨€(Python å’Œ JavaScript)æ²¡æœ‰å¯¹ç§æœ‰æˆå‘˜è¿›è¡Œä»»ä½•ä¿æŠ¤ã€‚Goå¯ä»¥é€šè¿‡unsafe.Pointer+åç§»åœ°å€ ã€\n[è¯¥ç±»å‹çš„å†…å®¹æš‚ä¸æ”¯æŒä¸‹è½½]\nä¸€ä¸ªè¿åæ›¿æ¢åŸåˆ™çš„æ–‡æ¡£ç±»å±‚æ¬¡ç»“æ„ä¾‹å­\n**ä¿®æ”¹å‰:**åªè¯»æ–‡ä»¶ä¸­çš„ä¿å­˜è¡Œä¸ºæ²¡æœ‰ä»»ä½•æ„ä¹‰ï¼Œå› æ­¤å­ç±»è¯•å›¾åœ¨é‡å†™åçš„æ–¹æ³•ä¸­é‡ç½®åŸºç¡€è¡Œä¸ºæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚\n**ä¿®æ”¹å:**å½“æŠŠåªè¯»æ–‡æ¡£ç±»ä½œä¸ºå±‚æ¬¡ç»“æ„ä¸­çš„åŸºç±»åï¼Œè¿™ä¸ªé—®é¢˜å¾—åˆ°äº†è§£å†³ã€‚\né€šè¿‡é‡æ–°è®¾è®¡ç±»å±‚æ¬¡ç»“æ„æ¥è§£å†³è¿™ä¸ªé—®é¢˜: ä¸€ä¸ªå­ç±»å¿…é¡»æ‰©å±•å…¶è¶…ç±»çš„è¡Œä¸ºï¼Œ å› æ­¤åªè¯»æ–‡æ¡£å˜æˆäº†å±‚æ¬¡ç»“æ„ä¸­çš„åŸºç±»ã€‚ å¯å†™æ–‡ä»¶ç°åœ¨å˜æˆäº†å­ç±»ï¼Œ å¯¹åŸºç±»è¿›è¡Œæ‰©å±•å¹¶æ·»åŠ äº†ä¿å­˜è¡Œä¸ºã€‚\næ¥å£éš”ç¦»åŸåˆ™\nInterface Segregation Principle\nå®¢æˆ·ç«¯ä¸åº”è¢«å¼ºè¿«ä¾èµ–äºå…¶ä¸ä½¿ç”¨çš„æ–¹æ³•ã€‚\nå°½é‡ç¼©å°æ¥å£çš„èŒƒå›´ï¼Œ ä½¿å¾—å®¢æˆ·ç«¯çš„ç±»ä¸å¿…å®ç°å…¶ä¸éœ€è¦çš„è¡Œä¸ºã€‚æ ¹æ®æ¥å£éš”ç¦»åŸåˆ™ï¼Œä½ å¿…é¡»å°†\u0026quot;è‡ƒè‚¿\u0026quot;çš„æ–¹æ³•æ‹†åˆ†ä¸ºå¤šä¸ªé¢—ç²’åº¦æ›´å°çš„å…·ä½“æ–¹æ³•ã€‚\n**ä¿®æ”¹å‰:**ä¸æ˜¯æ‰€æœ‰å®¢æˆ·ç«¯èƒ½æ»¡è¶³å¤æ‚æ¥å£çš„è¦æ±‚ã€‚\n**ä¿®æ”¹å:**ä¸€ä¸ªå¤æ‚çš„æ¥å£è¢«æ‹†åˆ†ä¸ºä¸€ç»„é¢—ç²’åº¦æ›´å°çš„æ¥å£ã€‚\nä¸å…¶ä»–åŸåˆ™ä¸€æ ·ï¼Œ ä½ å¯èƒ½ä¼šè¿‡åº¦ä½¿ç”¨è¿™æ¡åŸåˆ™ã€‚ ä¸è¦è¿›ä¸€æ­¥åˆ’åˆ†å·²ç»éå¸¸å…·ä½“çš„æ¥å£ã€‚ è®°ä½ï¼Œ åˆ›å»ºçš„æ¥å£è¶Šå¤šï¼Œ ä»£ç å°±è¶Šå¤æ‚ã€‚ å› æ­¤è¦ä¿æŒå¹³è¡¡ã€‚\nä¾èµ–å€’ç½®åŸåˆ™\nDependency Inversion Principle\né«˜å±‚æ¬¡çš„ç±»ä¸åº”è¯¥ä¾èµ–äºä½å±‚æ¬¡çš„ç±»ã€‚ ä¸¤è€…éƒ½åº”è¯¥ä¾èµ–äºæŠ½è±¡æ¥å£ã€‚ æŠ½è±¡æ¥å£ä¸åº”ä¾èµ–äºå…·ä½“å®ç°ã€‚ å…·ä½“å®ç°åº”è¯¥ä¾èµ–äºæŠ½è±¡æ¥å£ã€‚\nä½å±‚æ¬¡çš„ç±»å®ç°åŸºç¡€æ“ä½œ(ä¾‹å¦‚ç£ç›˜æ“ä½œã€ ä¼ è¾“ç½‘ç»œæ•°æ®å’Œ è¿æ¥æ•°æ®åº“ç­‰)ã€‚\né«˜å±‚æ¬¡ç±»åŒ…å«å¤æ‚ä¸šåŠ¡é€»è¾‘ä»¥æŒ‡å¯¼ä½å±‚æ¬¡ç±»æ‰§è¡Œç‰¹å®šæ“ä½œã€‚\nå¸¸è§åœºæ™¯ï¼š\nåœ¨æ–°ç³»ç»Ÿä¸Šå¼€å‘åŸå‹äº§å“æ—¶ï¼Œç”±äºä½å±‚æ¬¡çš„ä¸œè¥¿è¿˜æ²¡æœ‰å®ç°æˆ–ä¸ç¡®å®šï¼Œ ä½ ç”šè‡³æ— æ³•ç¡®å®šé«˜å±‚æ¬¡ç±»èƒ½å®ç°å“ªäº›åŠŸèƒ½ï¼Œä¸šåŠ¡é€»è¾‘ç±»å¯èƒ½ä¼šæ›´ä¾èµ–äºä½å±‚åŸè¯­ç±»ã€‚\nä¾èµ–å€’ç½®åŸåˆ™å»ºè®®æ”¹å˜è¿™ç§ä¾èµ–æ–¹å¼ã€‚\nä½¿ç”¨ä¸šåŠ¡æœ¯è¯­æ¥å¯¹é«˜å±‚æ¬¡ç±»ä¾èµ–çš„ä½å±‚æ¬¡æ“ä½œæ¥å£è¿›è¡Œæè¿°ã€‚ä¾‹å¦‚ï¼Œ ä¸šåŠ¡é€»è¾‘åº”è¯¥è°ƒç”¨åä¸º openReport(file) çš„æ–¹æ³•ï¼Œ è€Œä¸æ˜¯ openFile(x) ã€readBytes(n) å’Œ closeFile(x) ç­‰ä¸€ç³»åˆ—æ–¹æ³•ã€‚è¿™äº›æ¥å£è¢«è§†ä¸ºæ˜¯é«˜å±‚æ¬¡çš„ã€‚\nç°åœ¨ä½ å¯åŸºäºè¿™äº›æ¥å£åˆ›å»ºé«˜å±‚æ¬¡ç±»ï¼Œ è€Œä¸æ˜¯åŸºäºä½å±‚æ¬¡çš„å…·ä½“ç±»ã€‚ è¿™è¦æ¯”åŸå§‹çš„ä¾èµ–å…³ç³»çµæ´»å¾ˆå¤šã€‚\nä¸€æ—¦ä½å±‚æ¬¡çš„ç±»å®ç°äº†è¿™äº›æ¥å£ï¼Œ å®ƒä»¬å°†ä¾èµ–äºä¸šåŠ¡é€»è¾‘å±‚ï¼Œ ä»è€Œå€’ç½®äº†åŸå§‹çš„ä¾èµ–å…³ç³»ã€‚\nä¾èµ–å€’ç½®åŸåˆ™é€šå¸¸å’Œå¼€é—­åŸåˆ™å…±åŒå‘æŒ¥ä½œç”¨: ä½ æ— éœ€ä¿®æ”¹å·²æœ‰ç±»å°±èƒ½ç”¨ä¸åŒçš„ä¸šåŠ¡é€»è¾‘ç±»æ‰©å±•ä½å±‚æ¬¡çš„ç±»ã€‚\n**ä¿®æ”¹å‰:**é«˜å±‚æ¬¡çš„ç±»ä¾èµ–äºä½å±‚æ¬¡çš„ç±»ã€‚\n**ä¿®æ”¹å:**ä½å±‚æ¬¡çš„ç±»ä¾èµ–äºé«˜å±‚æ¬¡çš„æŠ½è±¡ã€‚\nå…¶ç»“æœæ˜¯åŸå§‹çš„ä¾èµ–å…³ç³»è¢«å€’ç½®ã€‚\nå…­ã€è®¾è®¡æ¨¡å¼ç›®å½• åˆ›å»ºå‹æ¨¡å¼ åˆ›å»ºå‹æ¨¡å¼æä¾›äº†åˆ›å»ºå¯¹è±¡çš„æœºåˆ¶ï¼Œ èƒ½å¤Ÿæå‡å·²æœ‰ä»£ç çš„çµæ´»æ€§å’Œå¯å¤ç”¨æ€§ã€‚\nå·¥å‚æ–¹æ³• é—®é¢˜\nå‡è®¾ä½ æ­£åœ¨å¼€å‘ä¸€æ¬¾ç‰©æµç®¡ç†åº”ç”¨ã€‚ æœ€åˆç‰ˆæœ¬åªèƒ½å¤„ç†å¡è½¦è¿è¾“ï¼Œå› æ­¤å¤§éƒ¨åˆ†ä»£ç éƒ½åœ¨ä½äºåä¸º å¡è½¦ çš„ç±»ä¸­ã€‚\nç°åœ¨æ¯å¤©éƒ½èƒ½æ”¶åˆ°åå‡ æ¬¡æ¥è‡ªæµ·è¿å…¬å¸çš„è¯·æ±‚ï¼Œ å¸Œæœ›åº”ç”¨èƒ½å¤Ÿæ”¯æŒæµ·ä¸Šç‰©æµåŠŸèƒ½ã€‚\nå¦‚æœä»£ç å…¶ä½™éƒ¨åˆ†ä¸ç°æœ‰ç±»å·²ç»å­˜åœ¨è€¦åˆå…³ç³»ï¼Œ é‚£ä¹ˆå‘ç¨‹åºä¸­æ·»åŠ æ–°ç±»å…¶å®å¹¶æ²¡æœ‰é‚£ä¹ˆå®¹æ˜“ã€‚\nè§£å†³æ–¹æ¡ˆ\nå·¥å‚æ–¹æ³•æ¨¡å¼å»ºè®®ä½¿ç”¨ç‰¹æ®Šçš„å·¥å‚æ–¹æ³•ä»£æ›¿å¯¹äºå¯¹è±¡æ„é€ å‡½æ•°çš„ç›´æ¥è°ƒç”¨(å³ä½¿ç”¨ new è¿ç®—ç¬¦)ã€‚\nå­ç±»å¯ä»¥ä¿®æ”¹å·¥å‚æ–¹æ³•è¿”å›çš„å¯¹è±¡ç±»å‹ã€‚\næ‰€æœ‰äº§å“éƒ½å¿…é¡»ä½¿ç”¨åŒä¸€æ¥å£ã€‚\nåªè¦äº§å“ç±»å®ç°ä¸€ä¸ªå…±åŒçš„æ¥å£ï¼Œ ä½ å°±å¯ä»¥å°†å…¶å¯¹è±¡ä¼ é€’ç»™å®¢æˆ·ä»£ç ï¼Œ è€Œæ— éœ€æä¾›é¢å¤–æ•°æ®ã€‚\nç»“æ„\näº§å“(Product)å°†ä¼šå¯¹æ¥å£è¿›è¡Œå£°æ˜ã€‚å¯¹äºæ‰€æœ‰ç”±åˆ›å»ºè€…åŠ å…¶å­ç±»æ„å»ºçš„å¯¹è±¡ï¼Œ è¿™äº›æ¥å£éƒ½æ˜¯é€šç”¨çš„ã€‚\nå…·ä½“äº§å“(Concrete Products)æ˜¯äº§å“æ¥å£çš„ä¸åŒå®ç°ã€‚\nåˆ›å»ºè€…(Creator)ç±»å£°æ˜è¿”å›äº§å“å¯¹è±¡çš„å·¥å‚æ–¹æ³•ã€‚è¯¥æ–¹æ³•çš„è¿”å›å¯¹è±¡ç±»å‹å¿…é¡»ä¸äº§å“æ¥å£ç›¸åŒ¹é…ã€‚\nå…·ä½“åˆ›å»ºè€…(Concrete Creators) å°†ä¼šé‡å†™åŸºç¡€å·¥å‚æ–¹æ³•ï¼Œ ä½¿å…¶è¿”å›ä¸åŒç±»å‹çš„äº§å“ã€‚\næ³¨æ„ï¼Œå¹¶ä¸ä¸€å®šæ¯æ¬¡è°ƒç”¨å·¥å‚æ–¹æ³•éƒ½ä¼šåˆ›å»ºæ–°çš„å®ä¾‹ã€‚ å·¥å‚ æ–¹æ³•ä¹Ÿå¯ä»¥è¿”å›ç¼“å­˜ã€ å¯¹è±¡æ± æˆ–å…¶ä»–æ¥æºçš„å·²æœ‰å¯¹è±¡ã€‚\nç¤ºä¾‹\nä½¿ç”¨å·¥å‚æ–¹æ³•å¼€å‘è·¨å¹³å° UI(ç”¨æˆ·ç•Œé¢)ç»„ä»¶ï¼Œå¹¶åŒæ—¶é¿å…å®¢æˆ·ä»£ç ä¸å…·ä½“ UI ç±»ä¹‹é—´çš„è€¦åˆã€‚\nåº”ç”¨åœºæ™¯\n**å½“ä½ åœ¨ç¼–å†™ä»£ç çš„è¿‡ç¨‹ä¸­ï¼Œå¦‚æœæ— æ³•é¢„çŸ¥å¯¹è±¡ç¡®åˆ‡ç±»åˆ«åŠå…¶ä¾èµ–å…³ç³»æ—¶ï¼Œå¯ä½¿ç”¨å·¥å‚æ–¹æ³•ã€‚**å·¥å‚æ–¹æ³•å°†åˆ›å»ºäº§å“çš„ä»£ç ä¸å®é™…ä½¿ç”¨äº§å“çš„ä»£ç åˆ†ç¦»ï¼Œ ä»è€Œèƒ½åœ¨ä¸å½±å“å…¶ä»–ä»£ç çš„æƒ…å†µä¸‹æ‰©å±•äº§å“åˆ›å»ºéƒ¨åˆ†ä»£ç ã€‚\n**å¦‚æœä½ å¸Œæœ›ç”¨æˆ·èƒ½æ‰©å±•ä½ è½¯ä»¶åº“æˆ–æ¡†æ¶çš„å†…éƒ¨ç»„ä»¶ï¼Œå¯ä½¿ç”¨å·¥å‚æ–¹æ³•ã€‚**ç»§æ‰¿å¯èƒ½æ˜¯æ‰©å±•è½¯ä»¶åº“æˆ–æ¡†æ¶é»˜è®¤è¡Œä¸ºçš„æœ€ç®€å•æ–¹æ³•ã€‚å°†å„æ¡†æ¶ä¸­æ„é€ ç»„ä»¶çš„ä»£ç é›†ä¸­åˆ°å•ä¸ªå·¥å‚æ–¹æ³•ä¸­ï¼Œ å¹¶åœ¨ç»§æ‰¿è¯¥ç»„ä»¶ä¹‹å¤–å…è®¸ä»»ä½•äººå¯¹è¯¥æ–¹æ³•è¿›è¡Œé‡å†™ã€‚\n**å¦‚æœä½ å¸Œæœ›å¤ç”¨ç°æœ‰å¯¹è±¡æ¥èŠ‚çœç³»ç»Ÿèµ„æºï¼Œè€Œä¸æ˜¯æ¯æ¬¡éƒ½é‡æ–°åˆ›å»ºå¯¹è±¡ï¼Œå¯ä½¿ç”¨å·¥å‚æ–¹æ³•ã€‚**åœ¨å¤„ç†å¤§å‹èµ„æºå¯†é›†å‹å¯¹è±¡(æ¯”å¦‚æ•°æ®åº“è¿æ¥ã€ æ–‡ä»¶ç³»ç»Ÿå’Œ ç½‘ç»œèµ„æº) æ—¶ï¼Œ ä½ ä¼šç»å¸¸ç¢°åˆ°è¿™ç§èµ„æºéœ€æ±‚ã€‚\nå¤ç”¨ç°æœ‰å¯¹è±¡çš„æ–¹æ³•:\n1ï¼‰å»ºå­˜å‚¨ç©ºé—´æ¥å­˜æ”¾æ‰€æœ‰å·²ç»åˆ›å»ºçš„å¯¹è±¡ã€‚\n2ï¼‰å½“ä»–äººè¯·æ±‚ä¸€ä¸ªå¯¹è±¡æ—¶ï¼Œ ç¨‹åºå°†åœ¨å¯¹è±¡æ± ä¸­æœç´¢å¯ç”¨å¯¹è±¡ã€‚\n3ï¼‰...ç„¶åå°†å…¶è¿”å›ç»™å®¢æˆ·ç«¯ä»£ç ã€‚\n4ï¼‰å¦‚æœæ²¡æœ‰å¯ç”¨å¯¹è±¡ï¼Œ ç¨‹åºåˆ™åˆ›å»ºä¸€ä¸ªæ–°å¯¹è±¡(å¹¶å°†å…¶æ·»åŠ åˆ° å¯¹è±¡æ± ä¸­)ã€‚\nå®ç°æ–¹å¼\nè®©æ‰€æœ‰äº§å“éƒ½éµå¾ªåŒä¸€æ¥å£ã€‚ è¯¥æ¥å£å¿…é¡»å£°æ˜å¯¹æ‰€æœ‰äº§å“éƒ½æœ‰æ„ä¹‰çš„æ–¹æ³•ã€‚\nåœ¨åˆ›å»ºç±»ä¸­æ·»åŠ ä¸€ä¸ªç©ºçš„å·¥å‚æ–¹æ³•ã€‚ è¯¥æ–¹æ³•çš„è¿”å›ç±»å‹å¿…é¡» éµå¾ªé€šç”¨çš„äº§å“æ¥å£ã€‚\nåœ¨åˆ›å»ºè€…ä»£ç ä¸­æ‰¾åˆ°å¯¹äºäº§å“æ„é€ å‡½æ•°çš„æ‰€æœ‰å¼•ç”¨ã€‚æ›¿æ¢ä¸ºå¯¹äºå·¥å‚æ–¹æ³•çš„è°ƒç”¨ï¼Œ åŒæ—¶å°†åˆ›å»ºäº§å“çš„ä»£ç ç§» å…¥å·¥å‚æ–¹æ³•ã€‚\nä¸ºå·¥å‚æ–¹æ³•ä¸­çš„æ¯ç§äº§å“ç¼–å†™ä¸€ä¸ªåˆ›å»ºè€…å­ç±»ï¼Œ ç„¶ååœ¨å­ç±»ä¸­é‡å†™å·¥å‚æ–¹æ³•ï¼Œ å¹¶å°†åŸºæœ¬æ–¹æ³•ä¸­çš„ç›¸å…³åˆ›å»ºä»£ç ç§»åŠ¨åˆ°å·¥å‚æ–¹æ³•ä¸­ã€‚\nå¦‚æœåº”ç”¨ä¸­çš„äº§å“ç±»å‹å¤ªå¤šï¼Œ é‚£ä¹ˆä¸ºæ¯ä¸ªäº§å“åˆ›å»ºå­ç±»å¹¶æ—  å¤ªå¤§å¿…è¦ï¼Œ è¿™æ—¶ä½ ä¹Ÿå¯ä»¥åœ¨å­ç±»ä¸­å¤ç”¨åŸºç±»ä¸­çš„æ§åˆ¶å‚æ•°ã€‚\né™†åœ°é‚®ä»¶åŒæ—¶ä½¿ç”¨å¡è½¦å’Œç«è½¦å¯¹è±¡ï¼š\nå¯ä»¥ç¼–å†™æ–°çš„å­ç±»\u0026mdash;\u0026mdash;ç«è½¦é‚®ä»¶ï¼Œä¹Ÿå¯ä»¥ç»™é™†åœ°é‚®ä»¶ä¼ é€’å‚æ•°ç”¨ä»¥æ§åˆ¶æƒ³è·å¾—çš„äº§å“ã€‚\nå¦‚æœä»£ç ç»è¿‡ä¸Šè¿°ç§»åŠ¨åï¼Œ åŸºç¡€å·¥å‚æ–¹æ³•ä¸­å·²ç»æ²¡æœ‰ä»»ä½•ä»£ç ï¼Œ ä½ å¯ä»¥å°†å…¶è½¬å˜ä¸ºæŠ½è±¡ç±»ã€‚ å¦‚æœåŸºç¡€å·¥å‚æ–¹æ³•ä¸­è¿˜æœ‰å…¶ä»–è¯­å¥ï¼Œ ä½ å¯ä»¥å°†å…¶è®¾ç½®ä¸ºè¯¥æ–¹æ³•çš„é»˜è®¤è¡Œä¸ºã€‚\nä¼˜ç¼ºç‚¹\nä¼˜ç‚¹\nå¯ä»¥é¿å…åˆ›å»ºè€…å’Œå…·ä½“äº§å“ä¹‹é—´çš„ç´§å¯†è€¦åˆã€‚\nå•ä¸€èŒè´£åŸåˆ™ã€‚å¯ä»¥å°†äº§å“åˆ›å»ºä»£ç æ”¾åœ¨ç¨‹åºçš„å•ä¸€ä½ç½®ï¼Œ ä»è€Œä½¿å¾—ä»£ç æ›´å®¹æ˜“ç»´æŠ¤ã€‚\nå¼€é—­åŸåˆ™ã€‚ æ— éœ€æ›´æ”¹ç°æœ‰ä»£ç ï¼Œ ä½ å°±å¯ä»¥åœ¨ç¨‹åºä¸­å¼•å…¥æ–°çš„äº§å“ç±»å‹ã€‚\nç¼ºç‚¹\nåº”ç”¨å·¥å‚æ–¹æ³•æ¨¡å¼éœ€è¦å¼•å…¥è®¸å¤šæ–°çš„å­ç±»ï¼Œ ä»£ç å¯èƒ½ä¼šå› æ­¤å˜å¾—æ›´å¤æ‚ã€‚ æœ€å¥½çš„æƒ…å†µæ˜¯å°†è¯¥æ¨¡å¼å¼•å…¥åˆ›å»ºè€…ç±»çš„ç°æœ‰å±‚æ¬¡ç»“æ„ä¸­ã€‚\nä¸å…¶ä»–æ¨¡å¼çš„å…³ç³»\ntodo\næŠ½è±¡å·¥å‚ é—®é¢˜\nå‡è®¾ä½ æ­£åœ¨å¼€å‘ä¸€æ¬¾å®¶å…·å•†åº—æ¨¡æ‹Ÿå™¨ï¼Œç³»åˆ—äº§å“åŠå…¶ä¸åŒå˜ä½“ï¼š\nä½ éœ€è¦è®¾æ³•å•ç‹¬ç”Ÿæˆæ¯ä»¶å®¶å…·å¯¹è±¡ï¼Œ ç¡®ä¿å…¶é£æ ¼ä¸€è‡´ã€‚ä¸”å®¶å…·ä¾›åº”å•†å¯¹äºäº§å“ç›®å½•çš„æ›´æ–°éå¸¸é¢‘ç¹ã€‚\nè§£å†³æ–¹æ¡ˆ\næŠ½è±¡å·¥å‚æ¨¡å¼å»ºè®®ä¸ºç³»åˆ—ä¸­çš„æ¯ä»¶äº§å“æ˜ç¡®å£°æ˜æ¥å£ (ä¾‹å¦‚æ¤…å­ã€ æ²™å‘æˆ–å’–å•¡æ¡Œ)ã€‚\nç¡®ä¿æ‰€æœ‰äº§å“å˜ä½“éƒ½ç»§æ‰¿è¿™äº›æ¥å£ã€‚\néœ€è¦å£°æ˜æŠ½è±¡å·¥å‚\u0026mdash;\u0026mdash;åŒ…å«ç³»åˆ—ä¸­æ‰€æœ‰äº§å“æ„é€ æ–¹æ³•çš„æ¥å£ï¼Œè¿™äº›æ–¹æ³•å¿…é¡»è¿”å›æŠ½è±¡äº§å“ç±»å‹ã€‚\næ¯ä¸ªå…·ä½“å·¥å‚ç±»éƒ½å¯¹åº”ä¸€ä¸ªç‰¹å®šçš„äº§å“å˜ä½“ã€‚\nç»“æ„\næŠ½è±¡äº§å“(Abstract Product)ä¸ºæ„æˆç³»åˆ—äº§å“çš„ä¸€ç»„ä¸åŒä½†ç›¸å…³çš„äº§å“å£°æ˜æ¥å£ã€‚\nå…·ä½“äº§å“(Concrete Product)æ˜¯æŠ½è±¡äº§å“çš„å¤šç§ä¸åŒç±»å‹å® ç°ã€‚æ‰€æœ‰å˜ä½“(ç»´å¤šåˆ©äºš/ç°ä»£)éƒ½å¿…é¡»å®ç°ç›¸åº”çš„æŠ½è±¡äº§å“(æ¤…å­/æ²™å‘)ã€‚\næŠ½è±¡å·¥å‚(Abstract Factory)æ¥å£å£°æ˜äº†ä¸€ç»„åˆ›å»ºå„ç§æŠ½è±¡äº§å“çš„æ–¹æ³•ã€‚\nå…·ä½“å·¥å‚(Concrete Factory)å®ç°æŠ½è±¡å·¥å‚çš„æ„å»ºæ–¹æ³•ã€‚æ¯ä¸ªå…·ä½“å·¥å‚éƒ½å¯¹åº”ç‰¹å®šäº§å“å˜ä½“ï¼Œ ä¸”ä»…åˆ›å»ºæ­¤ç§äº§å“å˜ä½“ã€‚\nç¤ºä¾‹\né€šè¿‡åº”ç”¨æŠ½è±¡å·¥å‚æ¨¡å¼ï¼Œ ä½¿å¾—å®¢æˆ·ç«¯ä»£ç æ— éœ€ä¸å…·ä½“ UI ç±»è€¦åˆï¼Œå°±èƒ½åˆ›å»ºè·¨å¹³å°çš„ UI å…ƒç´ ï¼ŒåŒæ—¶ç¡®ä¿æ‰€åˆ›å»ºçš„å…ƒç´ ä¸æŒ‡å®šçš„æ“ä½œç³»ç»ŸåŒ¹é…ã€‚\né€‚åˆåº”ç”¨åœºæ™¯\nå¦‚æœä»£ç éœ€è¦ä¸å¤šä¸ªä¸åŒç³»åˆ—çš„ç›¸å…³äº§å“äº¤äº’ï¼Œä½†æ˜¯ç”±äºæ— æ³•æå‰è·å–ç›¸å…³ä¿¡æ¯ï¼Œ æˆ–è€…å‡ºäºå¯¹æœªæ¥æ‰©å±•æ€§çš„è€ƒè™‘ï¼Œ ä½ ä¸å¸Œæœ›ä»£ç åŸºäºäº§å“çš„å…·ä½“ç±»è¿›è¡Œæ„å»ºï¼Œ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ ä½ å¯ä»¥ä½¿ç”¨æŠ½è±¡å·¥å‚ã€‚\nå¦‚æœä½ æœ‰ä¸€ä¸ªåŸºäºä¸€ç»„æŠ½è±¡æ–¹æ³•çš„ç±»ï¼Œä¸”å…¶ä¸»è¦åŠŸèƒ½å› æ­¤å˜å¾—ä¸æ˜ç¡®ï¼Œé‚£ä¹ˆåœ¨è¿™ç§æƒ…å†µä¸‹å¯ä»¥è€ƒè™‘ä½¿ç”¨æŠ½è±¡å·¥å‚æ¨¡å¼ã€‚\nå®ç°æ–¹å¼\nä»¥ä¸åŒçš„äº§å“ç±»å‹ä¸äº§å“å˜ä½“ä¸ºç»´åº¦ç»˜åˆ¶çŸ©é˜µã€‚\nä¸ºæ‰€æœ‰äº§å“å£°æ˜æŠ½è±¡äº§å“æ¥å£ã€‚ ç„¶åè®©æ‰€æœ‰å…·ä½“äº§å“ç±»å®ç°è¿™äº›æ¥å£ã€‚\nå£°æ˜æŠ½è±¡å·¥å‚æ¥å£ï¼Œ å¹¶ä¸”åœ¨æ¥å£ä¸­ä¸ºæ‰€æœ‰æŠ½è±¡äº§å“æä¾›ä¸€ç»„æ„å»ºæ–¹æ³•ã€‚\nä¸ºæ¯ç§äº§å“å˜ä½“å®ç°ä¸€ä¸ªå…·ä½“å·¥å‚ç±»ã€‚\nåœ¨åº”ç”¨ç¨‹åºä¸­å¼€å‘åˆå§‹åŒ–ä»£ç ã€‚ è¯¥ä»£ç æ ¹æ®åº”ç”¨ç¨‹åºé…ç½®æˆ–å½“å‰ç¯å¢ƒï¼Œ å¯¹ç‰¹å®šå…·ä½“å·¥å‚ç±»è¿›è¡Œåˆå§‹åŒ–ã€‚ ç„¶åå°†è¯¥å·¥å‚å¯¹è±¡ä¼ é€’ç»™æ‰€æœ‰éœ€è¦åˆ›å»ºäº§å“çš„ç±»ã€‚\næ‰¾å‡ºä»£ç ä¸­æ‰€æœ‰å¯¹äº§å“æ„é€ å‡½æ•°çš„ç›´æ¥è°ƒç”¨ï¼Œ å°†å…¶æ›¿æ¢ä¸ºå¯¹å·¥å‚å¯¹è±¡ä¸­ç›¸åº”æ„å»ºæ–¹æ³•çš„è°ƒç”¨ã€‚\nä¼˜ç¼ºç‚¹\nä¼˜ç‚¹\nä½ å¯ä»¥ç¡®ä¿åŒä¸€å·¥å‚ç”Ÿæˆçš„äº§å“ç›¸äº’åŒ¹é…ã€‚\nä½ å¯ä»¥é¿å…å®¢æˆ·ç«¯å’Œå…·ä½“äº§å“ä»£ç çš„è€¦åˆã€‚\nå•ä¸€èŒè´£åŸåˆ™ã€‚ ä½ å¯ä»¥å°†äº§å“ç”Ÿæˆä»£ç æŠ½å–åˆ°åŒä¸€ä½ç½®ï¼Œ ä½¿å¾—ä»£ç æ˜“äºç»´æŠ¤ã€‚\nå¼€é—­åŸåˆ™ã€‚ å‘åº”ç”¨ç¨‹åºä¸­å¼•å…¥æ–°äº§å“å˜ä½“æ—¶ï¼Œ ä½ æ— éœ€ä¿®æ”¹å®¢æˆ·ç«¯ä»£ç ã€‚\nç¼ºç‚¹\nç”±äºé‡‡ç”¨è¯¥æ¨¡å¼éœ€è¦å‘åº”ç”¨ä¸­å¼•å…¥ä¼—å¤šæ¥å£å’Œç±»ï¼Œ ä»£ç å¯èƒ½ä¼šæ¯”ä¹‹å‰æ›´åŠ å¤æ‚ã€‚\nç”Ÿæˆå™¨ é—®é¢˜\nå‡è®¾æœ‰è¿™æ ·ä¸€ä¸ªå¤æ‚å¯¹è±¡ï¼Œ åœ¨å¯¹å…¶è¿›è¡Œæ„é€ æ—¶éœ€è¦å¯¹è¯¸å¤šæˆå‘˜å˜é‡å’ŒåµŒå¥—å¯¹è±¡è¿›è¡Œç¹å¤çš„åˆå§‹åŒ–å·¥ä½œã€‚\nåšæ³•1ï¼šæ‰©å±• æˆ¿å±‹ åŸºç±»ï¼Œç„¶ååˆ›å»ºä¸€ç³»åˆ—æ¶µç›–æ‰€æœ‰å‚æ•°ç»„åˆçš„å­ç±»ã€‚ ä½†æœ€ç»ˆä½ å°†é¢å¯¹ç›¸å½“æ•°é‡çš„å­ç±»ã€‚\nåšæ³•2ï¼šæ— éœ€ç”Ÿæˆå­ç±»ã€‚ä½ å¯ä»¥åœ¨ æˆ¿å±‹ åŸºç±»ä¸­åˆ›å»ºä¸€ä¸ªåŒ…æ‹¬æ‰€æœ‰å¯èƒ½å‚æ•°çš„è¶…çº§æ„é€ å‡½æ•°ï¼Œ å¹¶ç”¨å®ƒæ¥æ§åˆ¶æˆ¿å±‹å¯¹ è±¡ã€‚\nä½†æ˜¯è¿™äº›å‚æ•°ä¹Ÿä¸æ˜¯æ¯æ¬¡éƒ½è¦å…¨éƒ¨ç”¨ä¸Šçš„ï¼Œè¿™ä½¿å¾—å¯¹äºæ„é€ å‡½æ•°çš„è°ƒç”¨ååˆ†ä¸ç®€æ´ã€‚\nè§£å†³æ–¹æ¡ˆ\nç”Ÿæˆå™¨æ¨¡å¼å»ºè®®å°†å¯¹è±¡æ„é€ ä»£ç ä»äº§å“ç±»ä¸­æŠ½å–å‡ºæ¥ï¼Œ å¹¶å°†å…¶æ”¾åœ¨ä¸€ä¸ªåä¸ºç”Ÿæˆå™¨çš„ç‹¬ç«‹å¯¹è±¡ä¸­ã€‚\nåˆ›å»ºå¯¹è±¡æ—¶æ— éœ€è°ƒç”¨æ‰€æœ‰æ­¥éª¤ï¼Œ è€Œåªéœ€è°ƒç”¨åˆ›å»ºç‰¹å®šå¯¹è±¡é…ç½®æ‰€éœ€çš„é‚£äº›æ­¥éª¤å³å¯ã€‚\nç»“æ„\nç”Ÿæˆå™¨(Builder)æ¥å£å£°æ˜åœ¨æ‰€æœ‰ç±»å‹ç”Ÿæˆå™¨ä¸­é€šç”¨çš„äº§å“æ„é€ æ­¥éª¤ã€‚\nå…·ä½“ç”Ÿæˆå™¨(Concrete Builders)æä¾›æ„é€ è¿‡ç¨‹çš„ä¸åŒå®ç°ã€‚å…·ä½“ç”Ÿæˆå™¨ä¹Ÿå¯ä»¥æ„é€ ä¸éµå¾ªé€šç”¨æ¥å£çš„äº§å“ã€‚\näº§å“(Products)æ˜¯æœ€ç»ˆç”Ÿæˆçš„å¯¹è±¡ã€‚ç”±ä¸åŒç”Ÿæˆå™¨æ„é€ çš„äº§å“æ— éœ€å±äºåŒä¸€ç±»å±‚æ¬¡ç»“æ„æˆ–æ¥å£ã€‚\nä¸»ç®¡(Director)ç±»å®šä¹‰è°ƒç”¨æ„é€ æ­¥éª¤çš„é¡ºåºï¼Œè¿™æ ·ä½ å°±å¯ä»¥åˆ›å»ºå’Œå¤ç”¨ç‰¹å®šçš„äº§å“é…ç½®ã€‚\nå®¢æˆ·ç«¯(Client)å¿…é¡»å°†æŸä¸ªç”Ÿæˆå™¨å¯¹è±¡ä¸ä¸»ç®¡ç±»å…³è”ã€‚\nç¤ºä¾‹\né€‚åˆåº”ç”¨åœºæ™¯\nä½¿ç”¨ç”Ÿæˆå™¨æ¨¡å¼å¯é¿å… \u0026ldquo;é‡å æ„é€ å‡½æ•° (telescopic constructor)\u0026ldquo;çš„å‡ºç°ã€‚\nå½“ä½ å¸Œæœ›ä½¿ç”¨ä»£ç åˆ›å»ºä¸åŒå½¢å¼çš„äº§å“(ä¾‹å¦‚çŸ³å¤´æˆ–æœ¨å¤´æˆ¿å±‹)æ—¶ï¼Œå¯ä½¿ç”¨ç”Ÿæˆå™¨æ¨¡å¼ã€‚\nä½¿ç”¨ç”Ÿæˆå™¨æ„é€ ç»„åˆæ ‘æˆ–å…¶ä»–å¤æ‚å¯¹è±¡ã€‚\nå®ç°æ–¹æ³•\næ¸…æ™°åœ°å®šä¹‰é€šç”¨æ­¥éª¤ï¼Œ ç¡®ä¿å®ƒä»¬å¯ä»¥åˆ¶é€ æ‰€æœ‰å½¢å¼çš„äº§å“ã€‚ å¦åˆ™ä½ å°†æ— æ³•è¿›ä¸€æ­¥å®æ–½è¯¥æ¨¡å¼ã€‚\nåœ¨åŸºæœ¬ç”Ÿæˆå™¨æ¥å£ä¸­å£°æ˜è¿™äº›æ­¥éª¤ã€‚\nä¸ºæ¯ä¸ªå½¢å¼çš„äº§å“åˆ›å»ºå…·ä½“ç”Ÿæˆå™¨ç±»ï¼Œ å¹¶å®ç°å…¶æ„é€ æ­¥éª¤ã€‚\nè€ƒè™‘åˆ›å»ºä¸»ç®¡ç±»ã€‚ å®ƒå¯ä»¥ä½¿ç”¨åŒä¸€ç”Ÿæˆå™¨å¯¹è±¡æ¥å°è£…å¤šç§æ„é€ äº§å“çš„æ–¹å¼ã€‚\nå®¢æˆ·ç«¯ä»£ç ä¼šåŒæ—¶åˆ›å»ºç”Ÿæˆå™¨å’Œä¸»ç®¡å¯¹è±¡ã€‚\nåªæœ‰åœ¨æ‰€æœ‰äº§å“éƒ½éµå¾ªç›¸åŒæ¥å£çš„æƒ…å†µä¸‹ï¼Œ æ„é€ ç»“æœå¯ä»¥ç›´æ¥é€šè¿‡ä¸»ç®¡ç±»è·å–ã€‚å¦åˆ™ï¼Œå®¢æˆ·ç«¯åº”å½“é€šè¿‡ç”Ÿæˆå™¨è·å–æ„é€ ç»“æœã€‚\nä¼˜ç¼ºç‚¹\nä¼˜ç‚¹\nä½ å¯ä»¥åˆ†æ­¥åˆ›å»ºå¯¹è±¡ï¼Œ æš‚ç¼“åˆ›å»ºæ­¥éª¤æˆ–é€’å½’è¿è¡Œåˆ›å»ºæ­¥éª¤ã€‚\nç”Ÿæˆä¸åŒå½¢å¼çš„äº§å“æ—¶ï¼Œ ä½ å¯ä»¥å¤ç”¨ç›¸åŒçš„åˆ¶é€ ä»£ç ã€‚\nå•ä¸€èŒè´£åŸåˆ™ã€‚ ä½ å¯ä»¥å°†å¤æ‚æ„é€ ä»£ç ä»äº§å“çš„ä¸šåŠ¡é€»è¾‘ä¸­åˆ†ç¦»å‡ºæ¥ã€‚\nç¼ºç‚¹\nç”±äºè¯¥æ¨¡å¼éœ€è¦æ–°å¢å¤šä¸ªç±»ï¼Œ å› æ­¤ä»£ç æ•´ä½“å¤æ‚ç¨‹åº¦ä¼šæœ‰æ‰€å¢åŠ ã€‚\nåŸå‹ é—®é¢˜\nå¦‚æœä½ æœ‰ä¸€ä¸ªå¯¹è±¡ï¼Œ å¹¶å¸Œæœ›ç”Ÿæˆä¸å…¶å®Œå…¨ç›¸åŒçš„ä¸€ä¸ªå¤åˆ¶å“ï¼Œ\nä½ å¿…é¡»æ–°å»ºä¸€ä¸ªå±äºç›¸åŒç±»çš„å¯¹è±¡ã€‚\nä½ å¿…é¡»éå†åŸå§‹å¯¹è±¡çš„æ‰€æœ‰æˆå‘˜å˜é‡ï¼Œ å¹¶å°†æˆå‘˜å˜é‡å€¼å¤åˆ¶åˆ°æ–°å¯¹è±¡ä¸­ã€‚\nå¸¦æ¥çš„é—®é¢˜ï¼š\næœ‰äº›å¯¹è±¡å¯èƒ½æ‹¥æœ‰ç§æœ‰æˆå‘˜å˜é‡\nå¿…é¡»çŸ¥é“å¯¹è±¡æ‰€å±çš„ç±»æ‰èƒ½åˆ›å»ºå¤åˆ¶å“ï¼Œ æ‰€ä»¥ä»£ç å¿…é¡»ä¾èµ–è¯¥ç±»ã€‚\nè§£å†³æ–¹æ¡ˆ\nåŸå‹æ¨¡å¼å°†å…‹éš†è¿‡ç¨‹å§”æ´¾ç»™è¢«å…‹éš†çš„å®é™…å¯¹è±¡ã€‚ æ¨¡å¼ä¸ºæ‰€æœ‰æ”¯æŒå…‹éš†çš„å¯¹è±¡å£°æ˜äº†ä¸€ä¸ªé€šç”¨æ¥å£ï¼Œ è¯¥æ¥å£è®©ä½ èƒ½å¤Ÿå…‹éš†å¯¹è±¡ï¼Œ åŒæ—¶åˆæ— éœ€å°†ä»£ç å’Œå¯¹è±¡æ‰€å±ç±»è€¦åˆã€‚\næ”¯æŒå…‹éš†çš„å¯¹è±¡å³ä¸ºåŸå‹ã€‚\nç»“æ„\nåŸºæœ¬å®ç°\nåŸå‹(Prototype)æ¥å£å°†å¯¹å…‹éš†æ–¹æ³•è¿›è¡Œå£°æ˜ã€‚åœ¨ç»å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œ å…¶ä¸­åªä¼šæœ‰ä¸€ä¸ªåä¸º clone å…‹éš† çš„æ–¹æ³•ã€‚\nå…·ä½“åŸå‹(Concrete Prototype)ç±»å°†å®ç°å…‹éš†æ–¹æ³•ã€‚é™¤äº†å°†åŸå§‹å¯¹è±¡çš„æ•°æ®å¤åˆ¶åˆ°å…‹éš†ä½“ä¸­ä¹‹å¤–ï¼Œ è¯¥æ–¹æ³•æœ‰æ—¶è¿˜éœ€å¤„ç†å…‹éš†è¿‡ç¨‹ä¸­çš„æç«¯æƒ…å†µï¼Œ ä¾‹å¦‚å…‹éš†å…³è”å¯¹è±¡å’Œæ¢³ç†é€’å½’ä¾èµ– ç­‰ç­‰ã€‚\nå®¢æˆ·ç«¯(Client)å¯ä»¥å¤åˆ¶å®ç°äº†åŸå‹æ¥å£çš„ä»»ä½•å¯¹è±¡ã€‚\nåŸå‹æ³¨å†Œè¡¨å®ç°\nåŸå‹æ³¨å†Œè¡¨(Prototype Registry)æä¾›äº†ä¸€ç§è®¿é—®å¸¸ç”¨åŸå‹çš„ç®€å•æ–¹æ³•ï¼Œ å…¶ä¸­å­˜å‚¨äº†ä¸€ç³»åˆ—å¯ä¾›éšæ—¶å¤åˆ¶çš„é¢„ç”Ÿæˆå¯¹è±¡ã€‚ æœ€ç®€å•çš„æ³¨å†Œè¡¨åŸå‹æ˜¯ä¸€ä¸ª åç§°â†’åŸå‹ çš„å“ˆå¸Œè¡¨ã€‚\nç¤ºä¾‹\nåŸå‹æ¨¡å¼èƒ½è®©ä½ ç”Ÿæˆå®Œå…¨ç›¸åŒçš„å‡ ä½•å¯¹è±¡å‰¯æœ¬ï¼Œ åŒæ—¶æ— éœ€ä»£ç ä¸å¯¹è±¡æ‰€å±ç±»è€¦åˆã€‚\né€‚åˆåº”ç”¨åœºæ™¯\nå¦‚æœä½ éœ€è¦å¤åˆ¶ä¸€äº›å¯¹è±¡ï¼ŒåŒæ—¶åˆå¸Œæœ›ä»£ç ç‹¬ç«‹äºè¿™äº›å¯¹è±¡æ‰€å±çš„å…·ä½“ç±»ï¼Œå¯ä»¥ä½¿ç”¨åŸå‹æ¨¡å¼ã€‚\nå¦‚æœå­ç±»çš„åŒºåˆ«ä»…åœ¨äºå…¶å¯¹è±¡çš„åˆå§‹åŒ–æ–¹å¼ï¼Œé‚£ä¹ˆä½ å¯ä»¥ä½¿ç”¨è¯¥æ¨¡å¼æ¥å‡å°‘å­ç±»çš„æ•°é‡ã€‚ åˆ«äººåˆ›å»ºè¿™äº›å­ç±»çš„ç›®çš„å¯èƒ½æ˜¯ä¸ºäº†åˆ›å»ºç‰¹å®šç±»å‹çš„å¯¹è±¡ã€‚\nå®ç°æ–¹å¼\nåˆ›å»ºåŸå‹æ¥å£ï¼Œ å¹¶åœ¨å…¶ä¸­å£°æ˜ å…‹éš† æ–¹æ³•\nåŸå‹ç±»å¿…é¡»å¦è¡Œå®šä¹‰ä¸€ä¸ªä»¥è¯¥ç±»å¯¹è±¡ä¸ºå‚æ•°çš„æ„é€ å‡½æ•°ã€‚ æ„é€ å‡½æ•°å¿…é¡»å¤åˆ¶å‚æ•°å¯¹è±¡ä¸­çš„æ‰€æœ‰æˆå‘˜å˜é‡å€¼åˆ°æ–°å»ºå®ä½“ä¸­ã€‚\nå…‹éš†æ–¹æ³•é€šå¸¸åªæœ‰ä¸€è¡Œä»£ç : ä½¿ç”¨ new è¿ç®—ç¬¦è°ƒç”¨åŸå‹ç‰ˆæœ¬çš„æ„é€ å‡½æ•°ã€‚\nä½ è¿˜å¯ä»¥åˆ›å»ºä¸€ä¸ªä¸­å¿ƒåŒ–åŸå‹æ³¨å†Œè¡¨ï¼Œ ç”¨äºå­˜å‚¨å¸¸ç”¨åŸå‹ã€‚\nä¼˜ç¼ºç‚¹\nä¼˜ç‚¹\nä½ å¯ä»¥å…‹éš†å¯¹è±¡ï¼Œ è€Œæ— éœ€ä¸å®ƒä»¬æ‰€å±çš„å…·ä½“ç±»ç›¸è€¦åˆã€‚\nä½ å¯ä»¥å…‹éš†é¢„ç”ŸæˆåŸå‹ï¼Œ é¿å…åå¤è¿è¡Œåˆå§‹åŒ–ä»£ç ã€‚\nä½ å¯ä»¥æ›´æ–¹ä¾¿åœ°ç”Ÿæˆå¤æ‚å¯¹è±¡ã€‚\nä½ å¯ä»¥ç”¨ç»§æ‰¿ä»¥å¤–çš„æ–¹å¼æ¥å¤„ç†å¤æ‚å¯¹è±¡çš„ä¸åŒé…ç½®ã€‚\nç¼ºç‚¹\nå…‹éš†åŒ…å«å¾ªç¯å¼•ç”¨çš„å¤æ‚å¯¹è±¡å¯èƒ½ä¼šéå¸¸éº»çƒ¦ã€‚\nå•ä¾‹ é—®é¢˜\nå•ä¾‹æ¨¡å¼åŒæ—¶è§£å†³äº†ä¸¤ä¸ªé—®é¢˜ï¼Œ æ‰€ä»¥è¿åäº†_å•ä¸€èŒè´£åŸåˆ™\nä¿è¯ä¸€ä¸ªç±»åªæœ‰ä¸€ä¸ªå®ä¾‹\nä¸ºè¯¥å®ä¾‹æä¾›ä¸€ä¸ªå…¨å±€è®¿é—®èŠ‚ç‚¹ã€‚\nç»“æ„\nç»“æ„å‹æ¨¡å¼\nç»“æ„å‹æ¨¡å¼ä»‹ç»å¦‚ä½•å°†å¯¹è±¡å’Œç±»ç»„è£…æˆè¾ƒå¤§çš„ç»“æ„ï¼Œ å¹¶åŒæ—¶ä¿æŒç»“æ„çš„çµæ´»å’Œé«˜æ•ˆã€‚\né€‚é…å™¨ é—®é¢˜\nè§£å†³æ–¹æ¡ˆ\nç»“æ„\nå¯¹è±¡é€‚é…å™¨\nå®ç°æ—¶ä½¿ç”¨äº†æ„æˆåŸåˆ™: é€‚é…å™¨å®ç°äº†å…¶ä¸­ä¸€ä¸ªå¯¹è±¡çš„æ¥å£ï¼Œ å¹¶å¯¹å¦ä¸€ä¸ªå¯¹è±¡è¿›è¡Œå°è£…ã€‚\nç±»é€‚é…å™¨\nä½¿ç”¨äº†ç»§æ‰¿æœºåˆ¶: é€‚é…å™¨åŒæ—¶ç»§æ‰¿ä¸¤ä¸ªå¯¹è±¡çš„æ¥å£\nç¤ºä¾‹\né€‚åˆåº”ç”¨åœºæ™¯\nå½“ä½ å¸Œæœ›ä½¿ç”¨æŸä¸ªç±»ï¼Œä½†æ˜¯å…¶æ¥å£ä¸å…¶ä»–ä»£ç ä¸å…¼å®¹æ—¶ï¼Œå¯ä»¥ä½¿ç”¨é€‚é…å™¨ç±»ã€‚\nå¦‚æœæ‚¨éœ€è¦å¤ç”¨è¿™æ ·ä¸€äº›ç±»ï¼Œä»–ä»¬å¤„äºåŒä¸€ä¸ªç»§æ‰¿ä½“ç³»ï¼Œå¹¶ ä¸”ä»–ä»¬åˆæœ‰äº†é¢å¤–çš„ä¸€äº›å…±åŒçš„æ–¹æ³•ï¼Œ ä½†æ˜¯è¿™äº›å…±åŒçš„æ–¹æ³• ä¸æ˜¯æ‰€æœ‰åœ¨è¿™ä¸€ç»§æ‰¿ä½“ç³»ä¸­çš„å­ç±»æ‰€å…·æœ‰çš„å…±æ€§ã€‚\nä¼˜ç¼ºç‚¹\nä¼˜ç‚¹\nå•ä¸€èŒè´£åŸåˆ™ï¼šå°†æ¥å£æˆ–æ•°æ®è½¬æ¢ä»£ç ä»ç¨‹åºä¸»è¦ä¸šåŠ¡é€»è¾‘ä¸­åˆ†ç¦»ã€‚\nå¼€é—­åŸåˆ™ï¼šåªè¦å®¢æˆ·ç«¯ä»£ç é€šè¿‡å®¢æˆ·ç«¯æ¥å£ä¸é€‚é…å™¨è¿›è¡Œäº¤äº’ï¼Œ ä½ å°±èƒ½åœ¨ä¸ä¿®æ”¹ç°æœ‰å®¢æˆ·ç«¯ä»£ç çš„æƒ…å†µä¸‹åœ¨ç¨‹åºä¸­æ·»åŠ æ–°ç±»å‹çš„é€‚é…å™¨ã€‚\nç¼ºç‚¹\nä»£ç æ•´ä½“å¤æ‚åº¦å¢åŠ ï¼Œ å› ä¸ºä½ éœ€è¦æ–°å¢ä¸€ç³»åˆ—æ¥å£å’Œç±»ã€‚\næ¡¥æ¥ é—®é¢˜\nè§£å†³æ–¹æ¡ˆ\næ¡¥æ¥æ¨¡å¼é€šè¿‡å°†ç»§æ‰¿æ”¹ä¸ºç»„åˆçš„æ–¹å¼æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚\nç»“æ„\nç¤ºä¾‹\né€‚åˆåº”ç”¨åœºæ™¯\nå¦‚æœä½ æƒ³è¦æ‹†åˆ†æˆ–é‡ç»„ä¸€ä¸ªå…·æœ‰å¤šé‡åŠŸèƒ½çš„åºæ‚ç±»(ä¾‹å¦‚èƒ½ä¸å¤šä¸ªæ•°æ®åº“æœåŠ¡å™¨è¿›è¡Œäº¤äº’çš„ç±»)ï¼Œå¯ä»¥ä½¿ç”¨æ¡¥æ¥æ¨¡å¼ã€‚\nå¦‚æœä½ å¸Œæœ›åœ¨å‡ ä¸ªç‹¬ç«‹ç»´åº¦ä¸Šæ‰©å±•ä¸€ä¸ªç±»ï¼Œå¯ä½¿ç”¨è¯¥æ¨¡å¼ã€‚\nå¦‚æœä½ éœ€è¦åœ¨è¿è¡Œæ—¶åˆ‡æ¢ä¸åŒå®ç°æ–¹æ³•ï¼Œå¯ä½¿ç”¨æ¡¥æ¥æ¨¡å¼ã€‚\nç»„åˆ ç»„åˆæ˜¯ä¸€ç§ç»“æ„å‹è®¾è®¡æ¨¡å¼ï¼Œ ä½ å¯ä»¥ä½¿ç”¨å®ƒå°†å¯¹è±¡ç»„åˆæˆæ ‘çŠ¶ç»“æ„ï¼Œå¹¶ä¸”èƒ½åƒä½¿ç”¨ç‹¬ç«‹å¯¹è±¡ä¸€æ ·ä½¿ç”¨å®ƒä»¬ã€‚\né—®é¢˜\nå¦‚æœåº”ç”¨çš„æ ¸å¿ƒæ¨¡å‹èƒ½ç”¨æ ‘çŠ¶ç»“æ„è¡¨ç¤ºï¼Œ åœ¨åº”ç”¨ä¸­ä½¿ç”¨ç»„åˆæ¨¡å¼æ‰æœ‰ä»·å€¼ã€‚\nå®šè´­ç³»ç»Ÿï¼šå¹¶ä¸èƒ½ç®€å•åœ°ä½¿ç”¨å¾ªç¯è¯­å¥æ¥è®¡ç®—è®¢å•æ€»ä»·ã€‚\nè§£å†³æ–¹æ¡ˆ\nç»„åˆæ¨¡å¼å»ºè®®ä½¿ç”¨ä¸€ä¸ªé€šç”¨æ¥å£æ¥ä¸ äº§å“ å’Œ ç›’å­ è¿›è¡Œäº¤äº’ï¼Œ å¹¶ä¸”åœ¨è¯¥æ¥å£ä¸­å£°æ˜ä¸€ä¸ªè®¡ç®—æ€»ä»·çš„æ–¹æ³•ã€‚ä»¥é€’å½’æ–¹å¼å¤„ç†å¯¹è±¡æ ‘ä¸­çš„æ‰€æœ‰é¡¹ç›®ã€‚\nç»“æ„\nç»„ä»¶(Component)æ¥å£æè¿°äº†æ ‘ä¸­ç®€å•é¡¹ç›®å’Œå¤æ‚é¡¹ç›®æ‰€ å…±æœ‰çš„æ“ä½œã€‚\nå¶èŠ‚ç‚¹(Leaf)æ˜¯æ ‘çš„åŸºæœ¬ç»“æ„ï¼Œå®ƒä¸åŒ…å«å­é¡¹ç›®ã€‚ ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œ å¶èŠ‚ç‚¹æœ€ç»ˆä¼šå®Œæˆå¤§éƒ¨åˆ†çš„å®é™…å·¥ä½œï¼Œ å› ä¸ºå®ƒ\nä»¬æ— æ³•å°†å·¥ä½œæŒ‡æ´¾ç»™å…¶ä»–éƒ¨åˆ†ã€‚\nå®¹å™¨(Container)\u0026mdash;\u0026mdash;åˆå\u0026quot;ç»„åˆ(Composite)\u0026rdquo;\u0026mdash;\u0026mdash;æ˜¯åŒ…å«å¶ èŠ‚ç‚¹æˆ–å…¶ä»–å®¹å™¨ç­‰å­é¡¹ç›®çš„å•ä½ã€‚ å®¹å™¨ä¸çŸ¥é“å…¶å­é¡¹ç›®æ‰€å± çš„å…·ä½“ç±»ï¼Œ å®ƒåªé€šè¿‡é€šç”¨çš„ç»„ä»¶æ¥å£ä¸å…¶å­é¡¹ç›®äº¤äº’ã€‚\nå®¢æˆ·ç«¯(Client)é€šè¿‡ç»„ä»¶æ¥å£ä¸æ‰€æœ‰é¡¹ç›®äº¤äº’ã€‚\nç¤ºä¾‹\nå‡ ä½•å½¢çŠ¶ç¼–è¾‘å™¨\né€‚ç”¨åœºæ™¯\néœ€è¦å®ç°æ ‘çŠ¶å¯¹è±¡ç»“æ„\nå¸Œæœ›å®¢æˆ·ç«¯ä»£ç ä»¥ç›¸åŒæ–¹å¼å¤„ç†ç®€å•å’Œå¤æ‚å…ƒç´ \nä¼˜ç¼ºç‚¹\nä¼˜ç‚¹\nä»¥åˆ©ç”¨å¤šæ€å’Œé€’å½’æœºåˆ¶æ›´æ–¹ä¾¿åœ°ä½¿ç”¨å¤æ‚æ ‘ç»“æ„\nå¼€é—­åŸåˆ™\nç¼ºç‚¹\nå¯¹äºåŠŸèƒ½å·®å¼‚è¾ƒå¤§çš„ç±»ï¼Œ æä¾›å…¬å…±æ¥å£æˆ–è®¸ä¼šæœ‰å›°éš¾ã€‚ åœ¨ç‰¹å®šæƒ…å†µä¸‹ï¼Œ ä½ éœ€è¦è¿‡åº¦ä¸€èˆ¬åŒ–ç»„ä»¶æ¥å£ï¼Œ ä»¤äººéš¾ä»¥ç†è§£ã€‚\nè£…é¥° è£…é¥°æ˜¯ä¸€ç§ç»“æ„å‹è®¾è®¡æ¨¡å¼ï¼Œ å…è®¸ä½ é€šè¿‡å°†å¯¹è±¡æ”¾å…¥åŒ…å«è¡Œä¸ºçš„ç‰¹æ®Šå°è£…å¯¹è±¡ä¸­æ¥ä¸ºåŸå¯¹è±¡ç»‘å®šæ–°çš„è¡Œä¸ºã€‚\né—®é¢˜\nå¼€å‘ä¸€ä¸ªæä¾›é€šçŸ¥åŠŸèƒ½çš„åº“ï¼š\nç¨‹åºå¯ä»¥ä½¿ç”¨é€šçŸ¥å™¨ç±»å‘é¢„å®šä¹‰çš„é‚®ç®±å‘é€é‡è¦äº‹ä»¶é€šçŸ¥ã€‚\nåæ¥é™¤äº†éœ€è¦æ”¯æŒé‚®ç®±ï¼Œè¿˜éœ€è¦å¾®ä¿¡ã€QQã€æ‰‹æœºçŸ­ä¿¡ã€‚\næ¯ç§é€šçŸ¥ç±»å‹éƒ½å°†ä½œä¸ºé€šçŸ¥å™¨çš„ä¸€ä¸ªå­ç±»å¾—ä»¥å®ç°ã€‚\nå¦‚æœéœ€è¦åŒæ—¶ä½¿ç”¨å¤šç§é€šçŸ¥æ–¹å¼å‘¢ï¼Ÿ\nå­ç±»ç»„åˆæ•°é‡çˆ†ç‚¸ã€‚\nè§£å†³æ–¹æ¡ˆ\nå½“ä½ éœ€è¦æ›´æ”¹ä¸€ä¸ªå¯¹è±¡çš„è¡Œä¸ºæ—¶ï¼Œ ç¬¬ä¸€ä¸ªè·³å…¥è„‘æµ·çš„æƒ³æ³•å°±æ˜¯æ‰©å±•å®ƒæ‰€å±çš„ç±»ã€‚ ä½†ç»§æ‰¿å¯èƒ½å¸¦æ¥ä¸€äº›ä¸¥é‡é—®é¢˜ï¼š\nç»§æ‰¿æ˜¯é™æ€çš„ã€‚ ä½ æ— æ³•åœ¨è¿è¡Œæ—¶æ›´æ”¹å·²æœ‰å¯¹è±¡çš„è¡Œä¸ºï¼Œ åªèƒ½ ä½¿ç”¨ç”±ä¸åŒå­ç±»åˆ›å»ºçš„å¯¹è±¡æ¥æ›¿ä»£å½“å‰çš„æ•´ä¸ªå¯¹è±¡ã€‚\nå­ç±»åªèƒ½æœ‰ä¸€ä¸ªçˆ¶ç±»ã€‚ å¤§éƒ¨åˆ†ç¼–ç¨‹è¯­è¨€ä¸å…è®¸ä¸€ä¸ªç±»åŒæ—¶ç»§ æ‰¿å¤šä¸ªç±»çš„è¡Œä¸ºã€‚\nèšåˆ(æˆ–ç»„åˆ)ç»„åˆæ˜¯è®¸å¤šè®¾è®¡æ¨¡å¼èƒŒåçš„å…³é”®åŸåˆ™(åŒ…æ‹¬ è£…é¥°åœ¨å†…)ã€‚\nåœ¨æ¶ˆæ¯é€šçŸ¥ç¤ºä¾‹ä¸­ï¼Œ æˆ‘ä»¬å¯ä»¥å°†ç®€å•é‚®ä»¶é€šçŸ¥è¡Œä¸ºæ”¾åœ¨ åŸºç±» é€šçŸ¥å™¨ ä¸­ï¼Œä½†å°†æ‰€æœ‰å…¶ä»–é€šçŸ¥æ–¹æ³•æ”¾å…¥è£…é¥°ä¸­ã€‚\nå®¢æˆ·ç«¯ä»£ç å¿…é¡»å°†åŸºç¡€é€šçŸ¥å™¨æ”¾å…¥ä¸€ç³»åˆ—è‡ªå·±æ‰€éœ€çš„è£…é¥°ä¸­ã€‚ å› æ­¤æœ€åçš„å¯¹è±¡å°†å½¢æˆä¸€ä¸ªæ ˆç»“æ„ã€‚\nç»“æ„\néƒ¨ä»¶(Component)å£°æ˜å°è£…å™¨å’Œè¢«å°è£…å¯¹è±¡çš„å…¬ç”¨æ¥å£ã€‚\nå…·ä½“éƒ¨ä»¶(Concrete Component)ç±»æ˜¯è¢«å°è£…å¯¹è±¡æ‰€å±çš„ç±»ã€‚å®ƒå®šä¹‰äº†åŸºç¡€è¡Œä¸ºï¼Œ ä½†è£…é¥°ç±»å¯ä»¥æ”¹å˜è¿™äº›è¡Œä¸ºã€‚\nåŸºç¡€è£…é¥°(Base Decorator)ç±»æ‹¥æœ‰ä¸€ä¸ªæŒ‡å‘è¢«å°è£…å¯¹è±¡çš„å¼• ç”¨æˆå‘˜å˜é‡ã€‚\nå…·ä½“è£…é¥°ç±»(Concrete Decorators)å®šä¹‰äº†å¯åŠ¨æ€æ·»åŠ åˆ°éƒ¨ä»¶çš„é¢å¤–è¡Œä¸ºã€‚\nå®¢æˆ·ç«¯(Client)å¯ä»¥ä½¿ç”¨å¤šå±‚è£…é¥°æ¥å°è£…éƒ¨ä»¶ï¼Œåªè¦å®ƒèƒ½ ä½¿ç”¨é€šç”¨æ¥å£ä¸æ‰€æœ‰å¯¹è±¡äº’åŠ¨å³å¯ã€‚\nç¤ºä¾‹\nè£…é¥°æ¨¡å¼èƒ½å¤Ÿå¯¹æ•æ„Ÿæ•°æ®è¿›è¡Œå‹ç¼©å’ŒåŠ å¯†ï¼Œ ä»è€Œå°†æ•°æ®ä»ä½¿ç”¨æ•°æ®çš„ä»£ç ä¸­ç‹¬ç«‹å‡ºæ¥ã€‚\né€‚ç”¨åœºæ™¯\nå¸Œæœ›åœ¨æ— éœ€ä¿®æ”¹ä»£ç çš„æƒ…å†µä¸‹å³å¯ä½¿ç”¨å¯¹è±¡ï¼Œä¸”å¸Œæœ›åœ¨è¿è¡Œæ—¶ä¸ºå¯¹è±¡æ–°å¢é¢å¤–çš„è¡Œä¸º\nå¦‚æœç”¨ç»§æ‰¿æ¥æ‰©å±•å¯¹è±¡è¡Œä¸ºçš„æ–¹æ¡ˆéš¾ä»¥å®ç°æˆ–è€…æ ¹æœ¬ä¸å¯è¡Œï¼Œ ä½ å¯ä»¥ä½¿ç”¨è¯¥æ¨¡å¼ã€‚\nå¤–è§‚\nå¤–è§‚æ˜¯ä¸€ç§ç»“æ„å‹è®¾è®¡æ¨¡å¼ï¼Œ èƒ½ä¸ºç¨‹åºåº“ã€æ¡†æ¶æˆ–å…¶ä»–å¤æ‚ç±»æä¾›ä¸€ä¸ªç®€å•çš„æ¥å£ã€‚\né—®é¢˜\nå‡è®¾ä½ å¿…é¡»åœ¨ä»£ç ä¸­ä½¿ç”¨æŸä¸ªå¤æ‚çš„åº“æˆ–æ¡†æ¶ä¸­çš„ä¼—å¤šå¯¹è±¡ã€‚ æ­£å¸¸æƒ…å†µä¸‹ï¼Œ ä½ éœ€è¦è´Ÿè´£æ‰€æœ‰å¯¹è±¡çš„åˆå§‹åŒ–å·¥ä½œã€ ç®¡ç†å…¶ä¾èµ–å…³ç³»å¹¶æŒ‰æ­£ç¡®çš„é¡ºåºæ‰§è¡Œæ–¹æ³•ç­‰ã€‚ æœ€ç»ˆï¼Œç¨‹åºä¸­ç±»çš„ä¸šåŠ¡é€»è¾‘å°†ä¸ç¬¬ä¸‰æ–¹ç±»çš„å®ç°ç»†èŠ‚ç´§å¯†è€¦åˆï¼Œè¾ƒéš¾ç»´æŠ¤ã€‚\nè§£å†³æ–¹æ¡ˆ\nå¤–è§‚ç±»ä¸ºåŒ…å«è®¸å¤šæ´»åŠ¨éƒ¨ä»¶çš„å¤æ‚å­ç³»ç»Ÿæä¾›ä¸€ä¸ªç®€å•çš„æ¥å£ã€‚ å®¢æˆ·ç«¯åªéœ€è¦è°ƒç”¨æä¾›äº†çœŸæ­£å…³å¿ƒçš„åŠŸèƒ½çš„æ¥å£ã€‚\nç»“æ„ å¤–è§‚(Facade)æä¾›äº†ä¸€ç§è®¿é—®ç‰¹å®šå­ç³»ç»ŸåŠŸèƒ½çš„ä¾¿æ·æ–¹å¼ã€‚\nåˆ›å»ºé™„åŠ å¤–è§‚(Additional Facade)ç±»å¯ä»¥é¿å…å¤šç§ä¸ç›¸å…³çš„åŠŸèƒ½æ±¡æŸ“å•ä¸€å¤–è§‚ä½¿å…¶å˜æˆåˆä¸€ä¸ªå¤æ‚ç»“æ„ã€‚\nå¤æ‚å­ç³»ç»Ÿ(Complex Subsystem)ç”±æ•°åä¸ªä¸åŒå¯¹è±¡æ„æˆã€‚\nå®¢æˆ·ç«¯(Client)ä½¿ç”¨å¤–è§‚ä»£æ›¿å¯¹å­ç³»ç»Ÿå¯¹è±¡çš„ç›´æ¥è°ƒç”¨ã€‚\nç¤ºä¾‹\nä½¿ç”¨å•ä¸ªå¤–è§‚ç±»éš”ç¦»å¤šé‡ä¾èµ–çš„ç¤ºä¾‹ï¼Œåœ¨æœ¬ä¾‹ä¸­ï¼Œ å¤–è§‚æ¨¡å¼ç®€åŒ–äº†å®¢æˆ·ç«¯ä¸å¤æ‚è§†é¢‘è½¬æ¢æ¡†æ¶ä¹‹é—´çš„äº¤äº’ã€‚\né€‚ç”¨åœºæ™¯\nå¦‚æœä½ éœ€è¦ä¸€ä¸ªæŒ‡å‘å¤æ‚å­ç³»ç»Ÿçš„ç›´æ¥æ¥å£ï¼Œä¸”è¯¥æ¥å£çš„åŠŸèƒ½æœ‰é™ï¼Œåˆ™å¯ä»¥ä½¿ç”¨å¤–è§‚æ¨¡å¼ã€‚\nå¦‚æœéœ€è¦å°†å­ç³»ç»Ÿç»„ç»‡ä¸ºå¤šå±‚ç»“æ„ï¼Œå¯ä»¥ä½¿ç”¨å¤–è§‚ã€‚å›åˆ°è§†é¢‘è½¬æ¢æ¡†æ¶çš„ä¾‹å­ã€‚ è¯¥æ¡†æ¶å¯ä»¥æ‹†åˆ†ä¸ºä¸¤ä¸ªå±‚æ¬¡: éŸ³é¢‘ç›¸å…³å’Œè§†é¢‘ç›¸å…³ã€‚ ä½ å¯ä»¥ä¸ºæ¯ä¸ªå±‚æ¬¡åˆ›å»ºä¸€ä¸ªå¤–è§‚ï¼Œ ç„¶åè¦æ±‚å„å±‚çš„ç±»å¿…é¡»é€šè¿‡è¿™äº›å¤–è§‚è¿›è¡Œäº¤äº’ã€‚\näº«å…ƒ\näº«å…ƒæ˜¯ä¸€ç§ç»“æ„å‹è®¾è®¡æ¨¡å¼ï¼Œ å®ƒæ‘’å¼ƒäº†åœ¨æ¯ä¸ªå¯¹è±¡ä¸­ä¿å­˜ æ‰€æœ‰æ•°æ®çš„æ–¹å¼ï¼Œé€šè¿‡å…±äº« å¤šä¸ªå¯¹è±¡æ‰€å…±æœ‰çš„ç›¸åŒçŠ¶æ€ï¼Œ è®©ä½ èƒ½åœ¨æœ‰é™çš„å†…å­˜å®¹é‡ä¸­è½½å…¥æ›´å¤šå¯¹è±¡ã€‚\né—®é¢˜\nå‡è®¾å¼€å‘äº†ä¸€æ¬¾ç®€å•çš„å°„å‡»æ¸¸æˆ:ï¼Œå®ç°äº†çœŸå®çš„ç²’å­ç³»ç»Ÿ ï¼Œ åœ¨ç¼–è¯‘æ¸¸æˆåå°†å…¶å‘é€ç»™äº†ä¸€ä¸ªæœ‹å‹è¿›è¡Œæµ‹è¯• ï¼Œæœ‹å‹çš„è®¾å¤‡æ€§èƒ½è¿œæ¯”ä¸ä¸Šä½ çš„ç”µè„‘ï¼Œ å› æ­¤æ¸¸æˆè¿è¡Œåœ¨ä»–çš„ç”µè„‘ä¸Šæ—¶å¾ˆå¿«å°±ä¼šå‡ºç°é—®é¢˜ã€‚\né—®é¢˜åœ¨äºæ¯ä¸ªç²’å­(ä¸€é¢—å­å¼¹ã€ ä¸€æšå¯¼ å¼¹æˆ–ä¸€å—å¼¹ç‰‡) éƒ½ç”±åŒ…å«å®Œæ•´æ•°æ®çš„ç‹¬ç«‹å¯¹è±¡æ¥è¡¨ç¤º\nè§£å†³æ–¹æ¡ˆ\nç²’å­ Particle ç±»çš„é¢œè‰²(color) å’Œç²¾çµå›¾(sprite)è¿™ä¸¤ä¸ªæˆå‘˜å˜é‡æ‰€æ¶ˆè€—çš„å†…å­˜è¦æ¯”å…¶ä»–å˜é‡å¤šå¾—å¤šï¼Œå¯¹äºæ‰€æœ‰çš„ç²’å­æ¥è¯´ï¼Œè¿™ä¸¤ä¸ªæˆå‘˜å˜é‡æ‰€å­˜å‚¨çš„æ•°æ®å‡ ä¹å®Œå…¨ä¸€æ ·ï¼Œæ¯ä¸ªç²’å­çš„å¦ä¸€äº›çŠ¶æ€(åæ ‡ã€ç§»åŠ¨çŸ¢é‡å’Œé€Ÿåº¦)åˆ™æ˜¯ä¸åŒçš„ã€‚\näº«å…ƒæ¨¡å¼å»ºè®®ä¸åœ¨å¯¹è±¡ä¸­å­˜å‚¨å¤–åœ¨çŠ¶æ€ï¼Œ è€Œæ˜¯å°†å…¶ä¼ é€’ç»™ä¾èµ–äºå®ƒçš„ä¸€ä¸ªç‰¹æ®Šæ–¹æ³•ã€‚ ç¨‹åºåªåœ¨å¯¹è±¡ä¸­ä¿å­˜å†…åœ¨çŠ¶æ€ï¼Œ ä»¥æ–¹ä¾¿åœ¨ä¸åŒæƒ…æ™¯ä¸‹é‡ç”¨ã€‚\nå‡å¦‚èƒ½ä»ç²’å­ç±»ä¸­æŠ½å‡ºå¤–åœ¨çŠ¶æ€ï¼Œ é‚£ä¹ˆæˆ‘ä»¬åªéœ€ä¸‰ä¸ªä¸åŒçš„å¯¹è±¡(å­å¼¹ã€å¯¼å¼¹å’Œå¼¹ç‰‡)å°±èƒ½è¡¨ç¤ºæ¸¸æˆä¸­çš„æ‰€æœ‰ç²’å­ã€‚\nå°†è¿™æ ·ä¸€ä¸ªä»…å­˜å‚¨å†…åœ¨çŠ¶æ€çš„å¯¹è±¡ç§°ä¸ºäº«å…ƒã€‚\nå¤–åœ¨çŠ¶æ€å­˜å‚¨\nåœ¨å¤§éƒ¨åˆ†æƒ…å†µä¸­ï¼Œ å®ƒä»¬ä¼šè¢«ç§»åŠ¨åˆ°å®¹å™¨å¯¹è±¡ä¸­ï¼Œ ä¹Ÿå°±æ˜¯æˆ‘ä»¬åº”ç”¨äº«å…ƒæ¨¡å¼å‰çš„èšåˆå¯¹è±¡ä¸­ã€‚ åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œ å®¹å™¨å¯¹è±¡å°±æ˜¯ä¸»è¦çš„ æ¸¸æˆ Game å¯¹è±¡ï¼Œ å…¶ä¼šå°†æ‰€æœ‰ç²’å­å­˜å‚¨åœ¨åä¸º ç²’å­ particles çš„æˆå‘˜å˜é‡ä¸­ã€‚\näº«å…ƒä¸ä¸å¯å˜æ€§\nç”±äºäº«å…ƒå¯¹è±¡å¯åœ¨ä¸åŒçš„æƒ…æ™¯ä¸­ä½¿ç”¨ï¼Œ ä½ å¿…é¡»ç¡®ä¿å…¶çŠ¶æ€ä¸ èƒ½è¢«ä¿®æ”¹ï¼Œåªèƒ½ç”±æ„é€ å‡½æ•°çš„å‚æ•°è¿›è¡Œä¸€æ¬¡æ€§åˆå§‹åŒ– ã€‚\näº«å…ƒå·¥å‚ å¯ä»¥åˆ›å»ºä¸€ä¸ªå·¥å‚æ–¹æ³•æ¥ç®¡ç†å·²æœ‰äº«å…ƒå¯¹è±¡çš„ç¼“å­˜æ± ã€‚\nç»“æ„\näº«å…ƒæ¨¡å¼åªæ˜¯ä¸€ç§ä¼˜åŒ–ã€‚ åœ¨åº”ç”¨è¯¥æ¨¡å¼ä¹‹å‰ï¼Œ ä½ è¦ç¡®å®šç¨‹åºä¸­å­˜åœ¨ä¸å¤§é‡ç±»ä¼¼å¯¹è±¡åŒæ—¶å ç”¨å†…å­˜ç›¸å…³çš„å†…å­˜æ¶ˆè€—é—®é¢˜ï¼Œ å¹¶ä¸”ç¡®ä¿è¯¥é—®é¢˜æ— æ³•ä½¿ç”¨å…¶ä»–æ›´å¥½çš„æ–¹å¼æ¥è§£å†³ã€‚\näº«å…ƒ(Flyweight)ç±»åŒ…å«åŸå§‹å¯¹è±¡ä¸­éƒ¨åˆ†èƒ½åœ¨å¤šä¸ªå¯¹è±¡ä¸­å…±äº«çš„çŠ¶æ€ã€‚ åŒä¸€äº«å…ƒå¯¹è±¡å¯åœ¨è®¸å¤šä¸åŒæƒ…æ™¯ä¸­ä½¿ç”¨ã€‚ äº«å…ƒä¸­ å­˜å‚¨çš„çŠ¶æ€è¢«ç§°ä¸º\u0026quot;å†…åœ¨çŠ¶æ€\u0026rdquo;ã€‚ ä¼ é€’ç»™äº«å…ƒæ–¹æ³•çš„çŠ¶æ€è¢« ç§°ä¸º\u0026quot;å¤–åœ¨çŠ¶æ€\u0026rdquo;ã€‚\næƒ…æ™¯(Context)ç±»åŒ…å«åŸå§‹å¯¹è±¡ä¸­å„ä¸ç›¸åŒçš„å¤–åœ¨çŠ¶æ€ã€‚æƒ…æ™¯ä¸äº«å…ƒå¯¹è±¡ç»„åˆåœ¨ä¸€èµ·å°±èƒ½è¡¨ç¤ºåŸå§‹å¯¹è±¡çš„å…¨éƒ¨çŠ¶æ€ã€‚\né€šå¸¸æƒ…å†µä¸‹ï¼Œ åŸå§‹å¯¹è±¡çš„è¡Œä¸ºä¼šä¿ç•™åœ¨äº«å…ƒç±»ä¸­ã€‚\nå®¢æˆ·ç«¯(Client)è´Ÿè´£è®¡ç®—æˆ–å­˜å‚¨äº«å…ƒçš„å¤–åœ¨çŠ¶æ€ã€‚\näº«å…ƒå·¥å‚(Flyweight Factory)ä¼šå¯¹å·²æœ‰äº«å…ƒçš„ç¼“å­˜æ± è¿›è¡Œç®¡ç†ã€‚\nç¤ºä¾‹\näº«å…ƒæ¨¡å¼èƒ½æœ‰æ•ˆå‡å°‘åœ¨ç”»å¸ƒä¸Šæ¸²æŸ“æ•°ç™¾ä¸‡ä¸ªæ ‘çŠ¶ å¯¹è±¡æ—¶æ‰€éœ€çš„å†…å­˜ã€‚\né€‚ç”¨åœºæ™¯\nä»…åœ¨ç¨‹åºå¿…é¡»æ”¯æŒå¤§é‡å¯¹è±¡ä¸”æ²¡æœ‰è¶³å¤Ÿçš„å†…å­˜å®¹é‡æ—¶ä½¿ç”¨äº«å…ƒæ¨¡å¼ã€‚\nåº”ç”¨è¯¥æ¨¡å¼æ‰€è·çš„æ”¶ç›Šå¤§å°å–å†³äºä½¿ç”¨å®ƒçš„æ–¹å¼å’Œæƒ…æ™¯ã€‚ å®ƒ åœ¨ä¸‹åˆ—æƒ…å†µä¸­æœ€æœ‰æ•ˆ:\nç¨‹åºéœ€è¦ç”Ÿæˆæ•°é‡å·¨å¤§çš„ç›¸ä¼¼å¯¹è±¡\nè¿™å°†è€—å°½ç›®æ ‡è®¾å¤‡çš„æ‰€æœ‰å†…å­˜\nå¯¹è±¡ä¸­åŒ…å«å¯æŠ½å–ä¸”èƒ½åœ¨å¤šä¸ªå¯¹è±¡é—´å…±äº«çš„é‡å¤çŠ¶æ€ã€‚\nä»£ç† ä»£ç†æ˜¯ä¸€ç§ç»“æ„å‹è®¾è®¡æ¨¡å¼ï¼Œ è®©ä½ èƒ½å¤Ÿæä¾›å¯¹è±¡çš„æ›¿ä»£å“ æˆ–å…¶å ä½ç¬¦ã€‚ä»£ç†æ§åˆ¶ç€å¯¹äºåŸå¯¹è±¡çš„è®¿é—®ï¼Œå¹¶å…è®¸åœ¨ å°†è¯·æ±‚æäº¤ç»™å¯¹è±¡å‰åè¿›è¡Œä¸€äº›å¤„ç†ã€‚\né—®é¢˜\næœ‰è¿™æ ·ä¸€ ä¸ªæ¶ˆè€—å¤§é‡ç³»ç»Ÿèµ„æºçš„å·¨å‹å¯¹è±¡ï¼Œ ä½ åªæ˜¯å¶å°”éœ€è¦ä½¿ç”¨å®ƒ ã€‚å¯ä»¥é€‰æ‹©å®ç°å»¶è¿Ÿåˆå§‹åŒ–: åœ¨å®é™…æœ‰éœ€è¦æ—¶å†åˆ›å»ºè¯¥å¯¹è±¡ï¼Œä½†å¾ˆå¯èƒ½ä¼šå¸¦æ¥å¾ˆå¤šé‡å¤ä»£ç ã€‚ åœ¨ç†æƒ³æƒ…å†µä¸‹ï¼Œ æˆ‘ä»¬å¸Œæœ›å°†ä»£ç ç›´æ¥æ”¾å…¥å¯¹è±¡çš„ç±»ä¸­ï¼Œ ä½†è¿™å¹¶éæ€»æ˜¯èƒ½å®ç°: æ¯”å¦‚ç±»å¯èƒ½æ˜¯ç¬¬ä¸‰æ–¹å°é—­åº“çš„ä¸€éƒ¨åˆ†ã€‚\nè§£å†³æ–¹æ¡ˆ\nä»£ç†æ¨¡å¼å»ºè®®æ–°å»ºä¸€ä¸ªä¸åŸæœåŠ¡å¯¹è±¡æ¥å£ç›¸åŒçš„ä»£ç†ç±»ï¼Œ ç„¶åæ›´æ–°åº”ç”¨ä»¥å°†ä»£ç†å¯¹è±¡ä¼ é€’ç»™æ‰€æœ‰åŸå§‹å¯¹è±¡å®¢æˆ·ç«¯ã€‚\nçœŸå®ä¸–ç•Œç±»æ¯”\nä¿¡ç”¨å¡æ˜¯é“¶è¡Œè´¦æˆ·çš„ä»£ç†ï¼Œ é“¶è¡Œè´¦æˆ·åˆ™æ˜¯ä¸€å¤§æ†ç°é‡‘çš„ä»£ç†ã€‚ ä¿¡ç”¨å¡å’Œç°é‡‘åœ¨æ”¯ä»˜è¿‡ç¨‹ä¸­çš„ç”¨å¤„ç›¸åŒã€‚\nç»“æ„\næœåŠ¡æ¥å£(Service Interface)å£°æ˜äº†æœåŠ¡æ¥å£ã€‚ä»£ç†å¿…é¡»éµå¾ªè¯¥æ¥å£æ‰èƒ½ä¼ªè£…æˆæœåŠ¡å¯¹è±¡ã€‚\næœåŠ¡(Service)ç±»æä¾›äº†ä¸€äº›å®ç”¨çš„ä¸šåŠ¡é€»è¾‘ã€‚\nä»£ç†(Proxy)ç±»åŒ…å«ä¸€ä¸ªæŒ‡å‘æœåŠ¡å¯¹è±¡çš„å¼•ç”¨æˆå‘˜å˜é‡ã€‚\nå®¢æˆ·ç«¯(Client) èƒ½é€šè¿‡åŒä¸€æ¥å£ä¸æœåŠ¡æˆ–ä»£ç†è¿›è¡Œäº¤äº’\nç¤ºä¾‹\næœ¬ä¾‹æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ä»£ç†æ¨¡å¼åœ¨ç¬¬ä¸‰æ–¹è…¾è®¯è§†é¢‘ (TencentVideoï¼Œ ä»£ç ç¤ºä¾‹ä¸­è®°ä¸º TV) ç¨‹åºåº“ä¸­æ·»åŠ å»¶è¿Ÿåˆ\nå§‹åŒ–å’Œç¼“å­˜ã€‚\né€‚ç”¨åœºæ™¯\nå»¶è¿Ÿåˆå§‹åŒ–(è™šæ‹Ÿä»£ç†)ã€‚å¦‚æœä½ æœ‰ä¸€ä¸ªå¶å°”ä½¿ç”¨çš„é‡é‡çº§æœåŠ¡å¯¹è±¡ï¼Œ ä¸€ç›´ä¿æŒè¯¥å¯¹è±¡è¿è¡Œä¼šæ¶ˆè€—ç³»ç»Ÿèµ„æºæ—¶ï¼Œ å¯ä½¿ç”¨ä»£ç†æ¨¡å¼ã€‚\nè®¿é—®æ§åˆ¶(ä¿æŠ¤ä»£ç†)ã€‚å¦‚æœä½ åªå¸Œæœ›ç‰¹å®šå®¢æˆ·ç«¯ä½¿ç”¨æœåŠ¡å¯¹è±¡ï¼Œ è¿™é‡Œçš„å¯¹è±¡å¯ä»¥æ˜¯æ“ä½œç³»ç»Ÿä¸­éå¸¸é‡è¦çš„éƒ¨åˆ†ï¼Œ è€Œå®¢æˆ· ç«¯åˆ™æ˜¯å„ç§å·²å¯åŠ¨çš„ç¨‹åº(åŒ…æ‹¬æ¶æ„ç¨‹åº)ï¼Œæ­¤æ—¶å¯ä½¿ç”¨ä»£ç†æ¨¡å¼ã€‚\næœ¬åœ°æ‰§è¡Œè¿œç¨‹æœåŠ¡(è¿œç¨‹ä»£ç†)ã€‚é€‚ç”¨äºæœåŠ¡å¯¹è±¡ä½äºè¿œç¨‹æœåŠ¡å™¨ä¸Šçš„æƒ…å½¢ã€‚\nè®°å½•æ—¥å¿—è¯·æ±‚(æ—¥å¿—è®°å½•ä»£ç†)ã€‚é€‚ç”¨äºå½“ä½ éœ€è¦ä¿å­˜å¯¹äºæœåŠ¡å¯¹è±¡çš„è¯·æ±‚å†å²è®°å½•æ—¶ã€‚ ä»£ç†å¯ä»¥åœ¨å‘æœåŠ¡ä¼ é€’è¯·æ±‚å‰è¿›è¡Œè®°å½•ã€‚\næ™ºèƒ½å¼•ç”¨ã€‚å¯åœ¨æ²¡æœ‰å®¢æˆ·ç«¯ä½¿ç”¨æŸä¸ªé‡é‡çº§å¯¹è±¡æ—¶ç«‹å³é”€æ¯è¯¥å¯¹è±¡ã€‚\nè¡Œä¸ºæ¨¡å¼ è´£ä»»é“¾ è´£ä»»é“¾æ¨¡å¼æ˜¯ä¸€ç§è¡Œä¸ºè®¾è®¡æ¨¡å¼ï¼Œ å…è®¸ä½ å°†è¯·æ±‚æ²¿ç€å¤„ç†è€…é“¾è¿›è¡Œå‘é€ã€‚ æ”¶åˆ°è¯·æ±‚åï¼Œ æ¯ä¸ªå¤„ç†è€…å‡å¯å¯¹è¯·æ±‚è¿›è¡Œå¤„ç†ï¼Œ æˆ–å°†å…¶ä¼ é€’ç»™é“¾ä¸Šçš„ä¸‹ä¸ªå¤„ç†è€…ã€‚\né—®é¢˜\nä¸€ä¸ªåœ¨çº¿è®¢è´­ç³»ç»Ÿéœ€è¦ä¸€ç³»åˆ—ç¹ççš„æ£€æŸ¥ã€‚\nè§£å†³æ–¹æ¡ˆ\nè´£ä»»é“¾ä¼šå°†ç‰¹å®šè¡Œä¸ºè½¬æ¢ä¸ºè¢«ç§°ä½œå¤„ç†è€…çš„ç‹¬ç«‹å¯¹è±¡ã€‚æ¯ä¸ªæ£€æŸ¥æ­¥éª¤éƒ½å¯è¢«æŠ½å–ä¸ºä»…æœ‰å•ä¸ªæ–¹æ³•çš„ç±»ï¼Œ å¹¶æ‰§è¡Œæ£€æŸ¥æ“ä½œã€‚\nç»“æ„\nå¤„ç†è€…(Handler)å£°æ˜äº†æ‰€æœ‰å…·ä½“å¤„ç†è€…çš„é€šç”¨æ¥å£ã€‚\nåŸºç¡€å¤„ç†è€…(Base Handler)æ˜¯ä¸€ä¸ªå¯é€‰çš„ç±»ï¼Œä½ å¯ä»¥å°†æ‰€æœ‰å¤„ç†è€…å…±ç”¨çš„æ ·æœ¬ä»£ç æ”¾ç½®åœ¨å…¶ä¸­ã€‚\nå…·ä½“å¤„ç†è€…(Concrete Handlers)åŒ…å«å¤„ç†è¯·æ±‚çš„å®é™…ä»£ç ã€‚\nå®¢æˆ·ç«¯(Client)å¯æ ¹æ®ç¨‹åºé€»è¾‘ä¸€æ¬¡æ€§æˆ–è€…åŠ¨æ€åœ°ç”Ÿæˆé“¾ã€‚\né€‚ç”¨åœºæ™¯\nå½“ç¨‹åºéœ€è¦ä½¿ç”¨ä¸åŒæ–¹å¼å¤„ç†ä¸åŒç§ç±»è¯·æ±‚ï¼Œè€Œä¸”è¯·æ±‚ç±»å‹å’Œé¡ºåºé¢„å…ˆæœªçŸ¥æ—¶\nå½“å¿…é¡»æŒ‰é¡ºåºæ‰§è¡Œå¤šä¸ªå¤„ç†è€…æ—¶\nå¦‚æœæ‰€éœ€å¤„ç†è€…åŠå…¶é¡ºåºå¿…é¡»åœ¨è¿è¡Œæ—¶è¿›è¡Œæ”¹å˜\nå‘½ä»¤ å‘½ä»¤æ˜¯ä¸€ç§è¡Œä¸ºè®¾è®¡æ¨¡å¼ï¼Œ å®ƒå¯å°†è¯·æ±‚è½¬æ¢ä¸ºä¸€ä¸ªåŒ…å«ä¸è¯·æ±‚ç›¸å…³çš„æ‰€æœ‰ä¿¡æ¯çš„ç‹¬ç«‹å¯¹è±¡ã€‚è¯¥è½¬æ¢è®©ä½ èƒ½æ ¹æ®ä¸åŒçš„è¯·æ±‚å°†æ–¹æ³•å‚æ•°åŒ–ã€å»¶è¿Ÿè¯·æ±‚æ‰§è¡Œæˆ–å°†å…¶æ”¾å…¥é˜Ÿåˆ—ä¸­ï¼Œä¸”èƒ½å®ç°å¯æ’¤é”€æ“ä½œã€‚\né—®é¢˜\nå¼€å‘ä¸€æ¬¾æ–°çš„æ–‡å­—ç¼–è¾‘å™¨ ï¼ŒåŒ…å«å¤šä¸ªæŒ‰é’®çš„å·¥å…·æ ï¼Œ å¹¶è®©æ¯ä¸ªæŒ‰é’®å¯¹åº”ç¼–è¾‘å™¨çš„ä¸åŒæ“ä½œã€‚\nè§£å†³æ–¹æ¡ˆ\né€šè¿‡å‘½ä»¤è®¿é—®ä¸šåŠ¡é€»è¾‘å±‚\nç»“æ„\nå‘ é€ è€… (Sender)\u0026mdash;\u0026mdash; äº¦ ç§° \u0026ldquo;è§¦ å‘ è€… (Invoker)\u0026rdquo; ï¼šè§¦å‘å‘½ä»¤\nå‘½ä»¤(Command)æ¥å£é€šå¸¸ä»…å£°æ˜ä¸€ä¸ªæ‰§è¡Œå‘½ä»¤çš„æ–¹æ³•ã€‚\nå…·ä½“å‘½ä»¤(Concrete Commands) ä¼šå®ç°å„ç§ç±»å‹çš„è¯·æ±‚ã€‚\næ¥æ”¶è€…(Receiver)ç±»åŒ…å«éƒ¨åˆ†ä¸šåŠ¡é€»è¾‘ã€‚\nå®¢æˆ·ç«¯(Client)ä¼šåˆ›å»ºå¹¶é…ç½®å…·ä½“å‘½ä»¤å¯¹è±¡ã€‚\nä½¿ç”¨åœºæ™¯\néœ€è¦é€šè¿‡æ“ä½œæ¥å‚æ•°åŒ–å¯¹è±¡\næƒ³è¦å°†æ“ä½œæ”¾å…¥é˜Ÿåˆ—ä¸­ã€æ“ä½œçš„æ‰§è¡Œæˆ–è€…è¿œç¨‹æ‰§è¡Œæ“ä½œ\næƒ³è¦å®ç°æ“ä½œå›æ»šåŠŸèƒ½\nè¿­ä»£å™¨ è¿­ä»£å™¨æ¨¡å¼æ˜¯ä¸€ç§è¡Œä¸ºè®¾è®¡æ¨¡å¼ï¼Œ è®©ä½ èƒ½åœ¨ä¸æš´éœ²é›†åˆåº•å±‚è¡¨ç°å½¢å¼ ï¼ˆåˆ—è¡¨ã€ æ ˆå’Œæ ‘ç­‰ï¼‰ çš„æƒ…å†µä¸‹éå†é›†åˆä¸­æ‰€æœ‰çš„å…ƒç´ ã€‚\né—®é¢˜\nå¦‚ä½•éå†é›†åˆ\nè§£å†³æ–¹æ¡ˆ\nè¿­ä»£å™¨æ¨¡å¼çš„ä¸»è¦æ€æƒ³æ˜¯å°†é›†åˆçš„éå†è¡Œä¸ºæŠ½å–ä¸ºå•ç‹¬çš„è¿­ä»£å™¨å¯¹è±¡ã€‚\nç»“æ„\nè¿­ä»£å™¨(Iterator)æ¥å£å£°æ˜äº†éå†é›†åˆæ‰€éœ€çš„æ“ä½œ\nå…·ä½“è¿­ä»£å™¨(Concrete Iterators)å®ç°éå†é›†åˆçš„ä¸€ç§ç‰¹å®šç®—æ³•ã€‚\né›†åˆ(Collection)æ¥å£å£°æ˜ä¸€ä¸ªæˆ–å¤šä¸ªæ–¹æ³•æ¥è·å–ä¸é›†åˆå…¼å®¹çš„è¿­ä»£å™¨ã€‚\nå…·ä½“é›†åˆ(Concrete Collections)ä¼šåœ¨å®¢æˆ·ç«¯è¯·æ±‚è¿­ä»£å™¨æ—¶è¿”å›ä¸€ä¸ªç‰¹å®šçš„å…·ä½“è¿­ä»£å™¨ç±»å®ä½“ã€‚\nå®¢æˆ·ç«¯(Client)é€šè¿‡é›†åˆå’Œè¿­ä»£å™¨çš„æ¥å£ä¸ä¸¤è€…è¿›è¡Œäº¤äº’ã€‚\nä½¿ç”¨åœºæ™¯\nå½“é›†åˆèƒŒåä¸ºå¤æ‚çš„æ•°æ®ç»“æ„ï¼Œä¸”ä½ å¸Œæœ›å¯¹å®¢æˆ·ç«¯éšè—å…¶å¤æ‚æ€§æ—¶\nä½¿ç”¨è¯¥æ¨¡å¼å¯ä»¥å‡å°‘ç¨‹åºä¸­é‡å¤çš„éå†ä»£ç ã€‚\nå¸Œæœ›ä»£ç èƒ½å¤Ÿéå†ä¸åŒçš„ç”šè‡³æ˜¯æ— æ³•é¢„çŸ¥çš„æ•°æ®ç»“æ„\nä¸­ä»‹è€… ä¸­ä»‹è€…æ¨¡å¼æ˜¯ä¸€ç§è¡Œä¸ºè®¾è®¡æ¨¡å¼ï¼Œ èƒ½è®©ä½ å‡å°‘å¯¹è±¡ä¹‹é—´æ··ä¹±æ— åºçš„ä¾èµ–å…³ç³»ã€‚ è¯¥æ¨¡å¼ä¼šé™åˆ¶å¯¹è±¡ä¹‹é—´çš„ç›´æ¥äº¤äº’ï¼Œ è¿«ä½¿å®ƒä»¬é€šè¿‡ä¸€ä¸ªä¸­ä»‹è€…å¯¹è±¡è¿›è¡Œåˆä½œã€‚\né—®é¢˜\nè®¾è®¡åˆ›å»ºå’Œä¿®æ”¹å®¢æˆ·èµ„æ–™çš„å¯¹è¯æ¡† ï¼Œå…ƒç´ é—´å­˜åœ¨è®¸å¤šå…³è”ï¼Œå¦‚ä½•è®¾è®¡å‡å°‘è€¦åˆã€‚\nè§£å†³æ–¹æ¡ˆ\nä¸­ä»‹è€…æ¨¡å¼å»ºè®®ä½ åœæ­¢ç»„ä»¶ä¹‹é—´çš„ç›´æ¥äº¤æµå¹¶ä½¿å…¶ç›¸äº’ç‹¬ç«‹ã€‚ ç»„ä»¶å¿…é¡»è°ƒç”¨ç‰¹æ®Šçš„ä¸­ä»‹è€…å¯¹è±¡ï¼Œ é€šè¿‡ä¸­ä»‹è€…å¯¹è±¡é‡å®šå‘è°ƒç”¨è¡Œä¸ºï¼Œ ä»¥é—´æ¥çš„æ–¹å¼è¿›è¡Œåˆä½œã€‚\nç»“æ„\n","permalink":"https://bleedkagax.github.io/post/1_deep_dive_into_design_patterns/","summary":"\u003ch1 id=\"ä¸€é¢å‘å¯¹è±¡-ç¨‹åºè®¾è®¡-ç®€ä»‹\"\u003e\u003cstrong\u003eä¸€ã€é¢å‘å¯¹è±¡ ç¨‹åºè®¾è®¡ ç®€ä»‹\u003c/strong\u003e\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eå¯¹è±¡ä¹‹é—´çš„å…³ç³»\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/1_deep_dive_into_design_patterns.png\" alt=\"img/1_deep_dive_into_design_patterns.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eä¾èµ–\u003c/strong\u003e:å¯¹ç±» B è¿›è¡Œä¿®æ”¹ä¼šå½±å“åˆ°ç±» A ã€‚\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eå…³è”\u003c/strong\u003e:å¯¹è±¡ A çŸ¥é“å¯¹è±¡ Bã€‚ç±» A ä¾èµ–äºç±» Bã€‚\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eèšåˆ\u003c/strong\u003e:å¯¹è±¡AçŸ¥é“å¯¹è±¡Bä¸”ç”±Bæ„æˆã€‚ç±»Aä¾èµ–äºç±»Bã€‚\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eç»„åˆ\u003c/strong\u003e:å¯¹è±¡ A çŸ¥é“å¯¹è±¡ Bã€ç”± B æ„æˆè€Œä¸”ç®¡ç†ç€ B çš„ç”Ÿå‘½å‘¨ æœŸã€‚ç±» A\nä¾èµ–äºç±» Bã€‚\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eå®ç°\u003c/strong\u003e: ç±» A å®šä¹‰çš„æ–¹æ³•ç”±æ¥å£ B å£°æ˜ã€‚ å¯¹è±¡ A å¯è¢«è§†ä¸ºå¯¹è±¡ Bã€‚ç±» A\nä¾èµ–äºç±» Bã€‚\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eç»§æ‰¿\u003c/strong\u003e: ç±» A ç»§æ‰¿ç±» B çš„æ¥å£å’Œå®ç°ï¼Œ ä½†æ˜¯å¯ä»¥å¯¹å…¶è¿›è¡Œæ‰© å±•ã€‚å¯¹è±¡ A\nå¯è¢«è§†ä¸ºå¯¹è±¡ Bã€‚ç±» A ä¾èµ–äºç±» Bã€‚\u003c/p\u003e","title":"Deep Dive Into Design Patterns"},{"content":"1. Your First Python Program 1.1. Diving In $ python3 humansize.py 1.2. Declaring Functions 1.2.1. Optional and Named Arguments def approximate_size(size, a_kilobyte_is_1024_bytes=True): 1.3. Writing Readable Code 1.3.1. Documentation Strings Triple quotes\ndef approximate_size(size, a_kilobyte_is_1024_bytes=True): \u0026#39;\u0026#39;\u0026#39;Convert a file size to human-readable form. Keyword arguments: size -- file size in bytes a_kilobyte_is_1024_bytes -- if True (default), use multiples of 1024 if False, use multiples of 1000 Returns: string \u0026#39;\u0026#39;\u0026#39; 1.4. TheÂ importÂ Search Path \u0026gt;\u0026gt;\u0026gt; import sys \u0026gt;\u0026gt;\u0026gt; sys.path [\u0026#39;\u0026#39;, \u0026#39;/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python311.zip\u0026#39;, \u0026#39;/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11\u0026#39;, \u0026#39;/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/lib-dynload\u0026#39;, \u0026#39;/Users/kagableed/Library/Python/3.11/lib/python/site-packages\u0026#39;, \u0026#39;/opt/homebrew/lib/python3.11/site-packages\u0026#39;] \u0026gt;\u0026gt;\u0026gt; 1.5. Everything Is An Object one of the functionâ€™s attributes,Â __doc__\n\u0026gt;\u0026gt;\u0026gt; import humansize \u0026gt;\u0026gt;\u0026gt; print(humansize.approximate_size.__doc__) Convert a file size to human-readable form. Keyword arguments: size -- file size in bytes a_kilobyte_is_1024_bytes -- if True (default), use multiples of 1024 if False, use multiples of 1000 Returns: string \u0026gt;\u0026gt;\u0026gt; 1.5.1. Whatâ€™s An Object? In Python, functions areÂ first-class objects. Modules areÂ first-class objects. Classes are first-class objects, and individual instances of a class are also first-class objects. everything in Python is an object. Strings are objects. Lists are objects. Functions are objects. Classes are objects. Class instances are objects. Even modules are objects.\n1.6. Indenting Code Indentation is a language requirement and not a matter of style. Python uses carriage returns to separate statements and a colon and indentation to separate code blocks.\n1.7. Exceptions if size \u0026lt; 0: raise ValueError(\u0026#39;number must be non-negative\u0026#39;) ThisÂ raiseÂ statement is actually creating an instance of theÂ ValueErrorÂ class. If one function doesnâ€™t handle it, the exception is passed to the calling function, then that functionâ€™s calling function, and so on â€œup the stack.â€ If the exception is never handled, your program will crash, Python will print a â€œtracebackâ€ to standard error.\n1.7.1. Catching Import Errors try: import chardet except ImportError: chardet = None try: from lxml import etree except ImportError: import xml.etree.ElementTree as etree 1.8. Unbound Variables You never declare the variableÂ multiple, you just assign a value to it.\nmultiple = 1024 if a_kilobyte_is_1024_bytes else 1000 1.9. Everything is Case-Sensitive All names in Python are case-sensitive: variable names, function names, class names, module names, exception names.\n1.10. Running Scripts importÂ the module\n\u0026gt;\u0026gt;\u0026gt; import humansize \u0026gt;\u0026gt;\u0026gt; humansize.__name__ \u0026#39;humansize\u0026#39; run the module directly as a standalone program, in which caseÂ __name__Â will be a special default value,Â __main__.\n2. Native Datatypes 2.1. Diving In BooleansÂ are eitherÂ TrueÂ orÂ False. NumbersÂ can be integers (1Â andÂ 2), floats (1.1Â andÂ 1.2), fractions (1/2Â andÂ 2/3), or even complex numbers. StringsÂ are sequences of Unicode characters,Â e.g.Â anÂ htmlÂ document. BytesÂ andÂ byte arrays,Â e.g.Â aÂ jpegÂ image file. ListsÂ are ordered sequences of values. TuplesÂ are ordered, immutable sequences of values. SetsÂ are unordered bags of values. DictionariesÂ are unordered bags of key-value pairs. 2.2. Booleans \u0026gt;\u0026gt;\u0026gt; size = 1 \u0026gt;\u0026gt;\u0026gt; size == 1 True 2.3. Numbers \u0026gt;\u0026gt;\u0026gt; type(2.0) \u0026lt;class \u0026#39;float\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; type(1) \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; type(2.0) \u0026lt;class \u0026#39;float\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; isinstance(1, int) True \u0026gt;\u0026gt;\u0026gt; isinstance(1 + 2.0, int) False 2.3.2. Common Numerical Operations \u0026gt;\u0026gt;\u0026gt; 11 / 2 5.5 \u0026gt;\u0026gt;\u0026gt; 11 // 2 5 \u0026gt;\u0026gt;\u0026gt; 11.0 / 2 5.5 \u0026gt;\u0026gt;\u0026gt; 11 ** 2 121 \u0026gt;\u0026gt;\u0026gt; 11 % 2 1 \u0026gt;\u0026gt;\u0026gt; -11 // 2 -6 \u0026gt;\u0026gt;\u0026gt; 11.0 // 2 5.0 2.3.3. Fractions \u0026gt;\u0026gt;\u0026gt; import fractions \u0026gt;\u0026gt;\u0026gt; x = fractions.Fraction(1, 3) \u0026gt;\u0026gt;\u0026gt; x Fraction(1, 3) \u0026gt;\u0026gt;\u0026gt; x * fractions.Fraction(1, 3) Fraction(1, 9) 2.3.4. Trigonometry \u0026gt;\u0026gt;\u0026gt; import math \u0026gt;\u0026gt;\u0026gt; math.tan(math.pi / 2) 1.633123935319537e+16 \u0026gt;\u0026gt;\u0026gt; math.tan(math.pi / 4) 0.9999999999999999 2.3.5. Numbers In A Boolean Context Zero values are false, and non-zero values are true.\n\u0026gt;\u0026gt;\u0026gt; def is_it_true(anything): ... if anything: ... print(\u0026#34;yes, it\u0026#39;s true\u0026#34;) ... else: ... print(\u0026#34;no, it\u0026#39;s false\u0026#34;) ... \u0026gt;\u0026gt;\u0026gt; is_it_true(1) yes, it\u0026#39;s true \u0026gt;\u0026gt;\u0026gt; is_it_true(0) no, it\u0026#39;s false 2.4. Lists 2.4.1. Creating A List \u0026gt;\u0026gt;\u0026gt; a_list = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;mpilgrim\u0026#39;, \u0026#39;z\u0026#39;, \u0026#39;example\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a_list [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;mpilgrim\u0026#39;, \u0026#39;z\u0026#39;, \u0026#39;example\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a_list[0] \u0026#39;a\u0026#39; \u0026gt;\u0026gt;\u0026gt; a_list[-1] \u0026#39;example\u0026#39; a_list[-n] == a_list[len(a_list) -Â n]\n2.4.2. Slicing A List \u0026gt;\u0026gt;\u0026gt; a_list [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;mpilgrim\u0026#39;, \u0026#39;z\u0026#39;, \u0026#39;example\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a_list[1:3] [\u0026#39;b\u0026#39;, \u0026#39;mpilgrim\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a_list[1:-1] [\u0026#39;b\u0026#39;, \u0026#39;mpilgrim\u0026#39;, \u0026#39;z\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a_list[1:0] [] \u0026gt;\u0026gt;\u0026gt; a_list[1:-1] [\u0026#39;b\u0026#39;, \u0026#39;mpilgrim\u0026#39;, \u0026#39;z\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a_list[1:4] [\u0026#39;b\u0026#39;, \u0026#39;mpilgrim\u0026#39;, \u0026#39;z\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a_list[1:] [\u0026#39;b\u0026#39;, \u0026#39;mpilgrim\u0026#39;, \u0026#39;z\u0026#39;, \u0026#39;example\u0026#39;] 2.4.3. Adding Items To A List \u0026gt;\u0026gt;\u0026gt; a_list = [\u0026#39;a\u0026#39;] \u0026gt;\u0026gt;\u0026gt; print(id(a_list)) 4309370688 \u0026gt;\u0026gt;\u0026gt; a_list = a_list + [2.0, 3] \u0026gt;\u0026gt;\u0026gt; print(id(a_list)) 4309370432 \u0026gt;\u0026gt;\u0026gt; a_list [\u0026#39;a\u0026#39;, 2.0, 3] \u0026gt;\u0026gt;\u0026gt; a_list.append(True) \u0026gt;\u0026gt;\u0026gt; a_list [\u0026#39;a\u0026#39;, 2.0, 3, True] \u0026gt;\u0026gt;\u0026gt; print(id(a_list)) 4309370432 \u0026gt;\u0026gt;\u0026gt; a_list.extend([\u0026#39;four\u0026#39;, \u0026#39;Î©\u0026#39;]) \u0026gt;\u0026gt;\u0026gt; a_list [\u0026#39;a\u0026#39;, 2.0, 3, True, \u0026#39;four\u0026#39;, \u0026#39;Î©\u0026#39;] \u0026gt;\u0026gt;\u0026gt; print(id(a_list)) 4309370432 \u0026gt;\u0026gt;\u0026gt; a_list.insert(0, \u0026#39;Î©\u0026#39;) \u0026gt;\u0026gt;\u0026gt; a_list [\u0026#39;Î©\u0026#39;, \u0026#39;a\u0026#39;, 2.0, 3, True, \u0026#39;four\u0026#39;, \u0026#39;Î©\u0026#39;] \u0026gt;\u0026gt;\u0026gt; print(id(a_list)) 4309370432 Letâ€™s look closer at the difference betweenÂ append()Â andÂ extend().\n\u0026gt;\u0026gt;\u0026gt; a_list = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a_list.extend([\u0026#39;d\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;f\u0026#39;]) \u0026gt;\u0026gt;\u0026gt; a_list [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;f\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a_list[-1] \u0026#39;f\u0026#39; \u0026gt;\u0026gt;\u0026gt; a_list.append([\u0026#39;g\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;i\u0026#39;]) \u0026gt;\u0026gt;\u0026gt; a_list [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;f\u0026#39;, [\u0026#39;g\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;i\u0026#39;]] \u0026gt;\u0026gt;\u0026gt; a_list[-1] [\u0026#39;g\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;i\u0026#39;] \u0026gt;\u0026gt;\u0026gt; len(a_list) 7 2.4.4. Searching For Values In A List \u0026gt;\u0026gt;\u0026gt; a_list = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;new\u0026#39;, \u0026#39;mpilgrim\u0026#39;, \u0026#39;new\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a_list.count(\u0026#39;new\u0026#39;) 2 \u0026gt;\u0026gt;\u0026gt; \u0026#39;new\u0026#39; in a_list True \u0026gt;\u0026gt;\u0026gt; \u0026#39;c\u0026#39; in a_list False \u0026gt;\u0026gt;\u0026gt; a_list.index(\u0026#39;mpilgrim\u0026#39;) 3 \u0026gt;\u0026gt;\u0026gt; a_list.index(\u0026#39;c\u0026#39;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; ValueError: \u0026#39;c\u0026#39; is not in list \u0026gt;\u0026gt;\u0026gt; a_list.index(\u0026#39;new\u0026#39;) 2 2.4.5. Removing Items From A List \u0026gt;\u0026gt;\u0026gt; a_list = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;new\u0026#39;, \u0026#39;mpilgrim\u0026#39;, \u0026#39;new\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a_list[1] \u0026#39;b\u0026#39; \u0026gt;\u0026gt;\u0026gt; del a_list[1] \u0026gt;\u0026gt;\u0026gt; a_list [\u0026#39;a\u0026#39;, \u0026#39;new\u0026#39;, \u0026#39;mpilgrim\u0026#39;, \u0026#39;new\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a_list[1] \u0026#39;new\u0026#39; \u0026gt;\u0026gt;\u0026gt; a_list.remove(\u0026#39;new\u0026#39;) \u0026gt;\u0026gt;\u0026gt; a_list [\u0026#39;a\u0026#39;, \u0026#39;mpilgrim\u0026#39;, \u0026#39;new\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a_list.remove(\u0026#39;new\u0026#39;) \u0026gt;\u0026gt;\u0026gt; a_list [\u0026#39;a\u0026#39;, \u0026#39;mpilgrim\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a_list.remove(\u0026#39;new\u0026#39;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; ValueError: list.remove(x): x not in list 2.4.6. Removing Items From A List: Bonus Round \u0026gt;\u0026gt;\u0026gt; a_list = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;new\u0026#39;, \u0026#39;mpilgrim\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a_list.pop() \u0026#39;mpilgrim\u0026#39; \u0026gt;\u0026gt;\u0026gt; a_list.pop(1) \u0026#39;b\u0026#39; \u0026gt;\u0026gt;\u0026gt; a_list [\u0026#39;a\u0026#39;, \u0026#39;new\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a_list.pop() \u0026#39;new\u0026#39; \u0026gt;\u0026gt;\u0026gt; a_list.pop() \u0026#39;a\u0026#39; \u0026gt;\u0026gt;\u0026gt; a_list.pop() Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; IndexError: pop from empty list 2.4.7. Lists In A Boolean Context Empty lists are false; all other lists are true.\n\u0026gt;\u0026gt;\u0026gt; def is_it_true(anything): ... if anything: ... print(\u0026#34;yes, it\u0026#39;s true\u0026#34;) ... else: ... print(\u0026#34;no, it\u0026#39;s false\u0026#34;) ... \u0026gt;\u0026gt;\u0026gt; is_it_true([]) no, it\u0026#39;s false \u0026gt;\u0026gt;\u0026gt; is_it_true([\u0026#39;a\u0026#39;]) yes, it\u0026#39;s true \u0026gt;\u0026gt;\u0026gt; is_it_true([False]) yes, it\u0026#39;s true 2.5. Tuples AÂ tupleÂ is an immutable list.\n\u0026gt;\u0026gt;\u0026gt; a_tuple = (\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;mpilgrim\u0026#34;, \u0026#34;z\u0026#34;, \u0026#34;example\u0026#34;) \u0026gt;\u0026gt;\u0026gt; a_tuple[0] \u0026#39;a\u0026#39; \u0026gt;\u0026gt;\u0026gt; a_tuple[-1] \u0026#39;example\u0026#39; \u0026gt;\u0026gt;\u0026gt; a_tuple[1:3] (\u0026#39;b\u0026#39;, \u0026#39;mpilgrim\u0026#39;) \u0026gt;\u0026gt;\u0026gt; print(id(a_tuple)) 4309516128 \u0026gt;\u0026gt;\u0026gt; print(id(a_tuple[1:3])) 4309521728 When you slice a list, you get a new list; when you slice a tuple, you get a new tuple.\n\u0026gt;\u0026gt;\u0026gt; a_tuple (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;mpilgrim\u0026#39;, \u0026#39;z\u0026#39;, \u0026#39;example\u0026#39;) \u0026gt;\u0026gt;\u0026gt; a_tuple.append(\u0026#39;new\u0026#39;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; AttributeError: \u0026#39;tuple\u0026#39; object has no attribute \u0026#39;append\u0026#39; \u0026gt;\u0026gt;\u0026gt; a_tuple.remove(\u0026#39;z\u0026#39;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; AttributeError: \u0026#39;tuple\u0026#39; object has no attribute \u0026#39;remove\u0026#39; \u0026gt;\u0026gt;\u0026gt; a_tuple.index(\u0026#39;example\u0026#39;) 4 \u0026gt;\u0026gt;\u0026gt; \u0026#34;z\u0026#34; in a_tuple True So what are tuples good for?\nTuples are faster than lists. â€œwrite-protectâ€ Some tuples can be used as dictionary keys. \u0026gt;\u0026gt;\u0026gt; list((\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;)) [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;] \u0026gt;\u0026gt;\u0026gt; tuple([\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;]) (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;) Tuples can be converted into lists, and vice-versa. In effect,Â tuple()Â freezes a list, andÂ list()Â thaws a tuple.\n2.5.1. Tuples In A Boolean Context \u0026gt;\u0026gt;\u0026gt; def is_it_true(anything): ... if anything: ... print(\u0026#34;yes, it\u0026#39;s true\u0026#34;) ... else: ... print(\u0026#34;no, it\u0026#39;s false\u0026#34;) ... \u0026gt;\u0026gt;\u0026gt; is_it_true(()) no, it\u0026#39;s false \u0026gt;\u0026gt;\u0026gt; is_it_true((False,)) yes, it\u0026#39;s true \u0026gt;\u0026gt;\u0026gt; type((False,)) \u0026lt;class \u0026#39;tuple\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; type([False,]) \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; 2.5.2. Assigning Multiple Values At Once \u0026gt;\u0026gt;\u0026gt; v = (\u0026#39;a\u0026#39;, 2, True) \u0026gt;\u0026gt;\u0026gt; (x, y, z) = v \u0026gt;\u0026gt;\u0026gt; x \u0026#39;a\u0026#39; \u0026gt;\u0026gt;\u0026gt; y 2 \u0026gt;\u0026gt;\u0026gt; z True \u0026gt;\u0026gt;\u0026gt; (MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY, SUNDAY) = range(7) \u0026gt;\u0026gt;\u0026gt; MONDAY 0 \u0026gt;\u0026gt;\u0026gt; SUNDAY 6 \u0026gt;\u0026gt;\u0026gt; 2.6. Sets 2.6.1. Creating A Set \u0026gt;\u0026gt;\u0026gt; a_set = {1} \u0026gt;\u0026gt;\u0026gt; a_set {1} \u0026gt;\u0026gt;\u0026gt; type(a_set) \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; create a set out of aÂ list.\n\u0026gt;\u0026gt;\u0026gt; a_list = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;mpilgrim\u0026#39;, True, False, 42] \u0026gt;\u0026gt;\u0026gt; a_set = set(a_list) \u0026gt;\u0026gt;\u0026gt; a_set {False, True, \u0026#39;b\u0026#39;, 42, \u0026#39;a\u0026#39;, \u0026#39;mpilgrim\u0026#39;} \u0026gt;\u0026gt;\u0026gt; a_list [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;mpilgrim\u0026#39;, True, False, 42] create an empty set.\n\u0026gt;\u0026gt;\u0026gt; a_set = set() \u0026gt;\u0026gt;\u0026gt; a_set set() \u0026gt;\u0026gt;\u0026gt; type(a_set) \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; not_sure = {} \u0026gt;\u0026gt;\u0026gt; type(not_sure) \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; Due to historical quirks carried over from Python 2, you can not create an empty set with two curly brackets.\n2.6.2. Modifying A Set \u0026gt;\u0026gt;\u0026gt; a_set = {1, 2} \u0026gt;\u0026gt;\u0026gt; a_set.add(4) \u0026gt;\u0026gt;\u0026gt; a_set {1, 2, 4} \u0026gt;\u0026gt;\u0026gt; a_set.update({2, 4, 6}) \u0026gt;\u0026gt;\u0026gt; a_set {1, 2, 4, 6} 2.6.3. Removing Items From A Set \u0026gt;\u0026gt;\u0026gt; a_set = {1, 3, 6, 10, 15, 21, 28, 36, 45} \u0026gt;\u0026gt;\u0026gt; a_set.discard(10) \u0026gt;\u0026gt;\u0026gt; a_set {1, 3, 36, 6, 45, 15, 21, 28} \u0026gt;\u0026gt;\u0026gt; a_set.discard(10) \u0026gt;\u0026gt;\u0026gt; a_set {1, 3, 36, 6, 45, 15, 21, 28} \u0026gt;\u0026gt;\u0026gt; a_set.remove(2) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; KeyError: 2 \u0026gt;\u0026gt;\u0026gt; a_set.remove(1) \u0026gt;\u0026gt;\u0026gt; a_set {3, 36, 6, 45, 15, 21, 28} If the value doesnâ€™t exist in the set, theÂ remove()Â method raises aÂ KeyErrorÂ exception.\n\u0026gt;\u0026gt;\u0026gt; a_set = {1, 3, 6, 10, 15, 21, 28, 36, 45} \u0026gt;\u0026gt;\u0026gt; a_set.pop() 1 \u0026gt;\u0026gt;\u0026gt; a_set.pop() 3 \u0026gt;\u0026gt;\u0026gt; a_set.pop() 36 \u0026gt;\u0026gt;\u0026gt; a_set {6, 10, 45, 15, 21, 28} \u0026gt;\u0026gt;\u0026gt; a_set.clear() \u0026gt;\u0026gt;\u0026gt; a_set.pop() Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; KeyError: \u0026#39;pop from an empty set\u0026#39; 2.6.4. Common Set Operations \u0026gt;\u0026gt;\u0026gt; a_set = {2, 4, 5, 9, 12, 21, 30, 51, 76, 127, 195} \u0026gt;\u0026gt;\u0026gt; 2 in a_set True \u0026gt;\u0026gt;\u0026gt; b_set = {1, 2, 3, 5, 6, 8, 9, 12, 15, 17, 18, 21} \u0026gt;\u0026gt;\u0026gt; a_set.union(b_set) {1, 2, 195, 4, 5, 3, 6, 8, 9, 12, 76, 15, 17, 18, 21, 30, 51, 127} \u0026gt;\u0026gt;\u0026gt; a_set.intersection(b_set) {2, 5, 9, 12, 21} \u0026gt;\u0026gt;\u0026gt; a_set.difference(b_set) {195, 4, 76, 51, 30, 127} \u0026gt;\u0026gt;\u0026gt; a_set.symmetric_difference(b_set) {1, 3, 195, 6, 4, 8, 76, 15, 17, 18, 51, 30, 127} TheÂ symmetric_difference()Â method returns a new set containing all the elements that are inÂ exactly oneÂ of the sets.\nThree of these methods are symmetric.\n\u0026gt;\u0026gt;\u0026gt; b_set.symmetric_difference(a_set) {1, 195, 4, 3, 6, 8, 76, 15, 17, 18, 51, 30, 127} \u0026gt;\u0026gt;\u0026gt; b_set.symmetric_difference(a_set) == a_set.symmetric_difference(b_set) True \u0026gt;\u0026gt;\u0026gt; b_set.union(a_set) == a_set.union(b_set) True \u0026gt;\u0026gt;\u0026gt; b_set.intersection(a_set) == a_set.intersection(b_set) True \u0026gt;\u0026gt;\u0026gt; b_set.difference(a_set) == a_set.difference(b_set) False \u0026gt;\u0026gt;\u0026gt; a_set = {1, 2, 3} \u0026gt;\u0026gt;\u0026gt; b_set = {1, 2, 3, 4} \u0026gt;\u0026gt;\u0026gt; a_set.issubset(b_set) True \u0026gt;\u0026gt;\u0026gt; b_set.issuperset(a_set) True \u0026gt;\u0026gt;\u0026gt; a_set.add(5) \u0026gt;\u0026gt;\u0026gt; a_set.issubset(b_set) False \u0026gt;\u0026gt;\u0026gt; b_set.issuperset(a_set) False 2.6.5. Sets In A Boolean Context \u0026gt;\u0026gt;\u0026gt; def is_it_true(anything): ... if anything: ... print(\u0026#34;yes, it\u0026#39;s true\u0026#34;) ... else: ... print(\u0026#34;no, it\u0026#39;s false\u0026#34;) ... \u0026gt;\u0026gt;\u0026gt; is_it_true(set()) no, it\u0026#39;s false \u0026gt;\u0026gt;\u0026gt; is_it_true({\u0026#39;a\u0026#39;}) yes, it\u0026#39;s true \u0026gt;\u0026gt;\u0026gt; is_it_true({False}) yes, it\u0026#39;s true 2.7. Dictionaries 2.7.1. Creating A Dictionary \u0026gt;\u0026gt;\u0026gt; a_dict {\u0026#39;server\u0026#39;: \u0026#39;db.diveintopython3.org\u0026#39;, \u0026#39;database\u0026#39;: \u0026#39;mysql\u0026#39;} \u0026gt;\u0026gt;\u0026gt; a_dict[\u0026#39;server\u0026#39;] \u0026#39;db.diveintopython3.org\u0026#39; \u0026gt;\u0026gt;\u0026gt; a_dict[\u0026#39;db.diveintopython3.org\u0026#39;] Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; KeyError: \u0026#39;db.diveintopython3.org\u0026#39; 2.7.2. Modifying A Dictionary \u0026gt;\u0026gt;\u0026gt; a_dict {\u0026#39;server\u0026#39;: \u0026#39;db.diveintopython3.org\u0026#39;, \u0026#39;database\u0026#39;: \u0026#39;mysql\u0026#39;} \u0026gt;\u0026gt;\u0026gt; a_dict[\u0026#39;database\u0026#39;] = \u0026#39;blog\u0026#39; \u0026gt;\u0026gt;\u0026gt; a_dict {\u0026#39;server\u0026#39;: \u0026#39;db.diveintopython3.org\u0026#39;, \u0026#39;database\u0026#39;: \u0026#39;blog\u0026#39;} \u0026gt;\u0026gt;\u0026gt; a_dict[\u0026#39;User\u0026#39;] = \u0026#39;mark\u0026#39; \u0026gt;\u0026gt;\u0026gt; a_dict {\u0026#39;server\u0026#39;: \u0026#39;db.diveintopython3.org\u0026#39;, \u0026#39;database\u0026#39;: \u0026#39;blog\u0026#39;, \u0026#39;User\u0026#39;: \u0026#39;mark\u0026#39;} 2.7.3 Mixed-Value Dictionaries Dictionary values can be any datatype, including integers, booleans, arbitrary objects, or even other dictionaries. Dictionary keys are more restricted, but they can be strings, integers, and a few other types.\n\u0026gt;\u0026gt;\u0026gt; SUFFIXES = {1000: [\u0026#39;KB\u0026#39;, \u0026#39;MB\u0026#39;, \u0026#39;GB\u0026#39;, \u0026#39;TB\u0026#39;, \u0026#39;PB\u0026#39;, \u0026#39;EB\u0026#39;, \u0026#39;ZB\u0026#39;, \u0026#39;YB\u0026#39;], ... 1024: [\u0026#39;KiB\u0026#39;, \u0026#39;MiB\u0026#39;, \u0026#39;GiB\u0026#39;, \u0026#39;TiB\u0026#39;, \u0026#39;PiB\u0026#39;, \u0026#39;EiB\u0026#39;, \u0026#39;ZiB\u0026#39;, \u0026#39;YiB\u0026#39;]} \u0026gt;\u0026gt;\u0026gt; len(SUFFIXES) 2 \u0026gt;\u0026gt;\u0026gt; 1000 in SUFFIXES True \u0026gt;\u0026gt;\u0026gt; SUFFIXES[1000] [\u0026#39;KB\u0026#39;, \u0026#39;MB\u0026#39;, \u0026#39;GB\u0026#39;, \u0026#39;TB\u0026#39;, \u0026#39;PB\u0026#39;, \u0026#39;EB\u0026#39;, \u0026#39;ZB\u0026#39;, \u0026#39;YB\u0026#39;] \u0026gt;\u0026gt;\u0026gt; SUFFIXES[1000][3] \u0026#39;TB\u0026#39; 2.7.4. Dictionaries In A Boolean Context Empty dictionaries are false; all other dictionaries are true.\n\u0026gt;\u0026gt;\u0026gt; is_it_true({}) no, it\u0026#39;s false \u0026gt;\u0026gt;\u0026gt; is_it_true({\u0026#39;a\u0026#39;: 1}) yes, it\u0026#39;s true 2.8 None NoneÂ is the only null value. It has its own datatype (NoneType).\n\u0026gt;\u0026gt;\u0026gt; type(None) \u0026lt;class \u0026#39;NoneType\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; None == False False \u0026gt;\u0026gt;\u0026gt; None == 0 False \u0026gt;\u0026gt;\u0026gt; None == None True \u0026gt;\u0026gt;\u0026gt; None == \u0026#39;\u0026#39; False \u0026gt;\u0026gt;\u0026gt; x = None \u0026gt;\u0026gt;\u0026gt; x == None True \u0026gt;\u0026gt;\u0026gt; y = None \u0026gt;\u0026gt;\u0026gt; x == y True 2.8.1. NoneÂ In A Boolean Context \u0026gt;\u0026gt;\u0026gt; is_it_true(None) no, it\u0026#39;s false \u0026gt;\u0026gt;\u0026gt; is_it_true(not None) yes, it\u0026#39;s true 3. Comprehensions 3.1 Diving In Every programming language has that one feature, a complicated thing intentionally made simple. This chapter will teach you about list comprehensions, dictionary comprehensions, and set comprehensions.\n3.2. Working With Files And Directories 3.2.1. The Current Working Directory The current working directory is an invisible property that Python holds in memory at all times.\n\u0026gt;\u0026gt;\u0026gt; import os \u0026gt;\u0026gt;\u0026gt; print(os.getcwd()) /Users/kagableed/Documents \u0026gt;\u0026gt;\u0026gt; os.chdir(\u0026#39;/Users/kagableed/Documents\u0026#39;) \u0026gt;\u0026gt;\u0026gt; print(os.getcwd()) /Users/kagableed/Documents 3.2.2. Working With Filenames and Directory Names \u0026gt;\u0026gt;\u0026gt; print(os.path.join(\u0026#39;/Users/kagableed/Downloads/\u0026#39;, \u0026#39;humansize.py\u0026#39;)) /Users/kagableed/Downloads/humansize.py \u0026gt;\u0026gt;\u0026gt; print(os.path.join(\u0026#39;/Users/kagableed/Downloads\u0026#39;, \u0026#39;humansize.py\u0026#39;)) /Users/kagableed/Downloads/humansize.py \u0026gt;\u0026gt;\u0026gt; print(os.path.expanduser(\u0026#39;~\u0026#39;)) /Users/kagableed \u0026gt;\u0026gt;\u0026gt; print(os.path.join(os.path.expanduser(\u0026#39;~\u0026#39;), \u0026#39;Download\u0026#39;, \u0026#39;humansize.py\u0026#39;)) /Users/kagableed/Download/humansize.py \u0026gt;\u0026gt;\u0026gt; pathname = \u0026#39;/Users/kagableed/Download/humansize.py\u0026#39; \u0026gt;\u0026gt;\u0026gt; os.path.split(pathname) (\u0026#39;/Users/kagableed/Download\u0026#39;, \u0026#39;humansize.py\u0026#39;) \u0026gt;\u0026gt;\u0026gt; (dirname, filename) = os.path.split(pathname) \u0026gt;\u0026gt;\u0026gt; dirname \u0026#39;/Users/kagableed/Download\u0026#39; \u0026gt;\u0026gt;\u0026gt; filename \u0026#39;humansize.py\u0026#39; \u0026gt;\u0026gt;\u0026gt; (shortname, extension) = os.path.splitext(filename) \u0026gt;\u0026gt;\u0026gt; shortname \u0026#39;humansize\u0026#39; \u0026gt;\u0026gt;\u0026gt; extension \u0026#39;.py\u0026#39; 3.2.3. Listing Directories TheÂ globÂ module uses shell-like wildcards.\n\u0026gt;\u0026gt;\u0026gt; import glob \u0026gt;\u0026gt;\u0026gt; glob.glob(\u0026#39;*.log\u0026#39;) [\u0026#39;java_error_in_goland_623.log\u0026#39;, \u0026#39;jbr_err_pid26969.log\u0026#39;, \u0026#39;jbr_err_pid14076.log\u0026#39;, \u0026#39;java_error_in_goland_14076.log\u0026#39;, \u0026#39;java_error_in_goland_38197.log\u0026#39;, \u0026#39;jbr_err_pid1051.log\u0026#39;, \u0026#39;java_error_in_phpstorm_26969.log\u0026#39;, \u0026#39;jbr_err_pid20754.log\u0026#39;] 3.2.4. Getting File Metadata \u0026gt;\u0026gt;\u0026gt; import os \u0026gt;\u0026gt;\u0026gt; print(os.getcwd()) /Users/kagableed \u0026gt;\u0026gt;\u0026gt; metadata = os.stat(\u0026#39;java_error_in_goland_623.log\u0026#39;) \u0026gt;\u0026gt;\u0026gt; metadata.st_mtime 1679028539.770996 \u0026gt;\u0026gt;\u0026gt; import time \u0026gt;\u0026gt;\u0026gt; time.localtime(metadata.st_mtime) time.struct_time(tm_year=2023, tm_mon=3, tm_mday=17, tm_hour=12, tm_min=48, tm_sec=59, tm_wday=4, tm_yday=76, tm_isdst=0) \u0026gt;\u0026gt;\u0026gt; metadata.st_size 384441 \u0026gt;\u0026gt;\u0026gt; os.chdir(\u0026#39;/Users/kagableed/Downloads\u0026#39;) \u0026gt;\u0026gt;\u0026gt; import humansize \u0026gt;\u0026gt;\u0026gt; humansize.approximate_size(metadata.st_size) \u0026#39;375.4 KiB\u0026#39; 3.2.5. Constructing Absolute Pathnames \u0026gt;\u0026gt;\u0026gt; import os \u0026gt;\u0026gt;\u0026gt; print(os.getcwd()) /Users/kagableed/Downloads \u0026gt;\u0026gt;\u0026gt; print(os.path.realpath(\u0026#39;humansize.py\u0026#39;)) /Users/kagableed/Downloads/humansize.py 3.3. List Comprehensions You can use any Python expression in a list comprehension.\n\u0026gt;\u0026gt;\u0026gt; a_list = [1, 9, 8, 4] \u0026gt;\u0026gt;\u0026gt; [elem ** 2 for elem in a_list] [1, 81, 64, 16] \u0026gt;\u0026gt;\u0026gt; a_list = [elem ** 2 for elem in a_list] \u0026gt;\u0026gt;\u0026gt; a_list [1, 81, 64, 16] \u0026gt;\u0026gt;\u0026gt; import os, glob \u0026gt;\u0026gt;\u0026gt; glob.glob(\u0026#39;*.py\u0026#39;) [\u0026#39;humansize.py\u0026#39;] \u0026gt;\u0026gt;\u0026gt; [os.path.realpath(f) for f in glob.glob(\u0026#39;*.py\u0026#39;)] [\u0026#39;/Users/kagableed/Downloads/humansize.py\u0026#39;] \u0026gt;\u0026gt;\u0026gt; import os, glob \u0026gt;\u0026gt;\u0026gt; [(os.stat(f).st_size, os.path.realpath(f)) for f in glob.glob(\u0026#39;*.log\u0026#39;) if os.stat(f).st_size \u0026gt; 10000 ] [(384441, \u0026#39;/Users/kagableed/java_error_in_goland_623.log\u0026#39;), (292827, \u0026#39;/Users/kagableed/java_error_in_goland_14076.log\u0026#39;), (262612, \u0026#39;/Users/kagableed/java_error_in_goland_38197.log\u0026#39;), (280394, \u0026#39;/Users/kagableed/java_error_in_phpstorm_26969.log\u0026#39;)] 3.4. Dictionary Comprehensions \u0026gt;\u0026gt;\u0026gt; import os, glob \u0026gt;\u0026gt;\u0026gt; metadata = [(f, os.stat(f)) for f in glob.glob(\u0026#39;*.log\u0026#39;)] \u0026gt;\u0026gt;\u0026gt; type(metadata) \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; type(metadata[0]) \u0026lt;class \u0026#39;tuple\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; metadata[0] (\u0026#39;java_error_in_goland_623.log\u0026#39;, os.stat_result(st_mode=33188, st_ino=34961543, st_dev=16777232, st_nlink=1, st_uid=501, st_gid=20, st_size=384441, st_atime=1679028542, st_mtime=1679028539, st_ctime=1679028539)) \u0026gt;\u0026gt;\u0026gt; metadata_dict = {f:os.stat(f) for f in glob.glob(\u0026#39;*.log\u0026#39;)} \u0026gt;\u0026gt;\u0026gt; type(metadata_dict) \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; list(metadata_dict.keys()) [\u0026#39;java_error_in_goland_623.log\u0026#39;, \u0026#39;jbr_err_pid26969.log\u0026#39;, \u0026#39;jbr_err_pid14076.log\u0026#39;, \u0026#39;java_error_in_goland_14076.log\u0026#39;, \u0026#39;java_error_in_goland_38197.log\u0026#39;, \u0026#39;jbr_err_pid1051.log\u0026#39;, \u0026#39;java_error_in_phpstorm_26969.log\u0026#39;, \u0026#39;jbr_err_pid20754.log\u0026#39;] \u0026gt;\u0026gt;\u0026gt; metadata_dict[\u0026#39;java_error_in_goland_623.log\u0026#39;].st_size 384441 3.4.1. Other Fun Stuff To Do With Dictionary Comprehensions swapping the keys and values of a dictionary.\n\u0026gt;\u0026gt;\u0026gt; a_dict = {\u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 2, \u0026#39;c\u0026#39;: 3} \u0026gt;\u0026gt;\u0026gt; {value:key for key, value in a_dict.items()} {1: \u0026#39;a\u0026#39;, 2: \u0026#39;b\u0026#39;, 3: \u0026#39;c\u0026#39;} \u0026gt;\u0026gt;\u0026gt; a_dict = {\u0026#39;a\u0026#39;: [1, 2, 3], \u0026#39;b\u0026#39;: 4, \u0026#39;c\u0026#39;: 5} \u0026gt;\u0026gt;\u0026gt; {value:key for key, value in a_dict.items()} Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;dictcomp\u0026gt; TypeError: unhashable type: \u0026#39;list\u0026#39; \u0026gt;\u0026gt;\u0026gt; a_dict = {\u0026#39;a\u0026#39;: (1, 2, 3), \u0026#39;b\u0026#39;: 4, \u0026#39;c\u0026#39;: 5} \u0026gt;\u0026gt;\u0026gt; {value:key for key, value in a_dict.items()} {(1, 2, 3): \u0026#39;a\u0026#39;, 4: \u0026#39;b\u0026#39;, 5: \u0026#39;c\u0026#39;} \u0026gt;\u0026gt;\u0026gt; a_dict = {\u0026#39;a\u0026#39;: {1: 2}, \u0026#39;b\u0026#39;: 4, \u0026#39;c\u0026#39;: 5} \u0026gt;\u0026gt;\u0026gt; {value:key for key, value in a_dict.items()} Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;dictcomp\u0026gt; TypeError: unhashable type: \u0026#39;dict\u0026#39; 3.5. Set Comprehensions \u0026gt;\u0026gt;\u0026gt; a_set = set(range(10)) \u0026gt;\u0026gt;\u0026gt; a_set {0, 1, 2, 3, 4, 5, 6, 7, 8, 9} \u0026gt;\u0026gt;\u0026gt; {x ** 2 for x in a_set} {0, 1, 64, 4, 36, 9, 16, 49, 81, 25} \u0026gt;\u0026gt;\u0026gt; {x ** 2 for x in a_set if x % 2 == 0} {0, 64, 4, 36, 16} 4. Strings 4.1. Some Boring Stuff You Need To Understand Before You Can Dive In Everything you thought you knew about strings is wrong, and there ainâ€™t no such thing as â€œplain text.â€\n4.2. Unicode Unicode is a system designed to representÂ everyÂ character fromÂ everyÂ language. There is exactly 1 number per character, and exactly 1 character per number.\ntodo ","permalink":"https://bleedkagax.github.io/post/dive_into_python_3/","summary":"\u003ch1 id=\"1-your-first-python-program\"\u003e1. Your First Python Program\u003c/h1\u003e\n\u003ch2 id=\"11-diving-in\"\u003e1.1. Diving In\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e$ python3 humansize.py\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"12-declaring-functions\"\u003e1.2. Declaring Functions\u003c/h2\u003e\n\u003ch3 id=\"121-optional-and-named-arguments\"\u003e1.2.1. Optional and Named Arguments\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eapproximate_size\u003c/span\u003e(size, a_kilobyte_is_1024_bytes\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e):\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"13-writing-readable-code\"\u003e1.3. Writing Readable Code\u003c/h2\u003e\n\u003ch3 id=\"131-documentation-strings\"\u003e1.3.1. Documentation Strings\u003c/h3\u003e\n\u003cp\u003eTriple quotes\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eapproximate_size\u003c/span\u003e(size, a_kilobyte_is_1024_bytes\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u0026#39;\u0026#39;Convert a file size to human-readable form.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    Keyword arguments:\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    size -- file size in bytes\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    a_kilobyte_is_1024_bytes -- if True (default), use multiples of 1024\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e                                if False, use multiples of 1000\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    Returns: string\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    \u0026#39;\u0026#39;\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pr","title":"Dive Into Python 3"},{"content":"ã€æµç¨‹å›¾ç±»å°ä½œæ–‡è¡¥å……è¡¨è¾¾ã€‘ ã€è¡¨è¾¾ï¼šæŒç»­æ—¶é—´ã€‘ æŒç»­æ—¶é—´çš„è¡¨è¾¾ It takes TIME to This stage lasts for TIME After a period of TIME During a TIME period For TIME\nã€è¡¨è¾¾ï¼šå°ºå¯¸ã€‘ ä¸åŒå½¢çŠ¶ square/squared rectangle/rectangular circle/circular triangle/triangular trapezoid/trapezoidal\né•¿åº¦/å®½åº¦/æ·±åº¦ length (long) width (wide) depth (deep)\nå®½çª„ wide/broad narrow/tight\nè–„åš thin thick\nã€è¡¨è¾¾ï¼šåŠ¨æ¤ç‰©ç›¸å…³è¯æ±‡ã€‘ æ¤ç‰©ç›¸å…³è¯æ±‡ ç§å­ seeds\nå¹¼è‹— seedlings\nå‘èŠ½ sprout germinate\næå¹² trunk branches twigs\næ ‘å¶ leaves (leaf)\nå¼€èŠ± flower(ing) bloom(ing)\nç»“æœ bear/produce (fruit)\nè½å¶ (leaves) fall defoliate\nç§æ¤ plant grow cultivate\næµ‡æ°´ water\næ–½è‚¥ fertilize\næ”¶è· harvest\nåŠ¨ç‰©ç›¸å…³è¯æ±‡ äº¤é… mate\näº§åµ lay/produce eggs\nå­µåŒ– hatch/incubate (eggs)\nç ´å£³ hatch from the eggs come out of the eggs\nå…»æ®– rear breed\næˆç†Ÿ mature reach maturity\nå†¬çœ  hibernate\næ –æ¯ inhabit perch\nä»¥\u0026hellip;ä¸ºé£Ÿ feed on\nã€è¡¨è¾¾ï¼šå‘ç”Ÿã€‘ â€œå‘ç”Ÿâ€çš„è¡¨è¾¾ take place occur/happen come about\nã€è¡¨è¾¾ï¼šæ–¹å‘ã€‘ æ°´å¹³/å‚ç›´/å€¾æ–œ/å†…å¤– angled/directed/sloped vertical horizontal upward/downward to the inner side to the outer side\nã€è¡¨è¾¾ï¼šé˜¶æ®µã€‘ é˜¶æ®µçš„è¡¨è¾¾ ç¬¬ä¸€é˜¶æ®µ First At the first stage/step Initially In the beginning Beginning at X stage\nç¬¬äºŒé˜¶æ®µ Next Then Subsequently In the next/subsequent step In the following phase\næœ€åçš„é˜¶æ®µ Finally At the final stage In the concluding phase\né˜¶æ®µçš„æ€»ç»“ X consists of three stages X is comprised of three phases Three main stages are shown on the diagram\nã€è¡¨è¾¾ï¼šç”Ÿäº§ç›¸å…³ã€‘ ç”Ÿäº§ç›¸å…³è¯æ±‡ ä½¿ç”¨ utilize employ implement apply\næ”¶é›† gather collect\nå‚¨å­˜ store conserve\nä¼ é€ transport transfer send deliver\næ··åˆ blend mix\næ··åˆç‰© mixture blend(s)\nå‹ç¼© condense compress\nç ”ç£¨ grind crush\nç²‰æœ«/ç¢å— powder(s) pieces chips\nåŠ çƒ­ heat\nçƒ˜å¹² dry\nå†·å´ cool\nå†·è— frozen refrigerate\næ²‰æ·€ settle\næ²‰æ·€ç‰© sediment deposite\nè£…ç½ can bottle\næ‰“åŒ… pack\nåŒ…è£… packaging\nåˆ†å‘ distribute\né“ºè®¾ lay install surface\næ­å»º build construct\næŒ–æ˜ dig excavateÂ ","permalink":"https://bleedkagax.github.io/post/flowchart-essay/","summary":"\u003ch1 id=\"æµç¨‹å›¾ç±»å°ä½œæ–‡è¡¥å……è¡¨è¾¾\"\u003e\u003cstrong\u003eã€æµç¨‹å›¾ç±»å°ä½œæ–‡è¡¥å……è¡¨è¾¾ã€‘\u003c/strong\u003e\u003c/h1\u003e\n\u003ch1 id=\"è¡¨è¾¾æŒç»­æ—¶é—´\"\u003e\u003cstrong\u003eã€è¡¨è¾¾ï¼šæŒç»­æ—¶é—´ã€‘\u003c/strong\u003e\u003c/h1\u003e\n\u003ch2 id=\"æŒç»­æ—¶é—´çš„è¡¨è¾¾\"\u003e\u003cstrong\u003eæŒç»­æ—¶é—´çš„è¡¨è¾¾\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eIt takes TIME to\nThis stage lasts for TIME\nAfter a period of TIME\nDuring a TIME period\nFor TIME\u003c/p\u003e\n\u003ch1 id=\"è¡¨è¾¾å°ºå¯¸\"\u003e\u003cstrong\u003eã€è¡¨è¾¾ï¼šå°ºå¯¸ã€‘\u003c/strong\u003e\u003c/h1\u003e\n\u003ch2 id=\"ä¸åŒå½¢çŠ¶\"\u003e\u003cstrong\u003eä¸åŒå½¢çŠ¶\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003esquare/squared\nrectangle/rectangular\ncircle/circular\ntriangle/triangular\ntrapezoid/trapezoidal\u003c/p\u003e\n\u003ch2 id=\"é•¿åº¦å®½åº¦æ·±åº¦\"\u003e\u003cstrong\u003eé•¿åº¦/å®½åº¦/æ·±åº¦\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003elength (long)\nwidth (wide)\ndepth (deep)\u003c/p\u003e\n\u003ch2 id=\"å®½çª„\"\u003e\u003cstrong\u003eå®½çª„\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003ewide/broad\nnarrow/tight\u003c/p\u003e\n\u003ch2 id=\"è–„åš\"\u003e\u003cstrong\u003eè–„åš\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003ethin\nthick\u003c/p\u003e\n\u003ch1 id=\"è¡¨è¾¾åŠ¨æ¤ç‰©ç›¸å…³è¯æ±‡\"\u003e\u003cstrong\u003eã€è¡¨è¾¾ï¼šåŠ¨æ¤ç‰©ç›¸å…³è¯æ±‡ã€‘\u003c/strong\u003e\u003c/h1\u003e\n\u003ch2 id=\"æ¤ç‰©ç›¸å…³è¯æ±‡\"\u003e\u003cstrong\u003eæ¤ç‰©ç›¸å…³è¯æ±‡\u003c/strong\u003e\u003c/h2\u003e\n\u003ch3 id=\"ç§å­\"\u003e\u003cstrong\u003eç§å­\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eseeds\u003c/p\u003e\n\u003ch3 id=\"å¹¼è‹—\"\u003e\u003cstrong\u003eå¹¼è‹—\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eseedlings\u003c/p\u003e\n\u003ch3 id=\"å‘èŠ½\"\u003e\u003cstrong\u003eå‘èŠ½\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003esprout\ngerminate\u003c/p\u003e","title":"flowchart essay"},{"content":"åŸºç¡€çŸ¥è¯† æ•°å­— è¿è¯»ï¼šdouble 0 , triple 0 7-screen cinema 4-liter engine æ—¶é—´ã€åœ°ç‚¹ã€ç”Ÿæ´»å¸¸è¯†\nåœˆå…³é”®è¯ å‰äºŒåäºŒ ç«–å‘æ¯”è¾ƒ æœ€ç¨³å®šï¼š æ•°å­—ã€åè¯ã€ä¸“æœ‰åè¯\nä¸ç¨³å®šï¼š å½¢å®¹è¯ã€åŠ¨è¯\nå¤§å‘è¯ï¼š å½¢å®¹è¯ï¼ˆæ¯”å¦‚æœ€é«˜çº§\u0026hellip;ï¼‰ å¸¸è§åä¹‰è¯ï¼ˆæ¯”å¦‚ close open\u0026hellip;ï¼‰ å¦å®šè¯ï¼ˆæ¯”å¦‚ noï¼‰\næ‰¾ä¸åŒçœ‹ç‰¹ç‚¹ è¾ƒç¨³å®šï¼š å¬åŸè¯ï¼Œå¥½å®šä½\nä¸ç¨³å®šï¼š æ‰¾æ›¿æ¢è¯ï¼Œçµæ´»åº”å¯¹\nå¤§å‘è¯ï¼š æœ‰é™·é˜±ï¼Œè¦å°å¿ƒ\nä¸‰å¤§ç‰¹å¾ åŸè¯(å‘éŸ³)\né€»è¾‘è¡¨è¾¾ and so, because one thing, another thing, the other but particularly in fact then for example\næ›¿æ¢æ”¹å†™\né”™é¢˜ä¸ƒå‘ è¯éŸ³ï¼ˆè¿è¯»ï¼‰ æ‹¼å†™ å¥å­ é€»è¾‘ æ”¹å†™ æ ¼å¼ å•å¤æ•°\nä¸»æµé…å¯¹å¼åœ°å›¾é¢˜ åœ°æ ‡ï¼šå›¾ä¸­å·²çŸ¥åœ°ç‚¹ æ–¹ä½ï¼šnorth east west south top bottom left right ç§»åŠ¨: ä½ç½®å…³é”® åœ°å›¾é¢˜æŠ€å·§ æ ‡æ³¨æ–¹ä½ åœˆæ‰€æœ‰åœ°åçŒœå‘éŸ³ æŒ‰ç…§é¢˜å·é¡ºåºåœ¨å›¾ä¸­æ ‡è®°ç­”æ¡ˆ é—®é¢˜å°å†™=æ”¹å†™ï¼Œå¯èƒ½æ— æ³•ç›´æ¥å®šä½ ç•™æ„é€»è¾‘å…³ç³»è¿æ¥è¯å¯¹ç­”æ¡ˆçš„æé†’ å¶å‘å¡«ç©ºå¼åœ°å›¾é¢˜ å¾ˆå°‘è€ƒ\næ ‡æ³¨æ–¹ä½ åœˆæ‰€æœ‰åœ°åçŒœå‘éŸ³ æŒ‰ç…§é¢˜å·é¡ºåºåœ¨å›¾ä¸­æ ‡è®°ç­”æ¡ˆ æ ¸å¿ƒè€ƒç‚¹ï¼šå‘éŸ³ã€æ‹¼å†™ å¬åŠ›é…å¯¹é¢˜ çŸ­æ”¹å†™â€”â€”è¯æˆ–è€…è¯ç»„ï¼ˆå±€éƒ¨ï¼‰ æ”¹è¯æ€§ åŒä¹‰è¯ åŒç±»è¯ è§£é‡Šè¯´æ˜ åŒé‡å¦å®š ä»£è¯æ›¿æ¢ è¯­å¢ƒ ç®€å•é¢ å€’\né•¿æ”¹å†™â€”â€”å¥å­ï¼ˆæ•´ä½“ï¼‰ å¥å­A = å¥å­B ä¸»åŠ¨å¥ = è¢«åŠ¨å¥\nå•é€‰é¢˜ ä¸‰å¤§å®šä½æ–¹æ³•ï¼ˆé—®é¢˜é‡ŒåŸè¯ã€é€»è¾‘è¿æ¥è¯ã€é—®é¢˜æ”¹å†™è¯ï¼‰ å¬ä¸æ‡‚+é€‰é¡¹åŸè¯=é™·é˜± å¬åˆ°æ”¹å†™æ›´å®‰å…¨ ç•™æ„é€‰é¡¹é—´çš„å¹¶åˆ—å…³ç³» æ³¨æ„è¯´è¯çš„äººçš„èº«ä»½ä¸æ€§åˆ« é¢„è¯»é¢„åˆ¤é¢˜ç›®é€‰é¡¹ ç”» æ¯é“é¢˜ç‹¬æœ‰çš„å…³é”®å†…å®¹ æœ‰å…·ä½“å†…å®¹çš„å®è¯ å¼ºé€»è¾‘å†…å®¹ï¼š å¦å®š å¹¶åˆ— A and B = B and A è½¬æŠ˜è®©æ­¥ ä¸ç”» æ¯é“é¢˜éƒ½æœ‰çš„å†…å®¹ æ²¡æœ‰å…·ä½“å†…å®¹çš„è™šè¯ æ²¡æœ‰ç‰¹å®šå«ä¹‰çš„åŠ¨è¯ï¼šdoã€haveã€get\u0026hellip; æ‹¼å‘½å¾€ä¸‹é¢„è¯» æŠ“ä½æ—¶é—´é—´éš™\nå­¦ä¼šé¢„åˆ¤ æ•°å­—ã€äººã€å•å¤æ•°\nç”»å…³é”®è¯åªæ˜¯æ‰‹æ®µï¼Œå…³é”®æ˜¯ç†è§£é¢˜ç›®ã€é¢„åˆ¤å†…å®¹ å¬éŸ³ å¤§é‡å•è¯å¬å†™ è¯­éŸ³ç°è±¡ è¿è¯»/è¿éŸ³ è¾…éŸ³+å…ƒéŸ³ è¾…éŸ³+è¾…éŸ³ å…ƒéŸ³+å…ƒéŸ³ åŠ éŸ³è¿è¯»/j/ /w/ å¼±è¯» ä¸€èˆ¬å®è¯é‡è¯»ã€è™šè¯å¼±è¯» å¼‚åŒ–ï¼ˆæµŠåŒ–ï¼‰ åŒåŒ– è¯­éŸ³è¯­è°ƒ æ…¢è¯»ã€é‡è¯»è¡¨å¼ºè°ƒï¼› è¯­éŸ³è¯­è°ƒï¼ˆç–‘é—®ã€å›°æƒ‘ã€æ²®ä¸§ï¼‰ã€‚\nå¬ä¹‰ æ„ç¾¤æ–­å¥ æ„ç¾¤ï¼šthought chunkï¼Œç‹¬ç«‹æ„æ€çš„å°åŒºå— é¡ºå¥é©±åŠ¨ ofä»‹è¯ç†è§£ çš„ length of time å…³äº sheer volume of both observation and investigation\nå®šè¯­ä»å¥ç†è§£ thatã€whichã€who å…ˆä¸»å¥åä»å¥ï¼šå…³äºã€ä»–/è¿™ä¸ª/é‚£å°±æ˜¯ã€ç›´æ¥ä¸ç¿»è¯‘ã€ç›´æ¥é‡å¤å…ˆè¡Œè¯\nç²¾å¬è·Ÿè¯» å¬æ”¹å†™ åŒä¹‰æ›¿æ¢æ”¹å†™ åŒä¹‰è¯ã€è¿‘ä¹‰è¯ã€åŸè¯æ”¹è¯æ€§ significant = important\nè§£é‡Š childhood = when I was a little boy\nä¸¾ä¾‹ã€èŒƒå›´å˜åŒ– pets = dogs and cats change = increase/decrease\nèŠ±å¼æ”¹å†™ ä¸»åŠ¨è¢«åŠ¨æ”¹å†™ å¦å®š+åä¹‰è¯ others å¬é€»è¾‘ å¹¶åˆ— and or also , too then not only, but also as well as one, another on the one hand, one the other hand besides in addition to along with ç¬¦å·ï¼š- ï¼›ç­‰\nå¹¶åˆ—äº¤æ¢ä½ç½® A and B = B and A\napples and other fruits = fruits such as apples\nå¦å®š no/not never/nor/handly ever/rather than/instead of/too to/too/avoid/unfortunately åä¹‰è¯\nè½¬æŠ˜è®©æ­¥ however/but/yet although/though/while/whereas/despite\nPart 1 å¡«ç©ºé¢˜ é¢„è¯»é¢„åˆ¤é¢˜ç›® æ³¨æ„å­—æ•°é™åˆ¶ï¼› ç”»ï¼š\næ¯é“é¢˜ç‹¬æœ‰å†…å®¹ å®è¯ é€»è¾‘å…³ç³»ï¼šå¦å®šã€å¹¶åˆ—ã€è½¬æŠ˜ å¡«ç©ºå‰å† è¯ã€ä»‹è¯ã€æ¯”è¾ƒã€æœ€é«˜çº§ å®šä½ åŸè¯ã€åŒä¹‰æ›¿æ¢ã€ç›¸å¯¹ä½ç½® å…³æ³¨ï¼šæ˜æ˜¾è¯ã€å®è¯ã€é€»è¾‘è¯\nå¡«è¯ å¤‡è€ƒï¼šå¤§é‡å¬å†™ç»ƒä¹ \nè€ƒå¯Ÿï¼š å¥å­å½¢å¼ä¸å˜ï¼Œæ›¿æ¢éƒ¨åˆ†è¯ =\u0026gt; æŒ‰é¡ºåºå¡«è¯ ç›¸å¯¹ä½ç½®é¡ºåºæ”¹å˜ =\u0026gt; é¢„è¯»ã€é‡è¯»æ…¢è¯»ã€å…ˆå¡«åˆé€‚è¯å¯åæ”¹\nå¡«ç©ºé¢˜å¡«æœ€å…·ä½“çš„è¯\né¢˜å¹²ä¸­å·²å‡ºç°è¯ä¸€èˆ¬ä¸ä¼šå†å¡«\nå•å¤æ•°\nå•è¯æ‹¼è¯»ã€æ•°å­—ä¸­æ³¨æ„çš„å‘éŸ³\nz UK/zed/ r w double u =\u0026gt; å¡« w Jay J for jacket å·ç  zero è¯» oh doubleã€triple 23 pounds 70 =\u0026gt; 23.70 é€‰æ‹©é¢˜ ç²¾å¬è·Ÿè¯»\né¢„è¯»é¢„åˆ¤é¢˜ç›® å…ˆè¯»æ‰€æœ‰é¢˜å¹²ï¼Œåè¯»é€‰é¡¹ ç”»å®è¯ã€é€»è¾‘è¯ è‡ªå·±æ¦‚æ‹¬æ¯ä¸ªé€‰é¡¹ æ³¨æ„ç”·/å¥³/bothè§‚ç‚¹\nå®šä½ å®è¯ã€é€»è¾‘è¯ ä¸“æœ‰åè¯\nè§£é¢˜ ä¸æ˜¯å¬åŸè¯æ˜¯æœ‰æ²¡æœ‰æåŠ, è€Œæ˜¯å¬æ„æ€ æ‹‰è¸©ï¼š Aä¸è¡Œ\u0026hellip;ï¼ŒBä¸ç¬¦åˆ\u0026hellip;ï¼Œä½†æ˜¯C\u0026hellip; æ­£ç¡®é€‰é¡¹ç‰¹ç‚¹ï¼š\nåŒä¹‰æ›¿æ¢ è½¬æŠ˜åä¸€èˆ¬æ˜¯é‡ç‚¹ é”™è¯¯é€‰é¡¹ç‰¹ç‚¹ï¼š\nä¿¡æ¯æ— æåŠã€å…³ç³»æ— ä¸­ç”Ÿæœ‰ æåŠäº†ï¼Œä½†æ˜¯å¦å®šè¯æ’é™¤ï¼šno/not/hardly/rather than/too to/avoid/unsual/unfortunately\u0026hellip; æåŠäº†ï¼Œä½†æ˜¯åä¹‰è¯æ’é™¤ï¼šexpensive/cheapã€straightforward/difficultã€straightaway/takes a long time å¹¶åˆ—é”™è¯¯(æ’é™¤æ³•) æåŠäº†ï¼Œä½†æ˜¯ä¸ç¬¦åˆé¢˜ç›®è¦æ±‚ï¼šç°åœ¨åšï¼Ÿä»¥ååšï¼Ÿ ","permalink":"https://bleedkagax.github.io/post/listening-skills/","summary":"\u003ch1 id=\"åŸºç¡€çŸ¥è¯†\"\u003eåŸºç¡€çŸ¥è¯†\u003c/h1\u003e\n\u003cp\u003eæ•°å­—\nè¿è¯»ï¼šdouble 0 , triple 0\n7-screen cinema\n4-liter engine\næ—¶é—´ã€åœ°ç‚¹ã€ç”Ÿæ´»å¸¸è¯†\u003c/p\u003e\n\u003ch1 id=\"åœˆå…³é”®è¯\"\u003eåœˆå…³é”®è¯\u003c/h1\u003e\n\u003ch3 id=\"å‰äºŒåäºŒ-ç«–å‘æ¯”è¾ƒ\"\u003eå‰äºŒåäºŒ ç«–å‘æ¯”è¾ƒ\u003c/h3\u003e\n\u003cp\u003eæœ€ç¨³å®šï¼š\næ•°å­—ã€åè¯ã€ä¸“æœ‰åè¯\u003c/p\u003e\n\u003cp\u003eä¸ç¨³å®šï¼š\nå½¢å®¹è¯ã€åŠ¨è¯\u003c/p\u003e\n\u003cp\u003eå¤§å‘è¯ï¼š\nå½¢å®¹è¯ï¼ˆæ¯”å¦‚æœ€é«˜çº§\u0026hellip;ï¼‰\nå¸¸è§åä¹‰è¯ï¼ˆæ¯”å¦‚ close open\u0026hellip;ï¼‰\nå¦å®šè¯ï¼ˆæ¯”å¦‚ noï¼‰\u003c/p\u003e\n\u003ch3 id=\"æ‰¾ä¸åŒçœ‹ç‰¹ç‚¹\"\u003eæ‰¾ä¸åŒçœ‹ç‰¹ç‚¹\u003c/h3\u003e\n\u003cp\u003eè¾ƒç¨³å®šï¼š\nå¬åŸè¯ï¼Œå¥½å®šä½\u003c/p\u003e\n\u003cp\u003eä¸ç¨³å®šï¼š\næ‰¾æ›¿æ¢è¯ï¼Œçµæ´»åº”å¯¹\u003c/p\u003e\n\u003cp\u003eå¤§å‘è¯ï¼š\næœ‰é™·é˜±ï¼Œè¦å°å¿ƒ\u003c/p\u003e\n\u003ch3 id=\"ä¸‰å¤§ç‰¹å¾\"\u003eä¸‰å¤§ç‰¹å¾\u003c/h3\u003e\n\u003cp\u003eåŸè¯(å‘éŸ³)\u003c/p\u003e\n\u003cp\u003eé€»è¾‘è¡¨è¾¾\nand\nso, because\none thing, another thing, the other\nbut\nparticularly\nin fact\nthen\nfor example\u003c/p\u003e\n\u003cp\u003eæ›¿æ¢æ”¹å†™\u003c/p\u003e\n\u003ch1 id=\"é”™é¢˜ä¸ƒå‘\"\u003eé”™é¢˜ä¸ƒå‘\u003c/h1\u003e\n\u003cp\u003eè¯éŸ³ï¼ˆè¿è¯»ï¼‰\næ‹¼å†™\nå¥å­\né€»è¾‘\næ”¹å†™\næ ¼å¼\nå•å¤æ•°\u003c/p\u003e","title":"listening skills"},{"content":"é›…æ€é˜…è¯» è¯æ±‡ + è¯­æ³• + è§£é¢˜æŠ€å·§ + é˜…è¯»é‡\nè¯­æ³• ä»å¥ éè°“è¯­ æ ¸å¿ƒï¼šåŒä¹‰æ›¿æ¢ åŒä¹‰è¯ åŒä¹‰çŸ­è¯­ åŒä¹‰å¥å­ï¼ˆä¸»åŠ¨è¢«åŠ¨ï¼‰ é¢˜å‹åˆ†ç±» 1. é¡ºåºé¢˜ é¢˜å‹å†…éƒ¨çš„å‡ºé¢˜é¡ºåº\nï¼ˆä¸€èˆ¬ä¸ºé¡ºåºï¼‰ åˆ¤æ–­ å¡«ç©º å›¾å½¢å¡«ç©º é€‰è¯å¡«ç©º å›ç­”é—®é¢˜ å•é€‰ å¥å­åŒ¹é…\n2. ä¹±åºé¢˜ æ®µè½åŒ¹é… Which paragraph contains äººå/å­¦è¯´/å›½å®¶/å…¬å¸ç­‰ä¿¡æ¯åŒ¹é… æ®µè½å¤§æ„ Heading\n3. ç‰¹æ®Šé¢˜ é€‰æ–‡ç« æ ‡é¢˜ Title/å‰¯æ ‡é¢˜ Subtitle å¤šé€‰\nå¹³è¡Œåšé¢˜æ³•ï¼šä¸‰æ­¥èµ° é¢„è¯»é¢˜ç”»å…³é”®è¯ï¼› å¸¦ç€é—®é¢˜å»è¯»æ–‡ç« å®šä½ï¼Œæ–‡ç« åªè¯»ä¸€éã€å„é¢˜å‹å¹³è¡Œ åšé¢˜ï¼› å¯¹æ¯”ç­”æ¡ˆå¥å’Œé¢˜ç›®è¿›è¡Œè§£é¢˜ 1. é¢„è¯»é¢˜ç›®åœˆå…³é”®è¯ åšé¢˜é¡ºåº é¡ºåºé¢˜ ä¿æŒæœ‰ä¸¤é¢˜å·²ç»é¢„è¯»\nä¹±åºé¢˜ é¢„è¯»æ‰€æœ‰é¢˜ç›®ï¼Œç”»å…³é”®è¯\nç‰¹æ®Šé¢˜ é€‰æ ‡é¢˜ï¼šè¯»å®Œå…¨æ–‡å†åšï¼› å¤šé€‰é¢˜ï¼š\né¢„è¯»é¢˜ç›® é¢˜ç›®æä¾›ä¿¡æ¯è¶³å¤Ÿå®šä½ç­”æ¡ˆæ—¶ï¼Œé€‰é¡¹åé¢è¯»ï¼›å¦åˆ™ï¼Œé¢„è¯»é€‰é¡¹ã€‚ ç”»å…³é”®è¯ ä¸ç”»ä»€ä¹ˆï¼Ÿ ä¸»æ—¨è¯ã€é«˜é¢‘è¯ä¸ç”»ã€‚\nä¸ç”»å¸¸è§é¢˜å¹²è¯ï¼Œreferenceã€accountã€mentionã€refer æ— å®é™…æ„ä¹‰ ä¸ç”»æ¯é“é¢˜éƒ½æœ‰çš„å†…å®¹ã€å…¨æ–‡åå¤å‡ºç°çš„è¯ ç”»ä»€ä¹ˆï¼Ÿ ç”»æ—¶é—´ã€æ•°å­—ã€å¤§å†™ä¸“æœ‰åè¯ã€äººåç­‰ ç”»æœ‰å…·ä½“å†…å®¹çš„å®è¯ content wordsã€ä¸ç”»æ²¡æœ‰å…·ä½“å†…å®¹çš„è™šè¯ function words \u0026mdash; ofã€itã€isã€does ç”»æ¯”è¾ƒçº§ã€æœ€é«˜çº§ã€å¦å®šè¯ï¼ˆåˆ¤æ–­é¢˜ï¼‰ ç”»å¡«ç©ºå‰çš„å† è¯ã€å¹¶åˆ—ï¼Œå¯èƒ½æœ‰å¯¹åº” æ³¨æ„ä¸åŒé¢˜ç›®ä¹‹é—´çš„å…³è” é€»è¾‘è¯\næ€»ç»“ é¢„è¯»é¢˜ç›®äº†è§£æ¯é“é¢˜é—®çš„æ˜¯ä»€ä¹ˆé—®é¢˜ï¼ŒæŠ“å¥å­é‡ç‚¹å†…å®¹\n2. è¯»æ–‡ç« å®šä½å…³é”®è¯æˆ–å…¶åŒä¹‰æ›¿æ¢æ”¹å†™ï¼Œå§‹ç»ˆè®°å¾—è‡ªå·±æ¥ä¸‹æ¥è¦åšé¢˜æœ‰å“ªäº› è¯»æ–‡ç« æ—¶è‡ªåŠ¨åœˆå‡º\nè½¬æŠ˜è¯ however/but/although/though/ while/whereas/despite/yet/ notwithstanding/nonetheless/nevertheless/ albeit ç­‰è½¬æŠ˜è¯åæ˜¯é‡ç‚¹\nå¹¶åˆ—è¯ and/or/also/as well as/ both \u0026hellip;and\u0026hellip;/not only\u0026hellip;but also\u0026hellip;/ in addition/besides/along with/ one the hand\u0026hellip; on the other hand\u0026hellip;/ not \u0026hellip;but\u0026hellip;/ either\u0026hellip;or\u0026hellip;/neither\u0026hellip;nor\u0026hellip;/ moreover/one\u0026hellip;another/ åˆ†å·ï¼›ç­‰ï¼Œå¹¶åˆ—å†…å®¹åŒç­‰é‡è¦ï¼› å¹¶åˆ—å…³ç³»æ˜¯å¡«ç©ºé¢˜ã€å¤šé€‰é¢˜è§£é¢˜å…³é”®ã€‚\nå› æœå…³è”è¯ because/because of/ therefore/thereby/ hence/as/since/ leading to/as a result/ due to/thanks to/owing to/ cause/caused by/ stem from/derive/ for/as a contributory factor/ ç­‰ï¼Œåˆ†æ¸…å› æœã€‚\nä¸¾ä¾‹å­ for example/for instance/ \u0026hellip;is a good example/such as/ ç­‰ï¼Œ\nâ€œè§‚ç‚¹ + ä¸¾ä¾‹å­â€œ ä¾‹å­å‰ä¸€èˆ¬ä¸ºé‡è¦è§‚ç‚¹ï¼› ä¾‹å­å¯èƒ½å¯¹åº” which paragraph contain é¢˜ä¸­çš„ an example of\u0026hellip;ã€‚\nto+åŠ¨è¯ to+åŠ¨è¯è¡¨ç›®çš„ï¼Œ â€œä¸ºäº†/æ¥â€ï¼Œç»å¸¸å¯¹åº” aimã€goalã€objectiveã€purposeç­‰\nä»£è¯ it/this/that/they ç­‰å…·ä½“ä»£æŒ‡ä»€ä¹ˆï¼Œå°±å»å‰ä¸€å¥æ‰¾ã€‚\n3. è§£é¢˜ åˆ¤æ–­é¢˜ TRUE/FALSE/NOT GIVEN åº•å±‚é€»è¾‘ True:agree\u0026mdash;ä¸€è‡´ã€ç›¸ç¬¦ã€ä¸€ä¸ªæ„æ€ åŒä¹‰æ›¿æ¢+æ„æ€ä¸€è‡´ ï¼ˆå  True ç»å¤šæ•°æƒ…å†µï¼‰ ç®€å•çš„æ¦‚æ‹¬æ€»ç»“ï¼ˆå¯èƒ½è·¨æ®µè½ï¼‰ False:contradict\u0026mdash;é©³æ–¥ã€çŸ›ç›¾ã€å¯¹ç«‹ã€æ„æ€å®Œå…¨ç›¸åã€ä¸å¯èƒ½åŒæ—¶æˆç«‹ã€ä¸å¯èƒ½å…±å­˜ åä¹‰è¯ ç›´æ¥å¦å®š It is now clear/has proven != not clear/no proof/ no evidence ç®€å•çš„æ¦‚æ‹¬æ€»ç»“ï¼Œæ„æ€ç›¸å æƒ…å†µå”¯ä¸€ä¸”ä¸ç›¸ç¬¦ a/one/the only != some majority/most != all/every Not Given:no information\u0026mdash;æ²¡æœ‰æåŠã€æ— ä¸­ç”Ÿæœ‰ã€è®¨è®ºä¸åœ¨ä¸€ä¸ªçº¬åº¦ï¼ˆè®¨è®ºçš„ä¸æ˜¯ä¸€å›äº‹ï¼‰ã€å¯èƒ½åŒæ—¶æˆç«‹ï¼ˆå¯èƒ½å…±å­˜ï¼‰ã€é¢˜ç›®å¯èƒ½çœŸä¹Ÿå¯èƒ½å‡ å†…å®¹æ²¡æœ‰æåŠ å‡ ä¸ªç‰¹ä¾‹ï¼šthe first/only/major/most æœ€é«˜çº§åŸæ–‡ä¸­æ²¡æœ‰æåŠ åä¾‹ï¼šæ²¡æœ‰æœ€é«˜çº§ï¼Œä½†æ˜¯æœ‰ the most\u0026hellip;=more than all other, å°±æ˜¯Trueã€‚ æåˆ°äº†å†…å®¹ï¼Œä½†æ˜¯å…¶ä¸­çš„å…³ç³»ï¼ˆæ¯”è¾ƒã€å› æœç­‰ï¼‰æœªæåŠ æ¯”è¾ƒæœªæåŠï¼š åŸæ–‡ï¼šA and B é¢˜ç›®ï¼šA is more\u0026hellip;than B (æ¨ªå‘ã€çºµå‘æ¯”è¾ƒ) åä¾‹ï¼šå¹¶ä¸æ˜¯æ¯”è¾ƒå°±ä¸€å®šæ˜¯Not Givenï¼Œæ¯”å¦‚æœ‰åŒä¹‰æ›¿æ¢æ”¹å†™ã€‚ 3. ä¸ç›¸ç¬¦ä½†æƒ…å†µå¹¶ä¸å”¯ä¸€\nTRUE/FALSE/NOT GIVEN è§£é¢˜æ€è·¯æ¢³ç† ä¿¡æ¯ä¸ç›¸ç¬¦æ—¶ï¼Œåˆ¤æ–­æ˜¯å¦æœ‰å”¯ä¸€æ€§ åä¹‰è¯ = FALSE ä¸ç›¸ç¬¦\nå”¯ä¸€æ€§ = FALSE ä¸å”¯ä¸€æ€§ = NOT GIVEN ææ¸…æ¥šä¸¤ä¸ªè¯æ˜¯ä¸æ˜¯ä¸€ä¸ªé€»è¾‘ã€ä¸€ä¸ªç»´åº¦ã€ä¸€ä»¶äº‹ è°¨é˜²â€œå·æ¢æ¦‚å¿µâ€\nçœ‹åˆ°The first/the only/the best/the biggest/the mostï¼Œåœ¨å…¶ä»–å†…å®¹ç¡®å®šçš„å‰æä¸‹ï¼Œè¦è°¨æ…å»æ‰¾æœ‰æ²¡æœ‰æåŠç›¸å…³ä¿¡æ¯ï¼ˆé¡ºåº/æ•°é‡/æœ€é«˜çº§æ¯”è¾ƒï¼‰ æ²¡æœ‰æåŠç›¸å…³ä¿¡æ¯ï¼ˆé¡ºåº/æ•°é‡/æœ€é«˜çº§æ¯”è¾ƒï¼‰= NG æåŠäº†ç›¸å…³ä¿¡æ¯ï¼ˆé¡ºåº/æ•°é‡/æœ€é«˜çº§æ¯”è¾ƒï¼‰\nä¸”ç›¸ç¬¦ = T ä¸”ä¸ç›¸ç¬¦ = F\nthe first = earlier than any other \u0026hellip;/earlier than all other \u0026hellip; the most K = more K than any other \u0026hellip;/more K than all other\u0026hellip; èŒƒå›´å˜åŒ–ï¼ˆæ¦‚æ‹¬å’Œå…·ä½“ã€å¤§ç±»å’Œç»†åˆ†ä¸¾ä¾‹ï¼‰æ˜¯å•å‘çš„åŒä¹‰æ›¿æ¢ æ–‡ï¼šæ¦‚æ‹¬ ï¼ˆæˆ‘åƒäº†æ°´æœï¼‰ é¢˜ï¼šå…·ä½“ ï¼ˆæˆ‘åƒäº†è‹¹æœï¼‰=\u0026gt; NG\næ–‡ï¼šå…·ä½“ ï¼ˆæˆ‘åƒäº†è‹¹æœï¼‰ é¢˜ï¼šæ¦‚æ‹¬ ï¼ˆæˆ‘åƒäº†æ°´æœï¼‰=\u0026gt; T\nå¹¶åˆ—å…³ç³»é‡Œå•æ‹¿å‡ºæ¥ä¸€ä¸ªæ˜¯æ²¡æœ‰é—®é¢˜çš„ï¼Œä½†è¦æ³¨æ„æ–¹å‘ æ–‡ï¼šA and B é¢˜ç›®ï¼šA =\u0026gt; T\næ–‡ï¼šA é¢˜ç›®ï¼šA and B =\u0026gt; NG\nè¿‡ç¨‹ä¹Ÿé‡è¦ æ–‡ï¼šå…ˆupådown é¢˜ï¼šupäº† =\u0026gt; T\nè¦å­¦ä¼šè‡ªå·±ä¸¾èº«è¾¹çš„ä¾‹å­ é€»è¾‘è¿ç§»\nå¡«ç©ºé¢˜ ä¸€èˆ¬æ˜¯é¡ºåºé¢˜ï¼Œå¶è§ä¸¤ä¸ªé¢ å€’ä½ç½®ï¼› å¡«ç©ºé¢˜æ˜¯ç»†èŠ‚é¢˜ï¼Œè€ƒå¯Ÿç»†èŠ‚ç­”æ¡ˆå¥å¯¹åº”ã€‚\nå¡«ç©ºé¢˜åˆ†ç±» æ€»ç»“å¡«ç©º é›†ä¸­åœ¨ä¸€æ®µæˆ–è€…éå¸ƒåœ¨å‡ æ®µ\nè¡¨æ ¼å¡«ç©º é›†ä¸­åœ¨ä¸€æ®µæˆ–è€…éå¸ƒåœ¨å‡ æ®µ\nå¥å­å¡«ç©º ä¸€èˆ¬éå¸ƒåœ¨å‡ æ®µ\né€‰è¯å¡«ç©º é›†ä¸­åœ¨ä¸€æ®µæˆ–è€…éå¸ƒåœ¨å‡ æ®µ é€‰é¡¹æ˜¯åŒä¹‰æ›¿æ¢æˆ–è€…åŸè¯\nå›¾ç‰‡å¡«ç©º ç­”æ¡ˆç›¸å¯¹é›†ä¸­\nå›ç­”å¥å­ å½“æˆæ™®é€šå¡«ç©ºæ¥åšï¼Œ é›†ä¸­åœ¨ä¸€æ®µæˆ–è€…éå¸ƒåœ¨å‡ æ®µ\næ€»ç»“ï¼šæ‰‹å†™å¡«ç©ºå’Œé€‰è¯å¡«ç©º é€‰è¯å¡«ç©ºæ³¨æ„åŒä¹‰æ›¿æ¢ æ³¨æ„å­—æ•°é™åˆ¶ï¼Œåœ¨æ»¡è¶³å­—æ•°é™åˆ¶çš„å‰æä¸‹å°½é‡å†™å®Œæ•´ã€‚\nå¡«ç©ºé¢˜è§£é¢˜æ€è·¯ å®šä½ï¼š åŸè¯æˆ–è€…åŒä¹‰æ›¿æ¢ï¼Œ é¡ºåºé¢˜åˆ©ç”¨ç›¸å¯¹é¡ºåºæ¥å®šä½\nè§£é¢˜ï¼š åŒä¹‰æ›¿æ¢æ”¹å†™\nè€ƒå¯Ÿå¹¶åˆ—å…³ç³»å¯¹åº” å¹¶åˆ—ä¸­å¯æ”¹é¡ºåº å¹¶åˆ—ä¸­å¯å•ç‹¬æ‹¿å‡ºä¸€ä¸¤ä¸ªé€»è¾‘ä¸Šæ²¡æœ‰é—®é¢˜ æ”¹å†™ A and other B = B such as/including A è€ƒå¯Ÿè½¬æŠ˜è®©æ­¥å…³ç³»å¯¹åº” è€ƒå¯Ÿå› æœè®©æ­¥å…³ç³»å¯¹åº” è¢«åŠ¨æ”¹å†™ ä¸»åŠ¨è¢«åŠ¨æ”¹å†™ï¼šåŒæ—¶åŠ¨è¯å¯èƒ½åŒä¹‰æ›¿æ¢ã€‚æ”¹æˆè¢«åŠ¨å¥å By + ä¸»ä½“ã€‚\nå®šè¯­ä»å¥æ”¹å†™ æ ¹æ®å¡«ç©ºè¯æ€§å¯¹åº” æ³¨æ„å¡«ç©ºå‰å®šå† è¯ the /ä¸å®šå† è¯ a, an/each/æ•°å­—/some/ä»‹è¯ç­‰å¯¹åº” ä»‹ç»ä¸“æœ‰åè¯å¸¸ç”¨ called/named/known as/å¼•å·/ç ´æŠ˜å·/, a\u0026hellip; åŒä½è¯­ç­‰æ¥å¼•å‡ºåç§° æ³¨æ„å¡«ç©ºå‰çš„å¦å®šè¯å¯¹åº” é€‰è¯å¡«ç©º å½“æˆæ™®é€šå¡«ç©ºæ¥åšï¼Œé€‰é¡¹å¯èƒ½æ˜¯åŸè¯ï¼Œä¹Ÿå¯èƒ½æ˜¯åŒä¹‰æ›¿æ¢ã€‚\næ³¨æ„å•å¤æ•°å¯¹åº” å–„ç”¨æ’é™¤æ³• å›ç­”é—®é¢˜ å½’ä¸ºé¢˜ç©ºé¢˜ï¼Œç»†èŠ‚ç­”æ¡ˆå¥åŒä¹‰æ›¿æ¢æ”¹å†™ã€‚\nåŸè¯å’ŒåŒä¹‰æ›¿æ¢å®šä½ç­”æ¡ˆå¥ æ ¹æ®é¢˜ç›®é—®çš„ä¸»ä½“æ¥å¡«ç­”æ¡ˆ what? who? how? what method? what sevice? what solution? æ³¨æ„äº‹é¡¹ ç­”æ¡ˆä»¥å‰‘æ¡¥ä¹¦ç­”æ¡ˆä¸ºå‡† å¤§å°å†™ä¸åŒºåˆ† å¡«ç©ºé¢˜é€šå¸¸æ˜¯åŸè¯ï¼Œå¾ˆå°‘æ”¹è¯æ€§ã€‚ å¡«ç©ºä¸€èˆ¬ä¸ä¼šå¡«é¢˜å¹²ä¸­å·²æœ‰çš„è¯ï¼Œæ³¨æ„é¿å…é‡å¤ï¼Œå°¤å…¶æ˜¯åŒä¹‰æ›¿æ¢é‡å¤ å¡«ç©ºé¢˜å¡«æœ€å…·ä½“ã€æŒ‡æ„æœ€æ˜ç¡®çš„è¯ A of Bï¼šæ ¹æ®è¯­å¢ƒæ¥å¡« unitã€metricsã€oneã€eachã€someç­‰åº¦é‡/å•ä½/é™å®š/ä»£è¯ä¹‹ç±»çš„è¯ä¸€èˆ¬ä¸å¡«ï¼Œæ— å®é™…æ„ä¹‰ æ®µè½åŒ¹é…é¢˜ ä¸ä¸€å®šæ¯ä¸ªæ®µè½éƒ½è€ƒåˆ° åšé¢˜å‰æ³¨æ„æ˜¯å¦æœ‰NBï¼š å¦‚æ¯ä¸ªå­—æ¯å¯ä½¿ç”¨å¤šæ¬¡ï¼Œä½†æ˜¯ä¸ä¸€å®šä¼šé€‰å¤šæ¬¡ï¼Œä¸€èˆ¬ä¼šå¤šé€‰ åˆ°åº•è€ƒä»€ä¹ˆ è€ƒå¯Ÿæ®µè½å±€éƒ¨åŒ…å«çš„ä¿¡æ¯\nè§£é¢˜æ€è·¯ ä¹±åºé¢˜ï¼Œ é¢„è¯»å…¨éƒ¨é¢˜ç›®ç”»å…³é”®è¯ï¼Œ åŸæ–‡æåˆ°ç›´æ¥é€‰ï¼Œ è¯»å®Œä¸€æ®µå›è¿‡å¤´æ¥æ‰«è§†ä¸‹æ˜¯å¦åˆé€‚é€‰é¡¹\nåŒä¹‰æ›¿æ¢ æ¦‚æ‹¬æ€»ç»“\næŸé“é¢˜ä¸ç¡®å®šå…ˆé€‰å‡ ä¸ªå¹¶æ ‡è®°ï¼Œåé¢æœ‰æ—¶é—´å†ç¡®å®š é¢˜å¹²è¯ ä¸ç”¨çœ‹çš„é¢˜å¹²è¯ï¼Œreference/refer/account/mention/description æåŠæè¿°\néœ€æ³¨æ„çš„é¢˜å¹²è¯\nexampleï¼šæ‰¾å…·ä½“ä¾‹å­ reasonï¼šæ‰¾å…·ä½“åŸå›  statistics/dataï¼šæ‰¾å…·ä½“æ•°å­—æ•°æ® æ„æ€ç›¸è¿‘çš„åŒä¹‰æ›¿æ¢åˆ†å¥½ç±» æ³¨æ„åŒºåˆ†é¢˜å¹²é‡Œçš„å•å¤æ•°ï¼Œå¦‚ examples ä¸ an exampleã€animals ä¸ an animal\næ³¨æ„é¢˜ç›®ä¸»å¹²æè¿°å¯¹è±¡ï¼Œäººï¼Ÿç‰©ï¼Ÿäº‹ï¼Ÿ\né¢˜ç›®çœ‹åˆ°future/predictç­‰è¯ä¸€èˆ¬é‡ç‚¹å…³æ³¨æœ€åä¸€æ®µ/æœ€åå‡ æ®µ\næ®µè½ç»“æ„ä¸headingé¢˜ æ®µè½ç»“æ„ è§‚ç‚¹ + è§£é‡Š/ä¸¾ä¾‹/è§£é‡Š+ä¸¾ä¾‹\nHeadingé¢˜ ä¹±åºé¢˜ï¼Œ é¢„è¯»å…¨éƒ¨é¢˜ç›®ç”»å…³é”®è¯ï¼Œ æ¯è¯»å®Œä¸€æ®µæ¥é€‰\nè€ƒä»€ä¹ˆ Headingé€‰æ®µè½æ ‡é¢˜ï¼Œé€‰æ®µè½å¤§æ„\næ®µè½ä¸­å¿ƒå¥çš„åŒä¹‰æ›¿æ¢æ”¹å†™ 1ï¼‰æ®µè½ä¸­å¿ƒå¥å¯èƒ½åœ¨\næ®µè½é¦–å¥ æ®µè½ç¬¬äºŒå¥ï¼šé¦–å¥ä¸ºèƒŒæ™¯å¼•å…¥è§‚ç‚¹ æ®µè½æœ«å¥ ä¸¾ä¾‹/è§£é‡Šå‰çš„è§‚ç‚¹å¥ è½¬æŠ˜åçš„é‡ç‚¹å¥ ä¸‹ä¸€æ®µé¦–å¥æˆ–è€…ä¸Šä¸€æ®µæœ«å¥çš„æ‰¿ä¸Šå¯ä¸‹ 2ï¼‰æ²¡æœ‰æ®µè½ä¸­å¿ƒå¥ï¼Œè‡ªå·±æ¥æ¦‚æ‹¬ Headingé¢˜æ³¨æ„äº‹é¡¹ é€‰æ®µè½å¤§æ„ï¼Œä¸å¯ä»¥åæ¦‚å…¨ ä¸€ä¸ªæ®µè½æœ‰å¤šä¸ªè§‚ç‚¹ï¼Œåˆ™ç»“åˆæ‰€æœ‰é€‰é¡¹æ ‡é¢˜é€‰å‡ºå…¶ä¸­ä¸€ä¸ª å­¦æœ¯æ–‡ç« æ˜¯çµæ´»çš„ï¼Œä¸å¯æ­»æ¿çš„å¥—æ¨¡æ¿ ï¼ˆè§‚ç‚¹+è§£é‡Š+ä¸¾ä¾‹ï¼‰ ç»†èŠ‚é¢˜ä¸Headingé¢˜å¯èƒ½æœ‰é‡åˆï¼Œå¯è”ç³»èµ·æ¥ï¼Œ æ®µè½ä¸­æœ‰æè¿°å®éªŒç ”ç©¶æ—¶ï¼šé‡ç‚¹çœ‹å®éªŒç»“è®º future/predictç­‰è¯ä¸€èˆ¬é‡ç‚¹å…³æ³¨æœ€åä¸€æ®µæˆ–è€…æœ€åå‡ æ®µ Headingé¢˜ä¸æ®µè½åŒ¹é…Containsé¢˜å¯¹æ¯” é€‰æ‹©é¢˜ é¡ºåºé¢˜ï¼Œé¢„è¯»ä¸¤é“é¢˜ç›®\nè€ƒå¯Ÿæ–¹æ³• ç»†èŠ‚å¯¹åº”ï¼Œç­”æ¡ˆå¥çš„åŒä¹‰æ›¿æ¢æ”¹å†™ =\u0026gt; å½“æˆåˆ¤æ–­é¢˜æ¥åš æ®µè½ç†è§£ =\u0026gt; å½“æˆheadingé¢˜æ¥åš tips no evidenceé©³æ–¥provedã€proofã€clearã€clarity å‡ ä¸ªç‰¹æ®Šçš„ç»†èŠ‚è€ƒæ³• é—®ä½ example/exemplifyçš„ä½œç”¨ï¼šè§‚ç‚¹ + ä¸¾ä¾‹ï¼Œå°±çœ‹å‰ä¸€å¥è§‚ç‚¹å¥ é—®ä½ ä»£è¯â€œThisâ€ã€â€œThatâ€â€œItâ€æŒ‡ä»£ä»€ä¹ˆï¼šå°±çœ‹å‰ä¸€å¥ä»£è¯æŒ‡ä»£ ç‰¢è®°åŸæ–‡ä¸­â€œto + åŠ¨è¯â€è¡¨ç›®çš„ï¼Œâ€œæ¥ã€ä¸ºäº†â€¦â€¦â€ å•é€‰é¢˜æ³¨æ„äº‹é¡¹ é¢˜å¹²è¯reviewer/writerï¼šæŒ‡æœ¬æ–‡ä½œè€… â€œemphasisâ€ã€â€œsuggestâ€ã€â€œinterestingâ€è¿™ç§é¢˜å¹²è¯ä¸ä¸€å®šæœ‰åŸæ–‡å¯¹åº” é€‰é¡¹ä¸­çš„åŸè¯å¾ˆå¤šæ—¶å€™æ˜¯å¹²æ‰°ï¼Œè¦çœ‹çš„ä¸æ˜¯æŸä¸ªå•è¯ï¼Œè€Œæ˜¯æ•´ä½“çš„æ„æ€æ˜¯ä¸æ˜¯ä¸€è‡´ é€‰æ‹©é¢˜å–„ç”¨æ’é™¤æ³• è¶Šæ¥è¶Šè€ƒå¯Ÿç†è§£ï¼šæ”¾å¼ƒå¹»æƒ³ï¼Œæå‡åŸºç¡€ï¼ˆè¯æ±‡+è¯­æ³•+é˜…è¯»èƒ½åŠ›ï¼‰ å¤šé€‰é¢˜ å¤šé€‰é¢˜è®°åˆ†åŸåˆ™ï¼šå ä¸¤ä¸ªé¢˜å·ï¼Œå¯¹ä¸€ä¸ªå°±å¾—ä¸€ä¸ªåˆ† å¤šé€‰é¢˜å‡ºé¢˜é¡ºåºæ¯”è¾ƒç‰¹æ®Šï¼šå¯èƒ½é›†ä¸­æŸæ®µã€å¯èƒ½åˆ†å¸ƒå…¨æ–‡ å¤šé€‰é¢˜ä¸¤ç§æƒ…å†µï¼š å½“é¢˜ç›®æä¾›ä¿¡æ¯å¥½å®šä½æ—¶ï¼Œç”¨é¢˜ç›®æ¥å®šä½å³å¯ å½“é¢˜ç›®æä¾›ä¿¡æ¯ä¸è¶³ä»¥å®šä½æ—¶ï¼Œéœ€è¦é¢„è¯»é€‰é¡¹æ¥å®šä½ åˆ¤æ–­æ€è·¯å’Œå•é€‰é¢˜ä¸€è‡´ \u0026mdash; å½“æˆåˆ¤æ–­é¢˜æ¥ç†è§£ï¼šå°±æ˜¯åŒä¹‰æ›¿æ¢æ”¹å†™è½¬è¿°ï¼ˆTrue æ˜¯æ­£ç¡®é€‰é¡¹ã€False å’Œ Not Given æ˜¯é”™è¯¯é€‰é¡¹ï¼‰ã€‚ ä¿¡æ¯åŒ¹é…ä¸å¥å­åŒ¹é… åˆ†ç±» ä¿¡æ¯åŒ¹é… äººåã€å¹´ä»£ã€å…¬å¸ å›½å®¶ã€å­¦è¯´ã€åŠ¨ç‰©ã€æ–¹æ³•\nå¥å­åŒ¹é… äººååŒ¹é…è§£é¢˜æ€è·¯ ä¹±åºé¢˜ï¼šé¢„è¯»å…¨éƒ¨é¢˜ç›®å¹¶ç”»å…³é”®è¯ \u0026mdash; æ–‡ä¸­å®šä½å¹¶åŒ¹é…\næ€è·¯Aï¼š é¢„è¯»é¢˜å¹²å…³é”®è¯\nè¯»æ–‡ç« åœ¨åŸæ–‡å®šä½é¢˜å¹² åŒ¹é…äººå æ€è·¯B: é¢„è¯»é¢˜å¹²å…³é”®è¯ä¸äººå\nå»åŸæ–‡å®šä½äººå çœ‹äººåå‰åå¥å­å¹¶åŒ¹é… å½“å…¨ç¯‡æ»¡æ˜¯äººåã€æ¯ä¸ªäººåå‡ºç°ä¸æ­¢ä¸€æ¬¡çš„æ—¶å€™â€œæ€è·¯ Bâ€ä¼šå¤±çµï¼Œæ¨èâ€œæ€è·¯ Aâ€\næ¨èåœ¨æ–‡ä¸­è¯»åˆ°ç¬¬ä¸€ä¸ªäººåæ—¶å†æ¥é¢„è¯»ç”»æ‰€æœ‰çš„å…³é”®è¯ï¼ˆè¶Šæ™šé¢„è¯»è®°çš„è¶Šæ¸…æ¥šï¼‰\næ ¸å¿ƒæ€è·¯ï¼š é¢„è¯»å…¨éƒ¨é¢˜å¹² \u0026mdash; è¯»æ–‡ç« ã€ç”¨é¢˜å¹²åŒä¹‰æ›¿æ¢æ”¹å†™æ¥å®šä½ \u0026mdash; åŒ¹é…äººåé€‰é¡¹\nå¥å­åŒ¹é…è§£é¢˜æ€è·¯ é¢˜å¹² + æ­£ç¡®é€‰é¡¹ = ç­”æ¡ˆå¥åŒä¹‰æ›¿æ¢æ”¹å†™ å¥å­åŒ¹é…ä¸€èˆ¬æ˜¯é¡ºåºé¢˜\né¢„è¯»é¢˜å¹²è¿˜æ˜¯é¢˜å¹²+é€‰é¡¹ é¢„è¯»ä¸¤é“é¢˜ç›®ï¼ˆå¦‚æœé¢˜ç›®ä¿¡æ¯ä¸å¤Ÿå®šä½ï¼Œåˆ™é€‰é¡¹ä¹Ÿè¦é¢„è¯»ï¼‰\u0026mdash; è¯»æ–‡ç« å®šä½ \u0026mdash; åŒ¹é…ç­”æ¡ˆ\né€‰æ–‡ç« æ ‡é¢˜/å‰¯æ ‡é¢˜ é€‰ä¸­å¿ƒæ€æƒ³\næŠ€å·§ å…¨æ–‡åå¤æåŠã€å…¶ä»–é¢˜ç›®åå¤å‡ºç°çš„å†…å®¹\n","permalink":"https://bleedkagax.github.io/post/reading-skills/","summary":"\u003ch1 id=\"é›…æ€é˜…è¯»\"\u003eé›…æ€é˜…è¯»\u003c/h1\u003e\n\u003cp\u003eè¯æ±‡ + è¯­æ³• + è§£é¢˜æŠ€å·§ + é˜…è¯»é‡\u003c/p\u003e\n\u003ch1 id=\"è¯­æ³•\"\u003eè¯­æ³•\u003c/h1\u003e\n\u003ch2 id=\"ä»å¥\"\u003eä»å¥\u003c/h2\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/reading-skills.png\" alt=\"img/reading-skills.png\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"éè°“è¯­\"\u003eéè°“è¯­\u003c/h2\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/reading-skills-46.png\" alt=\"img/reading-skills-46.png\"  /\u003e\n\u003c/p\u003e\n\u003ch1 id=\"æ ¸å¿ƒåŒä¹‰æ›¿æ¢\"\u003eæ ¸å¿ƒï¼šåŒä¹‰æ›¿æ¢\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eåŒä¹‰è¯\u003c/li\u003e\n\u003cli\u003eåŒä¹‰çŸ­è¯­\u003c/li\u003e\n\u003cli\u003eåŒä¹‰å¥å­ï¼ˆä¸»åŠ¨è¢«åŠ¨ï¼‰\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"é¢˜å‹åˆ†ç±»\"\u003eé¢˜å‹åˆ†ç±»\u003c/h1\u003e\n\u003ch2 id=\"1-é¡ºåºé¢˜\"\u003e1. é¡ºåºé¢˜\u003c/h2\u003e\n\u003cp\u003eé¢˜å‹å†…éƒ¨çš„å‡ºé¢˜é¡ºåº\u003cbr\u003e\nï¼ˆä¸€èˆ¬ä¸ºé¡ºåºï¼‰\nåˆ¤æ–­\nå¡«ç©º å›¾å½¢å¡«ç©º é€‰è¯å¡«ç©º å›ç­”é—®é¢˜\nå•é€‰\nå¥å­åŒ¹é…\u003c/p\u003e\n\u003ch2 id=\"2-ä¹±åºé¢˜\"\u003e2. ä¹±åºé¢˜\u003c/h2\u003e\n\u003cp\u003eæ®µè½åŒ¹é… Which paragraph contains\näººå/å­¦è¯´/å›½å®¶/å…¬å¸ç­‰ä¿¡æ¯åŒ¹é…\næ®µè½å¤§æ„ Heading\u003c/p\u003e\n\u003ch2 id=\"3-ç‰¹æ®Šé¢˜\"\u003e3. ç‰¹æ®Šé¢˜\u003c/h2\u003e\n\u003cp\u003eé€‰æ–‡ç« æ ‡é¢˜ Title/å‰¯æ ‡é¢˜ Subtitle\nå¤šé€‰\u003c/p\u003e","title":"reading skills"},{"content":"Essentially, refactoring is improving the design of code after it\u0026rsquo;s been written.\nIf you want to add a feature to a program, but find that the code isn\u0026rsquo;t easy to change due to a lack of good structure, refactor that program first so that it\u0026rsquo;s easier to add the feature, and then add the feature.\nIt is the change in requirements that makes refactoring necessary.\nThe refactoring technique is to modify the program at a tiny pace. If you make a mistake, it\u0026rsquo;s easy to spot it.\nThe test of good code is how easily one can modify it.\nTo summarize:\nThe key takeaways for efficient and organized refactoring are: Smaller steps lead to faster progress, keep your code in a working state forever, and small changes add up to a much better system design. Refactoring is not a â€œsilver bulletâ€, but it can be considered a â€œsilver tongsâ€, which can help you always have good control over your code. Refactoring is a tool.\n1. Bad taste in code 1. Mysterious Name There are only two hard things in Computer Science: cache invalidation and naming things-- Phil Karlt\nNaming is one of the two hardest things in programming. Because of this, renaming is probably the most commonly used refactoring technique, including changing function declarations (for renaming functions), variable renaming, and field renaming.\n2. Global Data Wrapped Variables. It may not hurt to have a small amount of global data, but the larger the number, the exponentially more difficult it is to deal with.\n3. Mutable Data Encapsulated variables can be used to ensure that all data update operations are performed through very few functions, making them easier to monitor and evolve.\nIf a variable is used to store different things at different times, split variables can be used to split it into variables for their own different purposes, thus avoiding dangerous update operations.\nUse move statements and refine functions to try to move logic out of the code that handles update operations, separating code that has no side effects from code that performs data update operations.\nWhen designing APIs, you can use ** to separate query functions from modification functions**.\nUse Remove set-value functions as early as possible to narrow the variable scope.\n4. Long Functions Actively Decompose Functions.\nPrinciple: Whenever we feel that we need to explain something in a comment, we write what we need to explain in a separate function and name it after its purpose (not how it was implemented).\nWhat kind of function is too long? More than 50 lines? More than 70 lines? It\u0026rsquo;s not the length of the function that matters, it\u0026rsquo;s the semantic distance between the â€œwhatâ€ and â€œhowâ€ of the function.\nHow do you determine which piece of code to refine? A good tip is to look for comments. They usually indicate the semantic distance between what the code does and how it does it.\nConditional expressions and loops often signal refinement as well. Conditional expressions can be handled using decomposition conditional expressions.\nFor huge switch statements, each branch should be turned into a separate function call by refining the function. If there are multiple switch statements that branch selection based on the same condition, you should use replace conditional expressions with polymorphism.\nLoops and code within loops should be refined into a separate function. If you find the distilled loop hard to name, it may be because it does several different things in it. If this is the case, be brave and use a split loop to break it up into its own separate tasks.\n5. Long Parameter List If it is possible to launch a query on one parameter to get the value of another parameter, then this second parameter can be removed by replacing the parameter with a query.\nIf you find yourself pulling a lot of data items out of an existing data structure, consider Using the Keep Objects Intact technique to pass directly into the original data structure. If there are several parameters that always appear at the same time, you can combine them into a single object by introducing a parameter object.\nIf a parameter is used as a flag to distinguish the behavior of a function, remove the flag parameter.\nUsing classes can effectively shorten the argument list. Introducing a class makes particular sense if multiple functions have the same few parameters. You can use functions combined into classes to make these common parameters into fields of this class.\n6. Shotgun Surgery If you have to make many small modifications within many different classes every time you encounter some kind of change, the bad taste you\u0026rsquo;re facing is Shotgun Surgery.\nMoving functions and moving fields puts all the code that needs to be modified into the same module. If there are a lot of functions that operate on similar data, you can use a combination of functions into a class. If some functions function to transform or enrich data structures, you can use functions to combine into transformations. If the output of some functions can be combined and made available to a piece of logic that specializes in using the results of those computations, this is often useful Split Stage (e.g., parsing an order before calculating the price of an order)**.\nA common strategy is to use refactoring related to inlining \u0026mdash;\u0026mdash; such as inline functions (or inline classes) \u0026mdash;\u0026mdash; to yank logic that shouldn\u0026rsquo;t be scattered back into one place**. After you\u0026rsquo;ve finished inlining, you may smell an overly long function or overly large class, and then use refactoring techniques related to refinement to break it up into more sensible chunks.\n7. Comments. If you need comments to explain what a piece of code does, try refining the function; If the function has been refined but still needs comments to explain its behavior, try renaming it with a change to the function declaration; **If you need comments to explain the specification of some system requirement, try introducing an assertion.\nWhen you feel the need to write comments, try refactoring first and try making all comments redundant.\n8. Data Clumps. Data that always appears tied together really should have objects of their own.\n9. Repeated Switches Polymorphism.\n10. **Lazy Element As the refactoring progresses it gets smaller and smaller and the class ends up with only one function. Remove this class in time to use inline functions or inline classes.\n11. Refused Bequest. Subclasses should inherit functions and data from the superclass.\nIf you do not want to support the interface of the superclass, you should not be false to the inheritance system, and you should use delegates (using combinations instead of inheritance) instead of subclasses or delegates instead of superclasses to draw a line in the sand.\n2. First set of reconstructions 1. Extract Function Separate Intent from Implementation: If you need to spend time browsing through a piece of code to figure out what it\u0026rsquo;s actually doing, then you should distill it down to a function and name it according to what it does. Because most of the time you don\u0026rsquo;t need to care about how the function accomplishes its purpose (that\u0026rsquo;s what the function does inside)\nGood names: in a big function, a piece of code puts a comment that distills it into a function, and the comment often suggests a good name.\nPractice*\nCreate a new function: name it after â€œwhat it doesâ€, not â€œhow it does itâ€.\nWithout local variables, refine directly into a function;\nwith local variables but read-only, passed as arguments to the target function\nLocal variables are assigned values: declared directly in the refining function if they are used only within the refining function; used outside the refining function as the return value of the refining function; multiple variables are modified by considering returning an object or using other refactoring techniques (querying instead of temporary variables, splitting variables)\n2. Inline Function Indirectness may help, but non-essential indirectness is always uncomfortable.\nSome functions have their contents and names clear and easy to read\nA group of functions is not well organized, inline to one big function first, then refine.\n3. Extract Variable Variables provide the right context: they help us break up expressions into more manageable forms, and also make it easier to understand what a portion of the code is doing.\nAccording to The Tao of Tidy Code, â€œUse explanatory variables to break up the computation into a series of well-named intermediate valuesâ€.\n4. Inline Variable Sometimes, variable names are no more expressive than the expression itself. There are also times when variables may get in the way of refactoring nearby code.\n5. Rename Variable Explain what a piece of program is doing, and be more careful naming fields whose scope extends beyond a single function call.\n6. Change Function Declaration A good name gives an immediate indication of what the function is used for;\nThe argument list of a function describes how the function coexists with the outside world, and modifying the argument list not only increases the scope of the function\u0026rsquo;s application, but also removes unnecessary coupling by changing the conditions required to connect a module.\n\u0026ldquo;A good way to improve the name of a function: write a comment describing what the function is used for, then turn that comment into the name of the function.â€\n7. Introduce Parameter Object Organize data into structures that make the relationships between data items clearer;\nshorter parameter list;\nCode consistency: all functions that use this data structure can access elements of it by the same name.\nChanging the conceptual picture of the code elevates these data structures to new abstractions\n8. Combine Functions into Class If you find a group of functions that manipulate the same piece of data (usually by passing that piece of data as a parameter to the function), it\u0026rsquo;s time to form a class. Classes explicitly provide a common environment for these functions, and calling them from within an object simplifies function calls by passing many fewer arguments.\n9. Split Phase A piece of code that handles two different things at simultaneously can be considered to be split into its own separate modules, because then each topic can be handled separately when it comes time to make changes.\n3. Encapsulate 1. Encapsulate Record Objects can hide details of the structure, help with renaming of fields, and are easy to expand to cope with changes.\n2. Encapsulate Variable For all mutable data, as long as its scope extends beyond a single function, I encapsulate it and only allow access through the function. The larger the scope of the data, the more important encapsulation becomes.\n3. Encapsulate Collection One mistake people often make when encapsulating collections is that ** only encapsulates access to the collection variables, but still lets the fetch function return the collection itself. This allows the collection\u0026rsquo;s member variables to be modified directly, while the class encapsulating it is completely unaware and unable to intervene**.\nPractice:\nProvide methods to modify the collection on the class \u0026mdash;\u0026mdash;Usually â€œaddâ€ and â€œremoveâ€ methods to unify the management.\n4. Substitute Algorithm 3. Move Characteristics Another type of refactoring that is also important is moving elements between contexts.\n1. æ¬ç§»å‡½æ•°ï¼ˆMove Functionï¼‰ ä»»ä½•å‡½æ•°éƒ½éœ€è¦å…·å¤‡ä¸Šä¸‹æ–‡ç¯å¢ƒæ‰èƒ½å­˜æ´»ã€‚\næ¬ç§»å‡½æ•°æœ€ç›´æ¥çš„ä¸€ä¸ªåŠ¨å› æ˜¯ï¼Œå®ƒé¢‘ç¹å¼•ç”¨å…¶ä»–ä¸Šä¸‹æ–‡ä¸­çš„å…ƒç´ ï¼Œè€Œå¯¹è‡ªèº«ä¸Šä¸‹æ–‡ä¸­çš„å…ƒç´ å´å…³å¿ƒç”šå°‘ï¼Œå°†å‡½æ•°ç§»åŠ¨åˆ°è”ç³»æ›´ç´§å¯†çš„ä¸Šä¸‹æ–‡é‚£ä¹ˆç³»ç»Ÿåˆ«å¤„å°±å¯ä»¥å‡å°‘å¯¹å½“å‰æ¨¡å—çš„ä¾èµ–ï¼Œè·å¾—æ›´å¥½çš„å°è£…æ•ˆæœã€‚\næ•´ç†ä»£ç æ—¶ï¼Œå‘ç°éœ€è¦é¢‘ç¹è°ƒç”¨ä¸€ä¸ªåˆ«å¤„çš„å‡½æ•°ï¼›æˆ–è€…å‡½æ•°å†…éƒ¨å®šä¹‰äº†ä¸€ä¸ªå¸®åŠ©å‡½æ•°ï¼Œè€Œè¯¥å¸®åŠ©å‡½æ•°å¯èƒ½åœ¨åˆ«çš„åœ°æ–¹ä¹Ÿæœ‰ç”¨å¤„ï¼Œæ­¤æ—¶å°±å¯ä»¥å°†å®ƒæ¬ç§»åˆ°æŸäº›æ›´é€šç”¨çš„åœ°æ–¹ã€‚\næ˜¯å¦éœ€è¦æ¬ç§»å‡½æ•°å¸¸å¸¸ä¸æ˜“æŠ‰æ‹©ï¼Œä½†å†³å®šè¶Šéš¾åšï¼Œé€šå¸¸è¯´æ˜\u0026quot;æ¬ç§»è¿™ä¸ªå‡½æ•°ä¸å¦\u0026quot;çš„é‡è¦æ€§ä¹Ÿè¶Šä½ã€‚\nèŒƒä¾‹ï¼šæ¬ç§»å†…åµŒå‡½æ•°è‡³é¡¶å±‚\nbeforeï¼š\nè®¡ç®—ä¸¤ç‚¹ä¹‹é—´è·ç¦»çš„å‡½æ•°åœ¨åˆ«å¤„ä¹Ÿæœ‰è°ƒç”¨\nafterï¼š\n2. æ¬ç§»è¯­å¥åˆ°å‡½æ•°ï¼ˆMove Statements into Functionï¼‰ \u0026ldquo;æ¶ˆé™¤é‡å¤\u0026rdquo;ï¼šå¦‚æœå‘ç°è°ƒç”¨æŸä¸ªå‡½æ•°æ—¶ï¼Œæ€»æœ‰ä¸€äº›ç›¸åŒçš„ä»£ç ä¹Ÿéœ€è¦æ¯æ¬¡æ‰§è¡Œï¼Œåˆ™è€ƒè™‘å°†æ­¤æ®µä»£ç åˆå¹¶åˆ°å‡½æ•°é‡Œå¤´ã€‚\nå¦‚æœæŸäº›è¯­å¥ä¸ä¸€ä¸ªå‡½æ•°æ”¾åœ¨ä¸€èµ·æ›´åƒä¸€ä¸ªæ•´ä½“ï¼Œå¹¶ä¸”æ›´æœ‰åŠ©äºç†è§£ï¼Œåˆ™å°†è¯­å¥æ¬ç§»åˆ°å‡½æ•°é‡Œå»ã€‚å¦‚æœå®ƒä»¬ä¸å‡½æ•°ä¸åƒä¸€ä¸ªæ•´ä½“ï¼Œä½†ä»åº”ä¸å‡½æ•°ä¸€èµ·æ‰§è¡Œï¼Œå¯ä»¥ç”¨æç‚¼å‡½æ•°å°†è¯­å¥å’Œå‡½æ•°ä¸€å¹¶æç‚¼å‡ºå»ã€‚\näº”. é‡æ–°ç»„ç»‡æ•°æ®\n1. æ‹†åˆ†å˜é‡ï¼ˆSplit Variableï¼‰\né™¤\u0026quot;å¾ªç¯å˜é‡\u0026quot;å’Œ\u0026quot;ç»“æœæ”¶é›†å˜é‡\u0026quot;å¤–ï¼Œè¿˜æœ‰å¾ˆå¤šå˜é‡ç”¨äºä¿å­˜ä¸€æ®µå†—é•¿ä»£ç çš„è¿ç®—ç»“æœï¼Œä»¥ä¾¿ç¨åä½¿ç”¨ã€‚è¿™ç§**å˜é‡åº”è¯¥åªè¢«èµ‹å€¼ä¸€æ¬¡ã€‚**å¦‚æœå®ƒä»¬è¢«èµ‹å€¼è¶…è¿‡ä¸€æ¬¡ï¼Œå°±æ„å‘³å®ƒä»¬åœ¨å‡½æ•°ä¸­æ‰¿æ‹…äº†ä¸€ä¸ªä»¥ä¸Šçš„è´£ä»»ã€‚å¦‚æœå˜é‡æ‰¿æ‹…å¤šä¸ªè´£ä»»ï¼Œå®ƒå°±åº”è¯¥è¢«æ›¿æ¢ï¼ˆåˆ†è§£ï¼‰ä¸ºå¤šä¸ªå˜é‡ï¼Œä¿æŒèŒè´£å•ä¸€ã€‚\nèŒƒä¾‹ï¼šå¯¹è¾“å…¥å‚æ•°èµ‹å€¼\nbeforeï¼š\nafterï¼š\nå…­. ç®€åŒ–æ¡ä»¶é€»è¾‘\n1. åˆ†è§£æ¡ä»¶è¡¨è¾¾å¼ï¼ˆDecompose Conditionalï¼‰\nç¨‹åºä¹‹ä¸­ï¼Œå¤æ‚çš„æ¡ä»¶é€»è¾‘æ˜¯æœ€å¸¸å¯¼è‡´å¤æ‚åº¦ä¸Šå‡çš„å› ç´ ä¹‹ä¸€ã€‚\nå¯¹äºæ¡ä»¶é€»è¾‘ï¼Œå°†æ¯ä¸ªåˆ†æ”¯æ¡ä»¶åˆ†è§£æˆæ–°å‡½æ•°è¿˜å¯ä»¥å¸¦æ¥æ›´å¤šå¥½å¤„ï¼šå¯ä»¥çªå‡ºæ¡ä»¶é€»è¾‘ï¼Œæ›´æ¸…æ¥šåœ°è¡¨æ˜æ¯ä¸ªåˆ†æ”¯çš„ä½œç”¨ï¼Œå¹¶ä¸”çªå‡ºæ¯ä¸ªåˆ†æ”¯çš„åŸå› ã€‚\næ³¨ï¼šå®é™…ä¸Šä¸ºæç‚¼å‡½æ•°çš„ä¸€ä¸ªåº”ç”¨åœºæ™¯ã€‚\n2. åˆå¹¶æ¡ä»¶è¡¨è¾¾å¼ï¼ˆConsolidate Conditional Expressionï¼‰\n3. ä»¥å«è¯­å¥å–ä»£åµŒå¥—æ¡ä»¶è¡¨è¾¾å¼ï¼ˆReplace Nested Conditional with Guard Clausesï¼‰\nå¦‚æœä¸¤æ¡åˆ†æ”¯éƒ½æ˜¯æ­£å¸¸è¡Œä¸ºï¼Œå°±åº”è¯¥ä½¿ç”¨å½¢å¦‚if...else...çš„æ¡ä»¶è¡¨è¾¾å¼ï¼›å¦‚æœæŸä¸ªæ¡ä»¶æå…¶ç½•è§ï¼Œå°±åº”è¯¥å•ç‹¬æ£€æŸ¥è¯¥æ¡ä»¶ï¼Œå¹¶åœ¨è¯¥æ¡ä»¶ä¸ºçœŸæ—¶ç«‹åˆ»ä»å‡½æ•°ä¸­è¿”å›ã€‚è¿™æ ·çš„å•ç‹¬æ£€æŸ¥å¸¸å¸¸è¢«ç§°ä¸º\u0026quot;å«è¯­å¥\u0026rdquo;ï¼ˆguard clausesï¼‰ã€‚\nå¦‚æœä½¿ç”¨if-then-elseç»“æ„ï¼Œåˆ™å¯¹ifåˆ†æ”¯å’Œelseåˆ†æ”¯çš„é‡è§†æ˜¯åŒç­‰çš„ï¼›ä»¥å«è¯­å¥å–ä»£åµŒå¥—æ¡ä»¶è¡¨è¾¾å¼çš„ç²¾é«“å°±æ˜¯ï¼šç»™æŸä¸€æ¡åˆ†æ”¯ä»¥ç‰¹åˆ«çš„é‡è§†ã€‚\n\u0026ldquo;æ¯ä¸ªå‡½æ•°åªèƒ½æœ‰ä¸€ä¸ªå…¥å£å’Œä¸€ä¸ªå‡ºå£\u0026quot;çš„è§‚å¿µæœªå¿…æœ‰ç”¨ï¼Œä¿æŒä»£ç æ¸…æ™°æ‰æ˜¯æœ€å…³é”®çš„ã€‚\nèŒƒä¾‹\nbefore\nafter\nèŒƒä¾‹ï¼šå°†æ¡ä»¶åè½¬\nåˆå§‹\nåè½¬\nåˆå¹¶æ¡ä»¶è¡¨è¾¾å¼\nåˆ é™¤å¯å˜å˜é‡\n4. ä»¥å¤šæ€å–ä»£æ¡ä»¶è¡¨è¾¾å¼ï¼ˆReplace Conditional with Polymorphismï¼‰\nä¸ƒ. é‡æ„API\nä»¥æŸ¥è¯¢å–ä»£å‚æ•°ï¼ˆReplace Parameter with Queryï¼‰\nå‡½æ•°çš„å‚æ•°åˆ—è¡¨åº”è¯¥æ€»ç»“è¯¥å‡½æ•°çš„å¯å˜æ€§ï¼Œæ ‡ç¤ºå‡ºå‡½æ•°å¯èƒ½ä½“ç°å‡ºè¡Œä¸ºå·®å¼‚çš„ä¸»è¦æ–¹å¼ã€‚å’Œä»»ä½•ä»£ç ä¸­çš„è¯­å¥ä¸€æ ·ï¼Œå‚æ•°åˆ—è¡¨åº”è¯¥å°½é‡é¿å…é‡å¤ï¼Œå¹¶ä¸”å‚æ•°åˆ—è¡¨è¶ŠçŸ­å°±è¶Šå®¹æ˜“ç†è§£ã€‚\nä½¿ç”¨åœºæ™¯ï¼šè°ƒç”¨å‡½æ•°æ—¶ä¼ å…¥äº†ä¸€ä¸ªå€¼ï¼Œè€Œè¿™ä¸ªå€¼ç”±å‡½æ•°è‡ªå·±æ¥è·å¾—ä¹Ÿæ˜¯åŒæ ·å®¹æ˜“\nä»€ä¹ˆæ˜¯\u0026quot;åŒæ ·å®¹æ˜“\u0026rdquo;ï¼šå‡½æ•°å¯ä»¥æ‰¿æ‹…è¿™ä»½åŸæœ¬ç”±è°ƒç”¨æ–¹æ‰€æ‰¿æ‹…çš„\u0026quot;è·å¾—æ­£ç¡®çš„å‚æ•°å€¼\u0026quot;çš„è´£ä»»ã€‚\nä»€ä¹ˆæ—¶å€™ä¸é€‚ç”¨ï¼šç§»é™¤å‚æ•°å¯èƒ½ä¼šç»™å‡½æ•°ä½“å¢åŠ ä¸å¿…è¦çš„ä¾èµ–å…³ç³»ã€‚\nä»¥å‚æ•°å–ä»£æŸ¥è¯¢ï¼ˆReplace Query with Parameterï¼‰\nå¥½å¤„ï¼šæ”¹å˜ä¾èµ–å…³ç³»ï¼Œå»æ‰ä»¤äººä¸å¿«çš„å¼•ç”¨ã€‚\næ³¨æ„ï¼šè¦è€ƒè™‘è´£ä»»åˆ†é…é—®é¢˜ï¼Œä¼šå¢åŠ å‡½æ•°è°ƒç”¨è€…çš„å¤æ‚åº¦ï¼Œè€Œè®¾è®¡æ¥å£æ—¶åˆéœ€è¦è€ƒè™‘æ˜“ç”¨æ€§ã€‚\nå…«. å¤„ç†ç»§æ‰¿å…³ç³»\nä»¥å§”æ‰˜å–ä»£è¶…ç±»ï¼ˆReplace Superclass with Delegateï¼‰\nç»§æ‰¿ï¼šå­ç±»ç»§æ‰¿çˆ¶ç±»çš„ç‰¹å¾å’Œè¡Œä¸º ï¼ˆè½¦-äº¤é€šå·¥å…·ï¼‰\nç»„åˆï¼šé€šè¿‡å¯¹ç°æœ‰å¯¹è±¡è¿›è¡Œæ‹¼è£…å³ç»„åˆäº§ç”Ÿæ–°çš„å…·æœ‰æ›´å¤æ‚çš„åŠŸèƒ½ ï¼ˆè½¦-è½®èƒï¼‰\nä»¥ç»„åˆå–ä»£ç»§æ‰¿ã€‚\nä¸€ä¸ªç»å…¸çš„è¯¯ç”¨ç»§æ‰¿çš„ä¾‹å­ï¼š\nè®©æ ˆï¼ˆstackï¼‰ç»§æ‰¿åˆ—è¡¨ï¼ˆlistï¼‰ã€‚è¿™ä¸ªæƒ³æ³•çš„å‡ºå‘ç‚¹æ˜¯æƒ³å¤ç”¨åˆ—è¡¨ç±»çš„æ•°æ®å­˜å‚¨å’Œæ“ä½œèƒ½åŠ›ã€‚è™½è¯´å¤ç”¨æ˜¯ä¸€ä»¶å¥½äº‹ï¼Œä½†è¿™ä¸ªç»§æ‰¿å…³ç³»æœ‰é—®é¢˜ï¼šåˆ—è¡¨ç±»çš„æ‰€æœ‰æ“ä½œéƒ½ä¼šå‡ºç°åœ¨æ ˆç±»çš„æ¥å£ä¸Šï¼Œç„¶è€Œå…¶ä¸­å¤§éƒ¨åˆ†æ“ä½œå¯¹ä¸€ä¸ªæ ˆæ¥è¯´å¹¶ä¸é€‚ç”¨ã€‚æ›´å¥½çš„åšæ³•åº”è¯¥æ˜¯æŠŠåˆ—è¡¨ä½œä¸ºæ ˆçš„å­—æ®µï¼ŒæŠŠå¿…è¦çš„æ“ä½œå§”æ´¾ç»™åˆ—è¡¨å°±è¡Œäº†ã€‚\nJava\npublic class Stack\u0026lt;E\u0026gt; extends Vector\u0026lt;E\u0026gt; {\npublic E push(E item) {\naddElement(item);\nreturn item;\n}\npublic synchronized E pop() {\nE obj;\nint len = size();\nobj = peek();\nremoveElementAt(len - 1);\nreturn obj;\n}\n}\nStackçœŸæ­£éœ€è¦çš„åªæœ‰å››ä¸ªæ–¹æ³•ï¼Œpush/pop/size/isEmptyï¼Œ Stackåªç”¨åˆ°äº† Vectorçš„ä¸¤ä¸ªæ–¹æ³• isEmpty å’Œ sizeï¼Œè€Œ push å’Œ pop æ˜¯ Stack è‡ªæœ‰çš„å®ç°ï¼Œ Vector æœ‰å¤§é‡çš„æ–¹æ³•ï¼Œ ä¸é€‚ç”¨äºstackã€‚\næ‰€ä»¥ï¼Œå¦‚æœçˆ¶ç±»çš„ä¸€äº›å‡½æ•°å¯¹å­ç±»å¹¶ä¸é€‚ç”¨ï¼Œå°±è¯´æ˜æˆ‘ä¸åº”è¯¥é€šè¿‡ç»§æ‰¿æ¥è·å¾—è¶…ç±»çš„åŠŸèƒ½ã€‚\nåŒæ—¶ä¹Ÿè¦é¿å…èµ°å¼¯è·¯ï¼šå®Œå…¨é¿å…ä½¿ç”¨ç»§æ‰¿ï¼Œå¦‚æœç¬¦åˆç»§æ‰¿å…³ç³»çš„è¯­ä¹‰æ¡ä»¶ï¼ˆè¶…ç±»çš„æ‰€æœ‰æ–¹æ³•éƒ½é€‚ç”¨äºå­ç±»ï¼Œå­ç±»çš„æ‰€æœ‰å®ä¾‹éƒ½æ˜¯è¶…ç±»çš„å®ä¾‹ï¼‰ï¼Œé‚£ä¹ˆç»§æ‰¿æ˜¯ä¸€ç§ç®€æ´åˆé«˜æ•ˆçš„å¤ç”¨æœºåˆ¶ã€‚\nå»ºè®®ï¼šé¦–å…ˆï¼ˆå°½é‡ï¼‰ä½¿ç”¨ç»§æ‰¿ï¼Œå¦‚æœå‘ç°ç»§æ‰¿æœ‰é—®é¢˜ï¼Œå†ä½¿ç”¨ä»¥å§”æ‰˜å–ä»£è¶…ç±»ã€‚\nèŒƒä¾‹\nèƒŒæ™¯ï¼š\nç»™ä¸€ä¸ªå¤åŸé‡Œå­˜æ”¾ä¸Šå¤å·è½´ï¼ˆscrollï¼‰çš„å›¾ä¹¦é¦†åšäº†å’¨è¯¢ã€‚ä»–ä»¬ç»™å·è½´çš„ä¿¡æ¯ç¼–åˆ¶äº†ä¸€ä»½ç›®å½•ï¼ˆcatalogï¼‰ï¼Œæ¯ä»½å·è½´éƒ½æœ‰ä¸€ä¸ªIDå·ï¼Œå¹¶è®°å½•äº†å·è½´çš„æ ‡é¢˜ï¼ˆtitleï¼‰å’Œä¸€ç³»åˆ—æ ‡ç­¾ï¼ˆtagï¼‰ï¼Œè¿™äº›å¤è€çš„å·è½´éœ€è¦æ—¥å¸¸æ¸…æ‰«ï¼Œå› æ­¤ä»£è¡¨å·è½´çš„Scrollç±»ç»§æ‰¿äº†ä»£è¡¨ç›®å½•é¡¹çš„CatalogItemç±»ï¼Œå¹¶æ‰©å±•å‡ºä¸\u0026quot;éœ€è¦æ¸…æ‰«\u0026quot;ç›¸å…³çš„æ•°æ®ã€‚\nè¿™å°±æ˜¯ä¸€ä¸ªå¸¸è§çš„å»ºæ¨¡é”™è¯¯ã€‚çœŸå®å­˜åœ¨çš„å·è½´å’Œåªå­˜åœ¨äºçº¸é¢ä¸Šçš„ç›®å½•é¡¹ï¼Œæ˜¯å®Œå…¨ä¸åŒçš„ä¸¤ç§ä¸œè¥¿ã€‚æ¯”å¦‚è¯´ï¼Œå…³äº\u0026quot;å¦‚ä½•æ²»ç–—ç°é³ç—…\u0026quot;çš„å·è½´å¯èƒ½æœ‰å¥½å‡ å·ï¼Œä½†åœ¨ç›®å½•ä¸Šå´åªè®°å½•ä¸€ä¸ªæ¡ç›®ã€‚è¿™æ ·çš„å»ºæ¨¡é”™è¯¯å¾ˆå¤šæ—¶å€™å¯ä»¥ç½®ä¹‹ä¸ç†ã€‚åƒ\u0026quot;æ ‡é¢˜\u0026quot;å’Œ\u0026quot;æ ‡ç­¾\u0026quot;è¿™æ ·çš„æ•°æ®ï¼Œå¯ä»¥è®¤ä¸ºå°±æ˜¯ç›®å½•ä¸­æ•°æ®çš„å‰¯æœ¬ã€‚å¦‚æœè¿™äº›æ•°æ®ä»ä¸å‘ç”Ÿæ”¹å˜ï¼Œå¯ä»¥æ¥å—è¿™æ ·çš„è¡¨ç°å½¢å¼ã€‚ä½†å¦‚æœéœ€è¦æ›´æ–°å…¶ä¸­æŸå¤„æ•°æ®ï¼Œå°±å¿…é¡»éå¸¸å°å¿ƒï¼Œç¡®ä¿åŒä¸€ä¸ªç›®å½•é¡¹å¯¹åº”çš„æ‰€æœ‰æ•°æ®å‰¯æœ¬éƒ½è¢«æ­£ç¡®åœ°æ›´æ–°ã€‚\nå°±ç®—æ²¡æœ‰æ•°æ®æ›´æ–°çš„é—®é¢˜ï¼ŒæŠŠç›®å½•ç±»ä½œä¸ºå·è½´ç±»çš„çˆ¶ç±»ï¼Œä¾ç„¶ä¼šè®©åæ¥çš„å¼€å‘è€…æ„Ÿåˆ°è¿·æƒ‘ã€‚\né¦–å…ˆåœ¨Scrollç±»ä¸­åˆ›å»ºä¸€ä¸ªå±æ€§ï¼Œä»¤å…¶æŒ‡å‘ä¸€ä¸ªæ–°å»ºçš„CatalogItemå®ä¾‹ã€‚\nç„¶åå¯¹äºå­ç±»ä¸­ç”¨åˆ°æ‰€æœ‰å±äºè¶…ç±»çš„å‡½æ•°ï¼Œæˆ‘è¦é€ä¸€ä¸ºå®ƒä»¬åˆ›å»ºè½¬å‘å‡½æ•°ã€‚\nè¯¦ç»†ç¬”è®°\nç¬¬1ç«  é‡æ„ï¼Œç¬¬ä¸€ä¸ªç¤ºä¾‹\næœ¬è´¨ä¸Šè¯´ï¼Œé‡æ„å°±æ˜¯åœ¨ä»£ç å†™å¥½ä¹‹åæ”¹è¿›å®ƒçš„è®¾è®¡ã€‚\nå¦‚æœä½ è¦ç»™ç¨‹åºæ·»åŠ ä¸€ä¸ªç‰¹æ€§ï¼Œä½†å‘ç°ä»£ç å› ç¼ºä¹è‰¯å¥½çš„ç»“æ„è€Œä¸æ˜“äºè¿›è¡Œæ›´æ”¹ï¼Œé‚£å°±å…ˆé‡æ„é‚£ä¸ªç¨‹åºï¼Œä½¿å…¶æ¯”è¾ƒå®¹æ˜“æ·»åŠ è¯¥ç‰¹æ€§ï¼Œç„¶åå†æ·»åŠ è¯¥ç‰¹æ€§ã€‚\næ˜¯éœ€æ±‚çš„å˜åŒ–ä½¿é‡æ„å˜å¾—å¿…è¦ã€‚\né‡æ„å‰ï¼Œå…ˆæ£€æŸ¥è‡ªå·±æ˜¯å¦æœ‰ä¸€å¥—å¯é çš„æµ‹è¯•é›†ã€‚è¿™äº›æµ‹è¯•å¿…é¡»æœ‰è‡ªæˆ‘æ£€éªŒèƒ½åŠ›ã€‚\næ¯æ¬¡æƒ³å°†ä¸€å—ä»£ç æŠ½å–æˆä¸€ä¸ªå‡½æ•°æ—¶ï¼Œéµå¾ªä¸€ä¸ªæ ‡å‡†æµç¨‹ï¼šæœ€å¤§ç¨‹åº¦å‡å°‘çŠ¯é”™çš„å¯èƒ½ã€‚\u0026mdash;\u0026mdash;æç‚¼å‡½æ•°\né‡æ„æŠ€æœ¯å°±æ˜¯ä»¥å¾®å°çš„æ­¥ä¼ä¿®æ”¹ç¨‹åºã€‚å¦‚æœä½ çŠ¯ä¸‹é”™è¯¯ï¼Œå¾ˆå®¹æ˜“ä¾¿å¯å‘ç°å®ƒã€‚\nè¥åœ°æ³•åˆ™ï¼šä¿è¯ç¦»å¼€æ—¶çš„ä»£ç åº“ä¸€å®šæ¯”ä½ æ¥æ—¶æ›´åŠ å¥åº·ã€‚å®Œç¾çš„å¢ƒç•Œå¾ˆéš¾è¾¾åˆ°ï¼Œä½†åº”è¯¥æ—¶æ—¶éƒ½å‹¤åŠ æ‹‚æ‹­ã€‚\nä»¥å®ä¾‹å±•å¼€å¦‚ä½•é‡æ„ï¼šåŒ…æ‹¬æç‚¼å‡½æ•°ã€å†…è”å˜é‡ã€æ¬ç§»å‡½æ•°å’Œä»¥å¤šæ€å–ä»£æ¡ä»¶è¡¨è¾¾å¼ç­‰ï¼Œ\nå‡ ä¸ªé‡è¦çš„é˜¶æ®µï¼šå°†åŸå‡½æ•°åˆ†è§£æˆä¸€ç»„åµŒå¥—çš„å‡½æ•°ã€åº”ç”¨æ‹†åˆ†é˜¶æ®µåˆ†ç¦»è®¡ç®—é€»è¾‘ä¸è¾“å‡ºæ ¼å¼åŒ–é€»è¾‘ï¼Œä»¥åŠä¸ºè®¡ç®—å™¨å¼•å…¥å¤šæ€æ€§æ¥å¤„ç†è®¡ç®—é€»è¾‘ã€‚æ¯ä¸€æ­¥éƒ½ç»™ä»£ç æ·»åŠ äº†æ›´å¤šçš„ç»“æ„ï¼Œä»¥ä¾¿æ›´å¥½åœ°è¡¨è¾¾ä»£ç çš„æ„å›¾ã€‚\nå¥½ä»£ç çš„æ£€éªŒæ ‡å‡†å°±æ˜¯äººä»¬æ˜¯å¦èƒ½è½»è€Œæ˜“ä¸¾åœ°ä¿®æ”¹å®ƒã€‚\næ€»ç»“ï¼š\nå¼€å±•é«˜æ•ˆæœ‰åºçš„é‡æ„ï¼Œå…³é”®çš„å¿ƒå¾—æ˜¯ï¼šå°çš„æ­¥å­å¯ä»¥æ›´å¿«å‰è¿›ï¼Œè¯·ä¿æŒä»£ç æ°¸è¿œå¤„äºå¯å·¥ä½œçŠ¶æ€ï¼Œå°æ­¥ä¿®æ”¹ç´¯ç§¯èµ·æ¥ä¹Ÿèƒ½å¤§å¤§æ”¹å–„ç³»ç»Ÿçš„è®¾è®¡ã€‚\nç¬¬2ç« ã€€é‡æ„çš„åŸåˆ™\nä¸ºä½•é‡æ„\nå®ƒä¸æ˜¯ä¸€é¢—\u0026quot;é“¶å¼¹\u0026quot;ï¼Œå´å¯ä»¥ç®—æ˜¯ä¸€æŠŠ\u0026quot;é“¶é’³å­\u0026quot;ï¼Œå¯ä»¥å¸®ä½ å§‹ç»ˆè‰¯å¥½åœ°æ§åˆ¶è‡ªå·±çš„ä»£ç ã€‚é‡æ„æ˜¯ä¸€ä¸ªå·¥å…·\né‡æ„æ”¹è¿›è½¯ä»¶çš„è®¾è®¡\nä»£ç ç»“æ„çš„æµå¤±æœ‰ç´¯ç§¯æ•ˆåº”ã€‚ç»å¸¸æ€§çš„é‡æ„æœ‰åŠ©äºä»£ç ç»´æŒè‡ªå·±è¯¥æœ‰çš„å½¢æ€ã€‚æ¶ˆé™¤é‡å¤ä»£ç ï¼Œä»¥ç¡®å®šæ‰€æœ‰äº‹ç‰©å’Œè¡Œä¸ºåœ¨ä»£ç ä¸­åªè¡¨è¿°ä¸€æ¬¡ï¼Œè¿™æ­£æ˜¯ä¼˜ç§€è®¾è®¡çš„æ ¹æœ¬ã€‚\né‡æ„ä½¿è½¯ä»¶æ›´å®¹æ˜“ç†è§£\nåœ¨é‡æ„ä¸ŠèŠ±ä¸€ç‚¹ç‚¹æ—¶é—´ï¼Œå°±å¯ä»¥è®©ä»£ç æ›´å¥½åœ°è¡¨è¾¾è‡ªå·±çš„æ„å›¾\u0026mdash;\u0026mdash;æ›´æ¸…æ™°åœ°è¯´å‡ºæˆ‘æƒ³è¦åšçš„ã€‚\né‡æ„å¸®åŠ©æ‰¾åˆ°bug\nKent Beckç»å¸¸å½¢å®¹è‡ªå·±çš„ä¸€å¥è¯ï¼š\u0026ldquo;æˆ‘ä¸æ˜¯ä¸€ä¸ªç‰¹åˆ«å¥½çš„ç¨‹åºå‘˜ï¼Œæˆ‘åªæ˜¯ä¸€ä¸ªæœ‰ç€ä¸€äº›ç‰¹åˆ«å¥½çš„ä¹ æƒ¯çš„è¿˜ä¸é”™çš„ç¨‹åºå‘˜ã€‚\u0026rdquo;\né‡æ„æé«˜ç¼–ç¨‹é€Ÿåº¦\néœ€è¦æ·»åŠ æ–°åŠŸèƒ½æ—¶ï¼Œå†…éƒ¨è´¨é‡è‰¯å¥½çš„è½¯ä»¶è®©æˆ‘å¯ä»¥å¾ˆå®¹æ˜“æ‰¾åˆ°åœ¨å“ªé‡Œä¿®æ”¹ã€å¦‚ä½•ä¿®æ”¹ã€‚è‰¯å¥½çš„æ¨¡å—åˆ’åˆ†ä½¿æˆ‘åªéœ€è¦ç†è§£ä»£ç åº“çš„ä¸€å°éƒ¨åˆ†ï¼Œå°±å¯ä»¥åšå‡ºä¿®æ”¹ã€‚å¦‚æœä»£ç å¾ˆæ¸…æ™°ï¼Œå¼•å…¥bugçš„å¯èƒ½æ€§å°±ä¼šå˜å°ã€‚\n\u0026ldquo;è®¾è®¡è€ä¹…æ€§å‡è¯´\u0026rdquo;ï¼šé€šè¿‡æŠ•å…¥ç²¾åŠ›æ”¹å–„å†…éƒ¨è®¾è®¡ï¼Œæˆ‘ä»¬å¢åŠ äº†è½¯ä»¶çš„è€ä¹…æ€§ï¼Œä»è€Œå¯ä»¥æ›´é•¿æ—¶é—´åœ°ä¿æŒå¼€å‘çš„å¿«é€Ÿã€‚\nä½•æ—¶é‡æ„\né¢„å¤‡æ€§é‡æ„ï¼šè®©æ·»åŠ æ–°åŠŸèƒ½æ›´å®¹æ˜“\né‡æ„çš„æœ€ä½³æ—¶æœºå°±åœ¨æ·»åŠ æ–°åŠŸèƒ½ä¹‹å‰ã€‚\nå¦‚æœæŠŠæŸäº›æ›´æ–°æ•°æ®çš„é€»è¾‘ä¸æŸ¥è¯¢é€»è¾‘åˆ†å¼€ï¼Œä¼šæ›´å®¹æ˜“é¿å…é€ æˆé”™è¯¯çš„é€»è¾‘çº ç¼ ã€‚ç”¨é‡æ„æ”¹å–„è¿™äº›æƒ…å†µï¼Œåœ¨åŒæ ·åœºåˆå†æ¬¡å‡ºç°åŒæ ·bugçš„æ¦‚ç‡ä¹Ÿä¼šé™ä½ã€‚\nå¸®åŠ©ç†è§£çš„é‡æ„ï¼šä½¿ä»£ç æ›´æ˜“æ‡‚\næ¡åƒåœ¾å¼é‡æ„\næœ‰è®¡åˆ’çš„é‡æ„å’Œè§æœºè¡Œäº‹çš„é‡æ„\né¢„å¤‡æ€§é‡æ„ã€å¸®åŠ©ç†è§£çš„é‡æ„ã€æ¡åƒåœ¾å¼é‡æ„\u0026mdash;\u0026mdash;éƒ½æ˜¯è§æœºè¡Œäº‹çš„\né•¿æœŸé‡æ„\nå¦‚æœæƒ³æ›¿æ¢æ‰ä¸€ä¸ªæ­£åœ¨ä½¿ç”¨çš„åº“ï¼Œå¯ä»¥å…ˆå¦‚æœæƒ³æ›¿æ¢æ‰ä¸€ä¸ªæ­£åœ¨ä½¿ç”¨çš„åº“ï¼Œå¯ä»¥å…ˆå¼•å…¥ä¸€å±‚æ–°çš„æŠ½è±¡ï¼Œä½¿å…¶å…¼å®¹æ–°æ—§ä¸¤ä¸ªåº“çš„æ¥å£ã€‚ä¸€æ—¦è°ƒç”¨æ–¹å·²ç»å®Œå…¨æ”¹ä¸ºä½¿ç”¨è¿™å±‚æŠ½è±¡ï¼Œæ›¿æ¢ä¸‹é¢çš„åº“å°±ä¼šå®¹æ˜“å¾—å¤šã€‚\nå¤å®¡ä»£ç æ—¶é‡æ„\nä¸åŸä½œè€…è‚©å¹¶è‚©ååœ¨ä¸€èµ·ï¼Œä¸€è¾¹æµè§ˆä»£ç ä¸€è¾¹é‡æ„ï¼Œä½“éªŒæ˜¯æœ€ä½³çš„ã€‚è¿™ç§å·¥ä½œæ–¹å¼å¾ˆè‡ªç„¶åœ°å¯¼å‘ç»“å¯¹ç¼–ç¨‹ï¼šåœ¨ç¼–ç¨‹çš„è¿‡ç¨‹ä¸­æŒç»­ä¸æ–­åœ°è¿›è¡Œä»£ç å¤å®¡ã€‚\né‡æ„çš„æŒ‘æˆ˜\nå»¶ç¼“æ–°åŠŸèƒ½å¼€å‘\né‡æ„çš„å”¯ä¸€ç›®çš„å°±æ˜¯è®©æˆ‘ä»¬å¼€å‘æ›´å¿«ï¼Œç”¨æ›´å°‘çš„å·¥ä½œé‡åˆ›é€ æ›´å¤§çš„ä»·å€¼ã€‚\næœ‰æ—¶ä¼šçœ‹åˆ°ä¸€ä¸ªï¼ˆå¤§è§„æ¨¡çš„ï¼‰é‡æ„å¾ˆæœ‰å¿…è¦è¿›è¡Œï¼Œè€Œé©¬ä¸Šè¦æ·»åŠ çš„åŠŸèƒ½éå¸¸å°ï¼Œè¿™æ—¶åº”å…ˆæŠŠæ–°åŠŸèƒ½åŠ ä¸Šï¼Œç„¶åå†åšè¿™æ¬¡å¤§è§„æ¨¡é‡æ„ã€‚\né‡æ„ä¸è¶³çš„æƒ…å†µè¿œå¤šäºé‡æ„è¿‡åº¦çš„æƒ…å†µã€‚æ¢å¥è¯è¯´ï¼Œç»å¤§å¤šæ•°äººåº”è¯¥å°è¯•å¤šåšé‡æ„ã€‚\né‡æ„çš„æ„ä¹‰ä¸åœ¨äºæŠŠä»£ç åº“æ‰“ç£¨å¾—é—ªé—ªå‘å…‰ï¼Œè€Œæ˜¯çº¯ç²¹ç»æµè§’åº¦å‡ºå‘çš„è€ƒé‡ã€‚æˆ‘ä»¬ä¹‹æ‰€ä»¥é‡æ„ï¼Œå› ä¸ºå®ƒèƒ½è®©æˆ‘ä»¬æ›´å¿«\u0026mdash;\u0026mdash;æ·»åŠ åŠŸèƒ½æ›´å¿«ï¼Œä¿®å¤bugæ›´å¿«ã€‚\nä»£ç æ‰€æœ‰æƒ\næ—§çš„æ¥å£æ ‡è®°ä¸º\u0026quot;ä¸æ¨èä½¿ç”¨\u0026quot;ï¼ˆdeprecatedï¼‰ã€‚\nåˆ†æ”¯\næŒç»­é›†æˆï¼ˆContinuous Integrationï¼ŒCIï¼‰ï¼Œä¹Ÿå«\u0026quot;åŸºäºä¸»å¹²å¼€å‘\u0026quot;ï¼ˆTrunk-Based Developmentï¼‰ã€‚\né‡æ„ã€æ¶æ„å’ŒYAGNI\né‡æ„å¯¹æ¶æ„æœ€å¤§çš„å½±å“åœ¨äºï¼Œé€šè¿‡é‡æ„ï¼Œæˆ‘ä»¬èƒ½å¾—åˆ°ä¸€ä¸ªè®¾è®¡è‰¯å¥½çš„ä»£ç åº“ï¼Œä½¿å…¶èƒ½å¤Ÿä¼˜é›…åœ°åº”å¯¹ä¸æ–­å˜åŒ–çš„éœ€æ±‚ã€‚\u0026ldquo;åœ¨ç¼–ç ä¹‹å‰å…ˆå®Œæˆæ¶æ„\u0026quot;è¿™ç§åšæ³•æœ€å¤§çš„é—®é¢˜åœ¨äºï¼Œå®ƒå‡è®¾äº†è½¯ä»¶çš„éœ€æ±‚å¯ä»¥é¢„å…ˆå……åˆ†ç†è§£ã€‚\né‡æ„ä¸è½¯ä»¶å¼€å‘è¿‡ç¨‹\næ—¢ç‰¢å›ºå¯é åˆèƒ½å¿«é€Ÿå“åº”å˜åŒ–çš„éœ€æ±‚ã€‚\nè‡ªåŠ¨åŒ–é‡æ„\nä¸ä»…èƒ½å¤„ç†æ–‡æœ¬ï¼Œè¿˜èƒ½å¤„ç†è¯­æ³•æ ‘ï¼Œè¿™æ˜¯IDEç›¸æ¯”äºæ–‡æœ¬ç¼–è¾‘å™¨æ›´å…ˆè¿›çš„åœ°æ–¹ã€‚é‡æ„å·¥å…·ä¸ä»…éœ€è¦ç†è§£å’Œä¿®æ”¹è¯­æ³•æ ‘ï¼Œè¿˜è¦çŸ¥é“å¦‚ä½•æŠŠä¿®æ”¹åçš„ä»£ç å†™å›ç¼–è¾‘å™¨è§†å›¾ã€‚å¦‚æœæˆ‘ç»™ä¸€ä¸ªå˜é‡æ”¹åï¼Œå·¥å…·ä¼šæé†’æˆ‘ä¿®æ”¹ä½¿ç”¨äº†æ—§åå­—çš„æ³¨é‡Šã€‚èƒ½å€ŸåŠ©è¯­æ³•æ ‘æ¥åˆ†æå’Œé‡æ„ç¨‹åºä»£ç ï¼Œè¿™æ˜¯IDEä¸æ™®é€šæ–‡æœ¬ç¼–è¾‘å™¨ç›¸æ¯”å…·æœ‰çš„ä¸€å¤§ä¼˜åŠ¿ã€‚\nç¬¬3ç« ã€€ä»£ç çš„åå‘³é“\nç¥ç§˜å‘½åï¼ˆMysterious Nameï¼‰\nå‘½åæ˜¯ç¼–ç¨‹ä¸­æœ€éš¾çš„ä¸¤ä»¶äº‹ä¹‹ä¸€[mf-2h]ã€‚æ­£å› ä¸ºå¦‚æ­¤ï¼Œæ”¹åå¯èƒ½æ˜¯æœ€å¸¸ç”¨çš„é‡æ„æ‰‹æ³•ï¼ŒåŒ…æ‹¬æ”¹å˜å‡½æ•°å£°æ˜ï¼ˆç”¨äºç»™å‡½æ•°æ”¹åï¼‰ã€å˜é‡æ”¹åã€å­—æ®µæ”¹åã€‚\né‡å¤ä»£ç ï¼ˆDuplicated Codeï¼‰\nè¿‡é•¿å‡½æ•°ï¼ˆLong Functionï¼‰\nç§¯æåœ°åˆ†è§£å‡½æ•°.\nåŸåˆ™ï¼šæ¯å½“æ„Ÿè§‰éœ€è¦ä»¥æ³¨é‡Šæ¥è¯´æ˜ç‚¹ä»€ä¹ˆçš„æ—¶å€™ï¼Œæˆ‘ä»¬å°±æŠŠéœ€è¦è¯´æ˜çš„ä¸œè¥¿å†™è¿›ä¸€ä¸ªç‹¬ç«‹å‡½æ•°ä¸­ï¼Œå¹¶ä»¥å…¶ç”¨é€”ï¼ˆè€Œéå®ç°æ‰‹æ³•ï¼‰å‘½åã€‚å…³é”®ä¸åœ¨äºå‡½æ•°çš„é•¿åº¦ï¼Œè€Œåœ¨äºå‡½æ•°\u0026quot;åšä»€ä¹ˆ\u0026quot;å’Œ\u0026quot;å¦‚ä½•åš\u0026quot;ä¹‹é—´çš„è¯­ä¹‰è·ç¦»ã€‚\nå¦‚ä½•ç¡®å®šè¯¥æç‚¼å“ªä¸€æ®µä»£ç å‘¢ï¼Ÿä¸€ä¸ªå¾ˆå¥½çš„æŠ€å·§æ˜¯ï¼šå¯»æ‰¾æ³¨é‡Šã€‚å®ƒä»¬é€šå¸¸èƒ½æŒ‡å‡ºä»£ç ç”¨é€”å’Œå®ç°æ‰‹æ³•ä¹‹é—´çš„è¯­ä¹‰è·ç¦»ã€‚\næ¡ä»¶è¡¨è¾¾å¼å’Œå¾ªç¯å¸¸å¸¸ä¹Ÿæ˜¯æç‚¼çš„ä¿¡å·ã€‚ä½ å¯ä»¥ä½¿ç”¨åˆ†è§£æ¡ä»¶è¡¨è¾¾å¼å¤„ç†æ¡ä»¶è¡¨è¾¾å¼ã€‚\nå¯¹äºåºå¤§çš„switchè¯­å¥ï¼Œå…¶ä¸­çš„æ¯ä¸ªåˆ†æ”¯éƒ½åº”è¯¥é€šè¿‡æç‚¼å‡½æ•°å˜æˆç‹¬ç«‹çš„å‡½æ•°è°ƒç”¨ã€‚å¦‚æœæœ‰å¤šä¸ªswitchè¯­å¥åŸºäºåŒä¸€ä¸ªæ¡ä»¶è¿›è¡Œåˆ†æ”¯é€‰æ‹©ï¼Œå°±åº”è¯¥ä½¿ç”¨ä»¥å¤šæ€å–ä»£æ¡ä»¶è¡¨è¾¾å¼ã€‚\nåº”è¯¥å°†å¾ªç¯å’Œå¾ªç¯å†…çš„ä»£ç æç‚¼åˆ°ä¸€ä¸ªç‹¬ç«‹çš„å‡½æ•°ä¸­ã€‚å¦‚æœä½ å‘ç°æç‚¼å‡ºçš„å¾ªç¯å¾ˆéš¾å‘½åï¼Œå¯èƒ½æ˜¯å› ä¸ºå…¶ä¸­åšäº†å‡ ä»¶ä¸åŒçš„äº‹ã€‚å¦‚æœæ˜¯è¿™ç§æƒ…å†µï¼Œè¯·å‹‡æ•¢åœ°ä½¿ç”¨æ‹†åˆ†å¾ªç¯å°†å…¶æ‹†åˆ†æˆå„è‡ªç‹¬ç«‹çš„ä»»åŠ¡ã€‚\nè¿‡é•¿å‚æ•°åˆ—è¡¨ï¼ˆLong Parameter Listï¼‰\nå¦‚æœå¯ä»¥å‘æŸä¸ªå‚æ•°å‘èµ·æŸ¥è¯¢è€Œè·å¾—å¦ä¸€ä¸ªå‚æ•°çš„å€¼ï¼Œé‚£ä¹ˆå°±å¯ä»¥ä½¿ç”¨ä»¥æŸ¥è¯¢å–ä»£å‚æ•°å»æ‰è¿™ç¬¬äºŒä¸ªå‚æ•°ã€‚\nå¦‚æœä½ å‘ç°è‡ªå·±æ­£åœ¨ä»ç°æœ‰çš„æ•°æ®ç»“æ„ä¸­æŠ½å‡ºå¾ˆå¤šæ•°æ®é¡¹ï¼Œå°±å¯ä»¥è€ƒè™‘ä½¿ç”¨ä¿æŒå¯¹è±¡å®Œæ•´æ‰‹æ³•ï¼Œç›´æ¥ä¼ å…¥åŸæ¥çš„æ•°æ®ç»“æ„ã€‚å¦‚æœæœ‰å‡ é¡¹å‚æ•°æ€»æ˜¯åŒæ—¶å‡ºç°ï¼Œå¯ä»¥ç”¨å¼•å…¥å‚æ•°å¯¹è±¡å°†å…¶åˆå¹¶æˆä¸€ä¸ªå¯¹è±¡ã€‚\nå¦‚æœæŸä¸ªå‚æ•°è¢«ç”¨ä½œåŒºåˆ†å‡½æ•°è¡Œä¸ºçš„æ ‡è®°ï¼ˆflagï¼‰ï¼Œå¯ä»¥ä½¿ç”¨ç§»é™¤æ ‡è®°å‚æ•°ã€‚\nä½¿ç”¨ç±»å¯ä»¥æœ‰æ•ˆåœ°ç¼©çŸ­å‚æ•°åˆ—è¡¨ã€‚å¦‚æœå¤šä¸ªå‡½æ•°æœ‰åŒæ ·çš„å‡ ä¸ªå‚æ•°ï¼Œå¼•å…¥ä¸€ä¸ªç±»å°±å°¤ä¸ºæœ‰æ„ä¹‰ã€‚ä½ å¯ä»¥ä½¿ç”¨å‡½æ•°ç»„åˆæˆç±»ï¼Œå°†è¿™äº›å…±åŒçš„å‚æ•°å˜æˆè¿™ä¸ªç±»çš„å­—æ®µã€‚\nå…¨å±€æ•°æ®ï¼ˆGlobal Dataï¼‰\nå°è£…å˜é‡ã€‚æœ‰å°‘é‡çš„å…¨å±€æ•°æ®æˆ–è®¸æ— å¦¨ï¼Œä½†æ•°é‡è¶Šå¤šï¼Œå¤„ç†çš„éš¾åº¦å°±ä¼šæŒ‡æ•°ä¸Šå‡ã€‚\nå¯å˜æ•°æ®ï¼ˆMutable Dataï¼‰\nå¯ä»¥ç”¨å°è£…å˜é‡æ¥ç¡®ä¿æ‰€æœ‰æ•°æ®æ›´æ–°æ“ä½œéƒ½é€šè¿‡å¾ˆå°‘å‡ ä¸ªå‡½æ•°æ¥è¿›è¡Œï¼Œä½¿å…¶æ›´å®¹æ˜“ç›‘æ§å’Œæ¼”è¿›ã€‚\nå¦‚æœä¸€ä¸ªå˜é‡åœ¨ä¸åŒæ—¶å€™è¢«ç”¨äºå­˜å‚¨ä¸åŒçš„ä¸œè¥¿ï¼Œå¯ä»¥ä½¿ç”¨æ‹†åˆ†å˜é‡å°†å…¶æ‹†åˆ†ä¸ºå„è‡ªä¸åŒç”¨é€”çš„å˜é‡ï¼Œä»è€Œé¿å…å±é™©çš„æ›´æ–°æ“ä½œã€‚ä½¿ç”¨ç§»åŠ¨è¯­å¥å’Œæç‚¼å‡½æ•°å°½é‡æŠŠé€»è¾‘ä»å¤„ç†æ›´æ–°æ“ä½œçš„ä»£ç ä¸­æ¬ç§»å‡ºæ¥ï¼Œå°†æ²¡æœ‰å‰¯ä½œç”¨çš„ä»£ç ä¸æ‰§è¡Œæ•°æ®æ›´æ–°æ“ä½œçš„ä»£ç åˆ†å¼€ã€‚è®¾è®¡APIæ—¶ï¼Œå¯ä»¥ä½¿ç”¨å°†æŸ¥è¯¢å‡½æ•°å’Œä¿®æ”¹å‡½æ•°åˆ†ç¦»ã€‚\nå°½æ—©ä½¿ç”¨ç§»é™¤è®¾å€¼å‡½æ•°ï¼Œç¼©å°å˜é‡ä½œç”¨åŸŸã€‚\nå‘æ•£å¼å˜åŒ–ï¼ˆDivergent Changeï¼‰\nå¦‚æœæŸä¸ªæ¨¡å—ç»å¸¸å› ä¸ºä¸åŒçš„åŸå› åœ¨ä¸åŒçš„æ–¹å‘ä¸Šå‘ç”Ÿå˜åŒ–ï¼Œå‘æ•£å¼å˜åŒ–å°±å‡ºç°äº†ã€‚\næç‚¼æ‹†åˆ†ã€‚\néœ°å¼¹å¼ä¿®æ”¹ï¼ˆShotgun Surgeryï¼‰\nå¦‚æœæ¯é‡åˆ°æŸç§å˜åŒ–ï¼Œä½ éƒ½å¿…é¡»åœ¨è®¸å¤šä¸åŒçš„ç±»å†…åšå‡ºè®¸å¤šå°ä¿®æ”¹ï¼Œä½ æ‰€é¢ä¸´çš„åå‘³é“å°±æ˜¯éœ°å¼¹å¼ä¿®æ”¹ã€‚\næ¬ç§»å‡½æ•°å’Œæ¬ç§»å­—æ®µæŠŠæ‰€æœ‰éœ€è¦ä¿®æ”¹çš„ä»£ç æ”¾è¿›åŒä¸€ä¸ªæ¨¡å—é‡Œã€‚å¦‚æœæœ‰å¾ˆå¤šå‡½æ•°éƒ½åœ¨æ“ä½œç›¸ä¼¼çš„æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å‡½æ•°ç»„åˆæˆç±»ã€‚å¦‚æœæœ‰äº›å‡½æ•°çš„åŠŸèƒ½æ˜¯è½¬åŒ–æˆ–è€…å……å®æ•°æ®ç»“æ„ï¼Œå¯ä»¥ä½¿ç”¨å‡½æ•°ç»„åˆæˆå˜æ¢ã€‚å¦‚æœä¸€äº›å‡½æ•°çš„è¾“å‡ºå¯ä»¥ç»„åˆåæä¾›ç»™ä¸€æ®µä¸“é—¨ä½¿ç”¨è¿™äº›è®¡ç®—ç»“æœçš„é€»è¾‘ï¼Œè¿™ç§æ—¶å€™å¸¸å¸¸ç”¨å¾—ä¸Šæ‹†åˆ†é˜¶æ®µã€‚\nä¸€ä¸ªå¸¸ç”¨çš„ç­–ç•¥å°±æ˜¯ä½¿ç”¨ä¸å†…è”ï¼ˆinlineï¼‰ç›¸å…³çš„é‡æ„\u0026mdash;\u0026mdash;å¦‚å†…è”å‡½æ•°ï¼ˆ1æˆ–æ˜¯å†…è”ç±»\u0026mdash;\u0026mdash;æŠŠæœ¬ä¸è¯¥åˆ†æ•£çš„é€»è¾‘æ‹½å›ä¸€å¤„ã€‚å®Œæˆå†…è”ä¹‹åï¼Œä½ å¯èƒ½ä¼šé—»åˆ°è¿‡é•¿å‡½æ•°æˆ–è€…è¿‡å¤§çš„ç±»çš„å‘³é“ï¼Œå†ç”¨ä¸æç‚¼ç›¸å…³çš„é‡æ„æ‰‹æ³•å°†å…¶æ‹†è§£æˆæ›´åˆç†çš„å°å—ã€‚\nä¾æ‹æƒ…ç»“ï¼ˆFeature Envyï¼‰\næ¨¡å—åŒ–ï¼Œå°±æ˜¯åŠ›æ±‚å°†ä»£ç åˆ†å‡ºåŒºåŸŸï¼Œæœ€å¤§åŒ–åŒºåŸŸå†…éƒ¨çš„äº¤äº’ã€æœ€å°åŒ–è·¨åŒºåŸŸçš„äº¤äº’ã€‚\nä¸€ä¸ªå‡½æ•°è·Ÿå¦ä¸€ä¸ªæ¨¡å—ä¸­çš„å‡½æ•°æˆ–è€…æ•°æ®äº¤æµæ ¼å¤–é¢‘ç¹ï¼Œè¿œèƒœäºåœ¨è‡ªå·±æ‰€å¤„æ¨¡å—å†…éƒ¨çš„äº¤æµï¼Œè¿™å°±æ˜¯ä¾æ‹æƒ…ç»“çš„å…¸å‹æƒ…å†µã€‚\næ•°æ®æ³¥å›¢ï¼ˆData Clumpsï¼‰\næ€»æ˜¯ç»‘åœ¨ä¸€èµ·å‡ºç°çš„æ•°æ®çœŸåº”è¯¥æ‹¥æœ‰å±äºå®ƒä»¬è‡ªå·±çš„å¯¹è±¡ã€‚\nåŸºæœ¬ç±»å‹åæ‰§ï¼ˆPrimitive Obsessionï¼‰\næŠŠé’±å½“ä½œæ™®é€šæ•°å­—æ¥è®¡ç®—çš„æƒ…å†µã€è®¡ç®—ç‰©ç†é‡æ—¶æ— è§†å•ä½ï¼ˆå¦‚æŠŠè‹±å¯¸ä¸æ¯«ç±³ç›¸åŠ ï¼‰çš„æƒ…å†µä»¥åŠå¤§é‡ç±»ä¼¼if (a \u0026lt; upper \u0026amp;\u0026amp; a \u0026gt; lower)è¿™æ ·çš„ä»£ç ã€‚\nè¿ç”¨ä»¥å¯¹è±¡å–ä»£åŸºæœ¬ç±»å‹ã€‚\né‡å¤çš„switch ï¼ˆRepeated Switchesï¼‰\nå¤šæ€ã€‚\nå¾ªç¯è¯­å¥ï¼ˆLoopsï¼‰\nï¼Ÿç®¡é“æ“ä½œï¼ˆå¦‚filterå’Œmapï¼‰\nå†—èµ˜çš„å…ƒç´ ï¼ˆLazy Elementï¼‰\néšç€é‡æ„çš„è¿›è¡Œè¶Šå˜è¶Šå°ï¼Œç±»æœ€ååªå‰©äº†ä¸€ä¸ªå‡½æ•°ã€‚åŠæ—¶åˆ é™¤è¿™ä¸ªç±»ï¼Œä½¿ç”¨å†…è”å‡½æ•°æˆ–æ˜¯å†…è”ç±»ã€‚\nå¤¸å¤¸å…¶è°ˆé€šç”¨æ€§ï¼ˆSpeculative Generalityï¼‰\nç”¨ä¸ä¸Šçš„è£…ç½®åªä¼šæŒ¡ä½ çš„è·¯ï¼Œæ‰€ä»¥ï¼ŒæŠŠå®ƒæ¬å¼€å§ã€‚\nä¸´æ—¶å­—æ®µï¼ˆTemporary Fieldï¼‰\nå…¶å†…éƒ¨æŸä¸ªå­—æ®µä»…ä¸ºæŸç§ç‰¹å®šæƒ…å†µè€Œè®¾ã€‚\nè¿‡é•¿çš„æ¶ˆæ¯é“¾ï¼ˆMessage Chainsï¼‰\nå…ˆè§‚å¯Ÿæ¶ˆæ¯é“¾æœ€ç»ˆå¾—åˆ°çš„å¯¹è±¡æ˜¯ç”¨æ¥å¹²ä»€ä¹ˆçš„ï¼Œçœ‹çœ‹èƒ½å¦ä»¥æç‚¼å‡½æ•°æŠŠä½¿ç”¨è¯¥å¯¹è±¡çš„ä»£ç æç‚¼åˆ°ä¸€ä¸ªç‹¬ç«‹çš„å‡½æ•°ä¸­ï¼Œå†è¿ç”¨æ¬ç§»å‡½æ•°æŠŠè¿™ä¸ªå‡½æ•°æ¨å…¥æ¶ˆæ¯é“¾ã€‚\nä¸­é—´äººï¼ˆMiddle Manï¼‰\næŸä¸ªç±»çš„æ¥å£æœ‰ä¸€åŠçš„å‡½æ•°éƒ½å§”æ‰˜ç»™å…¶ä»–ç±»ï¼Œè¿™æ ·å°±æ˜¯è¿‡åº¦è¿ç”¨ã€‚è¿™æ—¶åº”è¯¥ä½¿ç”¨ç§»é™¤ä¸­é—´äººã€‚\nå†…å¹•äº¤æ˜“ï¼ˆInsider Tradingï¼‰\næ¨¡å—ä¹‹é—´å¤§é‡äº¤æ¢æ•°æ®ï¼Œå› ä¸ºè¿™ä¼šå¢åŠ æ¨¡å—é—´çš„è€¦åˆã€‚\nåœ¨å®é™…æƒ…å†µé‡Œï¼Œä¸€å®šçš„æ•°æ®äº¤æ¢ä¸å¯é¿å…ï¼Œä½†æˆ‘ä»¬å¿…é¡»å°½é‡å‡å°‘è¿™ç§æƒ…å†µï¼Œå¹¶æŠŠè¿™ç§äº¤æ¢éƒ½æ”¾åˆ°æ˜é¢ä¸Šæ¥ã€‚\nè¿‡å¤§çš„ç±»ï¼ˆLarge Classï¼‰\nå¼‚æ›²åŒå·¥çš„ç±»ï¼ˆAlternative Classes with Different Interfacesï¼‰\nçº¯æ•°æ®ç±»ï¼ˆData Classï¼‰\nçº¯æ•°æ®ç±»ï¼šå®ƒä»¬æ‹¥æœ‰ä¸€äº›å­—æ®µï¼Œä»¥åŠç”¨äºè®¿é—®ï¼ˆè¯»å†™ï¼‰è¿™äº›å­—æ®µçš„å‡½æ•°ï¼Œé™¤æ­¤ä¹‹å¤–ä¸€æ— é•¿ç‰©ã€‚\nè¢«æ‹’ç»çš„é—èµ ï¼ˆRefused Bequestï¼‰\nå­ç±»åº”è¯¥ç»§æ‰¿è¶…ç±»çš„å‡½æ•°å’Œæ•°æ®ã€‚\nä¸æ„¿æ„æ”¯æŒè¶…ç±»çš„æ¥å£ï¼Œå°±ä¸è¦è™šæƒ…å‡æ„åœ°ç³Šå¼„ç»§æ‰¿ä½“ç³»ï¼Œåº”è¯¥è¿ç”¨ä»¥å§”æ‰˜å–ä»£å­ç±»æˆ–è€…ä»¥å§”æ‰˜å–ä»£è¶…ç±»å½»åº•åˆ’æ¸…ç•Œé™ã€‚\næ³¨é‡Šï¼ˆCommentsï¼‰\nå¦‚æœä½ éœ€è¦æ³¨é‡Šæ¥è§£é‡Šä¸€å—ä»£ç åšäº†ä»€ä¹ˆï¼Œè¯•è¯•æç‚¼å‡½æ•°ï¼›å¦‚æœå‡½æ•°å·²ç»æç‚¼å‡ºæ¥ï¼Œä½†è¿˜æ˜¯éœ€è¦æ³¨é‡Šæ¥è§£é‡Šå…¶è¡Œä¸ºï¼Œè¯•è¯•ç”¨æ”¹å˜å‡½æ•°å£°æ˜ä¸ºå®ƒæ”¹åï¼›å¦‚æœä½ éœ€è¦æ³¨é‡Šè¯´æ˜æŸäº›ç³»ç»Ÿçš„éœ€æ±‚è§„æ ¼ï¼Œè¯•è¯•å¼•å…¥æ–­è¨€ã€‚\nç¬¬4ç« ã€€æ„ç­‘æµ‹è¯•ä½“ç³»\nè‡ªæµ‹è¯•ä»£ç çš„ä»·å€¼\næ—¶é—´ç»Ÿè®¡ï¼šç¼–å†™ä»£ç çš„æ—¶é—´ä»…å æ‰€æœ‰æ—¶é—´ä¸­å¾ˆå°‘çš„ä¸€éƒ¨åˆ†ã€‚æœ‰äº›æ—¶é—´ç”¨æ¥å†³å®šä¸‹ä¸€æ­¥å¹²ä»€ä¹ˆï¼Œæœ‰äº›æ—¶é—´èŠ±åœ¨è®¾è®¡ä¸Šï¼Œä½†æ˜¯ï¼ŒèŠ±è´¹åœ¨è°ƒè¯•ä¸Šçš„æ—¶é—´æ˜¯æœ€å¤šçš„ã€‚\nä¸€å¥—æµ‹è¯•å°±æ˜¯ä¸€ä¸ªå¼ºå¤§çš„bugä¾¦æµ‹å™¨ï¼Œèƒ½å¤Ÿå¤§å¤§ç¼©å‡æŸ¥æ‰¾bugæ‰€éœ€çš„æ—¶é—´ã€‚\næ’°å†™æµ‹è¯•ä»£ç çš„æœ€å¥½æ—¶æœºæ˜¯åœ¨å¼€å§‹åŠ¨æ‰‹ç¼–ç ä¹‹å‰ï¼ŒæŠŠæ³¨æ„åŠ›é›†ä¸­äºæ¥å£è€Œéå®ç°ã€‚\næµ‹è¯•å®ä¾‹\næ€»æ˜¯ç¡®ä¿æµ‹è¯•ä¸è¯¥é€šè¿‡æ—¶çœŸçš„ä¼šå¤±è´¥ï¼šåœ¨ä»£ç ä¸­æš‚æ—¶å¼•å…¥ä¸€ä¸ªé”™è¯¯ã€‚\næ¢æµ‹è¾¹ç•Œæ¡ä»¶\nè¾“å…¥ï¼šç©ºé›†åˆã€0ã€ç©ºå­—ç¬¦ä¸²... é¢„æœŸè¾“å‡ºï¼šï¼Ÿ\nè€ƒè™‘å¯èƒ½å‡ºé”™çš„è¾¹ç•Œæ¡ä»¶ï¼ŒæŠŠæµ‹è¯•ç«åŠ›é›†ä¸­åœ¨é‚£å„¿ã€‚\nä¸è¦å› ä¸ºæµ‹è¯•æ— æ³•æ•æ‰æ‰€æœ‰çš„bugå°±ä¸å†™æµ‹è¯•ï¼Œå› ä¸ºæµ‹è¯•çš„ç¡®å¯ä»¥æ•æ‰åˆ°å¤§å¤šæ•°bugã€‚\nç¬¬5ç« ã€€ä»‹ç»é‡æ„åå½•\næœ¬ç« ä¸»è¦ä½œç”¨æ˜¯æ‰¿ä¸Šå¯ä¸‹ï¼Œç•¥ã€‚\nç¬¬6ç«  ç¬¬ä¸€ç»„é‡æ„\næç‚¼å‡½æ•°ï¼ˆExtract Functionï¼‰\nåŠ¨æœº\nå°†æ„å›¾ä¸å®ç°åˆ†å¼€ï¼šå¦‚æœä½ éœ€è¦èŠ±æ—¶é—´æµè§ˆä¸€æ®µä»£ç æ‰èƒ½å¼„æ¸…å®ƒåˆ°åº•åœ¨å¹²ä»€ä¹ˆï¼Œé‚£ä¹ˆå°±åº”è¯¥å°†å…¶æç‚¼åˆ°ä¸€ä¸ªå‡½æ•°ä¸­ï¼Œå¹¶æ ¹æ®å®ƒæ‰€åšçš„äº‹ä¸ºå…¶å‘½åã€‚å› ä¸ºå¤§å¤šæ•°æ—¶å€™æ ¹æœ¬ä¸éœ€è¦å…³å¿ƒå‡½æ•°å¦‚ä½•è¾¾æˆå…¶ç”¨é€”ï¼ˆè¿™æ˜¯å‡½æ•°ä½“å†…å¹²çš„äº‹ï¼‰\nå¥½åå­—ï¼šåœ¨ä¸€ä¸ªå¤§å‡½æ•°ä¸­ï¼Œä¸€æ®µä»£ç æ”¾ç€ä¸€å¥æ³¨é‡Šï¼Œæç‚¼æˆå‡½æ•°ï¼Œæ³¨é‡Šå¾€å¾€æç¤ºä¸€ä¸ªå¥½åå­—ã€‚\nåšæ³•\nåˆ›é€ ä¸€ä¸ªæ–°å‡½æ•°ï¼šä»¥\u0026quot;åšä»€ä¹ˆ\u0026quot;è€Œé\u0026quot;æ€ä¹ˆåš\u0026quot;æ¥å‘½åã€‚\næ— å±€éƒ¨å˜é‡ï¼Œç›´æ¥æç‚¼æˆå‡½æ•°ï¼›\næœ‰å±€éƒ¨å˜é‡ä½†åªè¯»ï¼Œä½œä¸ºå‚æ•°ä¼ é€’ç»™ç›®æ ‡å‡½æ•°\nå±€éƒ¨å˜é‡è¢«èµ‹å€¼ï¼šåªåœ¨æç‚¼å‡½æ•°ä¸­è¢«ä½¿ç”¨åˆ™å¯ç›´æ¥å£°æ˜åœ¨æç‚¼å‡½æ•°ä¸­ï¼›åœ¨æç‚¼å‡½æ•°å¤–ä¹Ÿè¢«ä½¿ç”¨åˆ™å¯ä½œä¸ºæç‚¼å‡½æ•°çš„è¿”å›å€¼ï¼›å¤šä¸ªå˜é‡è¢«ä¿®æ”¹å¯è€ƒè™‘è¿”å›ä¸€ä¸ªå¯¹è±¡æˆ–è€…ä½¿ç”¨å…¶ä»–é‡æ„æ‰‹æ³•ï¼ˆä»¥æŸ¥è¯¢å–ä»£ä¸´æ—¶å˜é‡ã€æ‹†åˆ†å˜é‡ï¼‰\nå†…è”å‡½æ•°ï¼ˆInline Functionï¼‰\nåŠ¨æœº\né—´æ¥æ€§å¯èƒ½å¸¦æ¥å¸®åŠ©ï¼Œä½†éå¿…è¦çš„é—´æ¥æ€§æ€»æ˜¯è®©äººä¸èˆ’æœã€‚\næŸäº›å‡½æ•°å…¶å†…å®¹å’Œåç§°æ¸…æ™°æ˜“è¯»\nä¸€ç¾¤å‡½æ•°çš„ç»„ç»‡ä¸ç”šåˆç†ï¼Œå…ˆå†…è”åˆ°ä¸€ä¸ªå¤§å‡½æ•°ï¼Œå†æç‚¼ã€‚\nåšæ³•\nç¡®å®šå‡½æ•°ä¸å…·å¤šæ€æ€§\næ‰¾åˆ°æ‰€æœ‰è°ƒç”¨ç‚¹æ‰§è¡Œæ›¿æ¢ï¼ˆé‡ç‚¹åœ¨äºå§‹ç»ˆå°æ­¥å‰è¿›ï¼‰\næç‚¼å˜é‡ï¼ˆExtract Variableï¼‰\nåŠ¨æœº\næä¾›äº†åˆé€‚çš„ä¸Šä¸‹æ–‡ï¼šå¸®åŠ©æˆ‘ä»¬å°†è¡¨è¾¾å¼åˆ†è§£ä¸ºæ¯”è¾ƒå®¹æ˜“ç®¡ç†çš„å½¢å¼ï¼Œä¹Ÿä¾¿äºç†è§£ä¸€éƒ¨åˆ†ä»£ç æ˜¯å¹²ä»€ä¹ˆçš„ã€‚\nå†…è”å˜é‡ï¼ˆInline Variableï¼‰\nåŠ¨æœº\næœ‰æ—¶å€™ï¼Œå˜é‡åå­—å¹¶ä¸æ¯”è¡¨è¾¾å¼æœ¬èº«æ›´å…·è¡¨ç°åŠ›ã€‚è¿˜æœ‰äº›æ—¶å€™ï¼Œå˜é‡å¯èƒ½ä¼šå¦¨ç¢é‡æ„é™„è¿‘çš„ä»£ç ã€‚\næ”¹å˜å‡½æ•°å£°æ˜ï¼ˆChange Function Declarationï¼‰\nåŠ¨æœº\nä¸€ä¸ªå¥½åå­—èƒ½è®©äººä¸€çœ¼çœ‹å‡ºå‡½æ•°çš„ç”¨é€”ï¼›\nå‡½æ•°çš„å‚æ•°åˆ—è¡¨é˜è¿°äº†å‡½æ•°å¦‚ä½•ä¸å¤–éƒ¨ä¸–ç•Œå…±å¤„ï¼Œä¿®æ”¹å‚æ•°åˆ—è¡¨ä¸ä»…èƒ½å¢åŠ å‡½æ•°çš„åº”ç”¨èŒƒå›´ï¼Œè¿˜èƒ½æ”¹å˜è¿æ¥ä¸€ä¸ªæ¨¡å—æ‰€éœ€çš„æ¡ä»¶ï¼Œä»è€Œå»é™¤ä¸å¿…è¦çš„è€¦åˆã€‚\nå°è£…å˜é‡ï¼ˆEncapsulate Variableï¼‰\nåŠ¨æœº\nå¯¹äºæ‰€æœ‰å¯å˜çš„æ•°æ®ï¼Œåªè¦å®ƒçš„ä½œç”¨åŸŸè¶…å‡ºå•ä¸ªå‡½æ•°ï¼Œæˆ‘å°±ä¼šå°†å…¶å°è£…èµ·æ¥ï¼Œåªå…è®¸é€šè¿‡å‡½æ•°è®¿é—®ã€‚æ•°æ®çš„ä½œç”¨åŸŸè¶Šå¤§ï¼Œå°è£…å°±è¶Šé‡è¦ã€‚\nå˜é‡æ”¹åï¼ˆRename Variableï¼‰\nåŠ¨æœº\nè§£é‡Šä¸€æ®µç¨‹åºåœ¨å¹²ä»€ä¹ˆï¼Œå¯¹äºä½œç”¨åŸŸè¶…å‡ºä¸€æ¬¡å‡½æ•°è°ƒç”¨çš„å­—æ®µï¼Œåˆ™éœ€è¦æ›´ç”¨å¿ƒå‘½åã€‚\nå¼•å…¥å‚æ•°å¯¹è±¡ï¼ˆIntroduce Parameter Objectï¼‰\nåŠ¨æœº\nå°†æ•°æ®ç»„ç»‡æˆç»“æ„ï¼Œä½¿æ•°æ®é¡¹ä¹‹é—´çš„å…³ç³»æ›´æ¸…æ™°ï¼›\nç¼©çŸ­å‚æ•°åˆ—è¡¨ï¼›\nä»£ç ä¸€è‡´æ€§ï¼šæ‰€æœ‰ä½¿ç”¨è¯¥æ•°æ®ç»“æ„çš„å‡½æ•°éƒ½å¯ä»¥é€šè¿‡ç›¸åŒçš„åå­—æ¥è®¿é—®å…¶ä¸­å…ƒç´ ã€‚\næ”¹å˜ä»£ç çš„æ¦‚å¿µå›¾æ™¯ï¼Œå°†è¿™äº›æ•°æ®ç»“æ„æå‡ä¸ºæ–°çš„æŠ½è±¡æ¦‚å¿µ\nå‡½æ•°ç»„åˆæˆç±»ï¼ˆCombine Functions into Classï¼‰\nåŠ¨æœº\nå¦‚æœå‘ç°ä¸€ç»„å‡½æ•°å½¢å½±ä¸ç¦»åœ°æ“ä½œåŒä¸€å—æ•°æ®ï¼ˆé€šå¸¸æ˜¯å°†è¿™å—æ•°æ®ä½œä¸ºå‚æ•°ä¼ é€’ç»™å‡½æ•°ï¼‰ï¼Œæ˜¯æ—¶å€™ç»„å»ºä¸€ä¸ªç±»äº†ã€‚ç±»èƒ½æ˜ç¡®åœ°ç»™è¿™äº›å‡½æ•°æä¾›ä¸€ä¸ªå…±ç”¨çš„ç¯å¢ƒï¼Œåœ¨å¯¹è±¡å†…éƒ¨è°ƒç”¨è¿™äº›å‡½æ•°å¯ä»¥å°‘ä¼ è®¸å¤šå‚æ•°ï¼Œä»è€Œç®€åŒ–å‡½æ•°è°ƒç”¨ã€‚\nå‡½æ•°ç»„åˆæˆå˜æ¢ï¼ˆCombine Functions into Transformï¼‰\nåŠ¨æœº\nåœ¨è½¯ä»¶ä¸­ï¼Œç»å¸¸éœ€è¦æŠŠæ•°æ®\u0026quot;å–‚\u0026quot;ç»™ä¸€ä¸ªç¨‹åºï¼Œè®©å®ƒå†è®¡ç®—å‡ºå„ç§æ´¾ç”Ÿä¿¡æ¯ã€‚è¿™äº›æ´¾ç”Ÿæ•°å€¼å¯èƒ½ä¼šåœ¨å‡ ä¸ªä¸åŒåœ°æ–¹ç”¨åˆ°ï¼Œå› æ­¤è¿™äº›è®¡ç®—é€»è¾‘ä¹Ÿå¸¸ä¼šåœ¨ç”¨åˆ°æ´¾ç”Ÿæ•°æ®çš„åœ°æ–¹é‡å¤ã€‚æŠŠæ‰€æœ‰è®¡ç®—æ´¾ç”Ÿæ•°æ®çš„é€»è¾‘æ”¶æ‹¢åˆ°ä¸€å¤„ï¼Œè¿™æ ·å§‹ç»ˆå¯ä»¥åœ¨å›ºå®šçš„åœ°æ–¹æ‰¾åˆ°å’Œæ›´æ–°è¿™äº›é€»è¾‘ï¼Œé¿å…åˆ°å¤„é‡å¤ã€‚\nå‡½æ•°ç»„åˆæˆå˜æ¢ä¸å‡½æ•°ç»„åˆæˆç±»åŒºåˆ«ï¼š\nå¦‚æœä»£ç ä¸­ä¼šå¯¹æºæ•°æ®åšæ›´æ–°ï¼Œé‚£ä¹ˆä½¿ç”¨ç±»è¦å¥½å¾—å¤šï¼›å¦‚æœä½¿ç”¨å˜æ¢ï¼Œæ´¾ç”Ÿæ•°æ®ä¼šè¢«å­˜å‚¨åœ¨æ–°ç”Ÿæˆçš„è®°å½•ä¸­ï¼Œä¸€æ—¦æºæ•°æ®è¢«ä¿®æ”¹ï¼Œæˆ‘å°±ä¼šé­é‡æ•°æ®ä¸ä¸€è‡´ã€‚\næ‹†åˆ†é˜¶æ®µï¼ˆSplit Phaseï¼‰\nåŠ¨æœº\nä¸€æ®µä»£ç åœ¨åŒæ—¶å¤„ç†ä¸¤ä»¶ä¸åŒçš„äº‹ï¼Œå¯ä»¥è€ƒè™‘æŠŠå®ƒæ‹†åˆ†æˆå„è‡ªç‹¬ç«‹çš„æ¨¡å—ï¼Œå› ä¸ºè¿™æ ·åˆ°äº†éœ€è¦ä¿®æ”¹çš„æ—¶å€™ï¼Œå¯ä»¥å•ç‹¬å¤„ç†æ¯ä¸ªä¸»é¢˜ã€‚\nä¾‹å­\né‡æ„å‰ï¼š\né‡æ„åï¼š\næç‚¼å‡½æ•°ã€å¼•å…¥ä¸­è½¬æ•°æ®ç»“æ„ï¼š\nç¬¬ä¸ƒç«  å°è£…\nå°è£…è®°å½•ï¼ˆEncapsulate Recordï¼‰\nåŠ¨æœº\nå¯¹è±¡å¯ä»¥éšè—ç»“æ„çš„ç»†èŠ‚ï¼Œæœ‰åŠ©äºå­—æ®µçš„æ”¹åï¼Œæ–¹ä¾¿æ‹“å±•ä»¥åº”å¯¹å˜åŒ–ã€‚\nå°è£…é›†åˆï¼ˆEncapsulate Collectionï¼‰\nåŠ¨æœº\nå°è£…é›†åˆæ—¶äººä»¬å¸¸å¸¸çŠ¯ä¸€ä¸ªé”™è¯¯ï¼šåªå¯¹é›†åˆå˜é‡çš„è®¿é—®è¿›è¡Œäº†å°è£…ï¼Œä½†ä¾ç„¶è®©å–å€¼å‡½æ•°è¿”å›é›†åˆæœ¬èº«ã€‚è¿™ä½¿å¾—é›†åˆçš„æˆå‘˜å˜é‡å¯ä»¥ç›´æ¥è¢«ä¿®æ”¹ï¼Œè€Œå°è£…å®ƒçš„ç±»åˆ™å…¨ç„¶ä¸çŸ¥ï¼Œæ— æ³•ä»‹å…¥ã€‚\nåšæ³•ï¼š\nåœ¨ç±»ä¸Šæä¾›ä¸€äº›ä¿®æ”¹é›†åˆçš„æ–¹æ³•\u0026mdash;\u0026mdash;é€šå¸¸æ˜¯\u0026quot;æ·»åŠ \u0026quot;å’Œ\u0026quot;ç§»é™¤\u0026quot;æ–¹æ³•ã€‚\nä»¥å¯¹è±¡å–ä»£åŸºæœ¬ç±»å‹ï¼ˆReplace Primitive with Objectï¼‰\nä»¥æŸ¥è¯¢å–ä»£ä¸´æ—¶å˜é‡ï¼ˆReplace Temp with Queryï¼‰\næç‚¼ç±»ï¼ˆExtract Classï¼‰\nåŠ¨æœº\nå¦‚æœæŸäº›æ•°æ®å’ŒæŸäº›å‡½æ•°æ€»æ˜¯ä¸€èµ·å‡ºç°ï¼ŒæŸäº›æ•°æ®ç»å¸¸åŒæ—¶å˜åŒ–ç”šè‡³å½¼æ­¤ç›¸ä¾ï¼Œè¿™å°±è¡¨ç¤ºä½ åº”è¯¥å°†å®ƒä»¬åˆ†ç¦»å‡ºå»ã€‚\nå¦‚æœä½ å‘ç°å­ç±»åŒ–åªå½±å“ç±»çš„éƒ¨åˆ†ç‰¹æ€§ï¼Œæˆ–å¦‚æœä½ å‘ç°æŸäº›ç‰¹æ€§éœ€è¦ä»¥ä¸€ç§æ–¹å¼æ¥å­ç±»åŒ–ï¼ŒæŸäº›ç‰¹æ€§åˆ™éœ€è¦ä»¥å¦ä¸€ç§æ–¹å¼å­ç±»åŒ–ï¼Œè¿™å°±æ„å‘³ç€ä½ éœ€è¦åˆ†è§£åŸæ¥çš„ç±»ã€‚\nå†…è”ç±»ï¼ˆInline Classï¼‰\néšè—å§”æ‰˜å…³ç³»ï¼ˆHide Delegateï¼‰\nç§»é™¤ä¸­é—´äººï¼ˆRemove Middle Manï¼‰\n\u0026ldquo;åˆé€‚çš„éšè—ç¨‹åº¦\u0026rdquo;ã€‚\næ›¿æ¢ç®—æ³•ï¼ˆSubstitute Algorithmï¼‰\nç¬¬8ç« ã€€æ¬ç§»ç‰¹æ€§\nå¦ä¸€ç§ç±»å‹çš„é‡æ„ä¹Ÿå¾ˆé‡è¦ï¼Œé‚£å°±æ˜¯åœ¨ä¸åŒçš„ä¸Šä¸‹æ–‡ä¹‹é—´æ¬ç§»å…ƒç´ ã€‚\næ¬ç§»å‡½æ•°ï¼ˆMove Functionï¼‰\nä»»ä½•å‡½æ•°éƒ½éœ€è¦å…·å¤‡ä¸Šä¸‹æ–‡ç¯å¢ƒæ‰èƒ½å­˜æ´»ã€‚\næ¬ç§»å‡½æ•°æœ€ç›´æ¥çš„ä¸€ä¸ªåŠ¨å› æ˜¯ï¼Œå®ƒé¢‘ç¹å¼•ç”¨å…¶ä»–ä¸Šä¸‹æ–‡ä¸­çš„å…ƒç´ ï¼Œè€Œå¯¹è‡ªèº«ä¸Šä¸‹æ–‡ä¸­çš„å…ƒç´ å´å…³å¿ƒç”šå°‘ï¼Œå°†å‡½æ•°ç§»åŠ¨åˆ°è”ç³»æ›´ç´§å¯†çš„ä¸Šä¸‹æ–‡é‚£ä¹ˆç³»ç»Ÿåˆ«å¤„å°±å¯ä»¥å‡å°‘å¯¹å½“å‰æ¨¡å—çš„ä¾èµ–ï¼Œè·å¾—æ›´å¥½çš„å°è£…æ•ˆæœã€‚\næ•´ç†ä»£ç æ—¶ï¼Œå‘ç°éœ€è¦é¢‘ç¹è°ƒç”¨ä¸€ä¸ªåˆ«å¤„çš„å‡½æ•°ï¼›æˆ–è€…å‡½æ•°å†…éƒ¨å®šä¹‰äº†ä¸€ä¸ªå¸®åŠ©å‡½æ•°ï¼Œè€Œè¯¥å¸®åŠ©å‡½æ•°å¯èƒ½åœ¨åˆ«çš„åœ°æ–¹ä¹Ÿæœ‰ç”¨å¤„ï¼Œæ­¤æ—¶å°±å¯ä»¥å°†å®ƒæ¬ç§»åˆ°æŸäº›æ›´é€šç”¨çš„åœ°æ–¹ã€‚\næ˜¯å¦éœ€è¦æ¬ç§»å‡½æ•°å¸¸å¸¸ä¸æ˜“æŠ‰æ‹©ï¼Œä½†å†³å®šè¶Šéš¾åšï¼Œé€šå¸¸è¯´æ˜\u0026quot;æ¬ç§»è¿™ä¸ªå‡½æ•°ä¸å¦\u0026quot;çš„é‡è¦æ€§ä¹Ÿè¶Šä½ã€‚\nèŒƒä¾‹ï¼šæ¬ç§»å†…åµŒå‡½æ•°è‡³é¡¶å±‚\nbeforeï¼š\nafterï¼š\nèŒƒä¾‹ï¼šåœ¨ç±»ä¹‹é—´æ¬ç§»å‡½æ•°\nbeforeï¼š\nafterï¼š\næ¬ç§»å­—æ®µï¼ˆMove Fieldï¼‰\nèŒƒä¾‹\nbeforeï¼š\nafterï¼š\nèŒƒä¾‹ï¼šæ¬ç§»å­—æ®µåˆ°å…±äº«å¯¹è±¡\nbeforeï¼š\nafterï¼š\næ¬ç§»è¯­å¥åˆ°å‡½æ•°ï¼ˆMove Statements into Functionï¼‰\n\u0026ldquo;æ¶ˆé™¤é‡å¤\u0026rdquo;ï¼šå¦‚æœå‘ç°è°ƒç”¨æŸä¸ªå‡½æ•°æ—¶ï¼Œæ€»æœ‰ä¸€äº›ç›¸åŒçš„ä»£ç ä¹Ÿéœ€è¦æ¯æ¬¡æ‰§è¡Œï¼Œåˆ™è€ƒè™‘å°†æ­¤æ®µä»£ç åˆå¹¶åˆ°å‡½æ•°é‡Œå¤´ã€‚\nå¦‚æœæŸäº›è¯­å¥ä¸ä¸€ä¸ªå‡½æ•°æ”¾åœ¨ä¸€èµ·æ›´åƒä¸€ä¸ªæ•´ä½“ï¼Œå¹¶ä¸”æ›´æœ‰åŠ©äºç†è§£ï¼Œåˆ™å°†è¯­å¥æ¬ç§»åˆ°å‡½æ•°é‡Œå»ã€‚å¦‚æœå®ƒä»¬ä¸å‡½æ•°ä¸åƒä¸€ä¸ªæ•´ä½“ï¼Œä½†ä»åº”ä¸å‡½æ•°ä¸€èµ·æ‰§è¡Œï¼Œå¯ä»¥ç”¨æç‚¼å‡½æ•°å°†è¯­å¥å’Œå‡½æ•°ä¸€å¹¶æç‚¼å‡ºå»ã€‚\nèŒƒä¾‹\nbeforeï¼š\nafterï¼š\næ¬ç§»è¯­å¥åˆ°è°ƒç”¨è€…ï¼ˆMove Statements to Callersï¼‰\néšç€ç³»ç»Ÿèƒ½åŠ›å‘ç”Ÿæ¼”è¿›ï¼ŒåŸå…ˆè®¾å®šçš„æŠ½è±¡è¾¹ç•Œæ€»ä¼šæ‚„æ— å£°æ¯åœ°å‘ç”Ÿåç§»ã€‚å¯¹äºå‡½æ•°æ¥è¯´ï¼Œè¿™æ ·çš„è¾¹ç•Œåç§»æ„å‘³ç€æ›¾ç»è§†ä¸ºä¸€ä¸ªæ•´ä½“ã€ä¸€ä¸ªå•å…ƒçš„è¡Œä¸ºï¼Œå¦‚ä»Šå¯èƒ½å·²ç»åˆ†åŒ–å‡ºä¸¤ä¸ªç”šè‡³æ˜¯å¤šä¸ªä¸åŒçš„å…³æ³¨ç‚¹ã€‚\nèŒƒä¾‹\nbeforeï¼š\nafterï¼š\nä»¥å‡½æ•°è°ƒç”¨å–ä»£å†…è”ä»£ç ï¼ˆReplace Inline Code with Function Callï¼‰\nç§»åŠ¨è¯­å¥ï¼ˆSlide Statementsï¼‰\nè®©å­˜åœ¨å…³è”çš„ä¸œè¥¿ä¸€èµ·å‡ºç°ï¼Œå¯ä»¥ä½¿ä»£ç æ›´å®¹æ˜“ç†è§£ã€‚\nå‘½ä»¤æŸ¥è¯¢åˆ†ç¦»åŸåˆ™ï¼ˆCommand-Query Separation,CQSåŸåˆ™ï¼‰ï¼š\n**æŸ¥è¯¢ï¼š**æ–¹æ³•è¿”å›ç»“æœï¼Œä½†ä¸æ”¹å˜ä»»ä½•ç³»ç»ŸçŠ¶æ€(æ— å‰¯ä½œç”¨)ã€‚\n**å‘½ä»¤ï¼š**æ–¹æ³•æ²¡æœ‰ç»“æœï¼Œä½†ä¼šæ”¹å˜ç³»ç»ŸçŠ¶æ€ã€‚\nä¼˜ç‚¹å¦‚ä¸‹\næŸ¥è¯¢ç±»å‹çš„æ–¹æ³•ï¼Œå¯¹äºè°ƒç”¨è€…æ¥è®²ä¸ç”¨åœ¨é¡¾è™‘å„ä¸ªæŸ¥è¯¢æ–¹æ³•çš„è°ƒç”¨é¡ºåºå’Œæ¬¡æ•°(å¿½ç•¥æ€§èƒ½çš„å› ç´ )ã€‚\nå‘½ä»¤ç±»å‹çš„æ–¹æ³•ï¼Œä»è¯­ä¹‰ä¸Šæ¥è®²æ›´å‡†ç¡®ã€‚\nèŒƒä¾‹\næ€è€ƒï¼šå“ªäº›è¯­å¥å¯ä»¥ç§»åŠ¨ï¼Ÿ\nèŒƒä¾‹ï¼šåŒ…å«æ¡ä»¶é€»è¾‘çš„ç§»åŠ¨\nbeforeï¼š\nafterï¼š\næ‹†åˆ†å¾ªç¯ï¼ˆSplit Loopï¼‰\nèŒƒä¾‹\nbeforeï¼š\nafterï¼š\nä»¥ç®¡é“å–ä»£å¾ªç¯ï¼ˆReplace Loop with Pipelineï¼‰\nmapè¿ç®—æ˜¯æŒ‡ç”¨ä¸€ä¸ªå‡½æ•°ä½œç”¨äºè¾“å…¥é›†åˆçš„æ¯ä¸€ä¸ªå…ƒç´ ä¸Šï¼Œå°†é›†åˆå˜æ¢æˆå¦å¤–ä¸€ä¸ªé›†åˆçš„è¿‡ç¨‹ï¼›filterè¿ç®—æ˜¯æŒ‡ç”¨ä¸€ä¸ªå‡½æ•°ä»è¾“å…¥é›†åˆä¸­ç­›é€‰å‡ºç¬¦åˆæ¡ä»¶çš„å…ƒç´ å­é›†çš„è¿‡ç¨‹ã€‚è¿ç®—å¾—åˆ°çš„é›†åˆå¯ä»¥ä¾›ç®¡é“çš„åç»­æµç¨‹ä½¿ç”¨ã€‚\nèŒƒä¾‹\nbeforeï¼š\nafterï¼š\nç§»é™¤æ­»ä»£ç ï¼ˆRemove Dead Codeï¼‰\nç¬¬9ç« ã€€é‡æ–°ç»„ç»‡æ•°æ®\næ‹†åˆ†å˜é‡ï¼ˆSplit Variableï¼‰\né™¤\u0026quot;å¾ªç¯å˜é‡\u0026quot;å’Œ\u0026quot;ç»“æœæ”¶é›†å˜é‡\u0026quot;å¤–ï¼Œè¿˜æœ‰å¾ˆå¤šå˜é‡ç”¨äºä¿å­˜ä¸€æ®µå†—é•¿ä»£ç çš„è¿ç®—ç»“æœï¼Œä»¥ä¾¿ç¨åä½¿ç”¨ã€‚è¿™ç§**å˜é‡åº”è¯¥åªè¢«èµ‹å€¼ä¸€æ¬¡ã€‚**å¦‚æœå®ƒä»¬è¢«èµ‹å€¼è¶…è¿‡ä¸€æ¬¡ï¼Œå°±æ„å‘³å®ƒä»¬åœ¨å‡½æ•°ä¸­æ‰¿æ‹…äº†ä¸€ä¸ªä»¥ä¸Šçš„è´£ä»»ã€‚å¦‚æœå˜é‡æ‰¿æ‹…å¤šä¸ªè´£ä»»ï¼Œå®ƒå°±åº”è¯¥è¢«æ›¿æ¢ï¼ˆåˆ†è§£ï¼‰ä¸ºå¤šä¸ªå˜é‡ï¼Œä¿æŒèŒè´£å•ä¸€ã€‚\nèŒƒä¾‹ï¼šå¯¹è¾“å…¥å‚æ•°èµ‹å€¼\nbeforeï¼š\nafterï¼š\nå­—æ®µæ”¹åï¼ˆRename Fieldï¼‰\nèŒƒä¾‹ï¼šç»™å­—æ®µæ”¹å\nbeforeï¼š\nafterï¼š\nä»¥æŸ¥è¯¢å–ä»£æ´¾ç”Ÿå˜é‡ï¼ˆReplace Derived Variable with Queryï¼‰\nèŒƒä¾‹\nå³æ—¶è®¡ç®—ï¼Œä¸å¿…æ¯æ¬¡æ›´æ–°ã€‚\nbeforeï¼š\nafterï¼š\nèŒƒä¾‹ï¼šä¸æ­¢ä¸€ä¸ªæ•°æ®æ¥æº\nbeforeï¼š\nafterï¼š\nå¼•å…¥æ–­è¨€ï¼š\nå°†å¼•ç”¨å¯¹è±¡æ”¹ä¸ºå€¼å¯¹è±¡ï¼ˆChange Reference to Valueï¼‰\nä¸éœ€è¦å…±äº«ä¸€ä¸ªå¯¹è±¡ã€‚\nèŒƒä¾‹\nbeforeï¼š\nafterï¼š\nå°†å€¼å¯¹è±¡æ”¹ä¸ºå¼•ç”¨å¯¹è±¡ï¼ˆChange Value to Referenceï¼‰\nå…±äº«ä¸€ä¸ªå¯¹è±¡ã€‚\nèŒƒä¾‹\nbeforeï¼š\nafterï¼š\nå­˜åœ¨çš„é—®é¢˜ï¼šæ„é€ å‡½æ•°ä¸ä¸€ä¸ªå…¨å±€çš„ä»“åº“å¯¹è±¡è€¦åˆã€‚\næ”¹è¿›çš„åŠæ³•ï¼šå°†ä»“åº“å¯¹è±¡ä½œä¸ºå‚æ•°ä¼ é€’ç»™æ„é€ å‡½æ•°ã€‚\nç¬¬10ç« ã€€ç®€åŒ–æ¡ä»¶é€»è¾‘\nåˆ†è§£æ¡ä»¶è¡¨è¾¾å¼ï¼ˆDecompose Conditionalï¼‰\nç¨‹åºä¹‹ä¸­ï¼Œå¤æ‚çš„æ¡ä»¶é€»è¾‘æ˜¯æœ€å¸¸å¯¼è‡´å¤æ‚åº¦ä¸Šå‡çš„å› ç´ ä¹‹ä¸€ã€‚\nå¯¹äºæ¡ä»¶é€»è¾‘ï¼Œå°†æ¯ä¸ªåˆ†æ”¯æ¡ä»¶åˆ†è§£æˆæ–°å‡½æ•°è¿˜å¯ä»¥å¸¦æ¥æ›´å¤šå¥½å¤„ï¼šå¯ä»¥çªå‡ºæ¡ä»¶é€»è¾‘ï¼Œæ›´æ¸…æ¥šåœ°è¡¨æ˜æ¯ä¸ªåˆ†æ”¯çš„ä½œç”¨ï¼Œå¹¶ä¸”çªå‡ºæ¯ä¸ªåˆ†æ”¯çš„åŸå› ã€‚\næ³¨ï¼šå®é™…ä¸Šä¸ºæç‚¼å‡½æ•°çš„ä¸€ä¸ªåº”ç”¨åœºæ™¯ã€‚\nèŒƒä¾‹\nbeforeï¼š\nafterï¼š\nåˆå¹¶æ¡ä»¶è¡¨è¾¾å¼ï¼ˆConsolidate Conditional Expressionï¼‰\nä»¥å«è¯­å¥å–ä»£åµŒå¥—æ¡ä»¶è¡¨è¾¾å¼ï¼ˆReplace Nested Conditional with Guard Clausesï¼‰\nå¦‚æœä¸¤æ¡åˆ†æ”¯éƒ½æ˜¯æ­£å¸¸è¡Œä¸ºï¼Œå°±åº”è¯¥ä½¿ç”¨å½¢å¦‚if...else...çš„æ¡ä»¶è¡¨è¾¾å¼ï¼›å¦‚æœæŸä¸ªæ¡ä»¶æå…¶ç½•è§ï¼Œå°±åº”è¯¥å•ç‹¬æ£€æŸ¥è¯¥æ¡ä»¶ï¼Œå¹¶åœ¨è¯¥æ¡ä»¶ä¸ºçœŸæ—¶ç«‹åˆ»ä»å‡½æ•°ä¸­è¿”å›ã€‚è¿™æ ·çš„å•ç‹¬æ£€æŸ¥å¸¸å¸¸è¢«ç§°ä¸º\u0026quot;å«è¯­å¥\u0026rdquo;ï¼ˆguard clausesï¼‰ã€‚\nå¦‚æœä½¿ç”¨if-then-elseç»“æ„ï¼Œåˆ™å¯¹ifåˆ†æ”¯å’Œelseåˆ†æ”¯çš„é‡è§†æ˜¯åŒç­‰çš„ï¼›ä»¥å«è¯­å¥å–ä»£åµŒå¥—æ¡ä»¶è¡¨è¾¾å¼çš„ç²¾é«“å°±æ˜¯ï¼šç»™æŸä¸€æ¡åˆ†æ”¯ä»¥ç‰¹åˆ«çš„é‡è§†ã€‚\n\u0026ldquo;æ¯ä¸ªå‡½æ•°åªèƒ½æœ‰ä¸€ä¸ªå…¥å£å’Œä¸€ä¸ªå‡ºå£\u0026quot;çš„è§‚å¿µæœªå¿…æœ‰ç”¨ï¼Œä¿æŒä»£ç æ¸…æ™°æ‰æ˜¯æœ€å…³é”®çš„ã€‚\nèŒƒä¾‹\nbefore\nafter\nèŒƒä¾‹ï¼šå°†æ¡ä»¶åè½¬\nåˆå§‹\nåè½¬\nåˆå¹¶æ¡ä»¶è¡¨è¾¾å¼\nåˆ é™¤å¯å˜å˜é‡\nä»¥å¤šæ€å–ä»£æ¡ä»¶è¡¨è¾¾å¼ï¼ˆReplace Conditional with Polymorphismï¼‰\nå¼•å…¥ç‰¹ä¾‹ï¼ˆIntroduce Special Caseï¼‰\n\u0026ldquo;ç‰¹ä¾‹\u0026rdquo;ï¼ˆSpecial Caseï¼‰æ¨¡å¼ï¼šåˆ›å»ºä¸€ä¸ªç‰¹ä¾‹å…ƒç´ ï¼Œç”¨ä»¥è¡¨è¾¾å¯¹è¿™ç§ç‰¹ä¾‹çš„å…±ç”¨è¡Œä¸ºçš„å¤„ç†ï¼Œä»è€Œç”¨ä¸€ä¸ªå‡½æ•°è°ƒç”¨å–ä»£å¤§éƒ¨åˆ†ç‰¹ä¾‹æ£€æŸ¥é€»è¾‘ã€‚\nå¼•å…¥æ–­è¨€ï¼ˆIntroduce Assertionï¼‰\nç¬¬11ç«  é‡æ„API\nå°†æŸ¥è¯¢å‡½æ•°å’Œä¿®æ”¹å‡½æ•°åˆ†ç¦»ï¼ˆSeparate Query from Modifierï¼‰\nèŒƒä¾‹\nbefore\nAfter\nå‡½æ•°å‚æ•°åŒ–ï¼ˆParameterize Functionï¼‰\nèŒƒä¾‹\nbefore\nAfter\ng)\nç§»é™¤æ ‡è®°å‚æ•°ï¼ˆRemove Flag Argumentï¼‰\n\u0026ldquo;æ ‡è®°å‚æ•°\u0026quot;æ˜¯è¿™æ ·çš„ä¸€ç§å‚æ•°ï¼šè°ƒç”¨è€…ç”¨å®ƒæ¥æŒ‡ç¤ºè¢«è°ƒå‡½æ•°åº”è¯¥æ‰§è¡Œå“ªä¸€éƒ¨åˆ†é€»è¾‘ã€‚\nèŒƒä¾‹\nBefore\nAfter\nä¿æŒå¯¹è±¡å®Œæ•´ï¼ˆPreserve Whole Objectï¼‰\nå‡å°‘å‡½æ•°å‚æ•°é•¿åº¦ï¼Œæ–¹ä¾¿åç»­æ‹“å±•ã€‚\nä»¥æŸ¥è¯¢å–ä»£å‚æ•°ï¼ˆReplace Parameter with Queryï¼‰\nå‡½æ•°çš„å‚æ•°åˆ—è¡¨åº”è¯¥æ€»ç»“è¯¥å‡½æ•°çš„å¯å˜æ€§ï¼Œæ ‡ç¤ºå‡ºå‡½æ•°å¯èƒ½ä½“ç°å‡ºè¡Œä¸ºå·®å¼‚çš„ä¸»è¦æ–¹å¼ã€‚å’Œä»»ä½•ä»£ç ä¸­çš„è¯­å¥ä¸€æ ·ï¼Œå‚æ•°åˆ—è¡¨åº”è¯¥å°½é‡é¿å…é‡å¤ï¼Œå¹¶ä¸”å‚æ•°åˆ—è¡¨è¶ŠçŸ­å°±è¶Šå®¹æ˜“ç†è§£ã€‚\nä½¿ç”¨åœºæ™¯ï¼šè°ƒç”¨å‡½æ•°æ—¶ä¼ å…¥äº†ä¸€ä¸ªå€¼ï¼Œè€Œè¿™ä¸ªå€¼ç”±å‡½æ•°è‡ªå·±æ¥è·å¾—ä¹Ÿæ˜¯åŒæ ·å®¹æ˜“\nä»€ä¹ˆæ˜¯\u0026quot;åŒæ ·å®¹æ˜“\u0026rdquo;ï¼šå‡½æ•°å¯ä»¥æ‰¿æ‹…è¿™ä»½åŸæœ¬ç”±è°ƒç”¨æ–¹æ‰€æ‰¿æ‹…çš„\u0026quot;è·å¾—æ­£ç¡®çš„å‚æ•°å€¼\u0026quot;çš„è´£ä»»ã€‚\nä»€ä¹ˆæ—¶å€™ä¸é€‚ç”¨ï¼šç§»é™¤å‚æ•°å¯èƒ½ä¼šç»™å‡½æ•°ä½“å¢åŠ ä¸å¿…è¦çš„ä¾èµ–å…³ç³»ã€‚\nç•™æ„ï¼šå¦‚æœåœ¨å¤„ç†çš„å‡½æ•°å…·æœ‰å¼•ç”¨é€æ˜æ€§ï¼ˆreferential transparencyï¼Œå³ï¼Œä¸è®ºä»»ä½•æ—¶å€™ï¼Œåªè¦ä¼ å…¥ç›¸åŒçš„å‚æ•°å€¼ï¼Œè¯¥å‡½æ•°çš„è¡Œä¸ºæ°¸è¿œä¸€è‡´ï¼‰ï¼Œè¿™æ ·çš„å‡½æ•°æ—¢å®¹æ˜“ç†è§£åˆå®¹æ˜“æµ‹è¯•ï¼Œä¸ä¼šå»é™¤å‚æ•°ï¼Œè®©å®ƒè®¿é—®ä¸€ä¸ªå¯å˜çš„å…¨éƒ¨å˜é‡ã€‚\nä»¥å‚æ•°å–ä»£æŸ¥è¯¢ï¼ˆReplace Query with Parameterï¼‰\nå¥½å¤„ï¼šæ”¹å˜ä¾èµ–å…³ç³»ï¼Œå»æ‰ä»¤äººä¸å¿«çš„å¼•ç”¨ã€‚\næ³¨æ„ï¼šè¦è€ƒè™‘è´£ä»»åˆ†é…é—®é¢˜ï¼Œä¼šå¢åŠ å‡½æ•°è°ƒç”¨è€…çš„å¤æ‚åº¦ï¼Œè€Œè®¾è®¡æ¥å£æ—¶åˆéœ€è¦è€ƒè™‘æ˜“ç”¨æ€§ã€‚\nç§»é™¤è®¾å€¼å‡½æ•°ï¼ˆRemove Setting Methodï¼‰\nå»é™¤ä¸å¿…è¦çš„è®¾å€¼å‡½æ•°ã€‚\nä»¥å·¥å‚å‡½æ•°å–ä»£æ„é€ å‡½æ•°ï¼ˆReplace Constructor with Factory Functionï¼‰\nå·¥å‚å‡½æ•°çš„å®ç°æ›´ä¸ºçµæ´»ã€‚\nä»¥å‘½ä»¤å–ä»£å‡½æ•°ï¼ˆReplace Function with Commandï¼‰\nä»¥å‡½æ•°å–ä»£å‘½ä»¤ï¼ˆReplace Command with Functionï¼‰\nå¤„ç†çš„é€»è¾‘ä¸æ˜¯ç‰¹åˆ«å¤æ‚ï¼Œåˆ™å‘½ä»¤å¯¹è±¡å¯èƒ½æ˜¾å¾—è´¹è€Œä¸æƒ ã€‚\nç¬¬12ç« ã€€å¤„ç†ç»§æ‰¿å…³ç³»\nå‡½æ•°ä¸Šç§»ï¼ˆPull Up Methodï¼‰\næ¶ˆé™¤é‡å¤ä»£ç ã€‚\nå­—æ®µä¸Šç§»ï¼ˆPull Up Fieldï¼‰\nåŒæ ·ä¹Ÿæ˜¯æ¶ˆé™¤é‡å¤ä»£ç ã€‚\næ„é€ å‡½æ•°æœ¬ä½“ä¸Šç§»ï¼ˆPull Up Constructor Bodyï¼‰\næç‚¼å„ä¸ªå­ç±»å‡½æ•°ä¸­çš„é‡å¤éƒ¨åˆ†è‡³çˆ¶ç±»ä¸­ï¼ŒåŒæ ·ä¹Ÿæ˜¯æ¶ˆé™¤é‡å¤ä»£ç ã€‚\nå‡½æ•°ä¸‹ç§»ï¼ˆPush Down Methodï¼‰\nå¦‚æœè¶…ç±»ä¸­çš„æŸä¸ªå‡½æ•°åªä¸ä¸€ä¸ªï¼ˆæˆ–å°‘æ•°å‡ ä¸ªï¼‰å­ç±»æœ‰å…³ï¼Œé‚£ä¹ˆæœ€å¥½å°†å…¶ä»çˆ¶ç±»ä¸­æŒªèµ°ï¼Œæ”¾åˆ°çœŸæ­£å…³å¿ƒå®ƒçš„å­ç±»ä¸­å»ã€‚\nå­—æ®µä¸‹ç§»ï¼ˆPush Down Fieldï¼‰\nå¦‚æœæŸä¸ªå­—æ®µåªè¢«ä¸€ä¸ªå­ç±»ï¼ˆæˆ–è€…ä¸€å°éƒ¨åˆ†å­ç±»ï¼‰ç”¨åˆ°ï¼Œå°±å°†å…¶æ¬ç§»åˆ°éœ€è¦è¯¥å­—æ®µçš„å­ç±»ä¸­ã€‚\nä»¥å­ç±»å–ä»£ç±»å‹ç ï¼ˆReplace Type Code with Subclassesï¼‰\nå¯ä»¥ç”¨å¤šæ€æ¥å¤„ç†æ¡ä»¶é€»è¾‘ï¼Œè€Œä¸æ˜¯æ ¹æ®ä¸åŒçš„ç±»å‹ç é‡‡å–ä¸åŒçš„è¡Œä¸ºã€‚\næœ‰äº›å­—æ®µæˆ–å‡½æ•°åªå¯¹ç‰¹å®šçš„ç±»å‹ç å–å€¼æ‰æœ‰æ„ä¹‰ï¼Œå­ç±»çš„å½¢å¼èƒ½æ›´æ˜ç¡®åœ°è¡¨è¾¾æ•°æ®ä¸ç±»å‹ä¹‹é—´çš„å…³ç³»ã€‚\nç§»é™¤å­ç±»ï¼ˆRemove Subclassï¼‰\nå¦‚æœå­ç±»çš„ç”¨å¤„å¤ªå°‘ï¼Œå¯ä»¥ç§»é™¤å­ç±»ï¼Œå°†æ›¿æ¢ä¸ºçˆ¶ç±»çš„ä¸€ä¸ªå­—æ®µã€‚\næç‚¼è¶…ç±»ï¼ˆExtract Superclassï¼‰\nç›®çš„åœ¨äºæŠŠé‡å¤çš„è¡Œä¸ºæ”¶æ‹¢ä¸€å¤„ã€‚\næŠ˜å ç»§æ‰¿ä½“ç³»ï¼ˆCollapse Hierarchyï¼‰\néšç€ç»§æ‰¿ä½“ç³»çš„æ¼”åŒ–ï¼Œæœ‰æ—¶ä¼šå‘ç°ä¸€ä¸ªç±»ä¸å…¶çˆ¶ç±»å·®åˆ«ä¸å¤§ï¼Œæ­¤æ—¶å¯ä»¥æŠŠçˆ¶ç±»å’Œå­ç±»åˆå¹¶èµ·æ¥ã€‚\nä»¥å§”æ‰˜å–ä»£å­ç±»ï¼ˆReplace Subclass with Delegateï¼‰\nä¸ç»§æ‰¿å…³ç³»ç›¸æ¯”ï¼Œä½¿ç”¨å§”æ‰˜ï¼ˆå³ç»„åˆï¼‰å…³ç³»æ—¶æ¥å£æ›´æ¸…æ™°ã€è€¦åˆæ›´å°‘ã€‚\nä»¥å§”æ‰˜å–ä»£è¶…ç±»ï¼ˆReplace Superclass with Delegateï¼‰\nä»¥ç»„åˆå–ä»£ç»§æ‰¿ã€‚\nä¸€ä¸ªç»å…¸çš„è¯¯ç”¨ç»§æ‰¿çš„ä¾‹å­ï¼šè®©æ ˆï¼ˆstackï¼‰ç»§æ‰¿åˆ—è¡¨ï¼ˆlistï¼‰ã€‚è¿™ä¸ªæƒ³æ³•çš„å‡ºå‘ç‚¹æ˜¯æƒ³å¤ç”¨åˆ—è¡¨ç±»çš„æ•°æ®å­˜å‚¨å’Œæ“ä½œèƒ½åŠ›ã€‚è™½è¯´å¤ç”¨æ˜¯ä¸€ä»¶å¥½äº‹ï¼Œä½†è¿™ä¸ªç»§æ‰¿å…³ç³»æœ‰é—®é¢˜ï¼šåˆ—è¡¨ç±»çš„æ‰€æœ‰æ“ä½œéƒ½ä¼šå‡ºç°åœ¨æ ˆç±»çš„æ¥å£ä¸Šï¼Œç„¶è€Œå…¶ä¸­å¤§éƒ¨åˆ†æ“ä½œå¯¹ä¸€ä¸ªæ ˆæ¥è¯´å¹¶ä¸é€‚ç”¨ã€‚æ›´å¥½çš„åšæ³•åº”è¯¥æ˜¯æŠŠåˆ—è¡¨ä½œä¸ºæ ˆçš„å­—æ®µï¼ŒæŠŠå¿…è¦çš„æ“ä½œå§”æ´¾ç»™åˆ—è¡¨å°±è¡Œäº†ã€‚\næ‰€ä»¥ï¼Œå¦‚æœè¶…ç±»çš„ä¸€äº›å‡½æ•°å¯¹å­ç±»å¹¶ä¸é€‚ç”¨ï¼Œå°±è¯´æ˜æˆ‘ä¸åº”è¯¥é€šè¿‡ç»§æ‰¿æ¥è·å¾—è¶…ç±»çš„åŠŸèƒ½ã€‚\nåŒæ—¶ä¹Ÿè¦é¿å…èµ°å¼¯è·¯ï¼šå®Œå…¨é¿å…ä½¿ç”¨ç»§æ‰¿ï¼Œå¦‚æœç¬¦åˆç»§æ‰¿å…³ç³»çš„è¯­ä¹‰æ¡ä»¶ï¼ˆè¶…ç±»çš„æ‰€æœ‰æ–¹æ³•éƒ½é€‚ç”¨äºå­ç±»ï¼Œå­ç±»çš„æ‰€æœ‰å®ä¾‹éƒ½æ˜¯è¶…ç±»çš„å®ä¾‹ï¼‰ï¼Œé‚£ä¹ˆç»§æ‰¿æ˜¯ä¸€ç§ç®€æ´åˆé«˜æ•ˆçš„å¤ç”¨æœºåˆ¶ã€‚\nå»ºè®®ï¼šé¦–å…ˆï¼ˆå°½é‡ï¼‰ä½¿ç”¨ç»§æ‰¿ï¼Œå¦‚æœå‘ç°ç»§æ‰¿æœ‰é—®é¢˜ï¼Œå†ä½¿ç”¨ä»¥å§”æ‰˜å–ä»£è¶…ç±»ã€‚\n","permalink":"https://bleedkagax.github.io/post/0_refactor/","summary":"\u003cp\u003eEssentially, \u003cstrong\u003erefactoring is improving the design of code after it\u0026rsquo;s been written\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eIf you want to add a feature to a program, but find that the code isn\u0026rsquo;t easy to change due to a lack of good structure, refactor that program first so that it\u0026rsquo;s easier to add the feature, and then add the feature.\u003c/p\u003e\n\u003cp\u003eIt is the change in \u003cstrong\u003erequirements\u003c/strong\u003e that makes refactoring necessary.\u003c/p\u003e\n\u003cp\u003eThe refactoring technique is to \u003cstrong\u003emodify the program at a tiny pace\u003c/strong\u003e. If you make a mistake, it\u0026rsquo;s easy to spot it.\u003c/p\u003e","title":"Refactor"},{"content":"1. General Intro to IELTS Speaking Test Introductory Frame Full Name English Name Country\nThe Process Part1 4-5 min, 3 topics, 9 questions Questions about yourself Topics to do with daily life Is there anything you don\u0026rsquo;t like about your living area? What do you study? Which do you prefer, Saturday or Sunday? Examiner can ONLY:\nrepeat question ask you to elaborate Examiner CANNOT:\nexplain create new questions Part2 3-4 min, 1 min for notes, 1-2 min to talk Can look at topic card and notes while speaking\nDescribe a person who often helps others You should say:\nwho this person is what this person is how this person often helps others and explain how you feel about this person. ONLY in PART2 can you\nsee the questions prepare You CAN\u0026rsquo;T ask for new topic\nè¯é¢˜å¡å’Œç¨¿çº¸è¢«æ‹¿èµ°äº†å¯ä»¥è¦æ±‚ç•™ä¸‹\nPart3 4-5 min, room for discussion and debate Topic is linked to Part2; your answer need not be Performance in Part3 is the deal breaker\nWhat are some reasons why people help others? Is it necessary to help those in need? Who should teach children to help others? How can the government help people in your country? What are some NGOs in your country that help people? You CAN:\nask for explanations\nredirect the question\nask for new question\nä¸æ¸…æ¥šé—®é¢˜ä¸€å®šè¦é—®\nå®åœ¨ä¸ç†Ÿæ‚‰çš„é—®é¢˜å¯ä»¥çµæ´»è°ƒæ•´ï¼Œè¯·æ±‚æ›´æ¢é¢˜ç›®\nGrading Criteria Fluency and Coherence Pronunciation Lexical Resources Grammatical Range and Accuracy è‡ªç„¶ä¸ºä¸»ï¼Œæ¸…æ™°åˆé€‚\nFluency and Coherence Dos\nSpeak at length Use connectives and discourse markers flexibly Develop topic well Dont\u0026rsquo;s\nRepeat and self-correct frequently Have a lot of language-related hesitation Over-use connectives and discourse markers Use connectives and discourse markers wrong Speaking at Length Q: Do you like eating fish? A: No, I don\u0026rsquo;t, cause it smells, and there are way too many bones.\ntoo short!!!\nAcceptable Length: Fluency and Coherence, Band 7 ==speaks at length== effortlessly and coherently uses a range of ==connectives and discourse markers== flexibly ==some== hesitation, repetiton, or self-correction Pronunciation must proounce vowels right can be slow yet also fluent intonation matters a lot practice word stress and sentence stress pause where needed (clear meaning) Pronunciation, Band 7 ==range of prounciation features== with mixed control ==effective use of features== ==easy to understand== Lexical Resources ä¸è¦ç”¨ å¤§è¯ éš¾è¯ åè¯\nLess common words Idiomatic Vocabulary Paraphrase Topic-related vocabulary Style and Collocation Precise Meaning Lexical Resources, Band 7 Grammatical Range and Accuracy Complex Structure Which do you prefer, tea or coffee?\nQuick Recap 2. Part1 Intro, Brainstorming, Ideas Part1 Question Styles Question Types Yes/No Wh- Choice Hypothetical 4 Main Topics People Places Objects Events 3 Mandatory Frames Where you live now? Hometown Work/Study Basic Answer Structure The TS + SD Principle Why use this? Topic sentence Suporting Details Brainstorming How to add details Templates for reference Templates in use Reservoir of ideas Reservoir How to use the reservoir Linking Words Basic grammar must be correct Linking Words must be correct Although/But å–å…¶ä¸€ besides =\u0026gt; except for In fact =\u0026gt; Actually\nPart2 Intro and Reminders Part2 Question Styles Format Instructions Procedure Basic Requirements Reminders Part2 Preparing Answers Understanding the Topic Card first second key words modifiers tense focus of topic A great example Brainstorming Method 1 Method1 æ›´ç»†çš„åˆ’åˆ† ä¾‹å­ Brainstorming Method 2 5Ws 1H Using 5Ws 1H Steps for brainstorming Useful Frameworks Taking notes Giving Answers Introducing Topic Introducing New Points Recycling Material Staying On Topic Filling up Time Part3 Intro and Reminders Part3 Question Types Discourse Reminders Part3 Preparing and Giving Answers Reservoir of ideas Important Tools keep asking yourself why ä¾‹å­ use high-level words ç»†èŠ‚ æ€»ç»“æ¦‚æ‹¬ å‡å\nStarting Sentence Template1 listing question Temlate2 explaining comparing suggesting agree/disagreeing predicting question Discourse ","permalink":"https://bleedkagax.github.io/post/speaking-skills/","summary":"\u003ch1 id=\"1-general-intro-to-ielts-speaking-test\"\u003e1. General Intro to IELTS Speaking Test\u003c/h1\u003e\n\u003ch2 id=\"introductory-frame\"\u003eIntroductory Frame\u003c/h2\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/speaking-skills.png\" alt=\"img/speaking-skills.png\"  /\u003e\n\nFull Name\nEnglish Name\nCountry\u003c/p\u003e\n\u003ch2 id=\"the-process\"\u003eThe Process\u003c/h2\u003e\n\u003ch3 id=\"part1-4-5-min-3-topics-9-questions\"\u003ePart1 4-5 min, 3 topics, 9 questions\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eQuestions about yourself\u003c/li\u003e\n\u003cli\u003eTopics to do with daily life\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003eIs there anything you don\u0026rsquo;t like about your living area?\u003c/li\u003e\n\u003cli\u003eWhat do you study?\u003c/li\u003e\n\u003cli\u003eWhich do you prefer, Saturday or Sunday?\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eExaminer can ONLY:\u003c/p\u003e","title":"speaking skills"},{"content":"What is Redis pipelining? Pipelining is a technique used to send multiple commands to the server without waiting for the replies, and then reading the replies in a single step.\nExplain Redis transactions. Redis transactions allow the execution of a group of commands in a single step. Key properties:\nAll commands in a transaction are serialized and executed sequentially Either all or none of the commands are processed Redis transactions are atomic How does Redis implement master-slave replication? Redis uses asynchronous replication, where a master can have multiple slaves. The replication is non-blocking on the master side, so the master can continue serving queries while slaves are synchronizing. Slaves can also be configured to accept connections from other slaves, creating a graph-like structure.\nWhat is Redis Sentinel? Redis Sentinel is a system designed to help manage Redis instances. It provides:\nMonitoring: Sentinel constantly checks if master and slave instances are working as expected Notification: Sentinel can notify the system administrator via an API, about the events happening in the Redis ecosystem Automatic failover: If a master is not working as expected, Sentinel can start a failover process where a slave is promoted to master Explain the concept of Redis Cluster. Redis Cluster is a distributed implementation of Redis with the following goals:\nHigh performance and linear scalability up to 1000 nodes No-single-point-of-failure Automatic split of dataset among multiple nodes Automatic rebalancing and migration of data when nodes are added or removed What is the purpose of Redis pub/sub? Redis Pub/Sub (Publish/Subscribe) is a messaging paradigm where senders (publishers) send messages to channels, without knowledge of what subscribers (if any) there may be. Subscribers express interest in one or more channels and only receive messages that are of interest, without knowledge of what publishers (if any) there are.\nCore Principles In-memory data storage: Redis keeps all data in RAM for fast access and manipulation. Single-threaded architecture: Ensures atomic operations without the need for complex locking mechanisms. Asynchronous operations: Allows for non-blocking I/O operations. Persistence options: Provides durability through snapshots and append-only files. Replication: Supports master-slave replication for high availability and data redundancy. Data Structures Strings: Binary-safe strings up to 512MB in size. Lists: Collections of string elements sorted by insertion order. Sets: Unordered collections of unique strings. Sorted Sets: Sets ordered by a score, allowing for range queries. Hashes: Maps between string fields and string values. Bitmaps: String data type with bit-level operations. HyperLogLogs: Probabilistic data structure for cardinality estimation. Geospatial indexes: Store and query geospatial data. Streams: Append-only log-like data structures. Single-Threaded Model Redis employs a single-threaded event loop model, which offers several advantages:\nSimplicity: No need for complex locking mechanisms. Atomic operations: Commands are executed sequentially without interruption. Predictable performance: Easier to reason about and optimize. Efficient memory usage: Avoids overhead of thread management. However, this model also has limitations:\nCPU-bound operations can block the entire server. Cannot fully utilize multi-core processors without running multiple Redis instances. Persistence RDB (Redis Database):\nPoint-in-time snapshots of the dataset. Compact single-file format. Perfect for backups and disaster recovery. Allows faster restarts with big datasets compared to AOF. AOF (Append-Only File):\nLogs every write operation received by the server. Higher durability (can be configured to fsync every second or on every query). Automatically rewrites in the background when the file gets too big. More durable than RDB in case of server crashes. Replication Redis supports master-slave replication, which allows slave Redis servers to be exact copies of master servers. Key features include:\nAsynchronous replication: Slaves acknowledge the amount of data processed from the master. Multiple slaves can be configured for a single master. Slaves can accept connections from other slaves, creating a cascading-like structure. Replication is non-blocking on the master side. Memory Optimization Use appropriate data structures:\nHashes for objects with few fields. Sorted sets for leaderboards or priority queues. Bitmaps for boolean data or counters for limited set of states. Implement key expiration policies:\nUse TTL (Time To Live) for volatile data. Implement LRU (Least Recently Used) eviction for caches. Enable compression for large objects:\nUse the compression configuration option for values above a certain size. Use Redis object sharing:\nEnable maxmemory-policy allkeys-lru to automatically evict least recently used keys. Monitor memory usage:\nUse the INFO memory command to get detailed memory usage statistics. Implement external monitoring tools to track memory usage over time. Optimize string usage:\nUse integer encoding for string values when possible. Avoid storing large strings; consider splitting them into smaller chunks. Use Redis Modules for specialized data structures:\nRedisBloom for probabilistic data structures. RedisTimeSeries for time series data. Performance Optimization Use pipelining for bulk operations:\nSend multiple commands in a single request to reduce network round trips. Implement connection pooling:\nReuse connections to avoid the overhead of creating new ones. Utilize Redis benchmarking tools:\nUse redis-benchmark to test performance under various scenarios. Implement custom benchmarks for specific use cases. Optimize network settings:\nIncrease the tcp-backlog value for high-concurrency scenarios. Tune kernel parameters like net.core.somaxconn and net.ipv4.tcp_max_syn_backlog. Use proper sharding techniques:\nImplement client-side sharding or use Redis Cluster for distributing data across multiple nodes. Optimize command usage:\nUse SCAN instead of KEYS for iterating over large key spaces. Use HMGET instead of multiple GET operations for retrieving multiple hash fields. Implement read-through and write-through caching:\nUse Redis as a cache in front of a slower data store. Utilize Redis Modules for specialized operations:\nRediSearch for full-text search capabilities. RedisGraph for graph-based queries. Persistence Optimization Tune RDB and AOF settings:\nAdjust the frequency of RDB snapshots based on your durability requirements. Configure AOF fsync policy (always, everysec, or no) based on performance needs. Use background saving for RDB snapshots:\nEnable rdb-save-incremental-fsync for smoother I/O operations during saves. Implement AOF rewrite thresholds:\nAdjust auto-aof-rewrite-percentage and auto-aof-rewrite-min-size for optimal AOF rewrites. Consider using both RDB and AOF:\nCombine the fast restarts of RDB with the durability of AOF. Use diskless replication:\nEnable repl-diskless-sync to send RDB files to slaves without using the disk. Optimize storage hardware:\nUse SSDs for better I/O performance. Consider using battery-backed RAID controllers for improved write performance. Replication Optimization Use asynchronous replication:\nConfigure an appropriate repl-backlog-size to handle temporary disconnections. Implement read-only replicas:\nDistribute read operations across multiple replicas to reduce load on the master. Configure appropriate timeout settings:\nAdjust repl-timeout and repl-ping-replica-period based on network conditions. Monitor replication lag:\nUse the INFO replication command to track replication offset and lag. Implement replica priority:\nSet replica-priority to control failover behavior in Redis Sentinel. Use PSYNC for efficient replication:\nEnsure partial resynchronization is possible after short disconnections. Implement a good topology:\nUse cascading replication for large numbers of replicas. Distributed Locks Acquire lock:\nSET resource_name my_random_value NX PX 30000 This sets the key if it doesn\u0026rsquo;t exist (NX) with an expiry of 30000 milliseconds (PX).\nPerform critical section operations.\nRelease lock using a Lua script:\nif redis.call(\u0026#34;get\u0026#34;,KEYS[1]) == ARGV[1] then return redis.call(\u0026#34;del\u0026#34;,KEYS[1]) else return 0 end Pipelining Pipelining is a technique to send multiple commands to the server without waiting for individual replies, then reading all replies in a single step.\nBenefits:\nReduced network round trips. Increased throughput, especially for high-latency connections. Example using Python:\nimport redis r = redis.Redis(host=\u0026#39;localhost\u0026#39;, port=6379, db=0) pipe = r.pipeline() for i in range(10000): pipe.set(f\u0026#39;key:{i}\u0026#39;, f\u0026#39;value:{i}\u0026#39;) pipe.expire(f\u0026#39;key:{i}\u0026#39;, 3600) pipe.execute() Best practices:\nGroup related commands in a single pipeline. Balance pipeline size with memory usage and network packet size. Use pipelining in combination with transactions for atomic operations. Transactions All commands in a transaction are serialized and executed sequentially. Either all commands or none are processed, ensuring atomicity. No rollback mechanism; if a command fails, others are still executed. WATCH command:\nProvides check-and-set (CAS) behavior. Allows for optimistic locking scenarios. Example with WATCH:\nWATCH account:1:balance VAL = GET account:1:balance MULTI SET account:1:balance \u0026lt;new-value\u0026gt; EXEC Pub/Sub Messaging Key commands:\nSUBSCRIBE: Listen for messages on one or more channels. PUBLISH: Send a message to a channel. PSUBSCRIBE: Subscribe to channels matching a pattern. Example:\nSUBSCRIBE news:sports PUBLISH news:sports \u0026#34;Lakers win the championship!\u0026#34; Use cases:\nReal-time notifications Chat systems Distributed system event propagation Limitations:\nAt-most-once delivery semantics No persistence of messages Lua Scripting Redis allows executing Lua scripts for complex operations, offering several advantages:\nReduced network overhead for complex operations. Atomic execution of multiple commands. Ability to create new \u0026ldquo;commands\u0026rdquo; as Lua scripts. Example:\nredis.call(\u0026#39;SET\u0026#39;, KEYS[1], ARGV[1]) redis.call(\u0026#39;EXPIRE\u0026#39;, KEYS[1], ARGV[2]) return redis.call(\u0026#39;GET\u0026#39;, KEYS[1]) Execute with:\nEVAL \u0026#34;redis.call(\u0026#39;SET\u0026#39;, KEYS[1], ARGV[1]); redis.call(\u0026#39;EXPIRE\u0026#39;, KEYS[1], ARGV[2]); return redis.call(\u0026#39;GET\u0026#39;, KEYS[1])\u0026#34; 1 mykey \u0026#34;Hello\u0026#34; 10 Best practices:\nUse EVALSHA for better performance with frequently used scripts. Implement script load command to preload scripts. Be cautious with long-running scripts as they can block the Redis server. Redis Modules Redis modules extend Redis functionality with custom commands and data types. Popular modules include:\nRediSearch: Full-text search engine\nSupports complex queries and aggregations Provides real-time indexing RedisJSON: Native JSON support\nAllows storing, updating, and retrieving JSON values Supports JSONPath-like syntax for querying RedisTimeSeries: Time series database\nEfficient storage and retrieval of time series data Supports downsampling and aggregation RedisAI: Machine learning model serving\nSupports TensorFlow, PyTorch, and ONNX models Enables real-time inferencing RedisGraph: Graph database module\nImplements property graph model Supports Cypher query language Redis Cluster Redis Cluster provides a way to run a Redis installation where data is automatically sharded across multiple Redis nodes.\nKey features:\nAutomatic partitioning: Uses hash slots for distributing keys. High availability: Supports master-slave replication with automatic failover. Linear scalability: Add or remove nodes without downtime. Cluster topology:\nMinimum of 3 master nodes recommended. Each master can have multiple replicas. Client-side sharding:\nClients must be cluster-aware to route requests to the correct node. Libraries like redis-py-cluster handle this transparently. Redis Sentinel Redis Sentinel provides high availability for Redis through automatic failover and monitoring.\nKey features:\nMonitoring: Constantly checks if master and slave instances are working as expected. Notification: Can notify system administrators or other programs about events. Automatic failover: Promotes a slave to master when the master fails. Configuration provider: Clients connect to Sentinels to ask for the address of the current master. Sentinel topology:\nRecommended to run at least 3 Sentinel instances for robust deployments. Sentinel instances should be placed on separate machines or virtual machines. Redis Streams Redis Streams is a log-like data structure that allows for efficient message queuing and real-time data processing.\nKey operations:\nXADD: Add new entries to a stream. XREAD: Read data from streams. XRANGE: Retrieve a range of entries from a stream. XGROUP: Manage consumer groups for parallel processing. Use cases:\nEvent sourcing Activity feeds Real-time analytics Example:\nXADD mystream * sensor-id 1234 temperature 19.8 XREAD COUNT 2 STREAMS mystream 0-0 Geospatial Indexing Redis supports geospatial operations for location-based services.\nKey commands:\nGEOADD: Add geospatial items to a sorted set. GEORADIUS: Query items within a given radius. GEODIST: Calculate distance between points. Example:\nGEOADD cities 13.361389 38.115556 \u0026#34;Palermo\u0026#34; 15.087269 37.502669 \u0026#34;Catania\u0026#34; GEORADIUS cities 15 37 100 km Use cases:\nNearby point-of-interest search Geofencing applications Location-based analytics Redis Monitoring and Debugging Use Redis INFO command for real-time statistics:\nMonitor memory usage, client connections, and command statistics. Implement monitoring tools:\nUse Redis Exporter for Prometheus integration. Set up Grafana dashboards for visualization. Utilize Redis Slowlog:\nIdentify and optimize slow commands. Adjust slowlog-log-slower-than and slowlog-max-len configurations. Use Redis MONITOR command for real-time command monitoring:\nUseful for debugging, but use cautiously in production due to performance impact. Implement proper logging and alerting mechanisms:\nSet up alerts for critical metrics (e.g., memory usage, replication lag). Use log aggregation tools for centralized logging. Use Redis MEMORY DOCTOR for memory analysis:\nIdentify memory-related issues and optimization opportunities. Implement distributed tracing:\nUse tools like Jaeger or Zipkin for tracing Redis operations in microservices architectures. Utilize Redis Latency Monitoring:\nUse the LATENCY command to identify sources of latency. Implement Redis Sentinel monitoring:\nMonitor master-slave relationships and failover events. Use Redis Cluster monitoring tools:\nMonitor cluster state, resharding operations, and node health. Implement application-level monitoring: Track cache hit rates, key distribution, and access patterns. Use Redis profiling tools: Leverage tools like redis-cli \u0026ndash;latency or redis-cli \u0026ndash;stat for performance insights. ","permalink":"https://bleedkagax.github.io/post/0_redis_interview/","summary":"\u003ch2 id=\"what-is-redis-pipelining\"\u003eWhat is Redis pipelining?\u003c/h2\u003e\n\u003cp\u003ePipelining is a technique used to send multiple commands to the server without waiting for the replies, and then reading the replies in a single step.\u003c/p\u003e\n\u003ch2 id=\"explain-redis-transactions\"\u003eExplain Redis transactions.\u003c/h2\u003e\n\u003cp\u003eRedis transactions allow the execution of a group of commands in a single step. Key properties:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAll commands in a transaction are serialized and executed sequentially\u003c/li\u003e\n\u003cli\u003eEither all or none of the commands are processed\u003c/li\u003e\n\u003cli\u003eRedis transactions are atomic\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"how-does-redis-implement-master-slave-replication\"\u003eHow does Redis implement master-slave replication?\u003c/h2\u003e\n\u003cp\u003eRedis uses asynchronous replication, where a master can have multiple slaves. The replication is non-blocking on the master side, so the master can continue serving queries while slaves are synchronizing. Slaves can also be configured to accept connections from other slaves, creating a graph-like structure.\u003c/p\u003e","title":"Redis Interview"}]